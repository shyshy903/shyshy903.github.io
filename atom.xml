<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Open-Box</title>
  
  <subtitle>just do it</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://shyshy903.github.io/"/>
  <updated>2020-02-14T09:16:06.595Z</updated>
  <id>https://shyshy903.github.io/</id>
  
  <author>
    <name>Haiyang Song</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Deep_learning/文本预处理与语言模型</title>
    <link href="https://shyshy903.github.io/2020/02/14/Deep_learning/%E6%96%87%E6%9C%AC%E9%A2%84%E5%A4%84%E7%90%86%E4%B8%8E%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/"/>
    <id>https://shyshy903.github.io/2020/02/14/Deep_learning/%E6%96%87%E6%9C%AC%E9%A2%84%E5%A4%84%E7%90%86%E4%B8%8E%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/</id>
    <published>2020-02-14T09:16:06.595Z</published>
    <updated>2020-02-14T09:16:06.595Z</updated>
    
    <content type="html"><![CDATA[<h1 id="文本预处理"><a href="#文本预处理" class="headerlink" title="文本预处理"></a>文本预处理</h1><ol><li>读入文本</li><li>分词</li><li>建立字典，将每个词映射到一个唯一的索引（index）</li><li>将文本从词的序列转换为索引的序列，方便输入模型</li></ol><h2 id="读入文本"><a href="#读入文本" class="headerlink" title="读入文本"></a>读入文本</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> collections</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_time_machine</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">with</span> open(<span class="string">'/home/kesci/input/timemachine7163/timemachine.txt'</span>, <span class="string">'r'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        lines = [re.sub(<span class="string">'[^a-z]+'</span>, <span class="string">' '</span>, line.strip().lower()) <span class="keyword">for</span> line <span class="keyword">in</span> f]</span><br><span class="line">    <span class="keyword">return</span> lines</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">lines = read_time_machine()</span><br><span class="line">print(<span class="string">'# sentences %d'</span> % len(lines))</span><br></pre></td></tr></table></figure><h2 id="分词"><a href="#分词" class="headerlink" title="分词"></a>分词</h2><p>将一个句子划分为若干个<code>token</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tokenize</span><span class="params">(sentences, token=<span class="string">'word'</span>)</span>:</span></span><br><span class="line">    <span class="string">"""Split sentences into word or char tokens"""</span></span><br><span class="line">    <span class="keyword">if</span> token == <span class="string">'word'</span>:</span><br><span class="line">        <span class="keyword">return</span> [sentence.split(<span class="string">' '</span>) <span class="keyword">for</span> sentence <span class="keyword">in</span> sentences]</span><br><span class="line">    <span class="keyword">elif</span> token == <span class="string">'char'</span>:</span><br><span class="line">        <span class="keyword">return</span> [list(sentence) <span class="keyword">for</span> sentence <span class="keyword">in</span> sentences]</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        print(<span class="string">'ERROR: unkown token type '</span>+token)</span><br><span class="line"></span><br><span class="line">tokens = tokenize(lines)</span><br><span class="line">tokens[<span class="number">0</span>:<span class="number">2</span>]</span><br></pre></td></tr></table></figure><h2 id="建立字典"><a href="#建立字典" class="headerlink" title="建立字典"></a>建立字典</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Vocab</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, tokens, min_freq=<span class="number">0</span>, use_special_tokens=False)</span>:</span></span><br><span class="line">        counter = count_corpus(tokens)  <span class="comment"># : </span></span><br><span class="line">        self.token_freqs = list(counter.items())</span><br><span class="line">        self.idx_to_token = []</span><br><span class="line">        <span class="keyword">if</span> use_special_tokens:</span><br><span class="line">            <span class="comment"># padding, begin of sentence, end of sentence, unknown</span></span><br><span class="line">            self.pad, self.bos, self.eos, self.unk = (<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line">            self.idx_to_token += [<span class="string">''</span>, <span class="string">''</span>, <span class="string">''</span>, <span class="string">''</span>]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.unk = <span class="number">0</span></span><br><span class="line">            self.idx_to_token += [<span class="string">''</span>]</span><br><span class="line">        self.idx_to_token += [token <span class="keyword">for</span> token, freq <span class="keyword">in</span> self.token_freqs</span><br><span class="line">                        <span class="keyword">if</span> freq &gt;= min_freq <span class="keyword">and</span> token <span class="keyword">not</span> <span class="keyword">in</span> self.idx_to_token]</span><br><span class="line">        self.token_to_idx = dict()</span><br><span class="line">        <span class="keyword">for</span> idx, token <span class="keyword">in</span> enumerate(self.idx_to_token):</span><br><span class="line">            self.token_to_idx[token] = idx</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> len(self.idx_to_token)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span><span class="params">(self, tokens)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> isinstance(tokens, (list, tuple)):</span><br><span class="line">            <span class="keyword">return</span> self.token_to_idx.get(tokens, self.unk)</span><br><span class="line">        <span class="keyword">return</span> [self.__getitem__(token) <span class="keyword">for</span> token <span class="keyword">in</span> tokens]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">to_tokens</span><span class="params">(self, indices)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> isinstance(indices, (list, tuple)):</span><br><span class="line">            <span class="keyword">return</span> self.idx_to_token[indices]</span><br><span class="line">        <span class="keyword">return</span> [self.idx_to_token[index] <span class="keyword">for</span> index <span class="keyword">in</span> indices]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">count_corpus</span><span class="params">(sentences)</span>:</span></span><br><span class="line">    tokens = [tk <span class="keyword">for</span> st <span class="keyword">in</span> sentences <span class="keyword">for</span> tk <span class="keyword">in</span> st]</span><br><span class="line">    <span class="keyword">return</span> collections.Counter(tokens)  <span class="comment"># 返回一个字典，记录每个词的出现次数</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 将词转化为索引</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">8</span>, <span class="number">10</span>):</span><br><span class="line">    print(<span class="string">'words:'</span>, tokens[i])</span><br><span class="line">    print(<span class="string">'indices:'</span>, vocab[tokens[i]])</span><br></pre></td></tr></table></figure><h2 id="用现有工具包分词"><a href="#用现有工具包分词" class="headerlink" title="用现有工具包分词"></a>用现有工具包分词</h2><h3 id="NLTK"><a href="#NLTK" class="headerlink" title="NLTK"></a>NLTK</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">text = <span class="string">"Mr. Chen doesn't agree with my suggestion."</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> nltk.tokenize <span class="keyword">import</span> word_tokenize</span><br><span class="line"><span class="keyword">from</span> nltk <span class="keyword">import</span> data</span><br><span class="line">data.path.append(<span class="string">'/home/kesci/input/nltk_data3784/nltk_data'</span>)</span><br><span class="line">print(word_tokenize(text))</span><br></pre></td></tr></table></figure><h3 id="SPACY"><a href="#SPACY" class="headerlink" title="SPACY"></a>SPACY</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> spacy</span><br><span class="line">nlp = spacy.load(<span class="string">'en_core_web_sm'</span>)</span><br><span class="line">doc = nlp(text)</span><br><span class="line">print([token.text <span class="keyword">for</span> token <span class="keyword">in</span> doc])</span><br></pre></td></tr></table></figure><h1 id="语言模型（基于统计的语言模型）"><a href="#语言模型（基于统计的语言模型）" class="headerlink" title="语言模型（基于统计的语言模型）"></a>语言模型（基于统计的语言模型）</h1><p><img src="https://img.vim-cn.com/74/bb98fdc35dd04377837535271dcebd321dfa19.png" alt=""></p><h1 id="n元语法"><a href="#n元语法" class="headerlink" title="n元语法"></a>n元语法</h1><p><img src="https://img.vim-cn.com/14/04dcd7cd184f97d2cbaed69a419d20bdd74c96.png" alt=""></p><h2 id="相邻采样"><a href="#相邻采样" class="headerlink" title="相邻采样"></a>相邻采样</h2><p>在相邻采样中，相邻的两个随机小批量在原始序列上的位置相毗邻</p><h2 id="随机采样"><a href="#随机采样" class="headerlink" title="随机采样"></a>随机采样</h2><p>下面的代码每次从数据里随机采样一个小批量。其中批量大小<code>batch_size</code>是每个小批量的样本数，<code>num_steps</code>是每个样本所包含的时间步数。 在随机采样中，每个样本是原始序列上任意截取的一段序列，相邻的两个随机小批量在原始序列上的位置不一定相毗邻。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;文本预处理&quot;&gt;&lt;a href=&quot;#文本预处理&quot; class=&quot;headerlink&quot; title=&quot;文本预处理&quot;&gt;&lt;/a&gt;文本预处理&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;读入文本&lt;/li&gt;
&lt;li&gt;分词&lt;/li&gt;
&lt;li&gt;建立字典，将每个词映射到一个唯一的索引（index）
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>循环神经网络</title>
    <link href="https://shyshy903.github.io/2020/02/14/Deep_learning/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    <id>https://shyshy903.github.io/2020/02/14/Deep_learning/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</id>
    <published>2020-02-13T16:00:00.000Z</published>
    <updated>2020-02-13T16:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="循环神经网络"><a href="#循环神经网络" class="headerlink" title="循环神经网络"></a>循环神经网络</h1><h2 id="简单循环神经网络的构造"><a href="#简单循环神经网络的构造" class="headerlink" title="简单循环神经网络的构造"></a>简单循环神经网络的构造</h2><p><img src="https://img.vim-cn.com/a8/d90fe522138ebfb79547e687f5fd82684648fa.png" alt=""></p><h2 id="裁剪梯度"><a href="#裁剪梯度" class="headerlink" title="裁剪梯度"></a>裁剪梯度</h2><p>循环神经网络中较容易出现梯度衰减或梯度爆炸，这会导致网络几乎无法训练。裁剪梯度（clip gradient）是一种应对梯度爆炸的方法。假设我们把所有模型参数的梯度拼接成一个向量  g ，并设裁剪的阈值是 θ 。裁剪后的梯度</p><h2 id="循环神经网络的pytorch实现"><a href="#循环神经网络的pytorch实现" class="headerlink" title="循环神经网络的pytorch实现"></a>循环神经网络的pytorch实现</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">sys.path.append(<span class="string">"/home/kesci/input"</span>)</span><br><span class="line"><span class="keyword">import</span> d2l_jay9460 <span class="keyword">as</span> d2l</span><br><span class="line">(corpus_indices, char_to_idx, idx_to_char, vocab_size) = d2l.load_data_jay_lyrics()</span><br><span class="line">device = torch.device(<span class="string">'cuda'</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">'cpu'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">rnn_layer = nn.RNN(input_size=vocab_size, hidden_size=num_hiddens)</span><br><span class="line">num_steps, batch_size = <span class="number">35</span>, <span class="number">2</span></span><br><span class="line">X = torch.rand(num_steps, batch_size, vocab_size)</span><br><span class="line">state = <span class="literal">None</span></span><br><span class="line">Y, state_new = rnn_layer(X, state)</span><br><span class="line">print(Y.shape, state_new.shape)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RNNModel</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, rnn_layer, vocab_size)</span>:</span></span><br><span class="line">        super(RNNModel, self).__init__()</span><br><span class="line">        self.rnn = rnn_layer</span><br><span class="line">        self.hidden_size = rnn_layer.hidden_size * (<span class="number">2</span> <span class="keyword">if</span> rnn_layer.bidirectional <span class="keyword">else</span> <span class="number">1</span>) </span><br><span class="line">        self.vocab_size = vocab_size</span><br><span class="line">        self.dense = nn.Linear(self.hidden_size, vocab_size)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, inputs, state)</span>:</span></span><br><span class="line">        <span class="comment"># inputs.shape: (batch_size, num_steps)</span></span><br><span class="line">        X = to_onehot(inputs, vocab_size)</span><br><span class="line">        X = torch.stack(X)  <span class="comment"># X.shape: (num_steps, batch_size, vocab_size)</span></span><br><span class="line">        hiddens, state = self.rnn(X, state)</span><br><span class="line">        hiddens = hiddens.view(<span class="number">-1</span>, hiddens.shape[<span class="number">-1</span>])  <span class="comment"># hiddens.shape: (num_steps * batch_size, hidden_size)</span></span><br><span class="line">        output = self.dense(hiddens)</span><br><span class="line">        <span class="keyword">return</span> output, state</span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict_rnn_pytorch</span><span class="params">(prefix, num_chars, model, vocab_size, device, idx_to_char,</span></span></span><br><span class="line"><span class="function"><span class="params">                      char_to_idx)</span>:</span></span><br><span class="line">    state = <span class="literal">None</span></span><br><span class="line">    output = [char_to_idx[prefix[<span class="number">0</span>]]]  <span class="comment"># output记录prefix加上预测的num_chars个字符</span></span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> range(num_chars + len(prefix) - <span class="number">1</span>):</span><br><span class="line">        X = torch.tensor([output[<span class="number">-1</span>]], device=device).view(<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        (Y, state) = model(X, state)  <span class="comment"># 前向计算不需要传入模型参数</span></span><br><span class="line">        <span class="keyword">if</span> t &lt; len(prefix) - <span class="number">1</span>:</span><br><span class="line">            output.append(char_to_idx[prefix[t + <span class="number">1</span>]])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            output.append(Y.argmax(dim=<span class="number">1</span>).item())</span><br><span class="line">    <span class="keyword">return</span> <span class="string">''</span>.join([idx_to_char[i] <span class="keyword">for</span> i <span class="keyword">in</span> output])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model = RNNModel(rnn_layer, vocab_size).to(device)</span><br><span class="line">predict_rnn_pytorch(<span class="string">'分开'</span>, <span class="number">10</span>, model, vocab_size, device, idx_to_char, char_to_idx)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_and_predict_rnn_pytorch</span><span class="params">(model, num_hiddens, vocab_size, device,</span></span></span><br><span class="line"><span class="function"><span class="params">                                corpus_indices, idx_to_char, char_to_idx,</span></span></span><br><span class="line"><span class="function"><span class="params">                                num_epochs, num_steps, lr, clipping_theta,</span></span></span><br><span class="line"><span class="function"><span class="params">                                batch_size, pred_period, pred_len, prefixes)</span>:</span></span><br><span class="line">    loss = nn.CrossEntropyLoss()</span><br><span class="line">    optimizer = torch.optim.Adam(model.parameters(), lr=lr)</span><br><span class="line">    model.to(device)</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(num_epochs):</span><br><span class="line">        l_sum, n, start = <span class="number">0.0</span>, <span class="number">0</span>, time.time()</span><br><span class="line">        data_iter = d2l.data_iter_consecutive(corpus_indices, batch_size, num_steps, device) <span class="comment"># 相邻采样</span></span><br><span class="line">        state = <span class="literal">None</span></span><br><span class="line">        <span class="keyword">for</span> X, Y <span class="keyword">in</span> data_iter:</span><br><span class="line">            <span class="keyword">if</span> state <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                <span class="comment"># 使用detach函数从计算图分离隐藏状态</span></span><br><span class="line">                <span class="keyword">if</span> isinstance (state, tuple): <span class="comment"># LSTM, state:(h, c)  </span></span><br><span class="line">                    state[<span class="number">0</span>].detach_()</span><br><span class="line">                    state[<span class="number">1</span>].detach_()</span><br><span class="line">                <span class="keyword">else</span>: </span><br><span class="line">                    state.detach_()</span><br><span class="line">            (output, state) = model(X, state) <span class="comment"># output.shape: (num_steps * batch_size, vocab_size)</span></span><br><span class="line">            y = torch.flatten(Y.T)</span><br><span class="line">            l = loss(output, y.long())</span><br><span class="line">            </span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            l.backward()</span><br><span class="line">            grad_clipping(model.parameters(), clipping_theta, device)</span><br><span class="line">            optimizer.step()</span><br><span class="line">            l_sum += l.item() * y.shape[<span class="number">0</span>]</span><br><span class="line">            n += y.shape[<span class="number">0</span>]</span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (epoch + <span class="number">1</span>) % pred_period == <span class="number">0</span>:</span><br><span class="line">            print(<span class="string">'epoch %d, perplexity %f, time %.2f sec'</span> % (</span><br><span class="line">                epoch + <span class="number">1</span>, math.exp(l_sum / n), time.time() - start))</span><br><span class="line">            <span class="keyword">for</span> prefix <span class="keyword">in</span> prefixes:</span><br><span class="line">                print(<span class="string">' -'</span>, predict_rnn_pytorch(</span><br><span class="line">                    prefix, pred_len, model, vocab_size, device, idx_to_char,</span><br><span class="line">                    char_to_idx))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">num_epochs, batch_size, lr, clipping_theta = <span class="number">250</span>, <span class="number">32</span>, <span class="number">1e-3</span>, <span class="number">1e-2</span></span><br><span class="line">pred_period, pred_len, prefixes = <span class="number">50</span>, <span class="number">50</span>, [<span class="string">'分开'</span>, <span class="string">'不分开'</span>]</span><br><span class="line">train_and_predict_rnn_pytorch(model, num_hiddens, vocab_size, device,</span><br><span class="line">                            corpus_indices, idx_to_char, char_to_idx,</span><br><span class="line">                            num_epochs, num_steps, lr, clipping_theta,</span><br><span class="line">                            batch_size, pred_period, pred_len, prefixes)</span><br></pre></td></tr></table></figure><p>RNN存在的问题：梯度较容易出现衰减或爆炸（BPTT）<br>⻔控循环神经⽹络：捕捉时间序列中时间步距离较⼤的依赖关系<br><img src="https://img.vim-cn.com/aa/5f1857a2a2320a5a6dd637d88c7018dffcbe43.png" alt="rnn1"></p><h3 id="GRU"><a href="#GRU" class="headerlink" title="GRU"></a>GRU</h3><p><img src="https://img.vim-cn.com/7d/cdb99137827b9038f1e5f34593f7169bbc3d87.png" alt="gru"></p><ul><li>重置⻔有助于捕捉时间序列⾥短期的依赖关系；</li><li>更新⻔有助于捕捉时间序列⾥⻓期的依赖关系</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">num_hiddens=<span class="number">256</span></span><br><span class="line">num_epochs, num_steps, batch_size, lr, clipping_theta = <span class="number">160</span>, <span class="number">35</span>, <span class="number">32</span>, <span class="number">1e2</span>, <span class="number">1e-2</span></span><br><span class="line">pred_period, pred_len, prefixes = <span class="number">40</span>, <span class="number">50</span>, [<span class="string">'分开'</span>, <span class="string">'不分开'</span>]</span><br><span class="line"></span><br><span class="line">lr = <span class="number">1e-2</span> <span class="comment"># 注意调整学习率</span></span><br><span class="line">gru_layer = nn.GRU(input_size=vocab_size, hidden_size=num_hiddens)</span><br><span class="line">model = d2l.RNNModel(gru_layer, vocab_size).to(device)</span><br><span class="line">d2l.train_and_predict_rnn_pytorch(model, num_hiddens, vocab_size, device,</span><br><span class="line">                                corpus_indices, idx_to_char, char_to_idx,</span><br><span class="line">                                num_epochs, num_steps, lr, clipping_theta,</span><br><span class="line">                                batch_size, pred_period, pred_len, prefixes)</span><br></pre></td></tr></table></figure><h3 id="LSTM"><a href="#LSTM" class="headerlink" title="LSTM"></a>LSTM</h3><ul><li>长短期记忆long short-term memory :</li><li>遗忘门:控制上一时间步的记忆细胞 输入门:控制当前时间步的输入</li><li>输出门:控制从记忆细胞到隐藏状态</li><li>记忆细胞：⼀种特殊的隐藏状态的信息的流动<br><img src="https://img.vim-cn.com/de/2d40e304a6f05b02fc8747d5e2a6f947fc064a.png" alt="lstm"></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">num_hiddens=<span class="number">256</span></span><br><span class="line">num_epochs, num_steps, batch_size, lr, clipping_theta = <span class="number">160</span>, <span class="number">35</span>, <span class="number">32</span>, <span class="number">1e2</span>, <span class="number">1e-2</span></span><br><span class="line">pred_period, pred_len, prefixes = <span class="number">40</span>, <span class="number">50</span>, [<span class="string">'分开'</span>, <span class="string">'不分开'</span>]</span><br><span class="line"></span><br><span class="line">lr = <span class="number">1e-2</span> <span class="comment"># 注意调整学习率</span></span><br><span class="line">lstm_layer = nn.LSTM(input_size=vocab_size, hidden_size=num_hiddens)</span><br><span class="line">model = d2l.RNNModel(lstm_layer, vocab_size)</span><br><span class="line">d2l.train_and_predict_rnn_pytorch(model, num_hiddens, vocab_size, device,</span><br><span class="line">                                corpus_indices, idx_to_char, char_to_idx,</span><br><span class="line">                                num_epochs, num_steps, lr, clipping_theta,</span><br><span class="line">                                batch_size, pred_period, pred_len, prefixes)</span><br></pre></td></tr></table></figure><h3 id="深度循环网络"><a href="#深度循环网络" class="headerlink" title="深度循环网络"></a>深度循环网络</h3><p>通过<code>num_layers</code>来进行控制</p><p><img src="https://img.vim-cn.com/d3/51bc59f0ae24e767576ee017fa06a031892f2b.png" alt=""></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">num_hiddens=<span class="number">256</span></span><br><span class="line">num_epochs, num_steps, batch_size, lr, clipping_theta = <span class="number">160</span>, <span class="number">35</span>, <span class="number">32</span>, <span class="number">1e2</span>, <span class="number">1e-2</span></span><br><span class="line">pred_period, pred_len, prefixes = <span class="number">40</span>, <span class="number">50</span>, [<span class="string">'分开'</span>, <span class="string">'不分开'</span>]</span><br><span class="line"></span><br><span class="line">lr = <span class="number">1e-2</span> <span class="comment"># 注意调整学习率</span></span><br><span class="line"></span><br><span class="line">gru_layer = nn.LSTM(input_size=vocab_size, hidden_size=num_hiddens,num_layers=<span class="number">2</span>)</span><br><span class="line">model = d2l.RNNModel(gru_layer, vocab_size).to(device)</span><br><span class="line">d2l.train_and_predict_rnn_pytorch(model, num_hiddens, vocab_size, device,</span><br><span class="line">                                corpus_indices, idx_to_char, char_to_idx,</span><br><span class="line">                                num_epochs, num_steps, lr, clipping_theta,</span><br><span class="line">                                batch_size, pred_period, pred_len, prefixes)</span><br></pre></td></tr></table></figure><h3 id="双向循环网络"><a href="#双向循环网络" class="headerlink" title="双向循环网络"></a>双向循环网络</h3><p><img src="https://img.vim-cn.com/4f/b21d208beaf51f1d33ef0455772236dc512ac0.png" alt=""></p><p>通过参数<code>bidirectional=True</code>来进行控制</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">num_hiddens=<span class="number">128</span></span><br><span class="line">num_epochs, num_steps, batch_size, lr, clipping_theta = <span class="number">160</span>, <span class="number">35</span>, <span class="number">32</span>, <span class="number">1e-2</span>, <span class="number">1e-2</span></span><br><span class="line">pred_period, pred_len, prefixes = <span class="number">40</span>, <span class="number">50</span>, [<span class="string">'分开'</span>, <span class="string">'不分开'</span>]</span><br><span class="line"></span><br><span class="line">lr = <span class="number">1e-2</span> <span class="comment"># 注意调整学习率</span></span><br><span class="line"></span><br><span class="line">gru_layer = nn.GRU(input_size=vocab_size, hidden_size=num_hiddens,bidirectional=<span class="literal">True</span>)</span><br><span class="line">model = d2l.RNNModel(gru_layer, vocab_size).to(device)</span><br><span class="line">d2l.train_and_predict_rnn_pytorch(model, num_hiddens, vocab_size, device,</span><br><span class="line">                                corpus_indices, idx_to_char, char_to_idx,</span><br><span class="line">                                num_epochs, num_steps, lr, clipping_theta,</span><br><span class="line">                                batch_size, pred_period, pred_len, prefixes)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;循环神经网络&quot;&gt;&lt;a href=&quot;#循环神经网络&quot; class=&quot;headerlink&quot; title=&quot;循环神经网络&quot;&gt;&lt;/a&gt;循环神经网络&lt;/h1&gt;&lt;h2 id=&quot;简单循环神经网络的构造&quot;&gt;&lt;a href=&quot;#简单循环神经网络的构造&quot; class=&quot;header
      
    
    </summary>
    
    
      <category term="deep_learning" scheme="https://shyshy903.github.io/categories/deep-learning/"/>
    
    
      <category term="DL" scheme="https://shyshy903.github.io/tags/DL/"/>
    
  </entry>
  
  <entry>
    <title>多层感知机</title>
    <link href="https://shyshy903.github.io/2020/02/13/Deep_learning/%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/"/>
    <id>https://shyshy903.github.io/2020/02/13/Deep_learning/%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/</id>
    <published>2020-02-12T16:00:00.000Z</published>
    <updated>2020-02-12T16:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="多层感知机"><a href="#多层感知机" class="headerlink" title="多层感知机"></a>多层感知机</h1><p>我们已经介绍了包括线性回归和softmax回归在内的单层神经网络。然而深度学习主要关注多层模型。在本节中，我们将以多层感知机（multilayer perceptron，MLP）为例，介绍多层神经网络的概念。</p><h2 id="隐藏层"><a href="#隐藏层" class="headerlink" title="隐藏层"></a>隐藏层</h2><p>多层感知机在单层神经网络的基础上引入了一到多个隐藏层（hidden layer）。隐藏层位于输入层和输出层之间。图3.3展示了一个多层感知机的神经网络图。</p><p><img src="https://img.vim-cn.com/2e/80d067a824cf71512d77c655855fe8c3488cc3.png" alt="带有隐藏层的多层感知机。它含有一个隐藏层，该层中有5个隐藏单元"></p><p>在图3.3所示的多层感知机中，输入和输出个数分别为4和3，中间的隐藏层中包含了5个隐藏单元（hidden unit）。由于输入层不涉及计算，图3.3中的多层感知机的层数为2。由图3.3可见，隐藏层中的神经元和输入层中各个输入完全连接，输出层中的神经元和隐藏层中的各个神经元也完全连接。因此，多层感知机中的隐藏层和输出层都是全连接层。</p><p>具体来说，给定一个小批量样本$\boldsymbol{X} \in \mathbb{R}^{n \times d}$，其批量大小为$n$，输入个数为$d$。假设多层感知机只有一个隐藏层，其中隐藏单元个数为$h$。记隐藏层的输出（也称为隐藏层变量或隐藏变量）为$\boldsymbol{H}$，有$\boldsymbol{H} \in \mathbb{R}^{n \times h}$。因为隐藏层和输出层均是全连接层，可以设隐藏层的权重参数和偏差参数分别为$\boldsymbol{W}_h \in \mathbb{R}^{d \times h}$和 $\boldsymbol{b}_h \in \mathbb{R}^{1 \times h}$，输出层的权重和偏差参数分别为$\boldsymbol{W}_o \in \mathbb{R}^{h \times q}$和$\boldsymbol{b}_o \in \mathbb{R}^{1 \times q}$。</p><p>我们先来看一种含单隐藏层的多层感知机的设计。其输出$\boldsymbol{O} \in \mathbb{R}^{n \times q}$的计算为</p><p>$$<br>\begin{aligned}<br>\boldsymbol{H} &amp;= \boldsymbol{X} \boldsymbol{W}_h + \boldsymbol{b}_h,\<br>\boldsymbol{O} &amp;= \boldsymbol{H} \boldsymbol{W}_o + \boldsymbol{b}_o,<br>\end{aligned}<br>$$</p><p>也就是将隐藏层的输出直接作为输出层的输入。如果将以上两个式子联立起来，可以得到</p><p>$$<br>\boldsymbol{O} = (\boldsymbol{X} \boldsymbol{W}_h + \boldsymbol{b}_h)\boldsymbol{W}_o + \boldsymbol{b}_o = \boldsymbol{X} \boldsymbol{W}_h\boldsymbol{W}_o + \boldsymbol{b}_h \boldsymbol{W}_o + \boldsymbol{b}_o.<br>$$</p><p>从联立后的式子可以看出，虽然神经网络引入了隐藏层，却依然等价于一个单层神经网络：其中输出层权重参数为$\boldsymbol{W}_h\boldsymbol{W}_o$，偏差参数为$\boldsymbol{b}_h \boldsymbol{W}_o + \boldsymbol{b}_o$。不难发现，即便再添加更多的隐藏层，以上设计依然只能与仅含输出层的单层神经网络等价。</p><h2 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h2><p>上述问题的根源在于全连接层只是对数据做仿射变换（affine transformation），而多个仿射变换的叠加仍然是一个仿射变换。解决问题的一个方法是引入非线性变换，例如对隐藏变量使用按元素运算的非线性函数进行变换，然后再作为下一个全连接层的输入。这个非线性函数被称为激活函数（activation function）。下面我们介绍几个常用的激活函数。</p><h3 id="ReLU函数"><a href="#ReLU函数" class="headerlink" title="ReLU函数"></a>ReLU函数</h3><p>ReLU（rectified linear unit）函数提供了一个很简单的非线性变换。给定元素$x$，该函数定义为</p><p>$$\text{ReLU}(x) = \max(x, 0).$$</p><p>可以看出，ReLU函数只保留正数元素，并将负数元素清零。为了直观地观察这一非线性变换，我们先定义一个绘图函数<code>xyplot</code>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">sys.path.insert(<span class="number">0</span>, <span class="string">'..'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">xyplot</span><span class="params">(x_vals,y_vals,name)</span>:</span></span><br><span class="line">    x_vals=x_vals.detach().numpy() <span class="comment"># we can't directly use var.numpy() because varibles might </span></span><br><span class="line">    y_vals=y_vals.detach().numpy() <span class="comment"># already required grad.,thus using var.detach().numpy() </span></span><br><span class="line">    plt.plot(x_vals,y_vals) </span><br><span class="line">    plt.xlabel(<span class="string">'x'</span>)</span><br><span class="line">    plt.ylabel(name+<span class="string">'(x)'</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x=Variable(torch.arange(<span class="number">-8.0</span>,<span class="number">8.0</span>,<span class="number">0.1</span>,dtype=torch.float32).reshape(int(<span class="number">16</span>/<span class="number">0.1</span>),<span class="number">1</span>),requires_grad=<span class="literal">True</span>)</span><br><span class="line">y=torch.nn.functional.relu(x)</span><br><span class="line">xyplot(x,y,<span class="string">'relu'</span>)</span><br></pre></td></tr></table></figure><p><img src="output_2_0.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y.backward(torch.ones_like(x),retain_graph=<span class="literal">True</span>)</span><br><span class="line">xyplot(x,x.grad,<span class="string">"grad of relu"</span>)</span><br></pre></td></tr></table></figure><p><img src="output_3_0.png" alt="png"></p><h3 id="sigmod函数"><a href="#sigmod函数" class="headerlink" title="sigmod函数"></a>sigmod函数</h3><p>sigmod函数可将元素的值变为0，1之间</p><p>$$\sigma(sigmod)= \frac{1}{1+exp^(-x)}$$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x=Variable(torch.arange(<span class="number">-8.0</span>,<span class="number">8.0</span>,<span class="number">0.1</span>,dtype=torch.float32).reshape(int(<span class="number">16</span>/<span class="number">0.1</span>),<span class="number">1</span>),requires_grad=<span class="literal">True</span>)</span><br><span class="line">y=torch.sigmoid(x)</span><br><span class="line">xyplot(x,y,<span class="string">'sigmoid'</span>)</span><br></pre></td></tr></table></figure><p><img src="output_5_0.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y.backward(torch.ones_like(x),retain_graph=<span class="literal">True</span>)</span><br><span class="line">xyplot(x,x.grad,<span class="string">'grad of sigmoid'</span>)</span><br></pre></td></tr></table></figure><p><img src="output_6_0.png" alt="png"></p><h3 id="tanh-函数"><a href="#tanh-函数" class="headerlink" title="tanh 函数"></a>tanh 函数</h3><p>tanh函数可以将元素的值变为-1，1之间<br>$$ tanh(x) = \frac{1-exp^(-2x)}{1+exp^(-2x)}$$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x=Variable(torch.arange(<span class="number">-8.0</span>,<span class="number">8.0</span>,<span class="number">0.1</span>,dtype=torch.float32).reshape(int(<span class="number">16</span>/<span class="number">0.1</span>),<span class="number">1</span>),requires_grad=<span class="literal">True</span>)</span><br><span class="line">y=torch.tanh(x)</span><br><span class="line">xyplot(x,y,<span class="string">"tanh"</span>)</span><br></pre></td></tr></table></figure><p><img src="output_8_0.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y.backward(torch.ones_like(x),retain_graph=<span class="literal">True</span>)</span><br><span class="line">xyplot(x,x.grad,<span class="string">"grad of tanh"</span>)</span><br></pre></td></tr></table></figure><p><img src="output_9_0.png" alt="png"></p><h3 id="关于激活函数的选择"><a href="#关于激活函数的选择" class="headerlink" title="关于激活函数的选择"></a>关于激活函数的选择</h3><p>ReLu函数是一个通用的激活函数，目前在大多数情况下使用。但是，ReLU函数只能在隐藏层中使用。</p><p>用于分类器时，sigmoid函数及其组合通常效果更好。由于梯度消失问题，有时要避免使用sigmoid和tanh函数。</p><p>在神经网络层数较多的时候，最好使用ReLu函数，ReLu函数比较简单计算量少，而sigmoid和tanh函数计算量大很多。</p><p>在选择激活函数的时候可以先选用ReLu函数如果效果不理想可以尝试其他激活函数。</p><h2 id="多层感知机的pytorch实现"><a href="#多层感知机的pytorch实现" class="headerlink" title="多层感知机的pytorch实现"></a>多层感知机的pytorch实现</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> init</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">sys.path.append(<span class="string">"."</span>) </span><br><span class="line"><span class="keyword">import</span> d2lzh_pytorch <span class="keyword">as</span> d2l</span><br><span class="line"></span><br><span class="line">print(torch.__version__)</span><br></pre></td></tr></table></figure><pre><code>1.3.1</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">num_inputs, num_outputs, num_hiddens = <span class="number">784</span>, <span class="number">10</span>, <span class="number">256</span></span><br><span class="line">    </span><br><span class="line">net = nn.Sequential(</span><br><span class="line">        d2l.FlattenLayer(),</span><br><span class="line">        nn.Linear(num_inputs, num_hiddens),</span><br><span class="line">        nn.ReLU(),</span><br><span class="line">        nn.Linear(num_hiddens, num_outputs), </span><br><span class="line">        )</span><br><span class="line">    </span><br><span class="line"><span class="keyword">for</span> params <span class="keyword">in</span> net.parameters():</span><br><span class="line">    init.normal_(params, mean=<span class="number">0</span>, std=<span class="number">0.01</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">batch_size = <span class="number">256</span></span><br><span class="line">train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)</span><br><span class="line">loss = torch.nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line">optimizer = torch.optim.SGD(net.parameters(), lr=<span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line">num_epochs = <span class="number">5</span></span><br><span class="line">d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size, <span class="literal">None</span>, <span class="literal">None</span>, optimizer)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">### 输出如下</span></span><br><span class="line">epoch <span class="number">1</span>, loss <span class="number">0.0031</span>, train acc <span class="number">0.703</span>, test acc <span class="number">0.757</span></span><br><span class="line">epoch <span class="number">2</span>, loss <span class="number">0.0019</span>, train acc <span class="number">0.824</span>, test acc <span class="number">0.822</span></span><br><span class="line">epoch <span class="number">3</span>, loss <span class="number">0.0016</span>, train acc <span class="number">0.845</span>, test acc <span class="number">0.825</span></span><br><span class="line">epoch <span class="number">4</span>, loss <span class="number">0.0015</span>, train acc <span class="number">0.855</span>, test acc <span class="number">0.811</span></span><br><span class="line">epoch <span class="number">5</span>, loss <span class="number">0.0014</span>, train acc <span class="number">0.865</span>, test acc <span class="number">0.846</span></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;多层感知机&quot;&gt;&lt;a href=&quot;#多层感知机&quot; class=&quot;headerlink&quot; title=&quot;多层感知机&quot;&gt;&lt;/a&gt;多层感知机&lt;/h1&gt;&lt;p&gt;我们已经介绍了包括线性回归和softmax回归在内的单层神经网络。然而深度学习主要关注多层模型。在本节中，我们将以多
      
    
    </summary>
    
    
      <category term="deep_learning" scheme="https://shyshy903.github.io/categories/deep-learning/"/>
    
    
      <category term="DL" scheme="https://shyshy903.github.io/tags/DL/"/>
    
  </entry>
  
  <entry>
    <title>softmax与分类模型</title>
    <link href="https://shyshy903.github.io/2020/02/12/Deep_learning/Softmax%E4%B8%8E%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B/"/>
    <id>https://shyshy903.github.io/2020/02/12/Deep_learning/Softmax%E4%B8%8E%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B/</id>
    <published>2020-02-11T16:00:00.000Z</published>
    <updated>2020-02-11T16:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="softmax回归"><a href="#softmax回归" class="headerlink" title="softmax回归"></a>softmax回归</h1><p>前几节介绍的线性回归模型适用于输出为连续值的情景。在另一类情景中，模型输出可以是一个像图像类别这样的离散值。对于这样的离散值预测问题，我们可以使用诸如softmax回归在内的分类模型。和线性回归不同，softmax回归的输出单元从一个变成了多个，且引入了softmax运算使输出更适合离散值的预测和训练。本节以softmax回归模型为例，介绍神经网络中的分类模型。</p><h2 id="分类问题"><a href="#分类问题" class="headerlink" title="分类问题"></a>分类问题</h2><p>让我们考虑一个简单的图像分类问题，其输入图像的高和宽均为2像素，且色彩为灰度。这样每个像素值都可以用一个标量表示。我们将图像中的4像素分别记为$x_1, x_2, x_3, x_4$。假设训练数据集中图像的真实标签为狗、猫或鸡（假设可以用4像素表示出这3种动物），这些标签分别对应离散值$y_1, y_2, y_3$。</p><p>我们通常使用离散的数值来表示类别，例如$y_1=1, y_2=2, y_3=3$。如此，一张图像的标签为1、2和3这3个数值中的一个。虽然我们仍然可以使用回归模型来进行建模，并将预测值就近定点化到1、2和3这3个离散值之一，但这种连续值到离散值的转化通常会影响到分类质量。因此我们一般使用更加适合离散值输出的模型来解决分类问题。</p><h2 id="softmax回归模型"><a href="#softmax回归模型" class="headerlink" title="softmax回归模型"></a>softmax回归模型</h2><p>softmax回归跟线性回归一样将输入特征与权重做线性叠加。与线性回归的一个主要不同在于，softmax回归的输出值个数等于标签里的类别数。因为一共有4种特征和3种输出动物类别，所以权重包含12个标量（带下标的$w$）、偏差包含3个标量（带下标的$b$），且对每个输入计算$o_1, o_2, o_3$这3个输出：</p><p>$$<br>\begin{aligned}<br>o_1 &amp;= x_1 w_{11} + x_2 w_{21} + x_3 w_{31} + x_4 w_{41} + b_1,\<br>o_2 &amp;= x_1 w_{12} + x_2 w_{22} + x_3 w_{32} + x_4 w_{42} + b_2,\<br>o_3 &amp;= x_1 w_{13} + x_2 w_{23} + x_3 w_{33} + x_4 w_{43} + b_3.<br>\end{aligned}<br>$$</p><p>图3.2用神经网络图描绘了上面的计算。softmax回归同线性回归一样，也是一个单层神经网络。由于每个输出$o_1, o_2, o_3$的计算都要依赖于所有的输入$x_1, x_2, x_3, x_4$，softmax回归的输出层也是一个全连接层。</p><p><img src="../img/softmaxreg.svg" alt="softmax回归是一个单层神经网络"></p><h3 id="softmax运算"><a href="#softmax运算" class="headerlink" title="softmax运算"></a>softmax运算</h3><p>既然分类问题需要得到离散的预测输出，一个简单的办法是将输出值$o_i$当作预测类别是$i$的置信度，并将值最大的输出所对应的类作为预测输出，即输出$\operatorname*{argmax}_i o_i$。例如，如果$o_1,o_2,o_3$分别为$0.1,10,0.1$，由于$o_2$最大，那么预测类别为2，其代表猫。</p><p>然而，直接使用输出层的输出有两个问题。一方面，由于输出层的输出值的范围不确定，我们难以直观上判断这些值的意义。例如，刚才举的例子中的输出值10表示“很置信”图像类别为猫，因为该输出值是其他两类的输出值的100倍。但如果$o_1=o_3=10^3$，那么输出值10却又表示图像类别为猫的概率很低。另一方面，由于真实标签是离散值，这些离散值与不确定范围的输出值之间的误差难以衡量。</p><p>softmax运算符（softmax operator）解决了以上两个问题。它通过下式将输出值变换成值为正且和为1的概率分布：</p><p>$$\hat{y}_1, \hat{y}_2, \hat{y}_3 = \text{softmax}(o_1, o_2, o_3),$$</p><p>其中</p><p>$$<br>\hat{y}<em>1 = \frac{ \exp(o_1)}{\sum</em>{i=1}^3 \exp(o_i)},\quad<br>\hat{y}<em>2 = \frac{ \exp(o_2)}{\sum</em>{i=1}^3 \exp(o_i)},\quad<br>\hat{y}<em>3 = \frac{ \exp(o_3)}{\sum</em>{i=1}^3 \exp(o_i)}.<br>$$</p><p>容易看出$\hat{y}_1 + \hat{y}_2 + \hat{y}_3 = 1$且$0 \leq \hat{y}_1, \hat{y}_2, \hat{y}_3 \leq 1$，因此$\hat{y}_1, \hat{y}_2, \hat{y}_3$是一个合法的概率分布。这时候，如果$\hat{y}_2=0.8$，不管$\hat{y}_1$和$\hat{y}_3$的值是多少，我们都知道图像类别为猫的概率是80%。此外，我们注意到</p><p>$$\operatorname<em>{argmax}_i o_i = \operatorname</em>{argmax}_i \hat y_i,$$</p><p>因此softmax运算不改变预测类别输出。</p><h2 id="单样本分类的矢量计算表达式"><a href="#单样本分类的矢量计算表达式" class="headerlink" title="单样本分类的矢量计算表达式"></a>单样本分类的矢量计算表达式</h2><p>为了提高计算效率，我们可以将单样本分类通过矢量计算来表达。在上面的图像分类问题中，假设softmax回归的权重和偏差参数分别为</p><p>$$<br>\boldsymbol{W} =<br>\begin{bmatrix}<br>    w_{11} &amp; w_{12} &amp; w_{13} \<br>    w_{21} &amp; w_{22} &amp; w_{23} \<br>    w_{31} &amp; w_{32} &amp; w_{33} \<br>    w_{41} &amp; w_{42} &amp; w_{43}<br>\end{bmatrix},\quad<br>\boldsymbol{b} =<br>\begin{bmatrix}<br>    b_1 &amp; b_2 &amp; b_3<br>\end{bmatrix},<br>$$</p><p>设高和宽分别为2个像素的图像样本$i$的特征为</p><p>$$\boldsymbol{x}^{(i)} = \begin{bmatrix}x_1^{(i)} &amp; x_2^{(i)} &amp; x_3^{(i)} &amp; x_4^{(i)}\end{bmatrix},$$</p><p>输出层的输出为</p><p>$$\boldsymbol{o}^{(i)} = \begin{bmatrix}o_1^{(i)} &amp; o_2^{(i)} &amp; o_3^{(i)}\end{bmatrix},$$</p><p>预测为狗、猫或鸡的概率分布为</p><p>$$\boldsymbol{\hat{y}}^{(i)} = \begin{bmatrix}\hat{y}_1^{(i)} &amp; \hat{y}_2^{(i)} &amp; \hat{y}_3^{(i)}\end{bmatrix}.$$</p><p>softmax回归对样本$i$分类的矢量计算表达式为</p><p>$$<br>\begin{aligned}<br>\boldsymbol{o}^{(i)} &amp;= \boldsymbol{x}^{(i)} \boldsymbol{W} + \boldsymbol{b},\<br>\boldsymbol{\hat{y}}^{(i)} &amp;= \text{softmax}(\boldsymbol{o}^{(i)}).<br>\end{aligned}<br>$$</p><h2 id="小批量样本分类的矢量计算表达式"><a href="#小批量样本分类的矢量计算表达式" class="headerlink" title="小批量样本分类的矢量计算表达式"></a>小批量样本分类的矢量计算表达式</h2><p>为了进一步提升计算效率，我们通常对小批量数据做矢量计算。广义上讲，给定一个小批量样本，其批量大小为$n$，输入个数（特征数）为$d$，输出个数（类别数）为$q$。设批量特征为$\boldsymbol{X} \in \mathbb{R}^{n \times d}$。假设softmax回归的权重和偏差参数分别为$\boldsymbol{W} \in \mathbb{R}^{d \times q}$和$\boldsymbol{b} \in \mathbb{R}^{1 \times q}$。softmax回归的矢量计算表达式为</p><p>$$<br>\begin{aligned}<br>\boldsymbol{O} &amp;= \boldsymbol{X} \boldsymbol{W} + \boldsymbol{b},\<br>\boldsymbol{\hat{Y}} &amp;= \text{softmax}(\boldsymbol{O}),<br>\end{aligned}<br>$$</p><p>其中的加法运算使用了广播机制，$\boldsymbol{O}, \boldsymbol{\hat{Y}} \in \mathbb{R}^{n \times q}$且这两个矩阵的第$i$行分别为样本$i$的输出$\boldsymbol{o}^{(i)}$和概率分布$\boldsymbol{\hat{y}}^{(i)}$。</p><h2 id="交叉熵损失函数"><a href="#交叉熵损失函数" class="headerlink" title="交叉熵损失函数"></a>交叉熵损失函数</h2><p>前面提到，使用softmax运算后可以更方便地与离散标签计算误差。我们已经知道，softmax运算将输出变换成一个合法的类别预测分布。实际上，真实标签也可以用类别分布表达：对于样本$i$，我们构造向量$\boldsymbol{y}^{(i)}\in \mathbb{R}^{q}$ ，使其第$y^{(i)}$（样本$i$类别的离散数值）个元素为1，其余为0。这样我们的训练目标可以设为使预测概率分布$\boldsymbol{\hat y}^{(i)}$尽可能接近真实的标签概率分布$\boldsymbol{y}^{(i)}$。</p><p>我们可以像线性回归那样使用平方损失函数$|\boldsymbol{\hat y}^{(i)}-\boldsymbol{y}^{(i)}|^2/2$。然而，想要预测分类结果正确，我们其实并不需要预测概率完全等于标签概率。例如，在图像分类的例子里，如果$y^{(i)}=3$，那么我们只需要$\hat{y}^{(i)}_3$比其他两个预测值$\hat{y}^{(i)}_1$和$\hat{y}^{(i)}_2$大就行了。即使$\hat{y}^{(i)}_3$值为0.6，不管其他两个预测值为多少，类别预测均正确。而平方损失则过于严格，例如$\hat y^{(i)}_1=\hat y^{(i)}_2=0.2$比$\hat y^{(i)}_1=0, \hat y^{(i)}_2=0.4$的损失要小很多，虽然两者都有同样正确的分类预测结果。</p><p>改善上述问题的一个方法是使用更适合衡量两个概率分布差异的测量函数。其中，交叉熵（cross entropy）是一个常用的衡量方法：</p><p>$$H\left(\boldsymbol y^{(i)}, \boldsymbol {\hat y}^{(i)}\right ) = -\sum_{j=1}^q y_j^{(i)} \log \hat y_j^{(i)},$$</p><p>其中带下标的$y_j^{(i)}$是向量$\boldsymbol y^{(i)}$中非0即1的元素，需要注意将它与样本$i$类别的离散数值，即不带下标的$y^{(i)}$区分。在上式中，我们知道向量$\boldsymbol y^{(i)}$中只有第$y^{(i)}$个元素$y^{(i)}<em>{y^{(i)}}$为1，其余全为0，于是$H(\boldsymbol y^{(i)}, \boldsymbol {\hat y}^{(i)}) = -\log \hat y</em>{y^{(i)}}^{(i)}$。也就是说，交叉熵只关心对正确类别的预测概率，因为只要其值足够大，就可以确保分类结果正确。当然，遇到一个样本有多个标签时，例如图像里含有不止一个物体时，我们并不能做这一步简化。但即便对于这种情况，交叉熵同样只关心对图像中出现的物体类别的预测概率。</p><p>假设训练数据集的样本数为$n$，交叉熵损失函数定义为<br>$$\ell(\boldsymbol{\Theta}) = \frac{1}{n} \sum_{i=1}^n H\left(\boldsymbol y^{(i)}, \boldsymbol {\hat y}^{(i)}\right ),$$</p><p>其中$\boldsymbol{\Theta}$代表模型参数。同样地，如果每个样本只有一个标签，那么交叉熵损失可以简写成$\ell(\boldsymbol{\Theta}) = -(1/n)  \sum_{i=1}^n \log \hat y_{y^{(i)}}^{(i)}$。从另一个角度来看，我们知道最小化$\ell(\boldsymbol{\Theta})$等价于最大化$\exp(-n\ell(\boldsymbol{\Theta}))=\prod_{i=1}^n \hat y_{y^{(i)}}^{(i)}$，即最小化交叉熵损失函数等价于最大化训练数据集所有标签类别的联合预测概率。</p><h1 id="softmax的pytorch实现"><a href="#softmax的pytorch实现" class="headerlink" title="softmax的pytorch实现"></a>softmax的pytorch实现</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 加载各种包或者模块</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> init</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">sys.path.append(<span class="string">r"D:\Documents\learning"</span>)</span><br><span class="line"><span class="comment"># import d2lzh as d2l</span></span><br><span class="line"></span><br><span class="line">print(torch.__version__)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成数据集</span></span><br><span class="line">batch_size = <span class="number">256</span></span><br><span class="line"><span class="comment"># train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, root='/home/kesci/input/FashionMNIST2065')</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义网络模型</span></span><br><span class="line">num_inputs = <span class="number">784</span></span><br><span class="line">num_outputs = <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LinearNet</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, num_inputs, num_outputs)</span>:</span></span><br><span class="line">        super(LinearNet, self).__init__()</span><br><span class="line">        self.linear = nn.Linear(num_inputs, num_outputs)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span> <span class="comment"># x 的形状: (batch, 1, 28, 28)</span></span><br><span class="line">        y = self.linear(x.view(x.shape[<span class="number">0</span>], <span class="number">-1</span>))</span><br><span class="line">        <span class="keyword">return</span> y</span><br><span class="line">    </span><br><span class="line"><span class="comment"># net = LinearNet(num_inputs, num_outputs)</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FlattenLayer</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(FlattenLayer, self).__init__()</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span> <span class="comment"># x 的形状: (batch, *, *, ...)</span></span><br><span class="line">        <span class="keyword">return</span> x.view(x.shape[<span class="number">0</span>], <span class="number">-1</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> OrderedDict</span><br><span class="line">net = nn.Sequential(</span><br><span class="line">        <span class="comment"># FlattenLayer(),</span></span><br><span class="line">        <span class="comment"># LinearNet(num_inputs, num_outputs) </span></span><br><span class="line">        OrderedDict([</span><br><span class="line">           (<span class="string">'flatten'</span>, FlattenLayer()),</span><br><span class="line">           (<span class="string">'linear'</span>, nn.Linear(num_inputs, num_outputs))]) <span class="comment"># 或者写成我们自己定义的 LinearNet(num_inputs, num_outputs) 也可以</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化模型参数</span></span><br><span class="line">init.normal_(net.linear.weight, mean=<span class="number">0</span>, std=<span class="number">0.01</span>)</span><br><span class="line">init.constant_(net.linear.bias, val=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义损失函数</span></span><br><span class="line">loss = nn.CrossEntropyLoss() <span class="comment"># 下面是他的函数原型</span></span><br><span class="line"><span class="comment"># class torch.nn.CrossEntropyLoss(weight=None, size_average=None, ignore_index=-100, reduce=None, reduction='mean')</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义优化函数</span></span><br></pre></td></tr></table></figure><pre><code>1.3.1</code></pre><h2 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">num_epochs = <span class="number">5</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_ch3</span><span class="params">(net, train_iter, test_iter, loss, num_epochs, batch_size,</span></span></span><br><span class="line"><span class="function"><span class="params">              params=None, lr=None, trainer=None)</span>:</span></span><br><span class="line">    <span class="string">"""Train and evaluate a model with CPU."""</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(num_epochs):</span><br><span class="line">        train_l_sum, train_acc_sum, n = <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> X, y <span class="keyword">in</span> train_iter:</span><br><span class="line">            <span class="keyword">with</span> autograd.record():</span><br><span class="line">                y_hat = net(X)</span><br><span class="line">                l = loss(y_hat, y).sum()</span><br><span class="line">            l.backward()</span><br><span class="line">            <span class="keyword">if</span> trainer <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">                sgd(params, lr, batch_size)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                trainer.step(batch_size)</span><br><span class="line">            y = y.astype(<span class="string">'float32'</span>)</span><br><span class="line">            train_l_sum += l.asscalar()</span><br><span class="line">            train_acc_sum += (y_hat.argmax(axis=<span class="number">1</span>) == y).sum().asscalar()</span><br><span class="line">            n += y.size</span><br><span class="line">        test_acc = evaluate_accuracy(test_iter, net)</span><br><span class="line">        print(<span class="string">'epoch %d, loss %.4f, train acc %.3f, test acc %.3f'</span></span><br><span class="line">              % (epoch + <span class="number">1</span>, train_l_sum / n, train_acc_sum / n, test_acc))</span><br><span class="line"></span><br><span class="line">train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size, <span class="literal">None</span>, <span class="literal">None</span>, optimizer)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;softmax回归&quot;&gt;&lt;a href=&quot;#softmax回归&quot; class=&quot;headerlink&quot; title=&quot;softmax回归&quot;&gt;&lt;/a&gt;softmax回归&lt;/h1&gt;&lt;p&gt;前几节介绍的线性回归模型适用于输出为连续值的情景。在另一类情景中，模型输出可以是一个
      
    
    </summary>
    
    
      <category term="java" scheme="https://shyshy903.github.io/categories/java/"/>
    
    
      <category term="DL" scheme="https://shyshy903.github.io/tags/DL/"/>
    
  </entry>
  
  <entry>
    <title>线性回归</title>
    <link href="https://shyshy903.github.io/2020/02/12/Deep_learning/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"/>
    <id>https://shyshy903.github.io/2020/02/12/Deep_learning/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/</id>
    <published>2020-02-11T16:00:00.000Z</published>
    <updated>2020-02-11T16:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h1><ul><li><p>模型<br>$$y = wx + b$$</p></li><li><p>损失函数<br>$$\ell(w_1, w_2, b) =\frac{1}{n} \sum_{i=1}^n \ell^{(i)}(w_1, w_2, b) =\frac{1}{n} \sum_{i=1}^n \frac{1}{2}\left(x_1^{(i)} w_1 + x_2^{(i)} w_2 + b - y^{(i)}\right)^2.$$</p></li><li><p>优化函数<br>$$<br>\begin{aligned}<br>w_1 &amp;\leftarrow w_1 -   \frac{\eta}{|\mathcal{B}|} \sum_{i \in \mathcal{B}} \frac{ \partial \ell^{(i)}(w_1, w_2, b)  }{\partial w_1} = w_1 -   \frac{\eta}{|\mathcal{B}|} \sum_{i \in \mathcal{B}}x_1^{(i)} \left(x_1^{(i)} w_1 + x_2^{(i)} w_2 + b - y^{(i)}\right),\<br>w_2 &amp;\leftarrow w_2 -   \frac{\eta}{|\mathcal{B}|} \sum_{i \in \mathcal{B}} \frac{ \partial \ell^{(i)}(w_1, w_2, b)  }{\partial w_2} = w_2 -   \frac{\eta}{|\mathcal{B}|} \sum_{i \in \mathcal{B}}x_2^{(i)} \left(x_1^{(i)} w_1 + x_2^{(i)} w_2 + b - y^{(i)}\right),\<br>b &amp;\leftarrow b -   \frac{\eta}{|\mathcal{B}|} \sum_{i \in \mathcal{B}} \frac{ \partial \ell^{(i)}(w_1, w_2, b)  }{\partial b} = b -   \frac{\eta}{|\mathcal{B}|} \sum_{i \in \mathcal{B}}\left(x_1^{(i)} w_1 + x_2^{(i)} w_2 + b - y^{(i)}\right).<br>\end{aligned}<br>$$</p></li><li><p>神经网络图（单层神经网络）</p></li></ul><h2 id="线性回归的pytorch实现"><a href="#线性回归的pytorch实现" class="headerlink" title="线性回归的pytorch实现"></a>线性回归的pytorch实现</h2><h3 id="生成数据集"><a href="#生成数据集" class="headerlink" title="生成数据集"></a>生成数据集</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">num_inputs = <span class="number">2</span></span><br><span class="line">num_examples = <span class="number">1000</span></span><br><span class="line">true_w = [<span class="number">2</span>, <span class="number">-3.4</span>]</span><br><span class="line">true_b = <span class="number">4.2</span></span><br><span class="line">features = torch.randn(num_examples, num_inputs)</span><br><span class="line">labels = true_w[<span class="number">0</span>] * features[:, <span class="number">0</span>] + true_w[<span class="number">1</span>] * features[:, <span class="number">1</span>] + true_b</span><br><span class="line">labels += torch.normal(mean=torch.zeros(labels.shape), std=<span class="number">0.01</span>)</span><br></pre></td></tr></table></figure><h3 id="读取数据"><a href="#读取数据" class="headerlink" title="读取数据"></a>读取数据</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils <span class="keyword">import</span> data <span class="keyword">as</span> tdata</span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">10</span></span><br><span class="line"><span class="comment"># 将训练数据的特征和标签组合</span></span><br><span class="line">dataset = tdata.TensorDataset(features, labels)</span><br><span class="line"><span class="comment"># 随机读取小批量</span></span><br><span class="line">data_iter = tdata.DataLoader(dataset, batch_size, shuffle=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> X, y <span class="keyword">in</span> data_iter:</span><br><span class="line">    print(X, y)</span><br><span class="line">    <span class="keyword">break</span></span><br></pre></td></tr></table></figure><pre><code>tensor([[ 0.2115,  1.4861],        [-0.2630,  0.8898],        [ 0.8301, -2.6101],        [ 1.5199, -0.5050],        [-0.4478,  0.6990],        [ 1.4203,  1.1574],        [ 1.3185,  1.1949],        [ 2.0129,  0.8379],        [ 1.1585, -0.1882],        [ 0.9050,  0.0398]]) tensor([-0.4229,  0.6551, 14.7292,  8.9412,  0.9225,  3.1058,  2.7778,  5.3856,         7.1542,  5.8629])</code></pre><h3 id="定义模型"><a href="#定义模型" class="headerlink" title="定义模型"></a>定义模型</h3><p>先导入<code>nn</code>模块。实际上，<code>“nn”</code>是<code>neural networks</code>（神经网络）的缩写。顾名思义，该模块定义了大量神经网络的层。我们先定义一个模型变量<code>net</code>，它是一个<code>Sequential</code>实例。在<code>nn</code>中，<code>Sequential</code>实例可以看作是一个串联各个层的容器。在构造模型时，我们在该容器中依次添加层。当给定输入数据时，容器中的每一层将依次计算并将输出作为下一层的输入。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line">net = nn.Sequential()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"> <span class="comment"># 全连接层是一个线性层，特征数为2，输出个数为1</span></span><br><span class="line">net.add_module(<span class="string">'linear'</span>, nn.Linear(<span class="number">2</span>, <span class="number">1</span>))</span><br></pre></td></tr></table></figure><h3 id="初始化模型参数"><a href="#初始化模型参数" class="headerlink" title="初始化模型参数"></a>初始化模型参数</h3><p>这里主要是初始化线性回归模型中的权重与偏差。使用<code>nn.init</code>模块<br>如<code>nn.init.normal(tensor, std=0.01)</code>指定随机初始化将随机采样均值为0、标准差为0.01的正态分布。偏差初始化默认为0</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> init</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">params_init</span><span class="params">(model)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> isinstance(model, nn.Linear):</span><br><span class="line">        init.normal_(tensor=model.weight.data, std=<span class="number">0.01</span>)</span><br><span class="line">        init.constant_(tensor=model.bias.data, val=<span class="number">0</span>)</span><br><span class="line">        </span><br><span class="line">net.apply(params_init)</span><br></pre></td></tr></table></figure><pre><code>Sequential(  (linear): Linear(in_features=2, out_features=1, bias=True))</code></pre><h3 id="定义损失函数与优化算法"><a href="#定义损失函数与优化算法" class="headerlink" title="定义损失函数与优化算法"></a>定义损失函数与优化算法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">loss = nn.MSELoss() <span class="comment"># 均方误差损失函数</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> optim</span><br><span class="line"></span><br><span class="line">optimizer = optim.SGD(net.parameters(), lr=<span class="number">0.03</span>)  <span class="comment"># lr为学习率</span></span><br></pre></td></tr></table></figure><h3 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">num_epochs = <span class="number">5</span> <span class="comment"># 初始化训练周期</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">1</span>, num_epochs + <span class="number">1</span>):</span><br><span class="line">    <span class="keyword">for</span> X, y <span class="keyword">in</span> data_iter:</span><br><span class="line">        net.zero_grad()</span><br><span class="line">        l = loss(net(X), y.reshape(batch_size, <span class="number">-1</span>))  <span class="comment"># -1表示自动计算列</span></span><br><span class="line">        l.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        l = loss(net(features), labels.reshape(num_examples, <span class="number">-1</span>))</span><br><span class="line">        print(<span class="string">'epoch %d, loss: %f'</span> % (epoch, l.data.numpy()))</span><br></pre></td></tr></table></figure><pre><code>epoch 1, loss: 0.000093epoch 2, loss: 0.000094epoch 3, loss: 0.000094epoch 4, loss: 0.000093epoch 5, loss: 0.000093</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">linear = net[<span class="number">0</span>]</span><br><span class="line">true_w, linear.weight.data</span><br></pre></td></tr></table></figure><pre><code>([2, -3.4], tensor([[ 2.0001, -3.4001]]))</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">true_b, linear.bias.data</span><br></pre></td></tr></table></figure><pre><code>(4.2, tensor([4.2001]))</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">net</span><br></pre></td></tr></table></figure><pre><code>Sequential(  (linear): Linear(in_features=2, out_features=1, bias=True))</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;线性回归&quot;&gt;&lt;a href=&quot;#线性回归&quot; class=&quot;headerlink&quot; title=&quot;线性回归&quot;&gt;&lt;/a&gt;线性回归&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;模型&lt;br&gt;$$y = wx + b$$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;损失函数&lt;br&gt;$$\ell(
      
    
    </summary>
    
    
      <category term="deep_learning" scheme="https://shyshy903.github.io/categories/deep-learning/"/>
    
    
      <category term="DL" scheme="https://shyshy903.github.io/tags/DL/"/>
    
  </entry>
  
  <entry>
    <title>理论催化计算（一）</title>
    <link href="https://shyshy903.github.io/2020/02/11/%E9%87%8F%E5%AD%90%E8%AE%A1%E7%AE%97/%E7%90%86%E8%AE%BA%E5%82%AC%E5%8C%96%E8%AE%A1%E7%AE%97(%E4%B8%80)/"/>
    <id>https://shyshy903.github.io/2020/02/11/%E9%87%8F%E5%AD%90%E8%AE%A1%E7%AE%97/%E7%90%86%E8%AE%BA%E5%82%AC%E5%8C%96%E8%AE%A1%E7%AE%97(%E4%B8%80)/</id>
    <published>2020-02-11T08:48:55.626Z</published>
    <updated>2020-02-11T08:48:55.627Z</updated>
    
    <content type="html"><![CDATA[<h1 id="（一）准备工作"><a href="#（一）准备工作" class="headerlink" title="（一）准备工作"></a>（一）准备工作</h1><h2 id="1-系统与软件部分"><a href="#1-系统与软件部分" class="headerlink" title="1 系统与软件部分"></a>1 系统与软件部分</h2><ul><li><code>Linux与windows</code>系统</li><li>编辑器：<code>windows</code>用<code>notepad++</code>编辑器，<code>linux</code>用<code>vim</code>编辑器</li><li>相关程序：</li></ul><ol><li><code>Materials studio</code> (用来建模)</li><li><code>Vesta</code>(用来进行可视化与文件转换)</li><li><code>VASP与CP2k</code>:用来做第一性原理计算的软件,CP2k是从头算分析动力学模拟，是表面催化计算的大杀器，资料少，学习困难</li><li><a href="http://www,psvasp.at" target="_blank" rel="noopener">p4vasp</a>:vasp计算结果的后处理程序</li><li><a href="http://www.ks.uiuc.edu/Research/vmd/" target="_blank" rel="noopener">VMD</a>:分子动力学的可视化程序，作图的玩着，自由度很高，使用复杂</li></ol><h2 id="2-理论知识部分"><a href="#2-理论知识部分" class="headerlink" title="2 理论知识部分"></a>2 理论知识部分</h2><h3 id="2-1-催化化学与量子化学"><a href="#2-1-催化化学与量子化学" class="headerlink" title="2.1 催化化学与量子化学"></a>2.1 催化化学与量子化学</h3><p>这里推荐两本书，<br><img src="https://ss0.baidu.com/73F1bjeh1BF3odCf/it/u=668807871,692209756&fm=85&s=C940E8110E375A88742D76C50300D0A0" alt="电催化，孙世刚院士著">)<img src="https://ss0.baidu.com/73F1bjeh1BF3odCf/it/u=2760061665,532098802&fm=85&s=B22BF604505753CC0292E9CC030050BA" alt="量子化学"></p><h3 id="2-2-密度泛函理论"><a href="#2-2-密度泛函理论" class="headerlink" title="2.2 密度泛函理论"></a>2.2 密度泛函理论</h3><p>这里也推荐本书：<br><img src="https://img.vim-cn.com/1d/caf343d9bf941549911857e38766ae912b5f66.jpg" alt=""></p><h1 id="（二）催化模型构建"><a href="#（二）催化模型构建" class="headerlink" title="（二）催化模型构建"></a>（二）催化模型构建</h1><h2 id="3-晶体结构数据库的使用"><a href="#3-晶体结构数据库的使用" class="headerlink" title="3 晶体结构数据库的使用"></a>3 晶体结构数据库的使用</h2><h3 id="3-1-相关说明"><a href="#3-1-相关说明" class="headerlink" title="3.1 相关说明"></a>3.1 相关说明</h3><p>第一篇单原子催化文章：<em>Nat. Chem., 2011, 3,634-641</em><br>研究晶体结构的文献都会给出结构的详细参数：比如，<em>J. Am. Chem. Soc. 136, 20, 7221-7224</em><br>注意：不要用<code>MS</code>里<code>build–crystals–build crystals</code>对着文献输入参数。费了半天劲还容易搞错，在晶体数据库里可以直接找到cif结构文件。</p><h3 id="3-2-晶体结构与数据库"><a href="#3-2-晶体结构与数据库" class="headerlink" title="3.2 晶体结构与数据库"></a>3.2 晶体结构与数据库</h3><ul><li>问题：找晶体结构到底在找什么？<br>答：<code>CIF</code>文件，后缀名为<code>.cif</code>，内部含有结构信息</li><li>常用的晶体结构数据库：<ul><li><code>ICSD – the Inorganic Crystal Structure Database</code> 无机晶体数据库。<a href="http://www2.fiz-karlsruhe.de/icsd_home.html" target="_blank" rel="noopener">http://www2.fiz-karlsruhe.de/icsd_home.html</a></li><li><code>CCDC – The Cambridge Crystallographic Data Centre</code><a href="https://www.ccdc.cam.ac.uk/" target="_blank" rel="noopener">https://www.ccdc.cam.ac.uk/</a></li><li><code>Materials studio</code>自带晶体数据库</li><li><code>Materials Project</code>（强烈推荐）：<a href="https://materialsproject.org/" target="_blank" rel="noopener">https://materialsproject.org/</a><br>特色，不但有实验结构参数，还有理论计算数据，比如磁矩，形成能，密度，带隙，空间群，点群，晶系，能带结构，弹性张量， 压电张量等数据。截至2018年9月11日，收录83989种无机化合物， 52179个能带结构</li><li>AMCSD – American Mineralogist Crystal Structure Database：<a href="http://rruff.geo.arizona.edu/AMS/amcsd.php" target="_blank" rel="noopener">http://rruff.geo.arizona.edu/AMS/amcsd.php</a></li><li>google search （ex： Al2O3 filetype:cif ）<h3 id="3-3-CCDC实战训练（一）-从文章中找到晶体结构"><a href="#3-3-CCDC实战训练（一）-从文章中找到晶体结构" class="headerlink" title="3.3 CCDC实战训练（一）-从文章中找到晶体结构"></a>3.3 CCDC实战训练（一）-从文章中找到晶体结构</h3></li></ul></li><li>如何从文章找到晶体结构？<br>答： 直接到文章末尾去找<code>CCDC</code>编码，但有时晶体结构也会出现在文章中或者SI里面。</li><li>如何从晶体数据库中获得结构文件？<ul><li>登录数据库查找<code>CCDC</code>编码</li></ul><ul><li>下载<code>CIF</code>文件</li></ul></li></ul><h3 id="3-4-ISDC-实战训练（二）-得到各种AL2O3模型"><a href="#3-4-ISDC-实战训练（二）-得到各种AL2O3模型" class="headerlink" title="3.4 ISDC 实战训练（二）-得到各种AL2O3模型"></a>3.4 ISDC 实战训练（二）-得到各种AL2O3模型</h3><p><code>Materials studio</code> 只有一种<code>Al2O3</code> 模型，是<code>a</code>型的<code>trigonal</code>晶系，也称作<code>corundum</code>刚玉。如果想要得到不同晶型的<code>Al2O3</code>就要去晶体数据库上找。</p><ul><li>总结：科研中碰到一个晶体，应该怎么找对应的结构文件。</li><li>依次尝试下列方法：</li></ul><ol><li>在<code>materials project</code>中直接输入对应元素和原子个数。如果<br>搞不清该化合物的晶型，提前<code>Google</code>该晶体所属晶系，点<br>群和空间群。</li><li>在<code>ICSD chemistry</code>中输入对应元素和原子个数。（<code>ICSD</code>是<br>最全的无机晶体数据库，如果这都找不到结构，应该回头<br>看那里搞错了）</li><li>在文献中找结构，然后去ICSD搜索该文献。</li><li>直接<code>google</code>，例如， <code>black phosphorus CIF</code><br>想偷懒可以在<code>MS</code>里， <code>File-input-structures</code>里找结构， <code>MS</code>里只有非常少数的常见结构。</li></ol><h1 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h1><p>非常感谢研之成理和清华化学系刘锦程博士，微信搜索研之成理就可以<code>get</code>一个非常非常优质的公众号了！！</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;（一）准备工作&quot;&gt;&lt;a href=&quot;#（一）准备工作&quot; class=&quot;headerlink&quot; title=&quot;（一）准备工作&quot;&gt;&lt;/a&gt;（一）准备工作&lt;/h1&gt;&lt;h2 id=&quot;1-系统与软件部分&quot;&gt;&lt;a href=&quot;#1-系统与软件部分&quot; class=&quot;header
      
    
    </summary>
    
    
      <category term="计算物理与化学" scheme="https://shyshy903.github.io/categories/%E8%AE%A1%E7%AE%97%E7%89%A9%E7%90%86%E4%B8%8E%E5%8C%96%E5%AD%A6/"/>
    
    
      <category term="计算物理与化学" scheme="https://shyshy903.github.io/tags/%E8%AE%A1%E7%AE%97%E7%89%A9%E7%90%86%E4%B8%8E%E5%8C%96%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>色彩搭配与设计</title>
    <link href="https://shyshy903.github.io/2020/02/11/%E8%AE%BE%E8%AE%A1/%E5%85%B3%E4%BA%8E%E9%A2%9C%E8%89%B2/"/>
    <id>https://shyshy903.github.io/2020/02/11/%E8%AE%BE%E8%AE%A1/%E5%85%B3%E4%BA%8E%E9%A2%9C%E8%89%B2/</id>
    <published>2020-02-11T08:48:55.613Z</published>
    <updated>2020-02-11T08:48:55.613Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Color"><a href="#Color" class="headerlink" title="Color"></a>Color</h1><h2 id="Material-design中的color"><a href="#Material-design中的color" class="headerlink" title="Material design中的color"></a>Material design中的color</h2><div><img src = "https://img.vim-cn.com/65/c21d40de1a5e93d9dbfd5f35e17f18d52b931f.webp"></div><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!--Material Colors--&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">color</span> <span class="attr">name</span>=<span class="string">"materialColorRed"</span>&gt;</span>#f44336<span class="tag">&lt;/<span class="name">color</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">color</span> <span class="attr">name</span>=<span class="string">"materialColorPink"</span>&gt;</span>#e91e63<span class="tag">&lt;/<span class="name">color</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">color</span> <span class="attr">name</span>=<span class="string">"materialColorPurple"</span>&gt;</span>#9c27b0<span class="tag">&lt;/<span class="name">color</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">color</span> <span class="attr">name</span>=<span class="string">"materialColorDeepPurple"</span>&gt;</span>#673ab7<span class="tag">&lt;/<span class="name">color</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">color</span> <span class="attr">name</span>=<span class="string">"materialColorIndigo"</span>&gt;</span>#3f51b5<span class="tag">&lt;/<span class="name">color</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">color</span> <span class="attr">name</span>=<span class="string">"materialColorBlue"</span>&gt;</span>#2196f3<span class="tag">&lt;/<span class="name">color</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">color</span> <span class="attr">name</span>=<span class="string">"materialColorLightBlue"</span>&gt;</span>#03a9f4<span class="tag">&lt;/<span class="name">color</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">color</span> <span class="attr">name</span>=<span class="string">"materialColorCyan"</span>&gt;</span>#00bcd4<span class="tag">&lt;/<span class="name">color</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">color</span> <span class="attr">name</span>=<span class="string">"materialColorTeal"</span>&gt;</span>#009688<span class="tag">&lt;/<span class="name">color</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">color</span> <span class="attr">name</span>=<span class="string">"materialColorGreen"</span>&gt;</span>#4caf50<span class="tag">&lt;/<span class="name">color</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">color</span> <span class="attr">name</span>=<span class="string">"materialColorLightGreen"</span>&gt;</span>#8bc34a<span class="tag">&lt;/<span class="name">color</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">color</span> <span class="attr">name</span>=<span class="string">"materialColorLime"</span>&gt;</span>#cddc39<span class="tag">&lt;/<span class="name">color</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">color</span> <span class="attr">name</span>=<span class="string">"materialColorYellow"</span>&gt;</span>#FFeb3b<span class="tag">&lt;/<span class="name">color</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">color</span> <span class="attr">name</span>=<span class="string">"materialColorAmber"</span>&gt;</span>#FFc107<span class="tag">&lt;/<span class="name">color</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">color</span> <span class="attr">name</span>=<span class="string">"materialColorOrange"</span>&gt;</span>#FF9800<span class="tag">&lt;/<span class="name">color</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">color</span> <span class="attr">name</span>=<span class="string">"materialColorDeepOrange"</span>&gt;</span>#FF5722<span class="tag">&lt;/<span class="name">color</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">color</span> <span class="attr">name</span>=<span class="string">"materialColorBrown"</span>&gt;</span>#795548<span class="tag">&lt;/<span class="name">color</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">color</span> <span class="attr">name</span>=<span class="string">"materialColorGrey"</span>&gt;</span>#9e9e9e<span class="tag">&lt;/<span class="name">color</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">color</span> <span class="attr">name</span>=<span class="string">"materialColorBlueGrey"</span>&gt;</span>#607d8b<span class="tag">&lt;/<span class="name">color</span>&gt;</span></span><br><span class="line">   <span class="comment">&lt;!--Text Colors--&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">color</span> <span class="attr">name</span>=<span class="string">"primaryText"</span>&gt;</span>#212121<span class="tag">&lt;/<span class="name">color</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">color</span> <span class="attr">name</span>=<span class="string">"secondaryText"</span>&gt;</span>#757575<span class="tag">&lt;/<span class="name">color</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">color</span> <span class="attr">name</span>=<span class="string">"dividerColor"</span>&gt;</span>#bdbdbd<span class="tag">&lt;/<span class="name">color</span>&gt;</span></span><br></pre></td></tr></table></figure>## 色彩的巧妙搭配<div align = center><img src = "https://img.vim-cn.com/21/b362eb8232618c5eb6692fef2cb5f1cf24aa63.png"></div><br><p><strong>几个色彩网站推荐</strong></p><p>拼色网站1： <a href="https://colordrop.io/" target="_blank" rel="noopener">https://colordrop.io/</a><br>拼色网站2：<a href="http://www.peise.net/tools/web/#" target="_blank" rel="noopener">http://www.peise.net/tools/web/#</a><br>RGB色值对照表 ：<a href="https://tool.oschina.net/commons?type=3" target="_blank" rel="noopener">https://tool.oschina.net/commons?type=3</a></p><p><strong>一个免费图片网站</strong><br><a href="https://unsplash.com/" target="_blank" rel="noopener">https://unsplash.com/</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Color&quot;&gt;&lt;a href=&quot;#Color&quot; class=&quot;headerlink&quot; title=&quot;Color&quot;&gt;&lt;/a&gt;Color&lt;/h1&gt;&lt;h2 id=&quot;Material-design中的color&quot;&gt;&lt;a href=&quot;#Material-design中的co
      
    
    </summary>
    
    
      <category term="设计" scheme="https://shyshy903.github.io/categories/%E8%AE%BE%E8%AE%A1/"/>
    
    
      <category term="color" scheme="https://shyshy903.github.io/tags/color/"/>
    
  </entry>
  
  <entry>
    <title>Java学习笔记（五）</title>
    <link href="https://shyshy903.github.io/2020/02/11/java/shyjava(5)/"/>
    <id>https://shyshy903.github.io/2020/02/11/java/shyjava(5)/</id>
    <published>2020-02-11T08:48:55.602Z</published>
    <updated>2020-02-11T08:48:55.602Z</updated>
    
    <content type="html"><![CDATA[<h1 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h1><h2 id="方法的定义"><a href="#方法的定义" class="headerlink" title="方法的定义"></a>方法的定义</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">MethodDeclaration:</span><br><span class="line">MethodHeader MethodBody</span><br><span class="line">MethodHeader:</span><br><span class="line"><span class="function">Modifiersopt ResultType <span class="title">Identifier</span><span class="params">(FormalParameterListopt)</span> Throwsopt</span></span><br><span class="line"><span class="function">Modifiers:</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">protected</span> <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">abstract</span> <span class="keyword">final</span></span></span><br><span class="line"><span class="function"><span class="keyword">synchronized</span> <span class="keyword">native</span> <span class="keyword">strictfp</span></span></span><br><span class="line"><span class="function">ResultType:</span></span><br><span class="line"><span class="function">Type</span></span><br><span class="line"><span class="function"><span class="keyword">void</span></span></span><br><span class="line"><span class="function">MethodBody:</span></span><br><span class="line"><span class="function"></span>&#123; statements &#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">max</span><span class="params">(<span class="keyword">int</span> num1, <span class="keyword">int</span> num2)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> result = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">if</span>(num1 &gt; num2)</span><br><span class="line">        result = num1;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        result = num2;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>方法签名(Method Signature)指方法名称、参数类型、参数数量和返回类型。一个类中不能包含签名相同或仅返回类型不同的多个方法。</li><li>方法头中声明的变量称为形参(formal parameter)。当调用方法时，可向形参传递一个值，这个值称为实参(actual parameter / argument)。形参可以使用final进行修饰，表示方法内部不允许修改该参数。</li><li>形参不允许有默认值，最后一个可为变长参数（可用…或数组定义，参见第7章数组）。方法不允许static局部变量。</li><li>方法可以有一个返回值(return value)。如果方法没有返回值，返回值类型为void，但构造函数确实没有返回值。</li></ul><h2 id="方法的调用"><a href="#方法的调用" class="headerlink" title="方法的调用"></a>方法的调用</h2><ul><li>声明方法只给出方法的定义。要执行方法，必须调用(call/invoke)方法。</li><li>如果方法有返回值，通常将方法调用作为一个值来处理（可放在一个表达式里）。<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> large = max(<span class="number">3</span>, <span class="number">4</span>) * <span class="number">2</span>;  </span><br><span class="line">System.out.println(max(<span class="number">3</span>,<span class="number">4</span>));</span><br><span class="line">如果方法没有返回值，方法调用必须是一条语句。</span><br><span class="line">System.out.println(“Welcome to Java!”);</span><br></pre></td></tr></table></figure></li><li>当调用方法时，程序控制权转移至被调用的方法。当执行return语句或到达方法结尾时，程序控制权转移至调用者。</li><li>调用当前类中的静态方法：可直接用“方法名”，也可用”类名.方法名“；实例函数中也可用” 方法名“或”this.方法名“调用。</li><li>调用其它类中的静态方法：必须用”类名.方法名“或”对象.方法名“调用；子类实例函数也可用” super.方法名“调用父类方法。</li><li>所有静态方法提倡用”类名.方法名“调用。如<code>Math.sin(3.0)</code></li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestMax</span> </span>&#123;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line"><span class="keyword">int</span> i = <span class="number">5</span>;</span><br><span class="line"><span class="keyword">int</span> j = <span class="number">2</span>;</span><br><span class="line"><span class="keyword">int</span> k = max(i, j);</span><br><span class="line">System.out.println(<span class="string">"The maximum between "</span> + i + <span class="string">" and "</span> + j + <span class="string">" is "</span> + k);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">max</span><span class="params">(<span class="keyword">int</span> num1, <span class="keyword">int</span> num2)</span> </span>&#123;</span><br><span class="line"><span class="keyword">int</span> result;</span><br><span class="line">result = (num1 &gt; num2) ?num1:num2;</span><br><span class="line"><span class="keyword">return</span> result ;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="调用程序栈"><a href="#调用程序栈" class="headerlink" title="调用程序栈"></a>调用程序栈</h2><p>每当调用一个方法时，系统将参数、局部变量存储在一个内存区域中，这个内存区域称为调用堆栈(call stack)。当方法结束返回到调用者时，系统自动释放相应的调用栈。</p><div align = center><img src = "https://img.vim-cn.com/9c/1276a008ebc0f1d635060c80096666064be1de.png"></div><h2 id="方法的参数传递"><a href="#方法的参数传递" class="headerlink" title="方法的参数传递"></a>方法的参数传递</h2><ul><li><p>如果方法声明中包含形参，调用方法时，必须提供实参。<br>实参的类型必须与形参的类型兼容：如父类形参可用子类实参。<br>实参顺序必须与形参的顺序一致。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">nPrintln</span><span class="params">(String message, <span class="keyword">int</span> n)</span> </span>&#123;  </span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n; i++)</span><br><span class="line">    System.out.println(message);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">nPrintln(“Hello”, <span class="number">3</span>); <span class="comment">//正确</span></span><br><span class="line">nPrintln(<span class="number">3</span>, “Hello”); <span class="comment">//错误</span></span><br></pre></td></tr></table></figure></li><li><p>当调用方法时，基本数据类型的实参值的副本被传递给方法的形参。方法内部对形参的修改不影响实参值。(Call by value)<br>对象类型的参数是引用调用（Call by reference）</p></li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestPassByValue</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line"><span class="keyword">int</span> num1 = <span class="number">1</span>;</span><br><span class="line"><span class="keyword">int</span> num2 = <span class="number">2</span>;</span><br><span class="line">System.out.println(<span class="string">"调用swap方法之前：num1 = "</span> + num1 + <span class="string">"，num2 = "</span> + num2);</span><br><span class="line"></span><br><span class="line">swap(num1, num2);</span><br><span class="line">System.out.println(<span class="string">"调用swap方法之后：num1 = "</span> + num1 + <span class="string">"，num2 = "</span> + num2);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">swap</span><span class="params">(<span class="keyword">int</span> n1, <span class="keyword">int</span> n2)</span> </span>&#123;</span><br><span class="line">System.out.println(<span class="string">"\t在swap方法内："</span>);</span><br><span class="line">System.out.println(<span class="string">"\t\t交换之前：n1 = "</span> + n1 + <span class="string">"，n2 = "</span> + n2);</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> temp = n1;</span><br><span class="line">n1 = n2;</span><br><span class="line">n2 = temp;</span><br><span class="line"></span><br><span class="line">System.out.println(<span class="string">"\t\t交换之后：n1 = "</span> + n1 + <span class="string">"，n2 = "</span> + n2);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="方法的重载"><a href="#方法的重载" class="headerlink" title="方法的重载"></a>方法的重载</h2><ul><li>方法重载(overloading)是指方法名称相同，但方法签名不同的方法，仅返回类型不同的方法不可重载。一个类中可以包含多个重载的方法。</li><li>当调用方法时，Java编译器会根据实参的个数和类型寻找最合适的方法进行调用。</li><li>调用时匹配成功的方法可能多于一个，则会产生编译二义性错误，称为歧义调用(ambiguous invocation）</li></ul><p><strong>重载示例</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestMethodOverloading</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="comment">/** Return the max between two int values */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">max</span><span class="params">(<span class="keyword">int</span> num1, <span class="keyword">int</span> num2)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestMethodOverloading</span> </span>&#123;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">/** Return the max between two int values */</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">max</span><span class="params">(<span class="keyword">int</span> num1, <span class="keyword">int</span> num2)</span> </span>&#123;</span><br><span class="line">                    <span class="keyword">return</span> (num1 &gt; num2) ？num1:num2; </span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">/** Return the max between two double values */</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">double</span> <span class="title">max</span><span class="params">(<span class="keyword">double</span> num1, <span class="keyword">double</span> num2)</span> </span>&#123;</span><br><span class="line">                    <span class="keyword">return</span> (num1 &gt; num2) ？num1:num2;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment">/** Return the max among three double values */</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">double</span> <span class="title">max</span><span class="params">(<span class="keyword">double</span> num1, <span class="keyword">double</span> num2, <span class="keyword">double</span> num3)</span> </span>&#123;</span><br><span class="line">                    <span class="keyword">return</span> max(max(num1, num2), num3);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestMethodOverloading</span> </span>&#123;</span><br><span class="line"> <span class="comment">/** Main method */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[ ] args)</span> </span>&#123;</span><br><span class="line"><span class="comment">// Invoke the max method with int parameters</span></span><br><span class="line">System.out.println(<span class="string">"The maximum between 3 and 4 is "</span></span><br><span class="line">+ max(<span class="number">3</span>, <span class="number">4</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">// Invoke the max method with the double parameters</span></span><br><span class="line">System.out.println(<span class="string">"The maximum between 3.0 and 5.4 is "</span> </span><br><span class="line">+ max(<span class="number">3.0</span>, <span class="number">5.4</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">// Invoke the max method with three double parameters</span></span><br><span class="line">System.out.println(<span class="string">"The maximum between 3.0, 5.4, and 10.14 is "</span> </span><br><span class="line">+ max(<span class="number">3.0</span>, <span class="number">5.4</span>, <span class="number">10.14</span>));</span><br><span class="line">&#125; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>有歧义的重载</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">AmbiguousOverloading</span> </span>&#123;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[ ] args)</span> </span>&#123;</span><br><span class="line"><span class="comment">//System.out.println(max(1, 2));  //该调用产生歧义</span></span><br><span class="line">        &#125;        <span class="comment">//以下任一函数的参数都相容（都能自动转换），编译无法确定用哪个函数</span></span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">double</span> <span class="title">max</span><span class="params">(<span class="keyword">int</span> num1, <span class="keyword">double</span> num2)</span> </span>&#123;</span><br><span class="line"><span class="keyword">if</span> (num1 &gt; num2)</span><br><span class="line"><span class="keyword">return</span> num1;</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line"><span class="keyword">return</span> num2;</span><br><span class="line">        &#125;</span><br><span class="line">       <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">double</span> <span class="title">max</span><span class="params">(<span class="keyword">double</span> num1, <span class="keyword">int</span> num2)</span> </span>&#123;</span><br><span class="line"><span class="keyword">if</span> (num1 &gt; num2)</span><br><span class="line"><span class="keyword">return</span> num1;</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line"><span class="keyword">return</span> num2;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="局部变量的作用域"><a href="#局部变量的作用域" class="headerlink" title="局部变量的作用域"></a>局部变量的作用域</h2><p>方法内部声明的变量称为局部变量(local variable)。<br>局部变量的作用域(scope)指程序中可以使用该变量的部分。局部变量的生命期和其作用域相同。<br>局部变量的作用域从它的声明开始，直到包含该变量的程序块结束。局部变量在使用前必须先赋值。<br>在方法中，可以在不同的非嵌套程序块中以相同的名称多次声明局部变量。但不能在嵌套的块中以相同的名称多次声明局部变量：无法访问外部块变量。<br>在for语句的初始动作部分声明的变量，作用域是整个循环。在for语句循环体中声明的变量，作用域从变量声明开始到循环体结束</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestLocalVariable</span> </span>&#123;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">method1</span><span class="params">( )</span> </span>&#123;</span><br><span class="line"><span class="keyword">int</span> x = <span class="number">1</span>; <span class="keyword">int</span> y = <span class="number">1</span>;</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt; <span class="number">10</span>; i++) &#123;</span><br><span class="line">x += i;  </span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt; <span class="number">10</span>; i++) &#123;</span><br><span class="line">y += i;              <span class="comment">//正确：两个循环未嵌套，都可用i</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//错误，变量i在嵌套的语句块中声明</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">method2</span><span class="params">( )</span> </span>&#123;</span><br><span class="line"><span class="comment">//int i = 1;</span></span><br><span class="line"><span class="comment">//int sum = 0;</span></span><br><span class="line"><span class="comment">//for (int i = 1; i &lt; 10; i++) &#123;//java不允许函数的局部变量或参数的作用域被覆盖</span></span><br><span class="line"><span class="comment">//sum += i;          //无法访问外部块局部变量</span></span><br><span class="line"><span class="comment">//&#125;</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>全局变量的声明与使用</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span>  <span class="class"><span class="keyword">class</span> <span class="title">args</span> </span>&#123;  </span><br><span class="line">     <span class="keyword">public</span> <span class="keyword">static</span> String username; <span class="comment">// 全局变量</span></span><br><span class="line">     <span class="keyword">public</span> <span class="keyword">static</span> String password; <span class="comment">//全局变量</span></span><br><span class="line">&#125;</span><br><span class="line">&gt;&gt; args.username</span><br><span class="line">&gt;&gt; args.password</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;方法&quot;&gt;&lt;a href=&quot;#方法&quot; class=&quot;headerlink&quot; title=&quot;方法&quot;&gt;&lt;/a&gt;方法&lt;/h1&gt;&lt;h2 id=&quot;方法的定义&quot;&gt;&lt;a href=&quot;#方法的定义&quot; class=&quot;headerlink&quot; title=&quot;方法的定义&quot;&gt;&lt;/a&gt;方法的定
      
    
    </summary>
    
    
      <category term="java" scheme="https://shyshy903.github.io/categories/java/"/>
    
    
      <category term="java" scheme="https://shyshy903.github.io/tags/java/"/>
    
  </entry>
  
  <entry>
    <title>Java学习笔记（四）</title>
    <link href="https://shyshy903.github.io/2020/02/11/java/shyjava(4)/"/>
    <id>https://shyshy903.github.io/2020/02/11/java/shyjava(4)/</id>
    <published>2020-02-11T08:48:55.599Z</published>
    <updated>2020-02-11T08:48:55.599Z</updated>
    
    <content type="html"><![CDATA[<h1 id="循环"><a href="#循环" class="headerlink" title="循环"></a>循环</h1><h2 id="while循环"><a href="#while循环" class="headerlink" title="while循环"></a>while循环</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> i = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">while</span> (i &lt; <span class="number">100</span>) &#123;</span><br><span class="line">    System.out.println(“Welcome to Java!”);</span><br><span class="line">    i++;     <span class="comment">//必须有语句改变循环条件</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="do-while循环"><a href="#do-while循环" class="headerlink" title="do while循环"></a>do while循环</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">循环体至少执行一次</span></span><br><span class="line"><span class="string">"</span><span class="string">""</span></span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">statement or block</span><br><span class="line"><span class="keyword">while</span> (loop-continuation-condition);</span><br></pre></td></tr></table></figure><h2 id="for-循环"><a href="#for-循环" class="headerlink" title="for 循环"></a>for 循环</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">100</span>; i++) &#123;</span><br><span class="line">    System.out.println(“Welcome to Java!”);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span>循环头中的每个部分可以是零个或多个以逗句分隔的表达式。</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>, j = <span class="number">0</span>; i + j &lt; <span class="number">10</span>; i++, j++) &#123;</span><br><span class="line">    System.out.println(“Welcome to Java!”);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">如果<span class="keyword">for</span>循环中的loop-continuation-condition被省略，则隐含为真。</span><br><span class="line"><span class="keyword">for</span> (;;) &#123;                   <span class="keyword">while</span>(<span class="keyword">true</span>) &#123;</span><br><span class="line">    <span class="comment">//do something  等价于        //do something</span></span><br><span class="line">&#125;                            &#125;</span><br></pre></td></tr></table></figure><h2 id="break-与-continue"><a href="#break-与-continue" class="headerlink" title="break 与 continue"></a>break 与 continue</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">break</span> <span class="comment">//跳出循环</span></span><br><span class="line"><span class="keyword">continue</span> <span class="comment">//跳出当前循环，继续循环</span></span><br></pre></td></tr></table></figure><h2 id="JDK1-5-增强的for循环"><a href="#JDK1-5-增强的for循环" class="headerlink" title="JDK1.5 增强的for循环"></a>JDK1.5 增强的for循环</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">JDK <span class="number">1.5</span>引入新的<span class="keyword">for</span>循环，可以不用下标就可以依次访问数组元素。语法：</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span>(elementType value : arrayRefVar) &#123;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">例如</span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; myList.length; i++) &#123;</span><br><span class="line"> sum += myList[i];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">double</span> value : myList) &#123;</span><br><span class="line">sum += value;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;循环&quot;&gt;&lt;a href=&quot;#循环&quot; class=&quot;headerlink&quot; title=&quot;循环&quot;&gt;&lt;/a&gt;循环&lt;/h1&gt;&lt;h2 id=&quot;while循环&quot;&gt;&lt;a href=&quot;#while循环&quot; class=&quot;headerlink&quot; title=&quot;while循环&quot;&gt;&lt;/
      
    
    </summary>
    
    
      <category term="java" scheme="https://shyshy903.github.io/categories/java/"/>
    
    
      <category term="java" scheme="https://shyshy903.github.io/tags/java/"/>
    
  </entry>
  
  <entry>
    <title>Java学习笔记（三）</title>
    <link href="https://shyshy903.github.io/2020/02/11/java/shyjava(3)/"/>
    <id>https://shyshy903.github.io/2020/02/11/java/shyjava(3)/</id>
    <published>2020-02-11T08:48:55.595Z</published>
    <updated>2020-02-11T08:48:55.596Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Shy-Learnjava（3）基础"><a href="#Shy-Learnjava（3）基础" class="headerlink" title="Shy-Learnjava（3）基础"></a>Shy-Learnjava（3）基础</h1><h2 id="3-数学函数、字符与字符串"><a href="#3-数学函数、字符与字符串" class="headerlink" title="3 数学函数、字符与字符串"></a>3 数学函数、字符与字符串</h2><h3 id="3-1-数学函数"><a href="#3-1-数学函数" class="headerlink" title="3.1 数学函数"></a>3.1 数学函数</h3><p><strong>Math是final类：在java.lang.Math中，所有数学函数都是静态方法</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># Math类中定义了常用的数学常量，如</span><br><span class="line">PI : <span class="number">3.14159265358979323846</span></span><br><span class="line">E : <span class="number">2.7182818284590452354</span></span><br><span class="line"># 方法:注意都是静态函数</span><br><span class="line"># 三角函数</span><br><span class="line">sin, cos, tan, asin, acos, atan,toRadians,toDigrees</span><br><span class="line"># 指数</span><br><span class="line">exp, log, log10，pow, sqrt</span><br><span class="line"># 取整</span><br><span class="line">ceil, floor, round</span><br><span class="line"># 其它</span><br><span class="line">min, max, abs, random（[<span class="number">0.0</span>,<span class="number">1.0</span>))</span><br></pre></td></tr></table></figure><p><strong>Math.random方法生成[0.0,1.0)之间的double类型的随机数</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">如：</span><br><span class="line">（<span class="keyword">int</span>）(Math.random( )*<span class="number">10</span>);<span class="comment">//[0,10)</span></span><br><span class="line"><span class="number">50</span>+(<span class="keyword">int</span>)(Math.random( )*<span class="number">50</span>);<span class="comment">//[50,100)</span></span><br><span class="line">一般地</span><br><span class="line">a+(<span class="keyword">int</span>)(Math.random( )*b)              <span class="comment">//返回[a, a+b)</span></span><br><span class="line">a+(<span class="keyword">int</span>)(Math.random( )*（b+<span class="number">1</span>）)       <span class="comment">//返回[a, a+b]</span></span><br></pre></td></tr></table></figure><p><strong>编写生成随机字符的方法</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">Java中每个字符对应一个Unicode编码从<span class="number">0000</span>到FFFF。  </span><br><span class="line">在生成一个随机字符，就是产生一个从<span class="number">0</span>到<span class="number">65535</span>之间的随机数。  </span><br><span class="line">所以, 计算表达式为：</span><br><span class="line"></span><br><span class="line">(<span class="keyword">int</span>)(Math.random( ) * (<span class="number">65535</span> + <span class="number">1</span>)) 。</span><br><span class="line"></span><br><span class="line">英文大、小写字母的Unicode是一串连续的整数，如</span><br><span class="line">‘a’的统一码是:   </span><br><span class="line">(<span class="keyword">int</span>)‘a’=<span class="number">97</span></span><br><span class="line">由于<span class="keyword">char</span>类型可自动地被转换为<span class="keyword">int</span>类型，所以我们可以对应使用如下整数值：</span><br><span class="line">‘a’=<span class="number">97</span>, ‘b’=<span class="number">98</span>， …, ‘z’=<span class="number">122</span></span><br><span class="line"></span><br><span class="line">因此，随机生成从‘a’-‘z’之间的字符就等于生成‘a’-‘z’之间的随机数，可用</span><br><span class="line">‘a’+（<span class="keyword">int</span>）(Math.Random( ) * (‘z’-’a’+<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">将上面讨论一般化，按如下表达式，可以生成任意<span class="number">2</span>个字符ch1和ch2（ch1&lt;ch2）之间的随机字符</span><br><span class="line"></span><br><span class="line">(<span class="keyword">char</span>)(ch1+(<span class="keyword">int</span>)(Math.rabdom()*(ch2-ch1+<span class="number">1</span>)))</span><br></pre></td></tr></table></figure><h3 id="3-2-字符数据类型"><a href="#3-2-字符数据类型" class="headerlink" title="3.2 字符数据类型"></a>3.2 字符数据类型</h3><p><strong>Unicode和ASCII码</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Java对字符采用<span class="number">16</span>位Unicode编码，因此<span class="keyword">char</span>类型的大小为二个字节</span><br><span class="line"><span class="number">16</span>位的Unicode用以\u开头的<span class="number">4</span>位<span class="number">16</span>进制数表示，范围从’\u0000’到’\uffff’,不能少写位数</span><br><span class="line">Unicode包括ASCII码，从’\u0000’到’\u007f’对应<span class="number">128</span>个ASCII字符</span><br><span class="line">JAVA中的ASCII字符也可以用Unicode表示，例如</span><br><span class="line"><span class="keyword">char</span> letter = ‘A’；</span><br><span class="line"><span class="keyword">char</span> letter = ‘\u0041’；<span class="comment">//等价，\u后面必须写满4位16进制数</span></span><br><span class="line">++和--运算符也可以用在<span class="keyword">char</span>类型数据上，运算结果为该字符之后或之前的字符，例如下面的语句显示字符b</span><br><span class="line"><span class="keyword">char</span> ch = ‘a’;</span><br><span class="line">System.out.println(++ch);  <span class="comment">//显示b</span></span><br></pre></td></tr></table></figure><p><strong>特殊字符转义</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">和C++一样，采用反斜杠(\)后面加上一个字符或者一些数字位组成转义序列，一个转义序列被当做一个字符</span><br><span class="line">如\n  \t  \b  \r  \f  \\  \<span class="string">'  \"</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">如果想打印带””的信息 He said “Java is fun “</span></span><br><span class="line"><span class="string">System.out.println(“He said \”Java is fun \””);</span></span><br></pre></td></tr></table></figure><p><strong>字符型和数据型的转换</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">char</span>类型数据可以转换成任意一种数值类型，反之亦然。将整数转换成<span class="keyword">char</span>类型数据时，只用到该数据的低<span class="number">16</span>位，其余被忽略。例如</span><br><span class="line"><span class="keyword">char</span> ch = （<span class="keyword">char</span>）<span class="number">0xAB0041</span>；</span><br><span class="line">       System.out.println(ch);<span class="comment">//显示A</span></span><br><span class="line">要将浮点数转成<span class="keyword">char</span>时，先把浮点数转成<span class="keyword">int</span>型，然后将整数转换成<span class="keyword">char</span></span><br><span class="line">       <span class="keyword">char</span> ch = （<span class="keyword">char</span>）<span class="number">65.25</span>；</span><br><span class="line">       System.out.println(ch);<span class="comment">//显示A</span></span><br><span class="line">当一个<span class="keyword">char</span>型转换成数值型时，这个字符的Unicode码就被转换成某种特定数据类型</span><br><span class="line">       <span class="keyword">int</span> i = （<span class="keyword">int</span>）‘A’；</span><br><span class="line">       System.out.println(i);<span class="comment">//显示65</span></span><br><span class="line"></span><br><span class="line">如果转换结果适用于目标变量（不会有精度损失），可以采用隐式转换；否则必须强制类型转换</span><br><span class="line"> <span class="keyword">int</span> i = ‘A’；</span><br><span class="line"> <span class="keyword">byte</span> b = （<span class="keyword">byte</span>）‘\uFFF4’;  <span class="comment">//取低8位二进制数</span></span><br><span class="line">所有数值运算符都可以用在<span class="keyword">char</span>型操作数上，  </span><br><span class="line">如果另一个操作数是数值，那么<span class="keyword">char</span>型操作数就自动转换为数值；  </span><br><span class="line">如果另外一个操作数是字符串，那么<span class="keyword">char</span>型操作数会自动转换成字符串再和另外一个操作数字符串相连</span><br><span class="line">      <span class="keyword">int</span> i = ‘<span class="number">2</span>’+ ‘<span class="number">3</span>’;</span><br><span class="line">      System.out.println（i）；  <span class="comment">// i为50+51=101</span></span><br><span class="line">      <span class="keyword">int</span> j = <span class="number">2</span> + ‘a’；       <span class="comment">//j = 99</span></span><br><span class="line">      System.out.println(j + “ is the Unicode of ”+ (<span class="keyword">char</span>)j);<span class="comment">//99 is the Unicode of  c</span></span><br></pre></td></tr></table></figure><p><strong>字符的比较测试</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">两个字符可以通过关系运算符进行比较，如同比较二个数值：通过字符的Unicode值进行比较</span><br><span class="line">Java为每个基本类型实现了对应的包装类，<span class="keyword">char</span>类型的包装类是Character类。注意包装类对象为引用类型，不是值类型</span><br><span class="line">Character类的作用</span><br><span class="line">将<span class="keyword">char</span>类型的数据封装成对象</span><br><span class="line">包含处理字符的方法和常量</span><br><span class="line">方法</span><br><span class="line">isDigit方法判断一个字符是否是数字</span><br><span class="line">isLetter方法判断一个字符是否是字母</span><br><span class="line">isLetterOrDigit方法判断一个字符是否是字母或数字</span><br><span class="line">isLowerCase方法判断一个字符是否是小写</span><br><span class="line">isUpperCase方法判断一个字符是否是大写</span><br><span class="line">toLowerCase方法将一个字符转换成小写</span><br><span class="line">toUpperCase方法将一个字符转换成大写</span><br></pre></td></tr></table></figure><h2 id="3-3-String-类，一个final类"><a href="#3-3-String-类，一个final类" class="headerlink" title="3.3 String 类，一个final类"></a>3.3 String 类，一个final类</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">java.lang.String表示一个固定长度的字符序列，实例化后字符不能改。</span><br><span class="line">构造函数</span><br><span class="line">长度(length)</span><br><span class="line">获取字符(charAt)</span><br><span class="line">连接(concat)</span><br><span class="line">截取(substring)</span><br><span class="line">比较(equals, equalsIgnoreCase, compareTo, startWith),</span><br><span class="line">endWith, regionMatch)</span><br><span class="line">转换(toLowerCase, toUpperCase, trim, replace)</span><br><span class="line">查找(indexOf, lastIndexOf)</span><br><span class="line">字符串和数组间转换(getChars, toCharArray), getChars返回<span class="keyword">void</span>,超出长度就异常</span><br><span class="line">字符串和数字间转换(valueOf)</span><br></pre></td></tr></table></figure><p><strong>String类对象的构造</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">从字面值创建字符串</span><br><span class="line">String newString = <span class="keyword">new</span> String(stringLiteral);</span><br><span class="line">例如：</span><br><span class="line">String message = <span class="keyword">new</span> String(<span class="string">"Welcome to Java"</span>);</span><br><span class="line">由于字符串经常使用，java提供了创建字符串的简写形式。</span><br><span class="line">String newString = stringLiteral;</span><br><span class="line">例如：</span><br><span class="line">String m1 = “Welcome”;  <span class="comment">//m1和m2中的字符都是不可修改的</span></span><br><span class="line">String m2 = “Welcome”;  <span class="comment">//故m1和m2可以优化引用同一常量：m1==m2</span></span><br><span class="line">String m3 = <span class="string">"Wel"</span> +<span class="string">"come"</span>;<span class="comment">//m1==m2==m3  </span></span><br><span class="line">String m4 = <span class="string">"Wel"</span> +<span class="keyword">new</span> String(<span class="string">"come"</span>); <span class="comment">//m1!=m4</span></span><br><span class="line"></span><br><span class="line">字符串对象创建之后，其内容是不可修改的。</span><br><span class="line">String s = “java”;</span><br><span class="line">s = “HTML”;</span><br><span class="line">String t =s;</span><br></pre></td></tr></table></figure><p><strong>字符串的比较</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">equals方法用于比较两个字符串是否包含相同的内容（字符序列）:</span><br><span class="line">两个字符串内容相同，返回<span class="keyword">true</span></span><br><span class="line">两个字符串内容不同，返回<span class="keyword">false</span></span><br><span class="line">比较字符串内容不能直接比较二个引用变量，比较二个引用变量只是判断这二个引用变量是否指向同一个对象</span><br><span class="line">equalsIngnoeCase忽略大小写比较内容是否相同</span><br><span class="line">regionMatch比较部分内容是否相同</span><br><span class="line">startsWith判断是否以某个字符串开始</span><br><span class="line">endsWith判断是否以某个字符串结束</span><br><span class="line">compareTo方法用于比较两个字符串的大小，即第一个不同字符的差值。s1.compareTo(s2)的返回值:</span><br><span class="line">当两个字符串相同时，返回０</span><br><span class="line">当s1按字典排序在s2之前，返回小于０的值</span><br><span class="line">当s1按字典排序在s2之后，返回大于０的值</span><br><span class="line">String s0 = <span class="string">"Java"</span>;</span><br><span class="line">String s1 = <span class="string">"Welcome to "</span> + s0;</span><br><span class="line">String s2 = <span class="string">"Welcome to Java"</span>;</span><br><span class="line">String s3 = <span class="string">"welcome to java"</span>;</span><br><span class="line">String s6 = <span class="string">"Welcome to Java"</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// equals用于比较两个字符串的内容是否相同</span></span><br><span class="line">System.out.println(<span class="string">"s1.equals(s2) is "</span> + s1.equals(s2)); <span class="comment">//true</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// equalsIgnoreCase忽略大小写</span></span><br><span class="line">System.out.println(<span class="string">"s2.equals(s3) is "</span> + s2.equals(s3)); <span class="comment">//false</span></span><br><span class="line">System.out.println(<span class="string">"s2.equalsIgnoreCase(s3) is "</span> + s2.equalsIgnoreCase(s3)); <span class="comment">//true</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// regionMatches比较部分字符串: 给定两个串的起始位置和长度</span></span><br><span class="line">System.out.println(<span class="string">"s2.regionMatches(11, s0, 0, 4) is "</span> + s2.regionMatches(<span class="number">11</span>, s0, <span class="number">0</span>, <span class="number">4</span>)); <span class="comment">//true</span></span><br><span class="line">System.out.println(<span class="string">"s3.regionMatches(11, s0, 0, 4) is "</span> + s3.regionMatches(<span class="number">11</span>, s0, <span class="number">0</span>, <span class="number">4</span>));<span class="comment">//false</span></span><br><span class="line">System.out.println(<span class="string">"s3.regionMatches(true, 11, s0, 0, 4) is "</span> + s3.regionMatches(<span class="keyword">true</span>, <span class="number">11</span>, s0, <span class="number">0</span>, <span class="number">4</span>));<span class="comment">//true,忽略大小写</span></span><br><span class="line">String s0 = <span class="string">"Java"</span>;</span><br><span class="line">String s1 = <span class="string">"Welcome to "</span> + s0;</span><br><span class="line">String s2 = <span class="string">"Welcome to Java"</span>;</span><br><span class="line">String s3 = <span class="string">"welcome to java"</span>;</span><br><span class="line">String s6 = <span class="string">"Welcome to Java"</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// startsWith判断是否以某个字符串开始</span></span><br><span class="line"><span class="comment">// endsWith判断是否以某个字符串结束</span></span><br><span class="line">System.out.println(<span class="string">"s2.startsWith(s0) is "</span> + s2.startsWith(s0));<span class="comment">//false</span></span><br><span class="line">System.out.println(<span class="string">"s2.endsWith(s0) is "</span> + s2.endsWith(s0));  <span class="comment">//true</span></span><br><span class="line">        </span><br><span class="line"><span class="comment">// compareTo根据字典排序比较两个字符串</span></span><br><span class="line">String s4 = <span class="string">"abc"</span>;</span><br><span class="line">String s5 = <span class="string">"abe"</span>;</span><br><span class="line">System.out.println(<span class="string">"s4.compareTo(s5) is "</span> + s4.compareTo(s5));<span class="comment">//-2</span></span><br></pre></td></tr></table></figure><p><strong>字符串方法</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">调用length( )方法可以获取字符串的长度。</span><br><span class="line">例如：</span><br><span class="line">message.length( )返回<span class="number">15</span></span><br><span class="line">charAt(index)方法可以获取指定位置的字符。index必须在<span class="number">0</span>到s.length()-<span class="number">1</span>之间。</span><br><span class="line">例如：</span><br><span class="line">message.charAt(<span class="number">0</span>)返回字符’W’</span><br><span class="line">concat方法用于连接两个字符串。例如：</span><br><span class="line">String s3 = s1.concat(s2);</span><br><span class="line">使用加号(+)连接两个字符串。例如：</span><br><span class="line">String s3 = s1 + s2;</span><br><span class="line">s1 + s2 + s3 等价于s1.concat(s2).concat(s3)</span><br><span class="line">连接操作返回一个新的字符串：因为String类型的实例不可修改。</span><br><span class="line">substring用于截取字符串的一部分，返回新字符串。</span><br><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">substring</span><span class="params">(<span class="keyword">int</span> beginIndex, <span class="keyword">int</span> endIndex)</span></span></span><br><span class="line"><span class="function">返回字符串的子串。子串从beginIndex开始，直到endIndex-1</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">substring</span><span class="params">(<span class="keyword">int</span> beginIndex)</span></span></span><br><span class="line"><span class="function">返回字符串的子串。子串从beginIndex开始，直到字符串的结尾。</span></span><br><span class="line"><span class="function">toLowerCase将字符串转换成小写形式，得到新串</span></span><br><span class="line"><span class="function">toUpperCase将字符串转换成大写形式，得到新串</span></span><br><span class="line"><span class="function">trim删除两端的空格，得到新串</span></span><br><span class="line"><span class="function">replace字符替换，得到新串</span></span><br><span class="line"><span class="function">String s0 </span>= <span class="string">"Java"</span>;</span><br><span class="line">String s1 = <span class="string">" Welcome to Java "</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// toLowerCase将字符串转换成小写形式</span></span><br><span class="line">System.out.println(<span class="string">"s1.toLowerCase() is "</span> + s1.toLowerCase());</span><br><span class="line">        </span><br><span class="line"><span class="comment">// toUpperCase将字符串转换成大写形式</span></span><br><span class="line">System.out.println(<span class="string">"s1.toUpperCase() is "</span> + s1.toUpperCase());</span><br><span class="line">        </span><br><span class="line"><span class="comment">// trim删除两端的空格</span></span><br><span class="line">System.out.println(<span class="string">"s1.trim() is "</span> + s1.trim( ));</span><br><span class="line">        </span><br><span class="line"><span class="comment">// replace字符替换</span></span><br><span class="line">System.out.println(“s1.replace(s0, \”HTML\“) is ” + s1.replace(s0, “HTML”)); <span class="comment">//Welcome to HTML</span></span><br><span class="line"><span class="comment">// indexOf返回字符串中字符或字符串匹配的位置，返回-1表示未找到。</span></span><br><span class="line"><span class="string">"Welcome to Java"</span>.indexOf(<span class="string">'W'</span>) returns <span class="number">0</span></span><br><span class="line"><span class="string">"Welcome to Java"</span>.indexOf(<span class="string">'x'</span>) returns -<span class="number">1</span></span><br><span class="line"><span class="string">"Welcome to Java"</span>.indexOf(<span class="string">'o‘,5) returns 9</span></span><br><span class="line"><span class="string">"Welcome to Java".indexOf("come") returns 3</span></span><br><span class="line"><span class="string">"Welcome to Java".indexOf("Java", 5) returns 11</span></span><br><span class="line"><span class="string">"Welcome to Java".indexOf("java", 5) returns -1</span></span><br><span class="line"><span class="string">"Welcome to Java".lastIndexOf('</span>a<span class="string">') returns 14</span></span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">toCharArray将字符串转换成字符数组</span><br><span class="line">String s = “Java”;</span><br><span class="line"><span class="keyword">char</span>[ ] charArray = s.toCharArray( );<span class="comment">// charArray.length=4</span></span><br><span class="line">将字符数组转换成字符串</span><br><span class="line">使用String的构造函数，可同时初始化</span><br><span class="line"><span class="keyword">new</span> String(<span class="keyword">new</span> <span class="keyword">char</span>[ ] &#123;‘J’,‘a’,‘v’,‘a’&#125; );</span><br><span class="line">使用valueOf方法</span><br><span class="line">String.valueOf(<span class="keyword">new</span> <span class="keyword">char</span>[ ] &#123;‘J’,‘a’,‘v’,‘a’&#125;);</span><br><span class="line">String.valueOf(<span class="number">2.34</span>);</span><br><span class="line">valueOf方法将基本数据类型转换为字符串。例如</span><br><span class="line">String s1 = String.valueOf(<span class="number">1.0</span>);  <span class="comment">//“１.0”</span></span><br><span class="line">String s2 = String.valueOf(<span class="keyword">true</span>); <span class="comment">//“true”</span></span><br><span class="line">字符串转换为基本类型</span><br><span class="line">Double.parseDouble(str)</span><br><span class="line">Integer.parseInt(str)</span><br><span class="line">Boolean.parseBoolean(str)</span><br><span class="line">回文是指顺读和倒读都一样的词语。例如“mom”,  “dad”, ”noon”都是回文。编写程序，判断一个字符串是否是回文。</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CheckPalindrome</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">boolean</span> <span class="title">isPalindrome</span><span class="params">(String s)</span> </span>&#123;</span><br><span class="line"><span class="comment">// The index of the first character in the string</span></span><br><span class="line"><span class="keyword">int</span> low = <span class="number">0</span>;</span><br><span class="line"><span class="comment">// The index of the last character in the string</span></span><br><span class="line"><span class="keyword">int</span> high = s.length( ) - <span class="number">1</span>;</span><br><span class="line"><span class="keyword">while</span> (low &lt; high) &#123;</span><br><span class="line"><span class="keyword">if</span> (s.charAt(low) != s.charAt(high)) <span class="keyword">return</span> <span class="keyword">false</span>; <span class="comment">// Not a palindrome</span></span><br><span class="line">low++;</span><br><span class="line">high--;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> <span class="keyword">true</span>; <span class="comment">// The string is a palindrome</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CheckPalindrome</span> </span>&#123;</span><br><span class="line"><span class="comment">/** Main method */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line"><span class="comment">// Prompt the user to enter a string</span></span><br><span class="line">String s = JOptionPane.showInputDialog(<span class="string">"Enter a string:"</span>);</span><br><span class="line">String output = <span class="string">""</span>;</span><br><span class="line"><span class="keyword">if</span> (isPalindrome(s))</span><br><span class="line">output = s + <span class="string">" is a palindrome"</span>;</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">output = s + <span class="string">" is not a palindrome"</span>;</span><br><span class="line"><span class="comment">// Display the result</span></span><br><span class="line">JOptionPane.showMessageDialog(<span class="keyword">null</span>, output);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>StringBuilder与StringBuffer</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line">String类一旦初始化完成，字符串就是不可修改的。</span><br><span class="line">StringBuilder与StringBuffer(<span class="keyword">final</span>类）初始化后还可以修改字符串。</span><br><span class="line">StringBuffer修改缓冲区的方法是同步的，更适合多任务环境。</span><br><span class="line">StringBuilder在单任务模式下与StringBuffer工作机制类似。</span><br><span class="line">由于可修改字符串， StringBuilder 与StringBuffer 增加了String类没有的一些函数，例如：append、insert、delete、replace、reverse、setCharAt等。</span><br><span class="line">仅以StringBuilder为例：</span><br><span class="line">StringBuilder  stringMy=<span class="keyword">new</span> StringBuilder( );</span><br><span class="line">StringMy.append(“Welcome to”);</span><br><span class="line">      StringMy.append(“ Java”);</span><br><span class="line">StringBuffer用于处理可变内容的字符串。</span><br><span class="line">append方法在字符串的结尾追加数据</span><br><span class="line">insert方法在指定位置上插入数据</span><br><span class="line">reverse方法翻转字符串</span><br><span class="line">replace方法替换字符</span><br><span class="line">toString方法返回String对象</span><br><span class="line">capacity方法返回缓冲区的容量</span><br><span class="line">length方法返回缓冲区中字符的个数</span><br><span class="line">setLength方法设置缓冲区的长度</span><br><span class="line">charAt方法返回指定位置的字符</span><br><span class="line">setCharAt方法设置指定位置的字符</span><br><span class="line">所有对StringBuffer对象内容进行修改的方法，都返回指向相同StringBuffer对象的引用</span><br><span class="line">StringBuffer bf = <span class="keyword">new</span> StringBuffer();</span><br><span class="line">StringBuffer bf1 = bf.append(<span class="string">"Welcome "</span>); </span><br><span class="line">StringBuffer bf2 = bf.append(<span class="string">"to "</span>);</span><br><span class="line">StringBuffer bf3 = bf.append(<span class="string">"Java"</span>);</span><br><span class="line"><span class="keyword">assert</span>(bf==bf1 &amp;&amp; bf==bf2 &amp;&amp; bf == bf3);</span><br><span class="line">因此以上语句可以直接写成：</span><br><span class="line">bf.append(<span class="string">"Welcome "</span>).append(<span class="string">"to "</span>).append(<span class="string">"Java"</span>);</span><br><span class="line"><span class="comment">// 追加</span></span><br><span class="line">StringBuffer bf = <span class="keyword">new</span> StringBuffer();</span><br><span class="line">bf.append(“Welcome”);</span><br><span class="line">bf.append(‘ ‘);</span><br><span class="line">bf.append(“to ”);</span><br><span class="line">bf.append(“Java”);</span><br><span class="line">System.out.println(bf.toString()); <span class="comment">//Welcome to Java</span></span><br><span class="line"><span class="comment">//插入</span></span><br><span class="line">bf.insert(<span class="number">11</span>,”HTML and ”) <span class="comment">//Welcome to HTML and JAVA</span></span><br><span class="line"><span class="comment">//删除</span></span><br><span class="line">bf.delete(<span class="number">8</span>,<span class="number">11</span>); <span class="comment">//Welcome Java</span></span><br><span class="line">bf.deleteCharAt(<span class="number">8</span>);<span class="comment">//Welcome o Java</span></span><br><span class="line">bf.reverse(); <span class="comment">//avaJ ot emocleW</span></span><br><span class="line">bf.replace（<span class="number">11</span>，<span class="number">15</span>，“HTML”）;<span class="comment">//Welcome to HTML</span></span><br><span class="line">bf.setCharAt(<span class="number">0</span>,’w’);<span class="comment">//welcome to java</span></span><br><span class="line"></span><br><span class="line">toString(): 从缓冲区返回字符串</span><br><span class="line">capacity()：返回缓冲区容量。length &lt;= capacity</span><br><span class="line">    当字符串长度超过缓冲区容量，capacity会自动增加</span><br><span class="line">length()：返回缓冲区中字符数量</span><br><span class="line">setLength(newLength)：设置缓冲区长度</span><br><span class="line">charAt(index)：返回下标为index的字符</span><br><span class="line"></span><br><span class="line"><span class="comment">// 编写程序，检查回文，并忽略不是字母和数字的字符。</span></span><br><span class="line">解决方案</span><br><span class="line">创建一个新的StringBuffer，将字符串的字母和数字添加到StringBuffer中，返回过滤后的String对象。</span><br><span class="line">翻转过滤后的字符串，并与过滤后的字符串进行比较，如果内容相同则是回文。</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">boolean</span> <span class="title">isPalindrome</span><span class="params">(String s)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Create a new string that is the reversal of s</span></span><br><span class="line">String s2 = reverse(s);</span><br><span class="line"><span class="comment">// Compare if the reversal is the same as the original stringreturn s2.equals(s);</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">reverse</span><span class="params">(String s)</span> </span>&#123;</span><br><span class="line">StringBuffer strBuf = <span class="keyword">new</span> StringBuffer(s);</span><br><span class="line">strBuf.reverse();</span><br><span class="line"><span class="keyword">return</span> strBuf.toString();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="3-4-格式化控制台输入输出"><a href="#3-4-格式化控制台输入输出" class="headerlink" title="3.4 格式化控制台输入输出"></a>3.4 格式化控制台输入输出</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">JDK1<span class="number">.5</span>提供了格式化控制台输出方法</span><br><span class="line">System.out.printf(format, item1, item2, …);</span><br><span class="line">格式化字符串</span><br><span class="line">String.format(format, item1, item2, …);</span><br><span class="line">格式描述符</span><br><span class="line">%b 布尔值</span><br><span class="line">%c 字符</span><br><span class="line">%d 十进制整数</span><br><span class="line">%f 浮点数</span><br><span class="line">%e 科学计数法</span><br><span class="line">%s 字符串</span><br><span class="line">String.format(“格式$：%<span class="number">1</span>$d,%<span class="number">2</span>$s”, <span class="number">99</span>,“abc”); <span class="comment">//结果”格式$：99，abc“</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestPrintf</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        System.out.printf(<span class="string">"boolean : %6b\n"</span>, <span class="keyword">false</span>);</span><br><span class="line">        System.out.printf(<span class="string">"boolean : %6b\n"</span>, <span class="keyword">true</span>);</span><br><span class="line">        System.out.printf(<span class="string">"character : %4c\n"</span>, <span class="string">'a'</span>);</span><br><span class="line">        System.out.printf(<span class="string">"integer : %6d, %6d\n"</span>, <span class="number">100</span>, <span class="number">200</span>);</span><br><span class="line">        System.out.printf(<span class="string">"double : %7.2f\n"</span>, <span class="number">12.345</span>);</span><br><span class="line">        System.out.printf(<span class="string">"String : %7s\n"</span>, <span class="string">"hello"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Shy-Learnjava（3）基础&quot;&gt;&lt;a href=&quot;#Shy-Learnjava（3）基础&quot; class=&quot;headerlink&quot; title=&quot;Shy-Learnjava（3）基础&quot;&gt;&lt;/a&gt;Shy-Learnjava（3）基础&lt;/h1&gt;&lt;h2 id=&quot;3
      
    
    </summary>
    
    
      <category term="java" scheme="https://shyshy903.github.io/categories/java/"/>
    
    
      <category term="java" scheme="https://shyshy903.github.io/tags/java/"/>
    
  </entry>
  
  <entry>
    <title>Java学习笔记（一）</title>
    <link href="https://shyshy903.github.io/2020/02/11/java/shyjava(1)/"/>
    <id>https://shyshy903.github.io/2020/02/11/java/shyjava(1)/</id>
    <published>2020-02-11T08:48:55.589Z</published>
    <updated>2020-02-11T08:48:55.589Z</updated>
    
    <content type="html"><![CDATA[<p><strong>从今天开始复习java</strong></p><h1 id="Shy-Learnjava（1）基础"><a href="#Shy-Learnjava（1）基础" class="headerlink" title="Shy-Learnjava（1）基础"></a>Shy-Learnjava（1）基础</h1><h2 id="0-编程风格"><a href="#0-编程风格" class="headerlink" title="0 编程风格"></a>0 编程风格</h2><ul><li><strong>注释</strong><ol><li>类和方法前使用文档注释</li><li>方法步骤前使用行注释。</li></ol></li><li><strong>命名</strong><ol><li>变量和方法名使用小写，如果有多个单词，第一个单词首字母小写，其它单词首字母大写。</li><li>类名的每个单词的首字母大写。</li><li>常量使用大写，单词间以下划线分隔。</li><li>缩进、空格、块样式（在eclipse中使用ctrl+shift+f）</li></ol></li></ul><h2 id="1-基本程序设计"><a href="#1-基本程序设计" class="headerlink" title="1 基本程序设计"></a>1 基本程序设计</h2><ul><li><p>编写一个程序</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ComputeArea</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span></span>&#123;</span><br><span class="line">        <span class="keyword">double</span> raidus;</span><br><span class="line">        <span class="keyword">double</span> area;</span><br><span class="line">        area = radius * raidus * <span class="number">3.14</span></span><br><span class="line">        System.out.println(<span class="string">"The area of the circle of raius"</span> + radius + <span class="string">"is"</span> + area);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="1-1-标准输入与输出"><a href="#1-1-标准输入与输出" class="headerlink" title="1.1 标准输入与输出"></a>1.1 标准输入与输出</h3></li><li><p>标准输入</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">System.out <span class="comment">//标准输出流类OutputStrem的对象</span></span><br><span class="line">System.in <span class="comment">//标准输入流类InputStrem的对象</span></span><br></pre></td></tr></table></figure></li><li><p>Scanner类</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.Scanner</span><br><span class="line">Scanner input = <span class="keyword">new</span> Scanner(System.in)</span><br><span class="line"><span class="keyword">double</span> d = input.nextDouble();</span><br><span class="line"><span class="comment">// 方法有</span></span><br><span class="line">nextByte()</span><br><span class="line">nextShort()</span><br><span class="line">nextInt()</span><br><span class="line">nextLong()</span><br><span class="line">nextFloat()</span><br><span class="line">nextDouble()</span><br><span class="line">next()  <span class="comment">// 读入一个字符串</span></span><br></pre></td></tr></table></figure><h3 id="1-2-标识符、常量与变量"><a href="#1-2-标识符、常量与变量" class="headerlink" title="1.2 标识符、常量与变量"></a>1.2 标识符、常量与变量</h3></li><li><p>标识符命名规则</p><ul><li>标识符是由字母、数字、下划线(_)、美元符号($)组成的字符序列。</li><li>标识符必须以字母、下划线(_)、美元符号($)开头。不能以数字开头。标识符不能是保留字。</li><li>标识符不能为true、false或null等事实上的保留字（参见英文维基网）</li><li>标识符可以为任意长度，但编译通常只接受前128字符</li><li>例如：$2, area, radius, showMessageDialog是合法的标识符；2A, d+4是非法的标识符</li></ul></li><li><p>java保留字</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">abstract</span>       <span class="keyword">default</span> <span class="keyword">if</span>        <span class="keyword">package</span>       <span class="keyword">this</span>   </span><br><span class="line"><span class="keyword">assert</span>               <span class="keyword">do</span>              goto            <span class="keyword">private</span>         <span class="keyword">throw</span>   </span><br><span class="line"><span class="keyword">boolean</span>        <span class="keyword">double</span>          implements<span class="keyword">protected</span> <span class="keyword">throws</span>        </span><br><span class="line"><span class="function"><span class="keyword">break</span>         <span class="keyword">else</span>        <span class="keyword">import</span>        <span class="keyword">public</span>        <span class="title">transient</span><span class="params">(非序列化)</span></span></span><br><span class="line"><span class="function"><span class="keyword">byte</span>        <span class="keyword">enum</span><span class="keyword">instanceof</span>return        <span class="keyword">true</span></span></span><br><span class="line"><span class="function"><span class="keyword">case</span>        extends<span class="keyword">int</span>        <span class="keyword">short</span>        <span class="keyword">try</span></span></span><br><span class="line"><span class="function"><span class="keyword">catch</span>        <span class="keyword">false</span>        interface       <span class="keyword">static</span>        <span class="keyword">void</span></span></span><br><span class="line"><span class="function"><span class="keyword">char</span>        <span class="keyword">final</span>           <span class="keyword">long</span>            <span class="title">strictfp</span><span class="params">(严格浮点)</span>   <span class="keyword">volatile</span>          </span></span><br><span class="line"><span class="function">class                 <span class="keyword">finally</span><span class="title">native</span><span class="params">(本地方法)</span>     <span class="keyword">super</span>        <span class="keyword">while</span></span></span><br><span class="line"><span class="function"><span class="keyword">const</span>        <span class="keyword">float</span>        new     <span class="keyword">switch</span>        </span></span><br><span class="line"><span class="function"><span class="keyword">continue</span>        <span class="keyword">for</span>                     <span class="keyword">null</span>         <span class="keyword">synchronized</span></span></span><br></pre></td></tr></table></figure></li><li><p>java常量</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">final</span> datatype CONSTANT_NAME = value;</span><br><span class="line"><span class="comment">//注意常量的声明和初始化必须同时完成</span></span><br><span class="line"><span class="keyword">final</span> <span class="keyword">double</span> PI = <span class="number">3.14159</span>;</span><br><span class="line"><span class="comment">// 避免重复输入</span></span><br><span class="line"><span class="comment">// 便于程序修改</span></span><br><span class="line"><span class="comment">// 便于程序阅读</span></span><br></pre></td></tr></table></figure><h3 id="1-3-赋值语句与基本表达式"><a href="#1-3-赋值语句与基本表达式" class="headerlink" title="1.3 赋值语句与基本表达式"></a>1.3 赋值语句与基本表达式</h3></li><li><p>赋值语句</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 赋值语句右读</span></span><br><span class="line">i = j = k = <span class="number">1</span>;</span><br><span class="line"><span class="comment">//不要认为i, j, k的值不变，volatile类型的变量值可变</span></span><br><span class="line">k = <span class="number">1</span>;</span><br><span class="line">j = k;  </span><br><span class="line">i = j;</span><br><span class="line"></span><br><span class="line"><span class="comment">//语法</span></span><br><span class="line">datatype variable = expression;</span><br><span class="line"><span class="comment">//例如：</span></span><br><span class="line"><span class="keyword">int</span> x = <span class="number">1</span>;   <span class="comment">//某些变量在申明时必须同时初始化：final int m=0;</span></span><br><span class="line"><span class="keyword">int</span> x = <span class="number">1</span>, y = <span class="number">2</span>;</span><br><span class="line"><span class="comment">//局部变量在使用前必须赋值。</span></span><br><span class="line"><span class="keyword">int</span> x, y;     <span class="comment">//若是成员变量，x, y有默认值=0</span></span><br><span class="line">y = x + <span class="number">1</span>; <span class="comment">//局部变量无默认值则错error</span></span><br></pre></td></tr></table></figure><h3 id="1-4-java-数据类型"><a href="#1-4-java-数据类型" class="headerlink" title="1.4 java 数据类型"></a>1.4 java 数据类型</h3><div align=center><img src="https://img.vim-cn.com/bc/a351f0120d3312145a6fe46f6a96aa7a61273e.png"></div></li><li><p>数值数据类型</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">整数</span><br><span class="line"><span class="keyword">byte</span><span class="number">8</span>位带符号整数(-<span class="number">128</span> 到 <span class="number">127</span>)</span><br><span class="line"><span class="keyword">short</span><span class="number">16</span>位带符号整数(-<span class="number">32768</span> 到 <span class="number">32767</span>)</span><br><span class="line"><span class="keyword">int</span><span class="number">32</span>位带符号整数(-<span class="number">2147483648</span> 到 <span class="number">2147483647</span>)</span><br><span class="line"><span class="keyword">long</span><span class="number">64</span>位带符号整数(-<span class="number">9223372036854775808</span> 到<span class="number">9223372036854775807</span>)</span><br><span class="line"></span><br><span class="line">浮点数</span><br><span class="line"><span class="keyword">float</span><span class="number">32</span>位浮点数(负数  -<span class="number">3.4</span>×<span class="number">1038</span>到-<span class="number">1.4</span>×<span class="number">10</span>-<span class="number">45</span> </span><br><span class="line">                  正数  <span class="number">1.4</span>×<span class="number">10</span>-<span class="number">45</span>到<span class="number">3.4</span>×<span class="number">1038</span> )</span><br><span class="line"><span class="keyword">double</span><span class="number">64</span>位浮点数(负数  -<span class="number">1.8</span>×<span class="number">10308</span>到-<span class="number">4.9</span>×<span class="number">10</span>-<span class="number">324</span></span><br><span class="line">                 正数  <span class="number">4.9</span>×<span class="number">10</span>-<span class="number">324</span>到<span class="number">1.8</span>×<span class="number">10308</span>)</span><br><span class="line"></span><br><span class="line">加(+)、减(-)、乘(*)、除(/)、求余(%)：注意+，-的优先级较低</span><br><span class="line"><span class="keyword">int</span> a = <span class="number">34</span> + <span class="number">1</span>;<span class="comment">// 35</span></span><br><span class="line"><span class="keyword">double</span> b = <span class="number">34.0</span> – <span class="number">0.1</span>;<span class="comment">// 33.9</span></span><br><span class="line"><span class="keyword">long</span> c = <span class="number">300</span> * <span class="number">30</span>;            <span class="comment">// 9000</span></span><br><span class="line"><span class="keyword">double</span> d = <span class="number">1.0</span> / <span class="number">2.0</span>;<span class="comment">// 0.5: 此处为浮点除</span></span><br><span class="line"><span class="keyword">int</span> e = <span class="number">1</span> / <span class="number">2</span>;<span class="comment">// 0: 此处为整除</span></span><br><span class="line"><span class="keyword">byte</span> f = <span class="number">20</span> % <span class="number">3</span>;<span class="comment">// 2: 取余数</span></span><br><span class="line">整数相除的结果还是整数，省略小数部分。</span><br><span class="line"><span class="keyword">int</span> i = <span class="number">5</span> / <span class="number">2</span><span class="comment">// 2</span></span><br><span class="line"><span class="keyword">int</span> j = -<span class="number">5</span> / <span class="number">2</span> <span class="comment">// -2</span></span><br><span class="line"></span><br><span class="line">字面值是直接出现在程序中的常量值。</span><br><span class="line"><span class="keyword">int</span> i = <span class="number">34</span>;</span><br><span class="line"><span class="keyword">long</span> k = <span class="number">100000L</span>; </span><br><span class="line">整数字面值</span><br><span class="line">以<span class="number">0</span>开头表示八进制，如<span class="number">035</span>；以<span class="number">0</span>x或<span class="number">0</span>X开头表示十六进制，如<span class="number">0x1D</span>,<span class="number">0X1d</span>；以<span class="number">1</span>-<span class="number">9</span>开头表示十进制，如<span class="number">29</span></span><br><span class="line">后缀字母：以l或L结尾表示<span class="keyword">long</span>类型，如<span class="number">29L</span>；其它表示<span class="keyword">int</span>类型。</span><br><span class="line">浮点数字面值</span><br><span class="line">浮点数是包含小数点的十进制数，后跟可选的指数部分。如</span><br><span class="line"><span class="number">18</span>.  <span class="number">1.8e1</span> .<span class="number">18E2</span></span><br><span class="line">后缀字母：以d或D结尾或者无后缀表示<span class="keyword">double</span>类型；以f或F结尾表示<span class="keyword">float</span>类型</span><br></pre></td></tr></table></figure></li><li><p>操作运算符</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">常用简洁操作符, 结果均为右值。</span><br><span class="line">操作符举例等价于</span><br><span class="line">+=i += <span class="number">8</span>i = i + <span class="number">8</span></span><br><span class="line">-=f -= <span class="number">8.0</span>f = f - <span class="number">8.0</span></span><br><span class="line">*=i *= <span class="number">8</span>i = i * <span class="number">8</span></span><br><span class="line">/=i /= <span class="number">8</span>i = i / <span class="number">8</span></span><br><span class="line">%=i %= <span class="number">8</span>i = i % <span class="number">8</span></span><br><span class="line">递增和递减运算符：++, --。结果均为右值。</span><br><span class="line">前缀表示先加(减)<span class="number">1</span>后使用</span><br><span class="line">后缀表示先使用后加(减) <span class="number">1</span></span><br><span class="line">    <span class="keyword">int</span> i =<span class="number">10</span>;             <span class="comment">//i=++i + ++i; 结果为23</span></span><br><span class="line">    <span class="keyword">int</span> newNum= <span class="number">10</span> * i++; <span class="comment">//newNum = 100, i = 11</span></span><br><span class="line">    <span class="keyword">int</span> newNum= <span class="number">10</span> * ++i; <span class="comment">//newNum = 110, i = 11</span></span><br></pre></td></tr></table></figure></li><li><p>数值类型转换</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">如果二元操作符的两个操作数的数据类型不同，那么根据下面的规则对操作数进行转换：</span><br><span class="line">如果有一个操作数是<span class="keyword">double</span>类型，另一个操作数转换为<span class="keyword">double</span>类型。</span><br><span class="line">否则，如果有一个操作数是<span class="keyword">float</span>类型，另一个操作数转换为<span class="keyword">float</span>类型。</span><br><span class="line">否则，如果有一个操作数是<span class="keyword">long</span>类型，另一个操作数转换为<span class="keyword">long</span>类型。</span><br><span class="line">否则，两个操作数都转换为<span class="keyword">int</span>类型。</span><br><span class="line">数据转换总是向较大范围的数据类型转换，避免精度损失</span><br><span class="line"><span class="keyword">long</span> k = i * <span class="number">3</span> + <span class="number">4</span>; <span class="comment">//i变成int参与右边表达式计算，计算结果转long</span></span><br><span class="line"><span class="keyword">double</span> d = i * <span class="number">3.1</span> + k / <span class="number">2</span>; <span class="comment">//i转double， k/2转double</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">将值赋值给较大取值范围的变量时，自动进行类型转换。</span><br><span class="line"><span class="keyword">byte</span> → <span class="keyword">char</span>→ <span class="keyword">short</span> → <span class="keyword">int</span> → <span class="keyword">long</span> → <span class="keyword">float</span> → <span class="keyword">double</span> </span><br><span class="line">将值赋值给较小取值范围的变量时，必须使用强制类型转换(type casting)。语法：</span><br><span class="line">(datatype)variableName</span><br><span class="line">例如：</span><br><span class="line"><span class="keyword">float</span> f = (<span class="keyword">float</span>)<span class="number">10.1</span>;<span class="comment">// 10.1是double类型</span></span><br><span class="line"><span class="keyword">int</span> i = (<span class="keyword">int</span>)f;<span class="comment">// 10</span></span><br><span class="line"><span class="keyword">int</span> j = (<span class="keyword">int</span>)-f;<span class="comment">// -10</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">``</span><br><span class="line"></span><br><span class="line">- 字符数据类型</span><br><span class="line">```java</span><br><span class="line"><span class="keyword">char</span>表示<span class="number">16</span>位的单个Unicode字符。</span><br><span class="line"><span class="keyword">char</span>类型的字面值</span><br><span class="line">以两个单引号界定的单个Unicode字符。如:<span class="string">'男'</span>,<span class="string">'女'</span></span><br><span class="line">可以用\uxxxx形式表示， xxxx为十六进制。如:<span class="string">'\u7537'</span>, <span class="string">'\u5973'</span></span><br><span class="line">转义字符表示：\n   \t  \b  \r   \f   \\   \<span class="string">'   \"</span></span><br><span class="line"><span class="string">例如：</span></span><br><span class="line"><span class="string">char letter = '</span>A<span class="string">';</span></span><br><span class="line"><span class="string">char numChar = '</span><span class="number">4</span><span class="string">';</span></span><br><span class="line"><span class="string">如果想打印带””的信息 He said “Java is fun “</span></span><br><span class="line"><span class="string">      System.out.println(“He said \”Java is fun \””); </span></span><br><span class="line"><span class="string">String表示一个字符序列，注意字符串是String类实现的，是引用类型</span></span><br><span class="line"><span class="string">字符串的字面值是由双引号界定的零个或多个字符。</span></span><br><span class="line"><span class="string">"Welcom to java!"                 ""</span></span><br><span class="line"><span class="string">连接运算：+, +=</span></span><br><span class="line"><span class="string">加号用于连接两个字符串。如果其中一个不是字符串，则先将该操作数转换成字符串，再执行连接操作。</span></span><br><span class="line"><span class="string">String message = "Welcome " + "to " + "java";  // Welcome to Java</span></span><br><span class="line"><span class="string">String s = “Chapter” + 2;           // Chapter2：不能都是数值</span></span><br><span class="line"><span class="string">String s1 += "Supplement" + '</span>B<span class="string">';           // SupplementB  </span></span><br><span class="line"><span class="string">message += " and Java is fun";  // Welcome to Java and Java is fun</span></span><br><span class="line"><span class="string">int i = 1;</span></span><br><span class="line"><span class="string">int j = 2;</span></span><br><span class="line"><span class="string">System.out.println("i + j = "  + i + j);          // i+j=12</span></span><br><span class="line"><span class="string">System.out.println("i + j = "  + (i + j));          // i+j = 3</span></span><br></pre></td></tr></table></figure></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;从今天开始复习java&lt;/strong&gt;&lt;/p&gt;
&lt;h1 id=&quot;Shy-Learnjava（1）基础&quot;&gt;&lt;a href=&quot;#Shy-Learnjava（1）基础&quot; class=&quot;headerlink&quot; title=&quot;Shy-Learnjava（1）基础&quot;&gt;
      
    
    </summary>
    
    
      <category term="java" scheme="https://shyshy903.github.io/categories/java/"/>
    
    
      <category term="java" scheme="https://shyshy903.github.io/tags/java/"/>
    
  </entry>
  
  <entry>
    <title>SQL语言进阶（一）</title>
    <link href="https://shyshy903.github.io/2020/02/11/SQL/SQL%E8%AF%AD%E8%A8%80%EF%BC%88%E4%B8%80%EF%BC%89/"/>
    <id>https://shyshy903.github.io/2020/02/11/SQL/SQL%E8%AF%AD%E8%A8%80%EF%BC%88%E4%B8%80%EF%BC%89/</id>
    <published>2020-02-11T08:48:55.585Z</published>
    <updated>2020-02-11T08:48:55.585Z</updated>
    
    <content type="html"><![CDATA[<h1 id="SQL语言"><a href="#SQL语言" class="headerlink" title="SQL语言"></a>SQL语言</h1><p>简单来说，你需要在数据库上执行的操作大部分都要由SQL语句完成</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> websites</span><br></pre></td></tr></table></figure><p>但是，SQL语句并不对大小写敏感，同时我们在本例教程中，每个语句都加上分号</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; use RUNOOB;</span><br><span class="line">Database changed</span><br><span class="line"></span><br><span class="line">mysql&gt; set names utf8;</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; SELECT * FROM Websites;</span><br><span class="line">+<span class="comment">----+--------------+---------------------------+-------+---------+</span></span><br><span class="line">| id | name         | url                       | alexa | country |</span><br><span class="line">+<span class="comment">----+--------------+---------------------------+-------+---------+</span></span><br><span class="line">| 1  | Google       | https://www.google.cm/    | 1     | USA     |</span><br><span class="line">| 2  | 淘宝          | https://www.taobao.com/   | 13    | CN      |</span><br><span class="line">| 3  | 菜鸟教程      | http://www.runoob.com/    | 4689  | CN      |</span><br><span class="line">| 4  | 微博          | http://weibo.com/         | 20    | CN      |</span><br><span class="line">| 5  | Facebook     | https://www.facebook.com/ | 3     | USA     |</span><br><span class="line">+<span class="comment">----+--------------+---------------------------+-------+---------+</span></span><br><span class="line">5 rows in <span class="keyword">set</span> (<span class="number">0.01</span> sec)</span><br></pre></td></tr></table></figure><p>下面的大部分都是基于这个表格的</p><h2 id="SQL-SELECT-语句"><a href="#SQL-SELECT-语句" class="headerlink" title="SQL SELECT 语句"></a>SQL SELECT 语句</h2><p>SELECT语句用于从数据库中选取数据，结果被存在一个结果表中，称为结果集</p><h3 id="SELECT-语法"><a href="#SELECT-语法" class="headerlink" title="SELECT 语法"></a>SELECT 语法</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> column_name,column_name <span class="keyword">FROM</span> table_name;  <span class="comment"># 选出指定列</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> table_name;  <span class="comment"># 选出所有的列</span></span><br></pre></td></tr></table></figure><h2 id="SQL-SELECT-DISTINCT-语句"><a href="#SQL-SELECT-DISTINCT-语句" class="headerlink" title="SQL SELECT DISTINCT 语句"></a>SQL SELECT DISTINCT 语句</h2><p>在表中，一个列可能会包含多个重复值，DISTINCT关键词用于返回唯一不同的值,就是会删掉重复的值</p><h3 id="SQL-SELECT-DISTINCT-语法"><a href="#SQL-SELECT-DISTINCT-语法" class="headerlink" title="SQL SELECT DISTINCT 语法"></a>SQL SELECT DISTINCT 语法</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">DISTINCT</span> column_name, column_name <span class="keyword">FROM</span> table_name;</span><br></pre></td></tr></table></figure><h2 id="SELECT-WHERE子句"><a href="#SELECT-WHERE子句" class="headerlink" title="SELECT WHERE子句"></a>SELECT WHERE子句</h2><p>WHERE子句用于提取那些阿玛尼组指定条件的记录</p><h3 id="SQL-WHERE-语法"><a href="#SQL-WHERE-语法" class="headerlink" title="SQL WHERE 语法"></a>SQL WHERE 语法</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> column_name,column_name <span class="keyword">FROM</span> table_name <span class="keyword">WHERE</span> column_name <span class="keyword">operator</span> <span class="keyword">value</span>;</span><br></pre></td></tr></table></figure><h3 id="文本字段-vs-数值字段"><a href="#文本字段-vs-数值字段" class="headerlink" title="文本字段 vs 数值字段"></a>文本字段 vs 数值字段</h3><p>SQL中使用<strong>单引号</strong>来环绕文本数值，但是如果是数值就不用使用单引号了，如：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> websites <span class="keyword">WHERE</span> <span class="keyword">id</span> = <span class="number">1</span>;</span><br><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> websites <span class="keyword">WHERE</span> country = <span class="string">'CN'</span>;</span><br></pre></td></tr></table></figure><h3 id="WHERE子句的运算符"><a href="#WHERE子句的运算符" class="headerlink" title="WHERE子句的运算符"></a>WHERE子句的运算符</h3><table><thead><tr><th>运算符</th><th>描述</th></tr></thead><tbody><tr><td>&lt;&gt;或者!=</td><td>不等于</td></tr><tr><td>BETWEEN</td><td>在某个范围内</td></tr><tr><td>LIKE</td><td>搜索某种模式</td></tr><tr><td>IN</td><td>指定针对某个列的可能值</td></tr><tr><td>## SQL AND &amp; OR 运算符</td><td></td></tr><tr><td>AND &amp; OR 运算符基于一个以上条件对记录进行过滤</td><td></td></tr><tr><td>* 如果第一个条件与第二个条件都成立，则ADN运算符显示一条记录</td><td></td></tr><tr><td>* 如果第一个条件与第二个条件有一个成立，则OR运算符显示一条记录</td><td></td></tr></tbody></table><h3 id="SQL-AND-amp-OR-语法"><a href="#SQL-AND-amp-OR-语法" class="headerlink" title="SQL AND &amp; OR 语法"></a>SQL AND &amp; OR 语法</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> Websites <span class="keyword">WHERE</span> country = <span class="string">'CN'</span> <span class="keyword">AND</span> alexa &gt; <span class="number">50</span>;</span><br><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> websites <span class="keyword">WHERE</span> country = <span class="string">'USA'</span> <span class="keyword">OR</span> country = <span class="string">'CN'</span>;</span><br></pre></td></tr></table></figure><h3 id="结合AND-和-OR"><a href="#结合AND-和-OR" class="headerlink" title="结合AND 和 OR"></a>结合AND 和 OR</h3><p>用法示例如下：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> websites <span class="keyword">WHERE</span> alexa &gt; <span class="number">15</span> </span><br><span class="line"><span class="keyword">AND</span> (country = <span class="string">'CN'</span> <span class="keyword">OR</span> country = <span class="string">'USA'</span>)</span><br></pre></td></tr></table></figure><h2 id="SQL-ORDER-BY-关键词"><a href="#SQL-ORDER-BY-关键词" class="headerlink" title="SQL ORDER BY 关键词"></a>SQL ORDER BY 关键词</h2><p>ORDER BY 关键词用于对于结果集按照一个列或者多个列进行排序</p><h3 id="SQL-ORDER-BY-的语法"><a href="#SQL-ORDER-BY-的语法" class="headerlink" title="SQL ORDER BY 的语法"></a>SQL ORDER BY 的语法</h3><p>ORDER BY关键词默认按照升序进行排列，如果需要降序，则可以使用DESC关键字</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> column_name, column_name <span class="keyword">FROM</span> table_name </span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> column_name, column_name <span class="keyword">ASC</span>|<span class="keyword">DESC</span>;</span><br></pre></td></tr></table></figure><h3 id="SQL-ORDER-BY-DESC-实例"><a href="#SQL-ORDER-BY-DESC-实例" class="headerlink" title="SQL ORDER BY(DESC)实例"></a>SQL ORDER BY(DESC)实例</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> websites <span class="keyword">ORDER</span> <span class="keyword">BY</span> alexa ;</span><br><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> websites <span class="keyword">ORDER</span> <span class="keyword">BY</span> alexa <span class="keyword">DESC</span>;</span><br></pre></td></tr></table></figure><h3 id="ORDER-BY-多列"><a href="#ORDER-BY-多列" class="headerlink" title="ORDER BY 多列"></a>ORDER BY 多列</h3><p>当有多列进行排序时，我们优先选择第一列</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> websites <span class="keyword">ORDER</span> <span class="keyword">BY</span> country,alexa;</span><br></pre></td></tr></table></figure><h2 id="SQL-INSERT-INTO语句"><a href="#SQL-INSERT-INTO语句" class="headerlink" title="SQL INSERT INTO语句"></a>SQL INSERT INTO语句</h2><p>INSERT INTO语句向表中插入新纪录</p><h3 id="SQL-INSERT-INTO语句的语法"><a href="#SQL-INSERT-INTO语句的语法" class="headerlink" title="SQL INSERT INTO语句的语法"></a>SQL INSERT INTO语句的语法</h3><p>INSERT 语句有两种编写形式：</p><ul><li>第一钟形式无需指定要插入数据的列名，只需要提供被插入的值即可：<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> table_name <span class="keyword">VALUES</span> (value1,value2,value3);</span><br></pre></td></tr></table></figure></li><li>第二种形式需要指定列名及被插入的值<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> table_name (column1, column2,column3) <span class="keyword">VALUES</span> (value1,value2,value3)</span><br></pre></td></tr></table></figure><h3 id="INSERT-INTO实例"><a href="#INSERT-INTO实例" class="headerlink" title="INSERT INTO实例"></a>INSERT INTO实例</h3>假设我们需要向‘websites’表钟插入一个新行<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> websites(<span class="keyword">name</span>, <span class="keyword">url</span>, alexa, country) <span class="keyword">VALUES</span>(<span class="string">'百度’, '</span>https://www.baidu.com/<span class="string">','</span><span class="number">4</span><span class="string">','</span>CN<span class="string">');</span></span><br></pre></td></tr></table></figure><h3 id="在指定的列插入数据"><a href="#在指定的列插入数据" class="headerlink" title="在指定的列插入数据"></a>在指定的列插入数据</h3>下面的SQL语句将插入一个新行，但是只在’name’、‘url’、’country‘列插入数据<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> websites(<span class="keyword">name</span>, <span class="keyword">url</span>, country) <span class="keyword">VALUES</span> (<span class="string">'stackoverflow'</span>, <span class="string">'http://stackoverflow.com/'</span>, <span class="string">'IND'</span>)</span><br></pre></td></tr></table></figure><h2 id="SQL-UPDATE-语句"><a href="#SQL-UPDATE-语句" class="headerlink" title="SQL UPDATE 语句"></a>SQL UPDATE 语句</h2>UPDATE语句用于更新表中已经存在的记录</li></ul><h3 id="UPDATE语句的语法"><a href="#UPDATE语句的语法" class="headerlink" title="UPDATE语句的语法"></a>UPDATE语句的语法</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">UPDATE</span> table_name <span class="keyword">SET</span> <span class="keyword">column</span> = value1, column2 = value2,... <span class="keyword">WHERE</span> some_column = some_value;</span><br></pre></td></tr></table></figure><h3 id="UPDATE实例"><a href="#UPDATE实例" class="headerlink" title="UPDATE实例"></a>UPDATE实例</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">UPADATE Websites <span class="keyword">SET</span> alexa = <span class="string">'500'</span>, country = <span class="string">'USA'</span> <span class="keyword">WHERE</span> <span class="keyword">name</span> = <span class="string">'菜鸟教程’;</span></span><br></pre></td></tr></table></figure><h2 id="SQL-DELETE"><a href="#SQL-DELETE" class="headerlink" title="SQL DELETE"></a>SQL DELETE</h2><p>DELET语句用于删除表中的行</p><h3 id="SQL-DELETE语法和实例"><a href="#SQL-DELETE语法和实例" class="headerlink" title="SQL DELETE语法和实例"></a>SQL DELETE语法和实例</h3><p>从表中删除网站名是百度且国家为CN的网站</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DELET FROM websites WHERE name = '百度' AND country = 'CN';</span><br></pre></td></tr></table></figure><h3 id="删除所有数据"><a href="#删除所有数据" class="headerlink" title="删除所有数据"></a>删除所有数据</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">DELETE</span> <span class="keyword">FROM</span> table_name;</span><br><span class="line"><span class="keyword">DELETE</span> * <span class="keyword">FROM</span> table_name;</span><br></pre></td></tr></table></figure><h2 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h2><p>非常感谢菜鸟教程，本文借鉴了菜鸟教程的表格和相关代码：<a href="https://www.runoob.com/sql/sql-syntax.html" target="_blank" rel="noopener">菜鸟教程</a>: <a href="https://www.runoob.com/sql/sql-syntax.html" target="_blank" rel="noopener">https://www.runoob.com/sql/sql-syntax.html</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;SQL语言&quot;&gt;&lt;a href=&quot;#SQL语言&quot; class=&quot;headerlink&quot; title=&quot;SQL语言&quot;&gt;&lt;/a&gt;SQL语言&lt;/h1&gt;&lt;p&gt;简单来说，你需要在数据库上执行的操作大部分都要由SQL语句完成&lt;/p&gt;
&lt;figure class=&quot;highlig
      
    
    </summary>
    
    
      <category term="SQL" scheme="https://shyshy903.github.io/categories/SQL/"/>
    
    
      <category term="SQL" scheme="https://shyshy903.github.io/tags/SQL/"/>
    
  </entry>
  
  <entry>
    <title>MySQL的安装与配置</title>
    <link href="https://shyshy903.github.io/2020/02/11/SQL/MySQL%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/"/>
    <id>https://shyshy903.github.io/2020/02/11/SQL/MySQL%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/</id>
    <published>2020-02-11T08:48:55.582Z</published>
    <updated>2020-02-11T08:48:55.582Z</updated>
    
    <content type="html"><![CDATA[<h1 id="MySQL的安装与配置"><a href="#MySQL的安装与配置" class="headerlink" title="MySQL的安装与配置"></a>MySQL的安装与配置</h1><h2 id="下载软件与安装"><a href="#下载软件与安装" class="headerlink" title="下载软件与安装"></a>下载软件与安装</h2><ol><li><p>到<code>mySQL</code>的官网：<a href="https://dev.mysql.com/downloads/mysql/" target="_blank" rel="noopener">点击这里</a>，看到下图，下载即可。</p></li><li><p>解压缩到你所需要的路径</p><h2 id="MySQL配置"><a href="#MySQL配置" class="headerlink" title="MySQL配置"></a>MySQL配置</h2><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">[mysqld]</span></span><br><span class="line"><span class="comment"># 设置3306端口</span></span><br><span class="line"><span class="string">port=3306</span></span><br><span class="line"><span class="comment"># 设置mysql的安装目录</span></span><br><span class="line"><span class="string">basedir=&lt;你的路径&gt;\mysql-8.0.11-winx64</span></span><br><span class="line"><span class="comment"># 设置mysql数据库的数据的存放目录</span></span><br><span class="line"><span class="string">datadir=&lt;你的路径&gt;\mysql-8.0.11-winx64\\data</span></span><br><span class="line"><span class="comment"># 允许最大连接数</span></span><br><span class="line"><span class="string">max_connections=200</span></span><br><span class="line"><span class="comment"># 允许连接失败的次数。这是为了防止有人从该主机试图攻击数据库系统</span></span><br><span class="line"><span class="string">max_connect_errors=10000</span></span><br><span class="line"><span class="comment"># 服务端使用的字符集默认为UTF8</span></span><br><span class="line"><span class="string">character-set-server=utf8</span></span><br><span class="line"><span class="comment"># 创建新表时将使用的默认存储引擎</span></span><br><span class="line"><span class="string">default-storage-engine=INNODB</span></span><br><span class="line"><span class="string">wait_timeout=31536000</span></span><br><span class="line"><span class="string">interactive_timeout=31536000</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#sql_mode=ONLY_FULL_GROUP_BY,STRICT_TRANS_TABLES,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION</span></span><br><span class="line"><span class="string">[mysql]</span></span><br><span class="line"><span class="comment"># 设置mysql客户端默认字符集</span></span><br><span class="line"><span class="string">default-character-set=utf8</span></span><br><span class="line"></span><br><span class="line"><span class="string">[client]</span></span><br><span class="line"><span class="comment"># 设置mysql客户端连接服务端时默认使用的端口</span></span><br><span class="line"><span class="string">port=3306</span></span><br><span class="line"><span class="string">default-character-set=utf8</span></span><br></pre></td></tr></table></figure><h2 id="环境变量配置"><a href="#环境变量配置" class="headerlink" title="环境变量配置"></a>环境变量配置</h2></li><li><p>系统变量添加</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">MYSQL_HOME  :</span> <span class="string">path</span></span><br></pre></td></tr></table></figure></li><li><p>环境变量添加</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">%MYSQL_HOME%\bin</span></span><br></pre></td></tr></table></figure></li><li><p>如果上面2个方法都不想使用，可以使用下面这个方法：<br><img src="https://img-blog.csdn.net/20180416193135760?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L20wXzM3Nzg4MzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""></p></li></ol><h2 id="MySQL初始化"><a href="#MySQL初始化" class="headerlink" title="MySQL初始化"></a>MySQL初始化</h2><ol><li>CMD运行<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ mysqld --initialize --user=mysql --console</span><br></pre></td></tr></table></figure><img src="https://img-blog.csdn.net/20180416190435744?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L20wXzM3Nzg4MzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""><br>务必记住这个初始密码，一会需要用这个初始密码登录mysql；<br>修改密码如果emm你把他点没了 你只要把datadir配置的那个data的文件删除了，然后重新执行初始化即可然后输入：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysqld --install</span><br></pre></td></tr></table></figure>再打开服务：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">net start mysql</span><br></pre></td></tr></table></figure></li></ol><h2 id="修改默认密码"><a href="#修改默认密码" class="headerlink" title="修改默认密码"></a>修改默认密码</h2><p>执行：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql -u root -p</span><br></pre></td></tr></table></figure><p>登录,输入初始密码，接下来修改密码：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ALTER USER <span class="string">"root@"</span>localhost<span class="string">" IDENTIFIED BY "</span>your password<span class="string">"</span></span><br></pre></td></tr></table></figure><h2 id="其它"><a href="#其它" class="headerlink" title="其它"></a>其它</h2><p>如果你在数据库连接工具的时候出现错误，则可以再<code>my.ini</code>文件中的<code>mysqld</code>中加入：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ default_authentication_plugin=mysql_native_password</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;MySQL的安装与配置&quot;&gt;&lt;a href=&quot;#MySQL的安装与配置&quot; class=&quot;headerlink&quot; title=&quot;MySQL的安装与配置&quot;&gt;&lt;/a&gt;MySQL的安装与配置&lt;/h1&gt;&lt;h2 id=&quot;下载软件与安装&quot;&gt;&lt;a href=&quot;#下载软件与安装&quot; c
      
    
    </summary>
    
    
      <category term="软件安装与配置" scheme="https://shyshy903.github.io/categories/%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/"/>
    
    
      <category term="SQL" scheme="https://shyshy903.github.io/tags/SQL/"/>
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="https://shyshy903.github.io/2020/02/11/hello-world/"/>
    <id>https://shyshy903.github.io/2020/02/11/hello-world/</id>
    <published>2020-02-11T07:40:07.968Z</published>
    <updated>2020-02-11T07:40:07.968Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>《机器学习实战》《西瓜书》笔记（八）- K均值聚类</title>
    <link href="https://shyshy903.github.io/2019/11/30/Machine_Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%888-K%E5%9D%87%E5%80%BC%E8%81%9A%E7%B1%BB%EF%BC%89/"/>
    <id>https://shyshy903.github.io/2019/11/30/Machine_Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%888-K%E5%9D%87%E5%80%BC%E8%81%9A%E7%B1%BB%EF%BC%89/</id>
    <published>2019-11-30T11:30:00.000Z</published>
    <updated>2020-02-11T08:48:55.575Z</updated>
    
    <content type="html"><![CDATA[<h1 id="K均值聚类"><a href="#K均值聚类" class="headerlink" title="K均值聚类"></a>K均值聚类</h1><p>算法伪代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">创建k个点作为起始质心（经常是随机选择）</span><br><span class="line">当任意一个点的簇分配结果发生改变时</span><br><span class="line">    对数据集中的每个数据点</span><br><span class="line">        对每个质心</span><br><span class="line">            计算质心与数据点之间的距离</span><br><span class="line">        将数据点分配到距离其最近的簇</span><br><span class="line">    对每一个簇，计算簇中所有点的均值，并且将该值作为质心</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：k-means聚类算法</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    dataSet - 用于聚类的数据集</span></span><br><span class="line"><span class="string">    k - 选取k个质心</span></span><br><span class="line"><span class="string">    distMeas - 距离计算方法,默认欧氏距离distEclud()</span></span><br><span class="line"><span class="string">    createCent - 获取k个质心的方法,默认随机获取randCent()</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    centroids - k个聚类的聚类结果</span></span><br><span class="line"><span class="string">    clusterAssment - 聚类误差</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">kMeans</span><span class="params">(dataSet, k, distMeas=distEclud, createCent=randCent)</span>:</span></span><br><span class="line">    <span class="comment"># 获取数据集样本数</span></span><br><span class="line">    m = np.shape(dataSet)[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># 初始化一个（m,2）全零矩阵</span></span><br><span class="line">    clusterAssment = np.mat(np.zeros((m, <span class="number">2</span>)))</span><br><span class="line">    <span class="comment"># 创建初始的k个质心向量</span></span><br><span class="line">    centroids = createCent(dataSet, k)</span><br><span class="line">    <span class="comment"># 聚类结果是否发生变化的布尔类型</span></span><br><span class="line">    clusterChanged = <span class="literal">True</span></span><br><span class="line">    <span class="comment"># 只要聚类结果一直发生变化，就一直执行聚类算法，直至所有数据点聚类结果不发生变化</span></span><br><span class="line">    <span class="keyword">while</span> clusterChanged:</span><br><span class="line">        <span class="comment"># 聚类结果变化布尔类型置为False</span></span><br><span class="line">        clusterChanged = <span class="literal">False</span></span><br><span class="line">        <span class="comment"># 遍历数据集每一个样本向量</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">            <span class="comment"># 初始化最小距离为正无穷，最小距离对应的索引为-1</span></span><br><span class="line">            minDist = float(<span class="string">'inf'</span>)</span><br><span class="line">            minIndex = <span class="number">-1</span></span><br><span class="line">            <span class="comment"># 循环k个类的质心</span></span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(k):</span><br><span class="line">                <span class="comment"># 计算数据点到质心的欧氏距离</span></span><br><span class="line">                distJI = distMeas(centroids[j, :], dataSet[i, :])</span><br><span class="line">                <span class="comment"># 如果距离小于当前最小距离</span></span><br><span class="line">                <span class="keyword">if</span> distJI &lt; minDist:</span><br><span class="line">                    <span class="comment"># 当前距离为最小距离，最小距离对应索引应为j(第j个类)</span></span><br><span class="line">                    minDist = distJI</span><br><span class="line">                    minIndex = j</span><br><span class="line">            <span class="comment"># 当前聚类结果中第i个样本的聚类结果发生变化：布尔值置为True，继续聚类算法</span></span><br><span class="line">            <span class="keyword">if</span> clusterAssment[i, <span class="number">0</span>] != minIndex: </span><br><span class="line">                clusterChanged = <span class="literal">True</span></span><br><span class="line">            <span class="comment"># 更新当前变化样本的聚类结果和平方误差</span></span><br><span class="line">            clusterAssment[i, :] = minIndex, minDist**<span class="number">2</span></span><br><span class="line">            <span class="comment"># 打印k-means聚类的质心</span></span><br><span class="line">        <span class="comment"># print(centroids)</span></span><br><span class="line">        <span class="comment"># 遍历每一个质心</span></span><br><span class="line">        <span class="keyword">for</span> cent <span class="keyword">in</span> range(k):</span><br><span class="line">            <span class="comment"># 将数据集中所有属于当前质心类的样本通过条件过滤筛选出来</span></span><br><span class="line">            ptsInClust = dataSet[np.nonzero(clusterAssment[:, <span class="number">0</span>].A == cent)[<span class="number">0</span>]]</span><br><span class="line">            <span class="comment"># 计算这些数据的均值(axis=0:求列均值)，作为该类质心向量</span></span><br><span class="line">            centroids[cent, :] = np.mean(ptsInClust, axis=<span class="number">0</span>)</span><br><span class="line">    <span class="comment"># 返回k个聚类，聚类结果及误差</span></span><br><span class="line">    <span class="keyword">return</span> centroids, clusterAssment</span><br></pre></td></tr></table></figure><h2 id="源代码"><a href="#源代码" class="headerlink" title="源代码"></a>源代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Created on Thu Aug  2 21:20:03 2018</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">@author: wzy</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：将文本文档中的数据读入到python中</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    fileName - 文件名</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    dataMat - 数据矩阵</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadDataSet</span><span class="params">(fileName)</span>:</span></span><br><span class="line">    dataMat = []</span><br><span class="line">    fr = open(fileName)</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> fr.readlines():</span><br><span class="line">        curLine = line.strip().split(<span class="string">'\t'</span>)</span><br><span class="line">        fltLine = list(map(float, curLine))</span><br><span class="line">        dataMat.append(fltLine)</span><br><span class="line">    <span class="keyword">return</span> dataMat</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：数据向量计算欧式距离</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    vecA - 数据向量A</span></span><br><span class="line"><span class="string">    vecB - 数据向量B</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    两个向量之间的欧几里德距离</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Modify:</span></span><br><span class="line"><span class="string">    2018-08-02</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">distEclud</span><span class="params">(vecA, vecB)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> np.sqrt(np.sum(np.power(vecA - vecB, <span class="number">2</span>)))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：随机初始化k个质心（质心满足数据边界之内）</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    dataSet - 输入的数据集</span></span><br><span class="line"><span class="string">    k - 选取k个质心</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    centroids - 返回初始化得到的k个质心向量</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">randCent</span><span class="params">(dataSet, k)</span>:</span></span><br><span class="line">    <span class="comment"># 得到数据样本的维度</span></span><br><span class="line">    n = np.shape(dataSet)[<span class="number">1</span>]</span><br><span class="line">    <span class="comment"># 初始化为一个(k,n)的全零矩阵</span></span><br><span class="line">    centroids = np.mat(np.zeros((k, n)))</span><br><span class="line">    <span class="comment"># 遍历数据集的每一个维度</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(n):</span><br><span class="line">        <span class="comment"># 得到该列数据的最小值,最大值</span></span><br><span class="line">        minJ = np.min(dataSet[:, j])</span><br><span class="line">        maxJ = np.max(dataSet[:, j])</span><br><span class="line">        <span class="comment"># 得到该列数据的范围(最大值-最小值)</span></span><br><span class="line">        rangeJ = float(maxJ - minJ)</span><br><span class="line">        <span class="comment"># k个质心向量的第j维数据值随机为位于(最小值，最大值)内的某一值</span></span><br><span class="line">        <span class="comment"># Create an array of the given shape and populate it with random samples from a uniform distribution over [0, 1).</span></span><br><span class="line">        centroids[:, j] = minJ + rangeJ * np.random.rand(k, <span class="number">1</span>)</span><br><span class="line">    <span class="comment"># 返回初始化得到的k个质心向量</span></span><br><span class="line">    <span class="keyword">return</span> centroids</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：k-means聚类算法</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    dataSet - 用于聚类的数据集</span></span><br><span class="line"><span class="string">    k - 选取k个质心</span></span><br><span class="line"><span class="string">    distMeas - 距离计算方法,默认欧氏距离distEclud()</span></span><br><span class="line"><span class="string">    createCent - 获取k个质心的方法,默认随机获取randCent()</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    centroids - k个聚类的聚类结果</span></span><br><span class="line"><span class="string">    clusterAssment - 聚类误差</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">kMeans</span><span class="params">(dataSet, k, distMeas=distEclud, createCent=randCent)</span>:</span></span><br><span class="line">    <span class="comment"># 获取数据集样本数</span></span><br><span class="line">    m = np.shape(dataSet)[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># 初始化一个（m,2）全零矩阵</span></span><br><span class="line">    clusterAssment = np.mat(np.zeros((m, <span class="number">2</span>)))</span><br><span class="line">    <span class="comment"># 创建初始的k个质心向量</span></span><br><span class="line">    centroids = createCent(dataSet, k)</span><br><span class="line">    <span class="comment"># 聚类结果是否发生变化的布尔类型</span></span><br><span class="line">    clusterChanged = <span class="literal">True</span></span><br><span class="line">    <span class="comment"># 只要聚类结果一直发生变化，就一直执行聚类算法，直至所有数据点聚类结果不发生变化</span></span><br><span class="line">    <span class="keyword">while</span> clusterChanged:</span><br><span class="line">        <span class="comment"># 聚类结果变化布尔类型置为False</span></span><br><span class="line">        clusterChanged = <span class="literal">False</span></span><br><span class="line">        <span class="comment"># 遍历数据集每一个样本向量</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">            <span class="comment"># 初始化最小距离为正无穷，最小距离对应的索引为-1</span></span><br><span class="line">            minDist = float(<span class="string">'inf'</span>)</span><br><span class="line">            minIndex = <span class="number">-1</span></span><br><span class="line">            <span class="comment"># 循环k个类的质心</span></span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(k):</span><br><span class="line">                <span class="comment"># 计算数据点到质心的欧氏距离</span></span><br><span class="line">                distJI = distMeas(centroids[j, :], dataSet[i, :])</span><br><span class="line">                <span class="comment"># 如果距离小于当前最小距离</span></span><br><span class="line">                <span class="keyword">if</span> distJI &lt; minDist:</span><br><span class="line">                    <span class="comment"># 当前距离为最小距离，最小距离对应索引应为j(第j个类)</span></span><br><span class="line">                    minDist = distJI</span><br><span class="line">                    minIndex = j</span><br><span class="line">            <span class="comment"># 当前聚类结果中第i个样本的聚类结果发生变化：布尔值置为True，继续聚类算法</span></span><br><span class="line">            <span class="keyword">if</span> clusterAssment[i, <span class="number">0</span>] != minIndex: </span><br><span class="line">                clusterChanged = <span class="literal">True</span></span><br><span class="line">            <span class="comment"># 更新当前变化样本的聚类结果和平方误差</span></span><br><span class="line">            clusterAssment[i, :] = minIndex, minDist**<span class="number">2</span></span><br><span class="line">            <span class="comment"># 打印k-means聚类的质心</span></span><br><span class="line">        <span class="comment"># print(centroids)</span></span><br><span class="line">        <span class="comment"># 遍历每一个质心</span></span><br><span class="line">        <span class="keyword">for</span> cent <span class="keyword">in</span> range(k):</span><br><span class="line">            <span class="comment"># 将数据集中所有属于当前质心类的样本通过条件过滤筛选出来</span></span><br><span class="line">            ptsInClust = dataSet[np.nonzero(clusterAssment[:, <span class="number">0</span>].A == cent)[<span class="number">0</span>]]</span><br><span class="line">            <span class="comment"># 计算这些数据的均值(axis=0:求列均值)，作为该类质心向量</span></span><br><span class="line">            centroids[cent, :] = np.mean(ptsInClust, axis=<span class="number">0</span>)</span><br><span class="line">    <span class="comment"># 返回k个聚类，聚类结果及误差</span></span><br><span class="line">    <span class="keyword">return</span> centroids, clusterAssment</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：绘制数据集</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    fileName - 文件名</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    None</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plotDataSet</span><span class="params">(filename)</span>:</span></span><br><span class="line">    <span class="comment"># 导入数据</span></span><br><span class="line">    datMat = np.mat(loadDataSet(filename))</span><br><span class="line">    <span class="comment"># 进行k-means算法其中k为4</span></span><br><span class="line">    myCentroids, clustAssing = kMeans(datMat, <span class="number">4</span>)</span><br><span class="line">    clustAssing = clustAssing.tolist()</span><br><span class="line">    myCentroids = myCentroids.tolist()</span><br><span class="line">    xcord = [[], [], [], []]</span><br><span class="line">    ycord = [[], [], [], []]</span><br><span class="line">    datMat = datMat.tolist()</span><br><span class="line">    m = len(clustAssing)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">        <span class="keyword">if</span> int(clustAssing[i][<span class="number">0</span>]) == <span class="number">0</span>:</span><br><span class="line">            xcord[<span class="number">0</span>].append(datMat[i][<span class="number">0</span>])</span><br><span class="line">            ycord[<span class="number">0</span>].append(datMat[i][<span class="number">1</span>])</span><br><span class="line">        <span class="keyword">elif</span> int(clustAssing[i][<span class="number">0</span>]) == <span class="number">1</span>:</span><br><span class="line">            xcord[<span class="number">1</span>].append(datMat[i][<span class="number">0</span>])</span><br><span class="line">            ycord[<span class="number">1</span>].append(datMat[i][<span class="number">1</span>])</span><br><span class="line">        <span class="keyword">elif</span> int(clustAssing[i][<span class="number">0</span>]) == <span class="number">2</span>:</span><br><span class="line">            xcord[<span class="number">2</span>].append(datMat[i][<span class="number">0</span>])</span><br><span class="line">            ycord[<span class="number">2</span>].append(datMat[i][<span class="number">1</span>])</span><br><span class="line">        <span class="keyword">elif</span> int(clustAssing[i][<span class="number">0</span>]) == <span class="number">3</span>:</span><br><span class="line">            xcord[<span class="number">3</span>].append(datMat[i][<span class="number">0</span>])</span><br><span class="line">            ycord[<span class="number">3</span>].append(datMat[i][<span class="number">1</span>])</span><br><span class="line">    fig = plt.figure()</span><br><span class="line">    ax = fig.add_subplot(<span class="number">111</span>)</span><br><span class="line">    <span class="comment"># 绘制样本点</span></span><br><span class="line">    ax.scatter(xcord[<span class="number">0</span>], ycord[<span class="number">0</span>], s=<span class="number">20</span>, c=<span class="string">'b'</span>, marker=<span class="string">'*'</span>, alpha=<span class="number">.5</span>)</span><br><span class="line">    ax.scatter(xcord[<span class="number">1</span>], ycord[<span class="number">1</span>], s=<span class="number">20</span>, c=<span class="string">'r'</span>, marker=<span class="string">'D'</span>, alpha=<span class="number">.5</span>)</span><br><span class="line">    ax.scatter(xcord[<span class="number">2</span>], ycord[<span class="number">2</span>], s=<span class="number">20</span>, c=<span class="string">'c'</span>, marker=<span class="string">'&gt;'</span>, alpha=<span class="number">.5</span>)</span><br><span class="line">    ax.scatter(xcord[<span class="number">3</span>], ycord[<span class="number">3</span>], s=<span class="number">20</span>, c=<span class="string">'k'</span>, marker=<span class="string">'o'</span>, alpha=<span class="number">.5</span>)</span><br><span class="line">    <span class="comment"># 绘制质心</span></span><br><span class="line">    ax.scatter(myCentroids[<span class="number">0</span>][<span class="number">0</span>], myCentroids[<span class="number">0</span>][<span class="number">1</span>], s=<span class="number">100</span>, c=<span class="string">'k'</span>, marker=<span class="string">'+'</span>, alpha=<span class="number">.5</span>)</span><br><span class="line">    ax.scatter(myCentroids[<span class="number">1</span>][<span class="number">0</span>], myCentroids[<span class="number">1</span>][<span class="number">1</span>], s=<span class="number">100</span>, c=<span class="string">'k'</span>, marker=<span class="string">'+'</span>, alpha=<span class="number">.5</span>)</span><br><span class="line">    ax.scatter(myCentroids[<span class="number">2</span>][<span class="number">0</span>], myCentroids[<span class="number">2</span>][<span class="number">1</span>], s=<span class="number">100</span>, c=<span class="string">'k'</span>, marker=<span class="string">'+'</span>, alpha=<span class="number">.5</span>)</span><br><span class="line">    ax.scatter(myCentroids[<span class="number">3</span>][<span class="number">0</span>], myCentroids[<span class="number">3</span>][<span class="number">1</span>], s=<span class="number">100</span>, c=<span class="string">'k'</span>, marker=<span class="string">'+'</span>, alpha=<span class="number">.5</span>)</span><br><span class="line">    plt.title(<span class="string">'DataSet'</span>)</span><br><span class="line">    plt.xlabel(<span class="string">'X'</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    plotDataSet(<span class="string">'testSet.txt'</span>)</span><br></pre></td></tr></table></figure><h1 id="二分K均值聚类"><a href="#二分K均值聚类" class="headerlink" title="二分K均值聚类"></a>二分K均值聚类</h1><p>算法伪代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">将所有点看成一个簇</span><br><span class="line">当簇数目小于K时</span><br><span class="line">    对每一个簇</span><br><span class="line">        计算总误差</span><br><span class="line">        在给定的簇上面进行K-均值聚类（k&#x3D;2)</span><br><span class="line">        计算将该簇一分为二之后的总误差</span><br><span class="line">    选择使得误差最小的那个簇进行划分操作</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：二分k-means聚类算法</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    dataSet - 用于聚类的数据集</span></span><br><span class="line"><span class="string">    k - 选取k个质心</span></span><br><span class="line"><span class="string">    distMeas - 距离计算方法,默认欧氏距离distEclud()</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    centList - k个聚类的聚类结果</span></span><br><span class="line"><span class="string">    clusterAssment - 聚类误差</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">biKmeans</span><span class="params">(dataSet, k, distMeas=distEclud)</span>:</span></span><br><span class="line">    <span class="comment"># 获取数据集的样本数</span></span><br><span class="line">    m = np.shape(dataSet)[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># 初始化一个元素均值0的(m, 2)矩阵</span></span><br><span class="line">    clusterAssment = np.mat(np.zeros((m, <span class="number">2</span>)))</span><br><span class="line">    <span class="comment"># 获取数据集每一列数据的均值，组成一个列表</span></span><br><span class="line">    centroid0 = np.mean(dataSet, axis=<span class="number">0</span>).tolist()[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># 当前聚类列表为将数据集聚为一类</span></span><br><span class="line">    centList = [centroid0]</span><br><span class="line">    <span class="comment"># 遍历每个数据集样本</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(m):</span><br><span class="line">        <span class="comment"># 计算当前聚为一类时各个数据点距离质心的平方距离</span></span><br><span class="line">        clusterAssment[j, <span class="number">1</span>] = distMeas(np.mat(centroid0), dataSet[j, :])**<span class="number">2</span></span><br><span class="line">    <span class="comment"># 循环，直至二分k-Means值达到k类为止</span></span><br><span class="line">    <span class="keyword">while</span> (len(centList) &lt; k):</span><br><span class="line">        <span class="comment"># 将当前最小平方误差置为正无穷</span></span><br><span class="line">        lowerSSE = float(<span class="string">'inf'</span>)</span><br><span class="line">        <span class="comment"># 遍历当前每个聚类</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(centList)):</span><br><span class="line">            <span class="comment"># 通过数组过滤筛选出属于第i类的数据集合</span></span><br><span class="line">            ptsInCurrCluster = dataSet[np.nonzero(clusterAssment[:, <span class="number">0</span>].A == i)[<span class="number">0</span>], :]</span><br><span class="line">            <span class="comment"># 对该类利用二分k-means算法进行划分，返回划分后的结果以及误差</span></span><br><span class="line">            centroidMat, splitClustAss = kMeans(ptsInCurrCluster, <span class="number">2</span>, distMeas)</span><br><span class="line">            <span class="comment"># 计算该类划分后两个类的误差平方和</span></span><br><span class="line">            sseSplit = np.sum(splitClustAss[:, <span class="number">1</span>])</span><br><span class="line">            <span class="comment"># 计算数据集中不属于该类的数据的误差平方和</span></span><br><span class="line">            sseNotSplit = np.sum(clusterAssment[np.nonzero(clusterAssment[:, <span class="number">0</span>].A != i)[<span class="number">0</span>], <span class="number">1</span>])</span><br><span class="line">            <span class="comment"># 打印这两项误差值</span></span><br><span class="line">            print(<span class="string">'sseSplit = %f, and notSplit = %f'</span> % (sseSplit, sseNotSplit))</span><br><span class="line">            <span class="comment"># 划分第i类后总误差小于当前最小总误差</span></span><br><span class="line">            <span class="keyword">if</span> (sseSplit + sseNotSplit) &lt; lowerSSE:</span><br><span class="line">                <span class="comment"># 第i类作为本次划分类</span></span><br><span class="line">                bestCentToSplit = i</span><br><span class="line">                <span class="comment"># 第i类划分后得到的两个质心向量</span></span><br><span class="line">                bestNewCents = centroidMat</span><br><span class="line">                <span class="comment"># 复制第i类中数据点的聚类结果即误差值</span></span><br><span class="line">                bestClustAss = splitClustAss.copy()</span><br><span class="line">                <span class="comment"># 将划分第i类后的总误差作为当前最小误差</span></span><br><span class="line">                lowerSSE = sseSplit + sseNotSplit</span><br><span class="line">        <span class="comment"># 数组过滤选出本次2-means聚类划分后类编号为1数据点，将这些数据点类编号变为</span></span><br><span class="line">        <span class="comment"># 当前类个数+1， 作为新的一个聚类</span></span><br><span class="line">        bestClustAss[np.nonzero(bestClustAss[:, <span class="number">0</span>].A == <span class="number">1</span>)[<span class="number">0</span>], <span class="number">0</span>] = len(centList)</span><br><span class="line">        <span class="comment"># 同理，将划分数据中类编号为0的数据点的类编号仍置为被划分的类编号，使类编号</span></span><br><span class="line">        <span class="comment"># 连续不出现空缺</span></span><br><span class="line">        bestClustAss[np.nonzero(bestClustAss[:, <span class="number">0</span>].A == <span class="number">0</span>)[<span class="number">0</span>], <span class="number">0</span>] = bestCentToSplit</span><br><span class="line">        <span class="comment"># 打印本次执行2-means聚类算法的类</span></span><br><span class="line">        print(<span class="string">'the bestCentToSplit is %d'</span> % bestCentToSplit)</span><br><span class="line">        <span class="comment"># 打印被划分的类的数据个数</span></span><br><span class="line">        print(<span class="string">'the len of bestClustAss is %d'</span> % len(bestClustAss))</span><br><span class="line">        <span class="comment"># 更新质心列表中变化后的质心向量</span></span><br><span class="line">        centList[bestCentToSplit] = bestNewCents[<span class="number">0</span>, :]</span><br><span class="line">        <span class="comment"># 添加新的类的质心向量</span></span><br><span class="line">        centList.append(bestNewCents[<span class="number">1</span>, :])</span><br><span class="line">        <span class="comment"># 更新clusterAssment列表中参与2-means聚类数据点变化后的分类编号，及数据该类的误差平方</span></span><br><span class="line">        clusterAssment[np.nonzero(clusterAssment[:, <span class="number">0</span>].A == bestCentToSplit)[<span class="number">0</span>], :] = bestClustAss</span><br><span class="line">    <span class="comment"># 返回聚类结果</span></span><br><span class="line">    <span class="keyword">return</span> centList, clusterAssment</span><br></pre></td></tr></table></figure><h2 id="源代码-1"><a href="#源代码-1" class="headerlink" title="源代码"></a>源代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Created on Fri Aug  3 13:53:40 2018</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">@author: wzy</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：将文本文档中的数据读入到python中</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    fileName - 文件名</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    dataMat - 数据矩阵</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadDataSet</span><span class="params">(fileName)</span>:</span></span><br><span class="line">    dataMat = []</span><br><span class="line">    fr = open(fileName)</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> fr.readlines():</span><br><span class="line">        curLine = line.strip().split(<span class="string">'\t'</span>)</span><br><span class="line">        fltLine = list(map(float, curLine))</span><br><span class="line">        dataMat.append(fltLine)</span><br><span class="line">    <span class="keyword">return</span> dataMat</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：数据向量计算欧式距离</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    vecA - 数据向量A</span></span><br><span class="line"><span class="string">    vecB - 数据向量B</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    两个向量之间的欧几里德距离</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">distEclud</span><span class="params">(vecA, vecB)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> np.sqrt(np.sum(np.power(vecA - vecB, <span class="number">2</span>)))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：随机初始化k个质心（质心满足数据边界之内）</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    dataSet - 输入的数据集</span></span><br><span class="line"><span class="string">    k - 选取k个质心</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    centroids - 返回初始化得到的k个质心向量</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">randCent</span><span class="params">(dataSet, k)</span>:</span></span><br><span class="line">    <span class="comment"># 得到数据样本的维度</span></span><br><span class="line">    n = np.shape(dataSet)[<span class="number">1</span>]</span><br><span class="line">    <span class="comment"># 初始化为一个(k,n)的全零矩阵</span></span><br><span class="line">    centroids = np.mat(np.zeros((k, n)))</span><br><span class="line">    <span class="comment"># 遍历数据集的每一个维度</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(n):</span><br><span class="line">        <span class="comment"># 得到该列数据的最小值,最大值</span></span><br><span class="line">        minJ = np.min(dataSet[:, j])</span><br><span class="line">        maxJ = np.max(dataSet[:, j])</span><br><span class="line">        <span class="comment"># 得到该列数据的范围(最大值-最小值)</span></span><br><span class="line">        rangeJ = float(maxJ - minJ)</span><br><span class="line">        <span class="comment"># k个质心向量的第j维数据值随机为位于(最小值，最大值)内的某一值</span></span><br><span class="line">        <span class="comment"># Create an array of the given shape and populate it with random samples from a uniform distribution over [0, 1).</span></span><br><span class="line">        centroids[:, j] = minJ + rangeJ * np.random.rand(k, <span class="number">1</span>)</span><br><span class="line">    <span class="comment"># 返回初始化得到的k个质心向量</span></span><br><span class="line">    <span class="keyword">return</span> centroids</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：k-means聚类算法</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    dataSet - 用于聚类的数据集</span></span><br><span class="line"><span class="string">    k - 选取k个质心</span></span><br><span class="line"><span class="string">    distMeas - 距离计算方法,默认欧氏距离distEclud()</span></span><br><span class="line"><span class="string">    createCent - 获取k个质心的方法,默认随机获取randCent()</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    centroids - k个聚类的聚类结果</span></span><br><span class="line"><span class="string">    clusterAssment - 聚类误差</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">kMeans</span><span class="params">(dataSet, k, distMeas=distEclud, createCent=randCent)</span>:</span></span><br><span class="line">    <span class="comment"># 获取数据集样本数</span></span><br><span class="line">    m = np.shape(dataSet)[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># 初始化一个（m,2）全零矩阵</span></span><br><span class="line">    clusterAssment = np.mat(np.zeros((m, <span class="number">2</span>)))</span><br><span class="line">    <span class="comment"># 创建初始的k个质心向量</span></span><br><span class="line">    centroids = createCent(dataSet, k)</span><br><span class="line">    <span class="comment"># 聚类结果是否发生变化的布尔类型</span></span><br><span class="line">    clusterChanged = <span class="literal">True</span></span><br><span class="line">    <span class="comment"># 只要聚类结果一直发生变化，就一直执行聚类算法，直至所有数据点聚类结果不发生变化</span></span><br><span class="line">    <span class="keyword">while</span> clusterChanged:</span><br><span class="line">        <span class="comment"># 聚类结果变化布尔类型置为False</span></span><br><span class="line">        clusterChanged = <span class="literal">False</span></span><br><span class="line">        <span class="comment"># 遍历数据集每一个样本向量</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">            <span class="comment"># 初始化最小距离为正无穷，最小距离对应的索引为-1</span></span><br><span class="line">            minDist = float(<span class="string">'inf'</span>)</span><br><span class="line">            minIndex = <span class="number">-1</span></span><br><span class="line">            <span class="comment"># 循环k个类的质心</span></span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(k):</span><br><span class="line">                <span class="comment"># 计算数据点到质心的欧氏距离</span></span><br><span class="line">                distJI = distMeas(centroids[j, :], dataSet[i, :])</span><br><span class="line">                <span class="comment"># 如果距离小于当前最小距离</span></span><br><span class="line">                <span class="keyword">if</span> distJI &lt; minDist:</span><br><span class="line">                    <span class="comment"># 当前距离为最小距离，最小距离对应索引应为j(第j个类)</span></span><br><span class="line">                    minDist = distJI</span><br><span class="line">                    minIndex = j</span><br><span class="line">            <span class="comment"># 当前聚类结果中第i个样本的聚类结果发生变化：布尔值置为True，继续聚类算法</span></span><br><span class="line">            <span class="keyword">if</span> clusterAssment[i, <span class="number">0</span>] != minIndex: </span><br><span class="line">                clusterChanged = <span class="literal">True</span></span><br><span class="line">            <span class="comment"># 更新当前变化样本的聚类结果和平方误差</span></span><br><span class="line">            clusterAssment[i, :] = minIndex, minDist**<span class="number">2</span></span><br><span class="line">            <span class="comment"># 打印k-means聚类的质心</span></span><br><span class="line">        <span class="comment"># print(centroids)</span></span><br><span class="line">        <span class="comment"># 遍历每一个质心</span></span><br><span class="line">        <span class="keyword">for</span> cent <span class="keyword">in</span> range(k):</span><br><span class="line">            <span class="comment"># 将数据集中所有属于当前质心类的样本通过条件过滤筛选出来</span></span><br><span class="line">            ptsInClust = dataSet[np.nonzero(clusterAssment[:, <span class="number">0</span>].A == cent)[<span class="number">0</span>]]</span><br><span class="line">            <span class="comment"># 计算这些数据的均值(axis=0:求列均值)，作为该类质心向量</span></span><br><span class="line">            centroids[cent, :] = np.mean(ptsInClust, axis=<span class="number">0</span>)</span><br><span class="line">    <span class="comment"># 返回k个聚类，聚类结果及误差</span></span><br><span class="line">    <span class="keyword">return</span> centroids, clusterAssment</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：二分k-means聚类算法</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    dataSet - 用于聚类的数据集</span></span><br><span class="line"><span class="string">    k - 选取k个质心</span></span><br><span class="line"><span class="string">    distMeas - 距离计算方法,默认欧氏距离distEclud()</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    centList - k个聚类的聚类结果</span></span><br><span class="line"><span class="string">    clusterAssment - 聚类误差</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">biKmeans</span><span class="params">(dataSet, k, distMeas=distEclud)</span>:</span></span><br><span class="line">    <span class="comment"># 获取数据集的样本数</span></span><br><span class="line">    m = np.shape(dataSet)[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># 初始化一个元素均值0的(m, 2)矩阵</span></span><br><span class="line">    clusterAssment = np.mat(np.zeros((m, <span class="number">2</span>)))</span><br><span class="line">    <span class="comment"># 获取数据集每一列数据的均值，组成一个列表</span></span><br><span class="line">    centroid0 = np.mean(dataSet, axis=<span class="number">0</span>).tolist()[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># 当前聚类列表为将数据集聚为一类</span></span><br><span class="line">    centList = [centroid0]</span><br><span class="line">    <span class="comment"># 遍历每个数据集样本</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(m):</span><br><span class="line">        <span class="comment"># 计算当前聚为一类时各个数据点距离质心的平方距离</span></span><br><span class="line">        clusterAssment[j, <span class="number">1</span>] = distMeas(np.mat(centroid0), dataSet[j, :])**<span class="number">2</span></span><br><span class="line">    <span class="comment"># 循环，直至二分k-Means值达到k类为止</span></span><br><span class="line">    <span class="keyword">while</span> (len(centList) &lt; k):</span><br><span class="line">        <span class="comment"># 将当前最小平方误差置为正无穷</span></span><br><span class="line">        lowerSSE = float(<span class="string">'inf'</span>)</span><br><span class="line">        <span class="comment"># 遍历当前每个聚类</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(centList)):</span><br><span class="line">            <span class="comment"># 通过数组过滤筛选出属于第i类的数据集合</span></span><br><span class="line">            ptsInCurrCluster = dataSet[np.nonzero(clusterAssment[:, <span class="number">0</span>].A == i)[<span class="number">0</span>], :]</span><br><span class="line">            <span class="comment"># 对该类利用二分k-means算法进行划分，返回划分后的结果以及误差</span></span><br><span class="line">            centroidMat, splitClustAss = kMeans(ptsInCurrCluster, <span class="number">2</span>, distMeas)</span><br><span class="line">            <span class="comment"># 计算该类划分后两个类的误差平方和</span></span><br><span class="line">            sseSplit = np.sum(splitClustAss[:, <span class="number">1</span>])</span><br><span class="line">            <span class="comment"># 计算数据集中不属于该类的数据的误差平方和</span></span><br><span class="line">            sseNotSplit = np.sum(clusterAssment[np.nonzero(clusterAssment[:, <span class="number">0</span>].A != i)[<span class="number">0</span>], <span class="number">1</span>])</span><br><span class="line">            <span class="comment"># 打印这两项误差值</span></span><br><span class="line">            print(<span class="string">'sseSplit = %f, and notSplit = %f'</span> % (sseSplit, sseNotSplit))</span><br><span class="line">            <span class="comment"># 划分第i类后总误差小于当前最小总误差</span></span><br><span class="line">            <span class="keyword">if</span> (sseSplit + sseNotSplit) &lt; lowerSSE:</span><br><span class="line">                <span class="comment"># 第i类作为本次划分类</span></span><br><span class="line">                bestCentToSplit = i</span><br><span class="line">                <span class="comment"># 第i类划分后得到的两个质心向量</span></span><br><span class="line">                bestNewCents = centroidMat</span><br><span class="line">                <span class="comment"># 复制第i类中数据点的聚类结果即误差值</span></span><br><span class="line">                bestClustAss = splitClustAss.copy()</span><br><span class="line">                <span class="comment"># 将划分第i类后的总误差作为当前最小误差</span></span><br><span class="line">                lowerSSE = sseSplit + sseNotSplit</span><br><span class="line">        <span class="comment"># 数组过滤选出本次2-means聚类划分后类编号为1数据点，将这些数据点类编号变为</span></span><br><span class="line">        <span class="comment"># 当前类个数+1， 作为新的一个聚类</span></span><br><span class="line">        bestClustAss[np.nonzero(bestClustAss[:, <span class="number">0</span>].A == <span class="number">1</span>)[<span class="number">0</span>], <span class="number">0</span>] = len(centList)</span><br><span class="line">        <span class="comment"># 同理，将划分数据中类编号为0的数据点的类编号仍置为被划分的类编号，使类编号</span></span><br><span class="line">        <span class="comment"># 连续不出现空缺</span></span><br><span class="line">        bestClustAss[np.nonzero(bestClustAss[:, <span class="number">0</span>].A == <span class="number">0</span>)[<span class="number">0</span>], <span class="number">0</span>] = bestCentToSplit</span><br><span class="line">        <span class="comment"># 打印本次执行2-means聚类算法的类</span></span><br><span class="line">        print(<span class="string">'the bestCentToSplit is %d'</span> % bestCentToSplit)</span><br><span class="line">        <span class="comment"># 打印被划分的类的数据个数</span></span><br><span class="line">        print(<span class="string">'the len of bestClustAss is %d'</span> % len(bestClustAss))</span><br><span class="line">        <span class="comment"># 更新质心列表中变化后的质心向量</span></span><br><span class="line">        centList[bestCentToSplit] = bestNewCents[<span class="number">0</span>, :]</span><br><span class="line">        <span class="comment"># 添加新的类的质心向量</span></span><br><span class="line">        centList.append(bestNewCents[<span class="number">1</span>, :])</span><br><span class="line">        <span class="comment"># 更新clusterAssment列表中参与2-means聚类数据点变化后的分类编号，及数据该类的误差平方</span></span><br><span class="line">        clusterAssment[np.nonzero(clusterAssment[:, <span class="number">0</span>].A == bestCentToSplit)[<span class="number">0</span>], :] = bestClustAss</span><br><span class="line">    <span class="comment"># 返回聚类结果</span></span><br><span class="line">    <span class="keyword">return</span> centList, clusterAssment</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：绘制数据集</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    fileName - 文件名</span></span><br><span class="line"><span class="string">    k - 选取k个质心</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    None</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plotDataSet</span><span class="params">(filename, k)</span>:</span></span><br><span class="line">    <span class="comment"># 导入数据</span></span><br><span class="line">    datMat = np.mat(loadDataSet(filename))</span><br><span class="line">    <span class="comment"># 进行k-means算法其中k为4</span></span><br><span class="line">    centList, clusterAssment = biKmeans(datMat, k)</span><br><span class="line">    clusterAssment = clusterAssment.tolist()</span><br><span class="line">    xcord = [[], [], []]</span><br><span class="line">    ycord = [[], [], []]</span><br><span class="line">    datMat = datMat.tolist()</span><br><span class="line">    m = len(clusterAssment)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">        <span class="keyword">if</span> int(clusterAssment[i][<span class="number">0</span>]) == <span class="number">0</span>:</span><br><span class="line">            xcord[<span class="number">0</span>].append(datMat[i][<span class="number">0</span>])</span><br><span class="line">            ycord[<span class="number">0</span>].append(datMat[i][<span class="number">1</span>])</span><br><span class="line">        <span class="keyword">elif</span> int(clusterAssment[i][<span class="number">0</span>]) == <span class="number">1</span>:</span><br><span class="line">            xcord[<span class="number">1</span>].append(datMat[i][<span class="number">0</span>])</span><br><span class="line">            ycord[<span class="number">1</span>].append(datMat[i][<span class="number">1</span>])</span><br><span class="line">        <span class="keyword">elif</span> int(clusterAssment[i][<span class="number">0</span>]) == <span class="number">2</span>:</span><br><span class="line">            xcord[<span class="number">2</span>].append(datMat[i][<span class="number">0</span>])</span><br><span class="line">            ycord[<span class="number">2</span>].append(datMat[i][<span class="number">1</span>])</span><br><span class="line">    fig = plt.figure()</span><br><span class="line">    ax = fig.add_subplot(<span class="number">111</span>)</span><br><span class="line">    <span class="comment"># 绘制样本点</span></span><br><span class="line">    ax.scatter(xcord[<span class="number">0</span>], ycord[<span class="number">0</span>], s=<span class="number">20</span>, c=<span class="string">'b'</span>, marker=<span class="string">'*'</span>, alpha=<span class="number">.5</span>)</span><br><span class="line">    ax.scatter(xcord[<span class="number">1</span>], ycord[<span class="number">1</span>], s=<span class="number">20</span>, c=<span class="string">'r'</span>, marker=<span class="string">'D'</span>, alpha=<span class="number">.5</span>)</span><br><span class="line">    ax.scatter(xcord[<span class="number">2</span>], ycord[<span class="number">2</span>], s=<span class="number">20</span>, c=<span class="string">'c'</span>, marker=<span class="string">'&gt;'</span>, alpha=<span class="number">.5</span>)</span><br><span class="line">    <span class="comment"># 绘制质心</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(k):</span><br><span class="line">        ax.scatter(centList[i].tolist()[<span class="number">0</span>][<span class="number">0</span>], centList[i].tolist()[<span class="number">0</span>][<span class="number">1</span>], s=<span class="number">100</span>, c=<span class="string">'k'</span>, marker=<span class="string">'+'</span>, alpha=<span class="number">.5</span>)</span><br><span class="line">    <span class="comment"># ax.scatter(centList[0].tolist()[0][0], centList[0].tolist()[0][1], s=100, c='k', marker='+', alpha=.5)</span></span><br><span class="line">    <span class="comment"># ax.scatter(centList[1].tolist()[0][0], centList[1].tolist()[0][1], s=100, c='k', marker='+', alpha=.5)</span></span><br><span class="line">    <span class="comment"># ax.scatter(centList[2].tolist()[0][0], centList[2].tolist()[0][1], s=100, c='k', marker='+', alpha=.5)</span></span><br><span class="line">    plt.title(<span class="string">'DataSet'</span>)</span><br><span class="line">    plt.xlabel(<span class="string">'X'</span>)</span><br><span class="line">    plt.show()</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    datMat = np.mat(loadDataSet(<span class="string">'testSet2.txt'</span>))</span><br><span class="line">    centList, myNewAssments = biKmeans(datMat, <span class="number">3</span>)</span><br><span class="line">    plotDataSet(<span class="string">'testSet2.txt'</span>, <span class="number">3</span>)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;K均值聚类&quot;&gt;&lt;a href=&quot;#K均值聚类&quot; class=&quot;headerlink&quot; title=&quot;K均值聚类&quot;&gt;&lt;/a&gt;K均值聚类&lt;/h1&gt;&lt;p&gt;算法伪代码：&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td 
      
    
    </summary>
    
    
      <category term="Machine_Learning" scheme="https://shyshy903.github.io/categories/Machine-Learning/"/>
    
    
      <category term="ML" scheme="https://shyshy903.github.io/tags/ML/"/>
    
  </entry>
  
  <entry>
    <title>《机器学习实战》《西瓜书》笔记（七）- SVM</title>
    <link href="https://shyshy903.github.io/2019/11/30/Machine_Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%887%20-SVM)/"/>
    <id>https://shyshy903.github.io/2019/11/30/Machine_Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%887%20-SVM)/</id>
    <published>2019-11-30T07:30:00.000Z</published>
    <updated>2020-02-11T08:48:55.572Z</updated>
    
    <content type="html"><![CDATA[<h1 id="SVM（支持向量机）"><a href="#SVM（支持向量机）" class="headerlink" title="SVM（支持向量机）"></a>SVM（支持向量机）</h1><p>支持向量（support vector)就是离分隔超平面最近的那些点。最大化支持向量到分割面的距离。</p><div align = center><img src = "https://img.vim-cn.com/25/6dd0e73f2ac658c2e82d39ddc79adc759cf28e.png"></div><h2 id="核函数（kneral-function"><a href="#核函数（kneral-function" class="headerlink" title="核函数（kneral function)"></a>核函数（kneral function)</h2><p>核函数就是将数据转化成易于分类器理解的一种形式，目前相对流行的一种核函数：径向基函数</p><h3 id="径向基函数"><a href="#径向基函数" class="headerlink" title="径向基函数"></a>径向基函数</h3><p>把数据从一个特征空间映射到另一个特征空间<br>$k(x,y)=exp(\frac{-||x-y||^2}{2\sigma^2})$<br>其中$\sigma$是确定到达率，是函数值跌倒0的速度参数</p><h1 id="代码示例"><a href="#代码示例" class="headerlink" title="代码示例"></a>代码示例</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br><span class="line">429</span><br><span class="line">430</span><br><span class="line">431</span><br><span class="line">432</span><br><span class="line">433</span><br><span class="line">434</span><br><span class="line">435</span><br><span class="line">436</span><br><span class="line">437</span><br><span class="line">438</span><br><span class="line">439</span><br><span class="line">440</span><br><span class="line">441</span><br><span class="line">442</span><br><span class="line">443</span><br><span class="line">444</span><br><span class="line">445</span><br><span class="line">446</span><br><span class="line">447</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Created on Wed Jul 25 11:04:01 2018</span></span><br><span class="line"><span class="string">k1越大会过拟合</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">@author: wzy</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">类说明：维护所有需要操作的值</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    dataMatIn - 数据矩阵</span></span><br><span class="line"><span class="string">    classLabels - 数据标签</span></span><br><span class="line"><span class="string">    C - 松弛变量</span></span><br><span class="line"><span class="string">    toler - 容错率</span></span><br><span class="line"><span class="string">    kTup - 包含核函数信息的元组，第一个参数存放该核函数类别，第二个参数存放必要的核函数需要用到的参数</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    None</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">optStruct</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, dataMatIn, classLabels, C, toler, kTup)</span>:</span></span><br><span class="line">        <span class="comment"># 数据矩阵</span></span><br><span class="line">        self.X = dataMatIn</span><br><span class="line">        <span class="comment"># 数据标签</span></span><br><span class="line">        self.labelMat = classLabels</span><br><span class="line">        <span class="comment"># 松弛变量</span></span><br><span class="line">        self.C = C</span><br><span class="line">        <span class="comment"># 容错率</span></span><br><span class="line">        self.tol = toler</span><br><span class="line">        <span class="comment"># 矩阵的行数</span></span><br><span class="line">        self.m = np.shape(dataMatIn)[<span class="number">0</span>]</span><br><span class="line">        <span class="comment"># 根据矩阵行数初始化alphas矩阵，一个m行1列的全零列向量</span></span><br><span class="line">        self.alphas = np.mat(np.zeros((self.m, <span class="number">1</span>)))</span><br><span class="line">        <span class="comment"># 初始化b参数为0</span></span><br><span class="line">        self.b = <span class="number">0</span></span><br><span class="line">        <span class="comment"># 根据矩阵行数初始化误差缓存矩阵，第一列为是否有效标志位，第二列为实际的误差E的值</span></span><br><span class="line">        self.eCache = np.mat(np.zeros((self.m, <span class="number">2</span>)))</span><br><span class="line">        <span class="comment"># 初始化核K</span></span><br><span class="line">        self.K = np.mat(np.zeros((self.m, self.m)))</span><br><span class="line">        <span class="comment"># 计算所有数据的核K</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(self.m):</span><br><span class="line">            self.K[:, i] = kernelTrans(self.X, self.X[i, :], kTup)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：通过核函数将数据转换更高维空间</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    X - 数据矩阵</span></span><br><span class="line"><span class="string">    A - 单个数据的向量</span></span><br><span class="line"><span class="string">    kTup - 包含核函数信息的元组</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    K - 计算的核K</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">kernelTrans</span><span class="params">(X, A, kTup)</span>:</span></span><br><span class="line">    <span class="comment"># 读取X的行列数</span></span><br><span class="line">    m, n = np.shape(X)</span><br><span class="line">    <span class="comment"># K初始化为m行1列的零向量</span></span><br><span class="line">    K = np.mat(np.zeros((m, <span class="number">1</span>)))</span><br><span class="line">    <span class="comment"># 线性核函数只进行内积</span></span><br><span class="line">    <span class="keyword">if</span> kTup[<span class="number">0</span>] == <span class="string">'lin'</span>:</span><br><span class="line">        K = X * A.T</span><br><span class="line">    <span class="comment"># 高斯核函数，根据高斯核函数公式计算</span></span><br><span class="line">    <span class="keyword">elif</span> kTup[<span class="number">0</span>] == <span class="string">'rbf'</span>:</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(m):</span><br><span class="line">            deltaRow = X[j, :] - A</span><br><span class="line">            K[j] = deltaRow * deltaRow.T</span><br><span class="line">        K = np.exp(K / (<span class="number">-1</span> * kTup[<span class="number">1</span>] ** <span class="number">2</span>))</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">raise</span> NameError(<span class="string">'核函数无法识别'</span>)</span><br><span class="line">    <span class="keyword">return</span> K</span><br><span class="line">     </span><br><span class="line">        </span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：读取数据</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    fileName - 文件名</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    dataMat - 数据矩阵</span></span><br><span class="line"><span class="string">    labelMat - 数据标签</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadDataSet</span><span class="params">(fileName)</span>:</span></span><br><span class="line">    <span class="comment"># 数据矩阵</span></span><br><span class="line">    dataMat = []</span><br><span class="line">    <span class="comment"># 标签向量</span></span><br><span class="line">    labelMat = []</span><br><span class="line">    <span class="comment"># 打开文件</span></span><br><span class="line">    fr = open(fileName)</span><br><span class="line">    <span class="comment"># 逐行读取</span></span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> fr.readlines():</span><br><span class="line">        <span class="comment"># 去掉每一行首尾的空白符，例如'\n','\r','\t',' '</span></span><br><span class="line">        <span class="comment"># 将每一行内容根据'\t'符进行切片</span></span><br><span class="line">        lineArr = line.strip().split(<span class="string">'\t'</span>)</span><br><span class="line">        <span class="comment"># 添加数据(100个元素排成一行)</span></span><br><span class="line">        dataMat.append([float(lineArr[<span class="number">0</span>]), float(lineArr[<span class="number">1</span>])])</span><br><span class="line">        <span class="comment"># 添加标签(100个元素排成一行)</span></span><br><span class="line">        labelMat.append(float(lineArr[<span class="number">2</span>]))</span><br><span class="line">    <span class="keyword">return</span> dataMat, labelMat</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：计算误差</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    oS - 数据结构</span></span><br><span class="line"><span class="string">    k - 标号为k的数据</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    Ek - 标号为k的数据误差</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calcEk</span><span class="params">(oS, k)</span>:</span></span><br><span class="line">    <span class="comment"># multiply(a,b)就是个乘法，如果a,b是两个数组，那么对应元素相乘</span></span><br><span class="line">    <span class="comment"># .T为转置</span></span><br><span class="line">    fXk = float(np.multiply(oS.alphas, oS.labelMat).T * oS.K[:, k]  + oS.b)</span><br><span class="line">    <span class="comment"># 计算误差项</span></span><br><span class="line">    Ek = fXk - float(oS.labelMat[k])</span><br><span class="line">    <span class="comment"># 返回误差项</span></span><br><span class="line">    <span class="keyword">return</span> Ek</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：随机选择alpha_j</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    i - alpha_i的索引值</span></span><br><span class="line"><span class="string">    m - alpha参数个数</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    j - alpha_j的索引值</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">selectJrand</span><span class="params">(i, m)</span>:</span></span><br><span class="line">    j = i</span><br><span class="line">    <span class="keyword">while</span>(j == i):</span><br><span class="line">        <span class="comment"># uniform()方法将随机生成一个实数，它在[x, y)范围内</span></span><br><span class="line">        j = int(random.uniform(<span class="number">0</span>, m))</span><br><span class="line">    <span class="keyword">return</span> j</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：内循环启发方式2</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    i - 标号为i的数据的索引值</span></span><br><span class="line"><span class="string">    oS - 数据结构</span></span><br><span class="line"><span class="string">    Ei - 标号为i的数据误差</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    j - 标号为j的数据的索引值</span></span><br><span class="line"><span class="string">    maxK - 标号为maxK的数据的索引值</span></span><br><span class="line"><span class="string">    Ej - 标号为j的数据误差</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">selectJ</span><span class="params">(i, oS, Ei)</span>:</span></span><br><span class="line">    <span class="comment"># 初始化</span></span><br><span class="line">    maxK = <span class="number">-1</span></span><br><span class="line">    maxDeltaE = <span class="number">0</span></span><br><span class="line">    Ej = <span class="number">0</span></span><br><span class="line">    <span class="comment"># 根据Ei更新误差缓存</span></span><br><span class="line">    oS.eCache[i] = [<span class="number">1</span>, Ei]</span><br><span class="line">    <span class="comment"># 对一个矩阵.A转换为Array类型</span></span><br><span class="line">    <span class="comment"># 返回误差不为0的数据的索引值</span></span><br><span class="line">    validEcacheList = np.nonzero(oS.eCache[:, <span class="number">0</span>].A)[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># 有不为0的误差</span></span><br><span class="line">    <span class="keyword">if</span>(len(validEcacheList) &gt; <span class="number">1</span>):</span><br><span class="line">        <span class="comment"># 遍历，找到最大的Ek</span></span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> validEcacheList:</span><br><span class="line">            <span class="comment"># 不计算k==i节省时间</span></span><br><span class="line">            <span class="keyword">if</span> k == i:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            <span class="comment"># 计算Ek</span></span><br><span class="line">            Ek = calcEk(oS, k)</span><br><span class="line">            <span class="comment"># 计算|Ei - Ek|</span></span><br><span class="line">            deltaE = abs(Ei - Ek)</span><br><span class="line">            <span class="comment"># 找到maxDeltaE</span></span><br><span class="line">            <span class="keyword">if</span>(deltaE &gt; maxDeltaE):</span><br><span class="line">                maxK = k</span><br><span class="line">                maxDeltaE = deltaE</span><br><span class="line">                Ej = Ek</span><br><span class="line">        <span class="comment"># 返回maxK，Ej</span></span><br><span class="line">        <span class="keyword">return</span> maxK, Ej</span><br><span class="line">    <span class="comment"># 没有不为0的误差</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># 随机选择alpha_j的索引值</span></span><br><span class="line">        j = selectJrand(i, oS.m)</span><br><span class="line">        <span class="comment"># 计算Ej</span></span><br><span class="line">        Ej = calcEk(oS, j)</span><br><span class="line">    <span class="comment"># 返回j，Ej</span></span><br><span class="line">    <span class="keyword">return</span> j, Ej</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：计算Ek,并更新误差缓存</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    oS - 数据结构</span></span><br><span class="line"><span class="string">    k - 标号为k的数据的索引值</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    None</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">updateEk</span><span class="params">(oS, k)</span>:</span></span><br><span class="line">    <span class="comment"># 计算Ek</span></span><br><span class="line">    Ek = calcEk(oS, k)</span><br><span class="line">    <span class="comment"># 更新误差缓存</span></span><br><span class="line">    oS.eCache[k] = [<span class="number">1</span>, Ek]</span><br><span class="line">    </span><br><span class="line">      </span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：修剪alpha_j</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    aj - alpha_j值</span></span><br><span class="line"><span class="string">    H - alpha上限</span></span><br><span class="line"><span class="string">    L - alpha下限</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    aj - alpha_j值</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Modify:</span></span><br><span class="line"><span class="string">    2018-07-24</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">clipAlpha</span><span class="params">(aj, H, L)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> aj &gt; H:</span><br><span class="line">        aj = H</span><br><span class="line">    <span class="keyword">if</span> L &gt; aj:</span><br><span class="line">        aj = L</span><br><span class="line">    <span class="keyword">return</span> aj</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：优化的SMO算法</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    i - 标号为i的数据的索引值</span></span><br><span class="line"><span class="string">    oS - 数据结构</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    1 - 有任意一对alpha值发生变化</span></span><br><span class="line"><span class="string">    0 - 没有任意一对alpha值发生变化或变化太小</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">innerL</span><span class="params">(i, oS)</span>:</span></span><br><span class="line">    <span class="comment"># 步骤1：计算误差Ei</span></span><br><span class="line">    Ei = calcEk(oS, i)</span><br><span class="line">    <span class="comment"># 优化alpha,设定一定的容错率</span></span><br><span class="line">    <span class="keyword">if</span>((oS.labelMat[i] * Ei &lt; -oS.tol) <span class="keyword">and</span> (oS.alphas[i] &lt; oS.C)) <span class="keyword">or</span> ((oS.labelMat[i] * Ei &gt; oS.tol) <span class="keyword">and</span> (oS.alphas[i] &gt; <span class="number">0</span>)):</span><br><span class="line">        <span class="comment"># 使用内循环启发方式2选择alpha_j,并计算Ej</span></span><br><span class="line">        j, Ej = selectJ(i, oS, Ei)</span><br><span class="line">        <span class="comment"># 保存更新前的alpha值，使用深层拷贝</span></span><br><span class="line">        alphaIold = oS.alphas[i].copy()</span><br><span class="line">        alphaJold = oS.alphas[j].copy()</span><br><span class="line">        <span class="comment"># 步骤2：计算上界H和下界L</span></span><br><span class="line">        <span class="keyword">if</span>(oS.labelMat[i] != oS.labelMat[j]):</span><br><span class="line">            L = max(<span class="number">0</span>, oS.alphas[j] - oS.alphas[i])</span><br><span class="line">            H = min(oS.C, oS.C + oS.alphas[j] - oS.alphas[i])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            L = max(<span class="number">0</span>, oS.alphas[j] + oS.alphas[i] - oS.C)</span><br><span class="line">            H = min(oS.C, oS.alphas[j] + oS.alphas[i])</span><br><span class="line">        <span class="keyword">if</span> L == H:</span><br><span class="line">            print(<span class="string">"L == H"</span>)</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        <span class="comment"># 步骤3：计算eta</span></span><br><span class="line">        eta = <span class="number">2.0</span> * oS.K[i, j] - oS.K[i, i] - oS.K[j, j]</span><br><span class="line">        <span class="keyword">if</span> eta &gt;= <span class="number">0</span>:</span><br><span class="line">            print(<span class="string">"eta &gt;= 0"</span>)</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        <span class="comment"># 步骤4：更新alpha_j</span></span><br><span class="line">        oS.alphas[j] -= oS.labelMat[j] * (Ei - Ej) / eta</span><br><span class="line">        <span class="comment"># 步骤5：修剪alpha_j</span></span><br><span class="line">        oS.alphas[j] = clipAlpha(oS.alphas[j], H, L)</span><br><span class="line">        <span class="comment"># 更新Ej至误差缓存</span></span><br><span class="line">        updateEk(oS, j)</span><br><span class="line">        <span class="keyword">if</span>(abs(oS.alphas[j] - alphaJold) &lt; <span class="number">0.00001</span>):</span><br><span class="line">            print(<span class="string">"alpha_j变化太小"</span>)</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        <span class="comment"># 步骤6：更新alpha_i</span></span><br><span class="line">        oS.alphas[i] += oS.labelMat[i] * oS.labelMat[j] * (alphaJold - oS.alphas[j])</span><br><span class="line">        <span class="comment"># 更新Ei至误差缓存</span></span><br><span class="line">        updateEk(oS, i)</span><br><span class="line">        <span class="comment"># 步骤7：更新b_1和b_2:</span></span><br><span class="line">        b1 = oS.b - Ei - oS.labelMat[i] * (oS.alphas[i] - alphaIold) * oS.K[i, i] - oS.labelMat[j] * (oS.alphas[j] - alphaJold) * oS.K[j, i]</span><br><span class="line">        b2 = oS.b - Ej - oS.labelMat[i] * (oS.alphas[i] - alphaIold) * oS.K[i, j] - oS.labelMat[j] * (oS.alphas[j] - alphaJold) * oS.K[j, j]</span><br><span class="line">        <span class="comment"># 步骤8：根据b_1和b_2更新b</span></span><br><span class="line">        <span class="keyword">if</span>(<span class="number">0</span> &lt; oS.alphas[i] &lt; oS.C):</span><br><span class="line">            oS.b = b1</span><br><span class="line">        <span class="keyword">elif</span>(<span class="number">0</span> &lt; oS.alphas[j] &lt; oS.C):</span><br><span class="line">            oS.b = b2</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            oS.b = (b1 + b2) / <span class="number">2.0</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：完整的线性SMO算法</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    dataMatIn - 数据矩阵</span></span><br><span class="line"><span class="string">    classLabels - 数据标签</span></span><br><span class="line"><span class="string">    C - 松弛变量</span></span><br><span class="line"><span class="string">    toler - 容错率</span></span><br><span class="line"><span class="string">    maxIter - 最大迭代次数</span></span><br><span class="line"><span class="string">    kTup - 包含核函数信息的元组</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    oS.b - SMO算法计算的b</span></span><br><span class="line"><span class="string">    oS.alphas - SMO算法计算的alphas</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">smoP</span><span class="params">(dataMatIn, classLabels, C, toler, maxIter, kTup = <span class="params">(<span class="string">'lin'</span>, <span class="number">0</span>)</span>)</span>:</span></span><br><span class="line">    <span class="comment"># 初始化数据结构</span></span><br><span class="line">    oS = optStruct(np.mat(dataMatIn), np.mat(classLabels).transpose(), C, toler, kTup)</span><br><span class="line">    <span class="comment"># 初始化当前迭代次数</span></span><br><span class="line">    iter = <span class="number">0</span></span><br><span class="line">    entrieSet = <span class="literal">True</span></span><br><span class="line">    alphaPairsChanged = <span class="number">0</span></span><br><span class="line">    <span class="comment"># 遍历整个数据集alpha都没有更新或者超过最大迭代次数，则退出循环</span></span><br><span class="line">    <span class="keyword">while</span>(iter &lt; maxIter) <span class="keyword">and</span> ((alphaPairsChanged &gt; <span class="number">0</span>) <span class="keyword">or</span> (entrieSet)):</span><br><span class="line">        alphaPairsChanged = <span class="number">0</span></span><br><span class="line">        <span class="comment"># 遍历整个数据集</span></span><br><span class="line">        <span class="keyword">if</span> entrieSet:</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(oS.m):</span><br><span class="line">                <span class="comment"># 使用优化的SMO算法</span></span><br><span class="line">                alphaPairsChanged += innerL(i, oS)</span><br><span class="line">                print(<span class="string">"全样本遍历:第%d次迭代 样本:%d, alpha优化次数:%d"</span> % (iter, i, alphaPairsChanged))</span><br><span class="line">            iter += <span class="number">1</span></span><br><span class="line">        <span class="comment"># 遍历非边界值</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 遍历不在边界0和C的alpha</span></span><br><span class="line">            nonBoundIs = np.nonzero((oS.alphas.A &gt; <span class="number">0</span>) * (oS.alphas.A &lt; C))[<span class="number">0</span>]</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> nonBoundIs:</span><br><span class="line">                alphaPairsChanged += innerL(i, oS)</span><br><span class="line">                print(<span class="string">"非边界遍历:第%d次迭代 样本:%d, alpha优化次数:%d"</span> % (iter, i, alphaPairsChanged))</span><br><span class="line">            iter += <span class="number">1</span></span><br><span class="line">        <span class="comment"># 遍历一次后改为非边界遍历</span></span><br><span class="line">        <span class="keyword">if</span> entrieSet:</span><br><span class="line">            entrieSet = <span class="literal">False</span></span><br><span class="line">        <span class="comment"># 如果alpha没有更新，计算全样本遍历</span></span><br><span class="line">        <span class="keyword">elif</span>(alphaPairsChanged == <span class="number">0</span>):</span><br><span class="line">            entrieSet = <span class="literal">True</span></span><br><span class="line">        print(<span class="string">"迭代次数:%d"</span> % iter)</span><br><span class="line">    <span class="comment"># 返回SMO算法计算的b和alphas</span></span><br><span class="line">    <span class="keyword">return</span> oS.b, oS.alphas</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：测试函数</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    k1 - 使用高斯核函数的时候表示到达率</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    None</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">testRbf</span><span class="params">(k1 = <span class="number">1.3</span>)</span>:</span></span><br><span class="line">    <span class="comment"># 加载训练集</span></span><br><span class="line">    dataArr, labelArr = loadDataSet(<span class="string">'testSetRBF.txt'</span>)</span><br><span class="line">    <span class="comment"># 根据训练集计算b, alphas</span></span><br><span class="line">    b, alphas = smoP(dataArr, labelArr, <span class="number">200</span>, <span class="number">0.0001</span>, <span class="number">100</span>, (<span class="string">'rbf'</span>, k1))</span><br><span class="line">    datMat = np.mat(dataArr)</span><br><span class="line">    labelMat = np.mat(labelArr).transpose()</span><br><span class="line">    <span class="comment"># 获得支持向量</span></span><br><span class="line">    svInd = np.nonzero(alphas.A &gt; <span class="number">0</span>)[<span class="number">0</span>]</span><br><span class="line">    sVs = datMat[svInd]</span><br><span class="line">    labelSV = labelMat[svInd]</span><br><span class="line">    print(<span class="string">"支持向量个数:%d"</span> % np.shape(sVs)[<span class="number">0</span>])</span><br><span class="line">    m, n = np.shape(datMat)</span><br><span class="line">    errorCount = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">        <span class="comment"># 计算各个点的核</span></span><br><span class="line">        kernelEval = kernelTrans(sVs, datMat[i, :], (<span class="string">'rbf'</span>, k1))</span><br><span class="line">        <span class="comment"># 根据支持向量的点计算超平面，返回预测结果</span></span><br><span class="line">        predict = kernelEval.T * np.multiply(labelSV, alphas[svInd]) + b</span><br><span class="line">        <span class="comment"># 返回数组中各元素的正负号，用1和-1表示，并统计错误个数</span></span><br><span class="line">        <span class="keyword">if</span> np.sign(predict) != np.sign(labelArr[i]):</span><br><span class="line">            errorCount += <span class="number">1</span></span><br><span class="line">    <span class="comment"># 打印错误率</span></span><br><span class="line">    print(<span class="string">'训练集错误率:%.2f%%'</span> % ((float(errorCount) / m) * <span class="number">100</span>))</span><br><span class="line">    <span class="comment"># 加载测试集</span></span><br><span class="line">    dataArr, labelArr = loadDataSet(<span class="string">'testSetRBF2.txt'</span>)</span><br><span class="line">    errorCount = <span class="number">0</span></span><br><span class="line">    datMat = np.mat(dataArr)</span><br><span class="line">    labelMat = np.mat(labelArr).transpose()</span><br><span class="line">    m, n = np.shape(datMat)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">        <span class="comment"># 计算各个点的核</span></span><br><span class="line">        kernelEval = kernelTrans(sVs, datMat[i, :], (<span class="string">'rbf'</span>, k1))</span><br><span class="line">        <span class="comment"># 根据支持向量的点计算超平面，返回预测结果</span></span><br><span class="line">        predict = kernelEval.T * np.multiply(labelSV, alphas[svInd]) + b</span><br><span class="line">        <span class="comment"># 返回数组中各元素的正负号，用1和-1表示，并统计错误个数</span></span><br><span class="line">        <span class="keyword">if</span> np.sign(predict) != np.sign(labelArr[i]):</span><br><span class="line">            errorCount += <span class="number">1</span></span><br><span class="line">    <span class="comment"># 打印错误率</span></span><br><span class="line">    print(<span class="string">'训练集错误率:%.2f%%'</span> % ((float(errorCount) / m) * <span class="number">100</span>))</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：数据可视化</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    dataMat - 数据矩阵</span></span><br><span class="line"><span class="string">    labelMat - 数据标签</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    None</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">showDataSet</span><span class="params">(dataMat, labelMat)</span>:</span></span><br><span class="line">    <span class="comment"># 正样本</span></span><br><span class="line">    data_plus = []</span><br><span class="line">    <span class="comment"># 负样本</span></span><br><span class="line">    data_minus = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(dataMat)):</span><br><span class="line">        <span class="keyword">if</span> labelMat[i] &gt; <span class="number">0</span>:</span><br><span class="line">            data_plus.append(dataMat[i])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            data_minus.append(dataMat[i])</span><br><span class="line">    <span class="comment"># 转换为numpy矩阵</span></span><br><span class="line">    data_plus_np = np.array(data_plus)</span><br><span class="line">    <span class="comment"># 转换为numpy矩阵</span></span><br><span class="line">    data_minus_np = np.array(data_minus)</span><br><span class="line">    <span class="comment"># 正样本散点图（scatter）</span></span><br><span class="line">    <span class="comment"># transpose转置</span></span><br><span class="line">    plt.scatter(np.transpose(data_plus_np)[<span class="number">0</span>], np.transpose(data_plus_np)[<span class="number">1</span>])</span><br><span class="line">    <span class="comment"># 负样本散点图（scatter）</span></span><br><span class="line">    plt.scatter(np.transpose(data_minus_np)[<span class="number">0</span>], np.transpose(data_minus_np)[<span class="number">1</span>])</span><br><span class="line">    <span class="comment"># 显示</span></span><br><span class="line">    plt.show()</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    testRbf()</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;SVM（支持向量机）&quot;&gt;&lt;a href=&quot;#SVM（支持向量机）&quot; class=&quot;headerlink&quot; title=&quot;SVM（支持向量机）&quot;&gt;&lt;/a&gt;SVM（支持向量机）&lt;/h1&gt;&lt;p&gt;支持向量（support vector)就是离分隔超平面最近的那些点。最大化
      
    
    </summary>
    
    
      <category term="Machine_Learning" scheme="https://shyshy903.github.io/categories/Machine-Learning/"/>
    
    
      <category term="ML" scheme="https://shyshy903.github.io/tags/ML/"/>
    
  </entry>
  
  <entry>
    <title>《机器学习实战》《西瓜书》笔记（五）- 朴素贝叶斯</title>
    <link href="https://shyshy903.github.io/2019/11/28/Machine_Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%885-%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%EF%BC%89/"/>
    <id>https://shyshy903.github.io/2019/11/28/Machine_Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%885-%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%EF%BC%89/</id>
    <published>2019-11-28T07:30:00.000Z</published>
    <updated>2020-02-11T08:48:55.558Z</updated>
    
    <content type="html"><![CDATA[<h1 id="贝叶斯"><a href="#贝叶斯" class="headerlink" title="贝叶斯"></a>贝叶斯</h1><h2 id="贝叶斯定理"><a href="#贝叶斯定理" class="headerlink" title="贝叶斯定理"></a>贝叶斯定理</h2><p>$p(c|x) = \frac{p(x|c)p(c)}{p(x)}$<br>其中c为类别，x为实例具有特征${x_1,x_2,…x_i}$<br>如果 $p(c_1|x) &gt; p(c_2|x)$，那么就属于类别c1,反之属于c2</p><h2 id="朴素贝叶斯的一般过程"><a href="#朴素贝叶斯的一般过程" class="headerlink" title="朴素贝叶斯的一般过程"></a>朴素贝叶斯的一般过程</h2><ol><li>收集数据，可以使用RSS源</li><li>准备数据，需要使用<strong>数值型或者布尔型</strong></li><li>分析数据，大量特征时，可以绘制直方图</li><li>训练算法，计算不同的独立特征的条件概率</li><li>测试算法，计算错误率</li><li>使用算法，封装贝叶斯分类器</li></ol><h2 id="文本分类"><a href="#文本分类" class="headerlink" title="文本分类"></a>文本分类</h2><h3 id="准备数据，从文本中构建词向量"><a href="#准备数据，从文本中构建词向量" class="headerlink" title="准备数据，从文本中构建词向量"></a>准备数据，从文本中构建词向量</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：创建实验样本</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    None</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    postingList - 实验样本切分的词条</span></span><br><span class="line"><span class="string">    classVec - 类别标签向量</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadDataSet</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="comment"># 切分的词条</span></span><br><span class="line">    postingList = [[<span class="string">'my'</span>, <span class="string">'dog'</span>, <span class="string">'has'</span>, <span class="string">'flea'</span>, <span class="string">'problems'</span>, <span class="string">'help'</span>, <span class="string">'please'</span>],</span><br><span class="line">                   [<span class="string">'maybe'</span>, <span class="string">'not'</span>, <span class="string">'take'</span>, <span class="string">'him'</span>, <span class="string">'to'</span>, <span class="string">'dog'</span>, <span class="string">'park'</span>, <span class="string">'stupid'</span>],</span><br><span class="line">                   [<span class="string">'my'</span>, <span class="string">'dalmation'</span>, <span class="string">'is'</span>, <span class="string">'so'</span>, <span class="string">'cute'</span>, <span class="string">'I'</span>, <span class="string">'love'</span>, <span class="string">'him'</span>],</span><br><span class="line">                   [<span class="string">'stop'</span>, <span class="string">'posting'</span>, <span class="string">'stupid'</span>, <span class="string">'worthless'</span>, <span class="string">'garbage'</span>],</span><br><span class="line">                   [<span class="string">'mr'</span>, <span class="string">'licks'</span>, <span class="string">'ate'</span>, <span class="string">'my'</span>, <span class="string">'steak'</span>, <span class="string">'how'</span>, <span class="string">'to'</span>, <span class="string">'stop'</span>, <span class="string">'him'</span>],</span><br><span class="line">                   [<span class="string">'quit'</span>, <span class="string">'buying'</span>, <span class="string">'worthless'</span>, <span class="string">'dog'</span>, <span class="string">'food'</span>, <span class="string">'stupid'</span>]]</span><br><span class="line">    <span class="comment"># 类别标签向量，1代表侮辱性词汇，0代表不是</span></span><br><span class="line">    classVec = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>]</span><br><span class="line">    <span class="comment"># 返回实验样本切分的词条、类别标签向量</span></span><br><span class="line">    <span class="keyword">return</span> postingList, classVec</span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：将切分的实验样本词条整理成不重复的词条列表，也就是词汇表</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    dataSet - 整理的样本数据集</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    vocabSet - 返回不重复的词条列表，也就是词汇表</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">createVocabList</span><span class="params">(dataSet)</span>:</span></span><br><span class="line">    <span class="comment"># 创建一个空的不重复列表</span></span><br><span class="line">    <span class="comment"># set是一个无序且不重复的元素集合</span></span><br><span class="line">    vocabSet = set([])</span><br><span class="line">    <span class="keyword">for</span> document <span class="keyword">in</span> dataSet:</span><br><span class="line">        <span class="comment"># 取并集</span></span><br><span class="line">        vocabSet = vocabSet | set(document)</span><br><span class="line">    <span class="keyword">return</span> list(vocabSet)</span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：根据vocabList词汇表，将inputSet向量化，向量的每个元素为1或0</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    vocabList - createVocabList返回的列表</span></span><br><span class="line"><span class="string">    inputSet - 切分的词条列表</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    returnVec - 文档向量，词集模型</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">setOfWords2Vec</span><span class="params">(vocabList, inputSet)</span>:</span></span><br><span class="line">    <span class="comment"># 创建一个其中所含元素都为0的向量</span></span><br><span class="line">    returnVec = [<span class="number">0</span>] * len(vocabList)</span><br><span class="line">    <span class="comment"># 遍历每个词条</span></span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> inputSet:</span><br><span class="line">        <span class="keyword">if</span> word <span class="keyword">in</span> vocabList:</span><br><span class="line">            <span class="comment"># 如果词条存在于词汇表中，则置1</span></span><br><span class="line">            <span class="comment"># index返回word出现在vocabList中的索引</span></span><br><span class="line">            <span class="comment"># 若这里改为+=则就是基于词袋的模型，遇到一个单词会增加单词向量中德对应值</span></span><br><span class="line">            returnVec[vocabList.index(word)] = <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            print(<span class="string">"the word: %s is not in my Vocabulary"</span> % word)</span><br><span class="line">    <span class="comment"># 返回文档向量</span></span><br><span class="line">    <span class="keyword">return</span> returnVec</span><br><span class="line"></span><br><span class="line">&gt;&gt; imort bayes</span><br><span class="line">&gt;&gt; listOposts, listClasses = bayes.loadDataSet()</span><br><span class="line">&gt;&gt; myVocabList = bayes.createVocabList(listOpists)</span><br><span class="line">&gt;&gt; bayes.setOfWords2Vec(myVocabList, listOpists)</span><br><span class="line">[<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0.</span>........]</span><br></pre></td></tr></table></figure><h3 id="训练算法，从词向量计算概率"><a href="#训练算法，从词向量计算概率" class="headerlink" title="训练算法，从词向量计算概率"></a>训练算法，从词向量计算概率</h3><p>$p(c|w) = \frac{p(w|c)p(c)}{p(w)}$<br>$p(c) = \frac{类别c的实例数}{总的实例数}$<br>$p(w|c)  = p(w_0,w_1,w_2,w_3,w_4 |c_i)$<br>$p(w|c)  = p(w_0|c_i)p(w_1|c_i)p(w_2|c_i)p(w_3|c_i)…p(w_n|c_i)$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br></pre></td><td class="code"><pre><span class="line">计算每个类别中的文档数目</span><br><span class="line">对每篇训练文档</span><br><span class="line">    对每个类被</span><br><span class="line">        如果词条出现在文档中，增加该词条的计数值</span><br><span class="line">        增加所有词条的计数值</span><br><span class="line">    对每个类别</span><br><span class="line">        对每个词条：</span><br><span class="line">            将该词条的数目除以总的词条数目<span class="number">1</span>得到条件概率</span><br><span class="line">    返回每个类别的条件概率</span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：朴素贝叶斯分类器训练函数</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    trainMatrix - 训练文档矩阵，即setOfWords2Vec返回的returnVec构成的矩阵</span></span><br><span class="line"><span class="string">    trainCategory - 训练类标签向量，即loadDataSet返回的classVec</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    p0Vect - 侮辱类的条件概率数组</span></span><br><span class="line"><span class="string">    p1Vect - 非侮辱类的条件概率数组</span></span><br><span class="line"><span class="string">    pAbusive - 文档属于侮辱类的概率</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">trainNB0</span><span class="params">(trainMatrix, trainCategory)</span>:</span></span><br><span class="line">    <span class="comment"># 计算训练文档数目</span></span><br><span class="line">    numTrainDocs = len(trainMatrix)</span><br><span class="line">    <span class="comment"># 计算每篇文档的词条数目</span></span><br><span class="line">    numWords = len(trainMatrix[<span class="number">0</span>])</span><br><span class="line">    <span class="comment"># 文档属于侮辱类的概率</span></span><br><span class="line">    pAbusive = sum(trainCategory)/float(numTrainDocs)</span><br><span class="line">    <span class="comment"># 创建numpy.zeros数组，词条出现数初始化为0</span></span><br><span class="line">    <span class="comment"># p0Num = np.zeros(numWords)</span></span><br><span class="line">    <span class="comment"># p1Num = np.zeros(numWords)</span></span><br><span class="line">    <span class="comment"># 创建numpy.ones数组，词条出现数初始化为1,拉普拉斯平滑</span></span><br><span class="line">    p0Num = np.ones(numWords)</span><br><span class="line">    p1Num = np.ones(numWords)</span><br><span class="line">    <span class="comment"># 分母初始化为0</span></span><br><span class="line">    <span class="comment"># p0Denom = 0.0</span></span><br><span class="line">    <span class="comment"># p1Denom = 0.0</span></span><br><span class="line">    <span class="comment"># 分母初始化为2，拉普拉斯平滑</span></span><br><span class="line">    p0Denom = <span class="number">2.0</span></span><br><span class="line">    p1Denom = <span class="number">2.0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(numTrainDocs):</span><br><span class="line">        <span class="comment"># 统计属于侮辱类的条件概率所需的数据，即P(w0|1),P(w1|1),P(w2|1)...</span></span><br><span class="line">        <span class="keyword">if</span> trainCategory[i] == <span class="number">1</span>:</span><br><span class="line">            <span class="comment"># 统计所有侮辱类文档中每个单词出现的个数</span></span><br><span class="line">            p1Num += trainMatrix[i]</span><br><span class="line">            <span class="comment"># 统计一共出现的侮辱单词的个数</span></span><br><span class="line">            p1Denom += sum(trainMatrix[i])</span><br><span class="line">        <span class="comment"># 统计属于非侮辱类的条件概率所需的数据，即P(w0|0),P(w1|0),P(w2|0)...</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 统计所有非侮辱类文档中每个单词出现的个数</span></span><br><span class="line">            p0Num += trainMatrix[i]</span><br><span class="line">            <span class="comment"># 统计一共出现的非侮辱单词的个数</span></span><br><span class="line">            p0Denom += sum(trainMatrix[i])</span><br><span class="line">    <span class="comment"># 每个侮辱类单词分别出现的概率</span></span><br><span class="line">    <span class="comment"># p1Vect = p1Num / p1Denom</span></span><br><span class="line">    <span class="comment"># 取对数，防止下溢出</span></span><br><span class="line">    p1Vect = np.log(p1Num / p1Denom)</span><br><span class="line">    <span class="comment"># 每个非侮辱类单词分别出现的概率</span></span><br><span class="line">    <span class="comment"># p0Vect = p0Num / p0Denom</span></span><br><span class="line">    <span class="comment"># 取对数，防止下溢出</span></span><br><span class="line">    p0Vect = np.log(p0Num / p0Denom)</span><br><span class="line">    <span class="comment"># 返回属于侮辱类的条件概率数组、属于非侮辱类的条件概率数组、文档属于侮辱类的概率</span></span><br><span class="line">    <span class="keyword">return</span> p0Vect, p1Vect, pAbusive</span><br><span class="line">```           </span><br><span class="line"><span class="comment">### 测试算法，改进</span></span><br><span class="line">为了避免$p(w|c)  = p(w_0|c_i)p(w_1|c_i)p(w_2|c_i)p(w_3|c_i)...p(w_n|c_i)$中出现某一项为<span class="number">0</span>的情况，这里采用对数矫正：</span><br><span class="line">$ln(a*b) = lna + lnb$</span><br><span class="line">```python</span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：朴素贝叶斯分类器分类函数</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    vec2Classify - 待分类的词条数组</span></span><br><span class="line"><span class="string">    p0Vec - 侮辱类的条件概率数组</span></span><br><span class="line"><span class="string">    p1Vec - 非侮辱类的条件概率数组</span></span><br><span class="line"><span class="string">    pClass1 - 文档属于侮辱类的概率</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    0 - 属于非侮辱类</span></span><br><span class="line"><span class="string">    1 - 属于侮辱类</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Modify:</span></span><br><span class="line"><span class="string">    2018-07-21</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">classifyNB</span><span class="params">(vec2Classify, p0Vec, p1Vec, pClass1)</span>:</span></span><br><span class="line">    <span class="comment"># 对应元素相乘</span></span><br><span class="line">    <span class="comment"># p1 = reduce(lambda x,y:x*y, vec2Classify * p1Vec) * pClass1</span></span><br><span class="line">    <span class="comment"># p0 = reduce(lambda x,y:x*y, vec2Classify * p0Vec) * (1.0 - pClass1)</span></span><br><span class="line">    <span class="comment"># 对应元素相乘，logA*B = logA + logB所以这里是累加</span></span><br><span class="line">    p1 = sum(vec2Classify * p1Vec) + np.log(pClass1)</span><br><span class="line">    p0 = sum(vec2Classify * p0Vec) + np.log(<span class="number">1.0</span> - pClass1)</span><br><span class="line">    <span class="comment"># print('p0:', p0)</span></span><br><span class="line">    <span class="comment"># print('p1:', p1)</span></span><br><span class="line">    <span class="keyword">if</span> p1 &gt; p0:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：测试朴素贝叶斯分类器</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    None</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    None</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Modify:</span></span><br><span class="line"><span class="string">    2018-07-21</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">testingNB</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="comment"># 创建实验样本</span></span><br><span class="line">    listOPosts, listclasses = loadDataSet()</span><br><span class="line">    <span class="comment"># 创建词汇表,将输入文本中的不重复的单词进行提取组成单词向量</span></span><br><span class="line">    myVocabList = createVocabList(listOPosts)</span><br><span class="line">    trainMat = []</span><br><span class="line">    <span class="keyword">for</span> postinDoc <span class="keyword">in</span> listOPosts:</span><br><span class="line">        <span class="comment"># 将实验样本向量化若postinDoc中的单词在myVocabList出现则将returnVec该位置的索引置1</span></span><br><span class="line">        <span class="comment"># 将6组数据list存储在trainMat中</span></span><br><span class="line">        trainMat.append(setOfWords2Vec(myVocabList, postinDoc))</span><br><span class="line">    <span class="comment"># 训练朴素贝叶斯分类器</span></span><br><span class="line">    p0V, p1V, pAb = trainNB0(np.array(trainMat), np.array(listclasses))</span><br><span class="line">    <span class="comment"># 测试样本1</span></span><br><span class="line">    testEntry = [<span class="string">'love'</span>, <span class="string">'my'</span>, <span class="string">'dalmation'</span>]</span><br><span class="line">    <span class="comment"># 测试样本向量化返回这三个单词出现位置的索引</span></span><br><span class="line">    thisDoc = np.array(setOfWords2Vec(myVocabList, testEntry))</span><br><span class="line">    <span class="keyword">if</span> classifyNB(thisDoc, p0V, p1V, pAb):</span><br><span class="line">        <span class="comment"># 执行分类并打印结果</span></span><br><span class="line">        print(testEntry, <span class="string">'属于侮辱类'</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># 执行分类并打印结果</span></span><br><span class="line">        print(testEntry, <span class="string">'属于非侮辱类'</span>)</span><br><span class="line">    <span class="comment"># 测试样本2</span></span><br><span class="line">    testEntry = [<span class="string">'stupid'</span>, <span class="string">'garbage'</span>]</span><br><span class="line">    <span class="comment"># 将实验样本向量化</span></span><br><span class="line">    thisDoc = np.array(setOfWords2Vec(myVocabList, testEntry))</span><br><span class="line">    <span class="keyword">if</span> classifyNB(thisDoc, p0V, p1V, pAb):</span><br><span class="line">        <span class="comment"># 执行分类并打印结果</span></span><br><span class="line">        print(testEntry, <span class="string">'属于侮辱类'</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># 执行分类并打印结果</span></span><br><span class="line">        print(testEntry, <span class="string">'属于非侮辱类'</span>)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;贝叶斯&quot;&gt;&lt;a href=&quot;#贝叶斯&quot; class=&quot;headerlink&quot; title=&quot;贝叶斯&quot;&gt;&lt;/a&gt;贝叶斯&lt;/h1&gt;&lt;h2 id=&quot;贝叶斯定理&quot;&gt;&lt;a href=&quot;#贝叶斯定理&quot; class=&quot;headerlink&quot; title=&quot;贝叶斯定理&quot;&gt;&lt;/a&gt;
      
    
    </summary>
    
    
      <category term="Machine_Learning" scheme="https://shyshy903.github.io/categories/Machine-Learning/"/>
    
    
      <category term="ML" scheme="https://shyshy903.github.io/tags/ML/"/>
    
  </entry>
  
  <entry>
    <title>《机器学习实战》《西瓜书》笔记（六）- logist回归</title>
    <link href="https://shyshy903.github.io/2019/11/28/Machine_Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%886-%20Logistic%E5%9B%9E%E5%BD%92%EF%BC%89/"/>
    <id>https://shyshy903.github.io/2019/11/28/Machine_Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%886-%20Logistic%E5%9B%9E%E5%BD%92%EF%BC%89/</id>
    <published>2019-11-28T07:30:00.000Z</published>
    <updated>2020-02-11T08:48:55.568Z</updated>
    
    <content type="html"><![CDATA[<h1 id="logist回归"><a href="#logist回归" class="headerlink" title="logist回归"></a>logist回归</h1><h2 id="最佳回归系数与Sigmod函数"><a href="#最佳回归系数与Sigmod函数" class="headerlink" title="最佳回归系数与Sigmod函数"></a>最佳回归系数与Sigmod函数</h2><p>$\sigma = 1/(1 + e^{-z})$<br>$z = w_0x_0+ w_1x_1+ w_2x_2+ ….w_nx_n$<br>$z = w^TX$</p><h3 id="梯度上升法"><a href="#梯度上升法" class="headerlink" title="梯度上升法"></a>梯度上升法</h3><p>$w = w + α* grad f(w)$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：梯度上升算法测试函数</span></span><br><span class="line"><span class="string">        求函数f(x) = -x^2+4x的极大值</span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    None</span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    None</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">Gradient_Ascent_test</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="comment"># f(x)的导数</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">f_prime</span><span class="params">(x_old)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">-2</span> * x_old + <span class="number">4</span></span><br><span class="line">    <span class="comment"># 初始值，给一个小于x_new的值</span></span><br><span class="line">    x_old = <span class="number">-1</span></span><br><span class="line">    <span class="comment"># 梯度上升算法初始值，即从(0, 0)开始</span></span><br><span class="line">    x_new = <span class="number">0</span></span><br><span class="line">    <span class="comment"># 步长，也就是学习速率，控制更新的幅度</span></span><br><span class="line">    alpha = <span class="number">0.01</span></span><br><span class="line">    <span class="comment"># 精度，也就是更新阈值</span></span><br><span class="line">    presision = <span class="number">0.00000001</span></span><br><span class="line">    <span class="keyword">while</span> abs(x_new - x_old) &gt; presision:</span><br><span class="line">        x_old = x_new</span><br><span class="line">        <span class="comment"># 利用上面的公式</span></span><br><span class="line">        x_new = x_old + alpha * f_prime(x_old)</span><br><span class="line">    <span class="comment"># 打印最终求解的极值近似值</span></span><br><span class="line">    print(x_new)</span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：sigmoid函数</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    inX - 数据</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    sigmoid函数</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span><span class="params">(inX)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1.0</span> / (<span class="number">1</span> + np.exp(-inX))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：梯度上升法</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    dataMath - 数据集</span></span><br><span class="line"><span class="string">    classLabels - 数据标签</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    weights.getA() - 求得的权重数组（最优参数）</span></span><br><span class="line"><span class="string">    weights_array - 每次更新的回归系数</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gradAscent</span><span class="params">(dataMath, classLabels)</span>:</span></span><br><span class="line">    <span class="comment"># 转换成numpy的mat(矩阵)</span></span><br><span class="line">    dataMatrix = np.mat(dataMath)</span><br><span class="line">    <span class="comment"># 转换成numpy的mat(矩阵)并进行转置</span></span><br><span class="line">    labelMat = np.mat(classLabels).transpose()</span><br><span class="line">    <span class="comment"># 返回dataMatrix的大小，m为行数，n为列数</span></span><br><span class="line">    m, n = np.shape(dataMatrix)</span><br><span class="line">    <span class="comment"># 移动步长，也就是学习效率，控制更新的幅度</span></span><br><span class="line">    alpha = <span class="number">0.01</span></span><br><span class="line">    <span class="comment"># 最大迭代次数</span></span><br><span class="line">    maxCycles = <span class="number">500</span></span><br><span class="line">    weights = np.ones((n, <span class="number">1</span>))</span><br><span class="line">    weights_array = np.array([])</span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> range(maxCycles):</span><br><span class="line">        <span class="comment"># 梯度上升矢量化公式</span></span><br><span class="line">        h = sigmoid(dataMatrix * weights)</span><br><span class="line">        error = labelMat - h</span><br><span class="line">        weights = weights + alpha * dataMatrix.transpose() * error</span><br><span class="line">        <span class="comment"># numpy.append(arr, values, axis=None):就是arr和values会重新组合成一个新的数组，做为返回值。</span></span><br><span class="line">        <span class="comment"># 当axis无定义时，是横向加成，返回总是为一维数组</span></span><br><span class="line">        weights_array = np.append(weights_array, weights)</span><br><span class="line">    weights_array = weights_array.reshape(maxCycles, n)</span><br><span class="line">    <span class="comment"># 将矩阵转换为数组，返回权重数组</span></span><br><span class="line">    <span class="comment"># mat.getA()将自身矩阵变量转化为ndarray类型变量</span></span><br><span class="line">    <span class="keyword">return</span> weights.getA(), weights_array</span><br></pre></td></tr></table></figure><h3 id="绘制决策边界"><a href="#绘制决策边界" class="headerlink" title="绘制决策边界"></a>绘制决策边界</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：绘制数据集</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    weights - 权重参数数组</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    None</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plotBestFit</span><span class="params">(weights)</span>:</span></span><br><span class="line">    <span class="comment"># 加载数据集</span></span><br><span class="line">    dataMat, labelMat = loadDataSet()</span><br><span class="line">    <span class="comment"># 转换成numpy的array数组</span></span><br><span class="line">    dataArr = np.array(dataMat)</span><br><span class="line">    <span class="comment"># 数据个数</span></span><br><span class="line">    <span class="comment"># 例如建立一个4*2的矩阵c，c.shape[1]为第一维的长度2， c.shape[0]为第二维的长度4</span></span><br><span class="line">    n = np.shape(dataMat)[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># 正样本</span></span><br><span class="line">    xcord1 = []</span><br><span class="line">    ycord1 = []</span><br><span class="line">    <span class="comment"># 负样本</span></span><br><span class="line">    xcord2 = []</span><br><span class="line">    ycord2 = []</span><br><span class="line">    <span class="comment"># 根据数据集标签进行分类</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(n):</span><br><span class="line">        <span class="keyword">if</span> int(labelMat[i]) == <span class="number">1</span>:</span><br><span class="line">            <span class="comment"># 1为正样本</span></span><br><span class="line">            xcord1.append(dataArr[i, <span class="number">1</span>])</span><br><span class="line">            ycord1.append(dataArr[i, <span class="number">2</span>])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 0为负样本</span></span><br><span class="line">            xcord2.append(dataArr[i, <span class="number">1</span>])</span><br><span class="line">            ycord2.append(dataArr[i, <span class="number">2</span>])</span><br><span class="line">    <span class="comment"># 新建图框</span></span><br><span class="line">    fig = plt.figure()</span><br><span class="line">    <span class="comment"># 添加subplot</span></span><br><span class="line">    ax = fig.add_subplot(<span class="number">111</span>)</span><br><span class="line">    <span class="comment"># 绘制正样本</span></span><br><span class="line">    ax.scatter(xcord1, ycord1, s=<span class="number">20</span>, c=<span class="string">'red'</span>, marker=<span class="string">'s'</span>, alpha=<span class="number">.5</span>)</span><br><span class="line">    <span class="comment"># 绘制负样本</span></span><br><span class="line">    ax.scatter(xcord2, ycord2, s=<span class="number">20</span>, c=<span class="string">'green'</span>, alpha=<span class="number">.5</span>)</span><br><span class="line">    <span class="comment"># x轴坐标</span></span><br><span class="line">    x = np.arange(<span class="number">-3.0</span>, <span class="number">3.0</span>, <span class="number">0.1</span>)</span><br><span class="line">    <span class="comment"># w0*x0 + w1*x1 * w2*x2 = 0</span></span><br><span class="line">    <span class="comment"># x0 = 1, x1 = x, x2 = y</span></span><br><span class="line">    y = (-weights[<span class="number">0</span>] - weights[<span class="number">1</span>] * x) / weights[<span class="number">2</span>]</span><br><span class="line">    ax.plot(x, y)</span><br><span class="line">    <span class="comment"># 绘制title</span></span><br><span class="line">    plt.title(<span class="string">'BestFit'</span>)</span><br><span class="line">    <span class="comment"># 绘制label</span></span><br><span class="line">    plt.xlabel(<span class="string">'x1'</span>)</span><br><span class="line">    plt.ylabel(<span class="string">'y2'</span>)</span><br><span class="line">    <span class="comment"># 显示</span></span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure><h3 id="随机梯度上升法"><a href="#随机梯度上升法" class="headerlink" title="随机梯度上升法"></a>随机梯度上升法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：改进的随机梯度上升法</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    dataMatrix - 数据数组</span></span><br><span class="line"><span class="string">    classLabels - 数据标签</span></span><br><span class="line"><span class="string">    numIter - 迭代次数</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    weights - 求得的回归系数数组（最优参数）</span></span><br><span class="line"><span class="string">    weights_array - 每次更新的回归系数</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">stocGradAscent1</span><span class="params">(dataMatrix, classLabels, numIter=<span class="number">150</span>)</span>:</span></span><br><span class="line">    <span class="comment"># 返回dataMatrix的大小，m为行数，n为列数</span></span><br><span class="line">    m, n = np.shape(dataMatrix)</span><br><span class="line">    <span class="comment"># 参数初始化</span></span><br><span class="line">    weights = np.ones(n)</span><br><span class="line">    weights_array = np.array([])</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(numIter):</span><br><span class="line">        dataIndex = list(range(m))</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">            <span class="comment"># 每次都降低alpha的大小</span></span><br><span class="line">            alpha = <span class="number">4</span>/(<span class="number">1.0</span>+j+i)+<span class="number">0.01</span></span><br><span class="line">            <span class="comment"># 随机选择样本</span></span><br><span class="line">            randIndex = int(random.uniform(<span class="number">0</span>, len(dataIndex)))</span><br><span class="line">            <span class="comment"># 随机选择一个样本计算h</span></span><br><span class="line">            h = sigmoid(sum(dataMatrix[randIndex] * weights))</span><br><span class="line">            <span class="comment"># 计算误差</span></span><br><span class="line">            error = classLabels[randIndex] - h</span><br><span class="line">            <span class="comment"># 更新回归系数</span></span><br><span class="line">            weights = weights + alpha * error * dataMatrix[randIndex]</span><br><span class="line">            <span class="comment"># 添加返回系数到数组中当axis为0时，数组是加在下面（列数要相同）</span></span><br><span class="line">            weights_array = np.append(weights_array, weights, axis=<span class="number">0</span>)</span><br><span class="line">            <span class="comment"># 删除已使用的样本</span></span><br><span class="line">            <span class="keyword">del</span>(dataIndex[randIndex])</span><br><span class="line">    <span class="comment"># 改变维度</span></span><br><span class="line">    weights_array = weights_array.reshape(numIter*m, n)</span><br><span class="line">    <span class="comment"># 返回</span></span><br><span class="line">    <span class="keyword">return</span> weights, weights_array</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：绘制回归系数与迭代次数的关系</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    weights_array1 - 回归系数数组1</span></span><br><span class="line"><span class="string">    weights_array2 - 回归系数数组2</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    None</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plotWeights</span><span class="params">(weights_array1, weights_array2)</span>:</span></span><br><span class="line">    <span class="comment"># 设置汉字格式为14号简体字</span></span><br><span class="line">    font = FontProperties(fname=<span class="string">r"C:\Windows\Fonts\simsun.ttc"</span>, size=<span class="number">14</span>)</span><br><span class="line">    <span class="comment"># 将fig画布分隔成1行1列，不共享x轴和y轴，fig画布的大小为（20, 10）</span></span><br><span class="line">    <span class="comment"># 当nrows=3，ncols=2时，代表fig画布被分为6个区域，axs[0][0]代表第一行第一个区域</span></span><br><span class="line">    fig, axs = plt.subplots(nrows=<span class="number">3</span>, ncols=<span class="number">2</span>, sharex=<span class="literal">False</span>, sharey=<span class="literal">False</span>, figsize=(<span class="number">20</span>, <span class="number">10</span>))</span><br><span class="line">    <span class="comment"># x1坐标轴的范围</span></span><br><span class="line">    x1 = np.arange(<span class="number">0</span>, len(weights_array1), <span class="number">1</span>)</span><br><span class="line">    <span class="comment"># 绘制w0与迭代次数的关系</span></span><br><span class="line">    axs[<span class="number">0</span>][<span class="number">0</span>].plot(x1, weights_array1[:, <span class="number">0</span>])</span><br><span class="line">    axs0_title_text = axs[<span class="number">0</span>][<span class="number">0</span>].set_title(<span class="string">u'改进的梯度上升算法，回归系数与迭代次数关系'</span>, FontProperties=font)</span><br><span class="line">    axs0_ylabel_text = axs[<span class="number">0</span>][<span class="number">0</span>].set_ylabel(<span class="string">u'w0'</span>, FontProperties=font)</span><br><span class="line">    plt.setp(axs0_title_text, size=<span class="number">20</span>, weight=<span class="string">'bold'</span>, color=<span class="string">'black'</span>)</span><br><span class="line">    plt.setp(axs0_ylabel_text, size=<span class="number">20</span>, weight=<span class="string">'bold'</span>, color=<span class="string">'black'</span>)</span><br><span class="line">    <span class="comment"># 绘制w1与迭代次数的关系</span></span><br><span class="line">    axs[<span class="number">1</span>][<span class="number">0</span>].plot(x1, weights_array1[:, <span class="number">1</span>])</span><br><span class="line">    axs1_ylabel_text = axs[<span class="number">1</span>][<span class="number">0</span>].set_ylabel(<span class="string">u'w1'</span>, FontProperties=font)</span><br><span class="line">    plt.setp(axs1_ylabel_text, size=<span class="number">20</span>, weight=<span class="string">'bold'</span>, color=<span class="string">'black'</span>)</span><br><span class="line">    <span class="comment"># 绘制w2与迭代次数的关系</span></span><br><span class="line">    axs[<span class="number">2</span>][<span class="number">0</span>].plot(x1, weights_array1[:, <span class="number">2</span>])</span><br><span class="line">    axs2_title_text = axs[<span class="number">2</span>][<span class="number">0</span>].set_title(<span class="string">u'迭代次数'</span>, FontProperties=font)</span><br><span class="line">    axs2_ylabel_text = axs[<span class="number">2</span>][<span class="number">0</span>].set_ylabel(<span class="string">u'w2'</span>, FontProperties=font)</span><br><span class="line">    plt.setp(axs2_title_text, size=<span class="number">20</span>, weight=<span class="string">'bold'</span>, color=<span class="string">'black'</span>)</span><br><span class="line">    plt.setp(axs2_ylabel_text, size=<span class="number">20</span>, weight=<span class="string">'bold'</span>, color=<span class="string">'black'</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># x2坐标轴的范围</span></span><br><span class="line">    x2 = np.arange(<span class="number">0</span>, len(weights_array2), <span class="number">1</span>)</span><br><span class="line">    <span class="comment"># 绘制w0与迭代次数的关系</span></span><br><span class="line">    axs[<span class="number">0</span>][<span class="number">1</span>].plot(x2, weights_array2[:, <span class="number">0</span>])</span><br><span class="line">    axs0_title_text = axs[<span class="number">0</span>][<span class="number">1</span>].set_title(<span class="string">u'梯度上升算法，回归系数与迭代次数关系'</span>, FontProperties=font)</span><br><span class="line">    axs0_ylabel_text = axs[<span class="number">0</span>][<span class="number">1</span>].set_ylabel(<span class="string">u'w0'</span>, FontProperties=font)</span><br><span class="line">    plt.setp(axs0_title_text, size=<span class="number">20</span>, weight=<span class="string">'bold'</span>, color=<span class="string">'black'</span>)</span><br><span class="line">    plt.setp(axs0_ylabel_text, size=<span class="number">20</span>, weight=<span class="string">'bold'</span>, color=<span class="string">'black'</span>)</span><br><span class="line">    <span class="comment"># 绘制w1与迭代次数的关系</span></span><br><span class="line">    axs[<span class="number">1</span>][<span class="number">1</span>].plot(x2, weights_array2[:, <span class="number">1</span>])</span><br><span class="line">    axs1_ylabel_text = axs[<span class="number">1</span>][<span class="number">1</span>].set_ylabel(<span class="string">u'w1'</span>, FontProperties=font)</span><br><span class="line">    plt.setp(axs1_ylabel_text, size=<span class="number">20</span>, weight=<span class="string">'bold'</span>, color=<span class="string">'black'</span>)</span><br><span class="line">    <span class="comment"># 绘制w2与迭代次数的关系</span></span><br><span class="line">    axs[<span class="number">2</span>][<span class="number">1</span>].plot(x2, weights_array2[:, <span class="number">2</span>])</span><br><span class="line">    axs2_title_text = axs[<span class="number">2</span>][<span class="number">1</span>].set_title(<span class="string">u'迭代次数'</span>, FontProperties=font)</span><br><span class="line">    axs2_ylabel_text = axs[<span class="number">2</span>][<span class="number">1</span>].set_ylabel(<span class="string">u'w2'</span>, FontProperties=font)</span><br><span class="line">    plt.setp(axs2_title_text, size=<span class="number">20</span>, weight=<span class="string">'bold'</span>, color=<span class="string">'black'</span>)</span><br><span class="line">    plt.setp(axs2_ylabel_text, size=<span class="number">20</span>, weight=<span class="string">'bold'</span>, color=<span class="string">'black'</span>)</span><br><span class="line">    </span><br><span class="line">    plt.show()</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="comment"># 测试简单梯度上升法</span></span><br><span class="line">    <span class="comment"># Gradient_Ascent_test()</span></span><br><span class="line">    <span class="comment"># 加载数据集</span></span><br><span class="line">    dataMat, labelMat = loadDataSet()</span><br><span class="line">    <span class="comment"># 训练权重</span></span><br><span class="line">    weights2, weights_array2 = gradAscent(dataMat, labelMat)</span><br><span class="line">    <span class="comment"># 新方法训练权重</span></span><br><span class="line">    weights1, weights_array1 = stocGradAscent1(np.array(dataMat), labelMat)</span><br><span class="line">    <span class="comment"># 绘制数据集中的y和x的散点图</span></span><br><span class="line">    <span class="comment"># plotBestFit(weights)</span></span><br><span class="line">    <span class="comment"># print(gradAscent(dataMat, labelMat))</span></span><br><span class="line">    plotWeights(weights_array1, weights_array2)</span><br></pre></td></tr></table></figure><h2 id="梯度下降法"><a href="#梯度下降法" class="headerlink" title="梯度下降法"></a>梯度下降法</h2><p>$w = w - α*gradf(w)$</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;logist回归&quot;&gt;&lt;a href=&quot;#logist回归&quot; class=&quot;headerlink&quot; title=&quot;logist回归&quot;&gt;&lt;/a&gt;logist回归&lt;/h1&gt;&lt;h2 id=&quot;最佳回归系数与Sigmod函数&quot;&gt;&lt;a href=&quot;#最佳回归系数与Sigmod函
      
    
    </summary>
    
    
      <category term="Machine_Learning" scheme="https://shyshy903.github.io/categories/Machine-Learning/"/>
    
    
      <category term="ML" scheme="https://shyshy903.github.io/tags/ML/"/>
    
  </entry>
  
  <entry>
    <title>《机器学习实战》《西瓜书》笔记（四）- 决策树</title>
    <link href="https://shyshy903.github.io/2019/11/27/Machine_Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%884-DecisionTree)/"/>
    <id>https://shyshy903.github.io/2019/11/27/Machine_Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%884-DecisionTree)/</id>
    <published>2019-11-27T07:30:00.000Z</published>
    <updated>2020-02-11T08:48:55.554Z</updated>
    
    <content type="html"><![CDATA[<h1 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h1><p>决策树本质上是一种流程图，长方形代表<strong>判断模块</strong>，椭圆代表<strong>终止模块</strong>，左右箭头指引<strong>节点的上下分支</strong><br>决策树相比较于KNN，其重要的原因就是其数据形式非常容易理解，而KNN的数据形式所包含的内在含义却不是很容易理解</p><div align = center><img src = " https://img.vim-cn.com/10/8d6b3cb5f550b03b25681ed2bdc0f7cc424005.png"></div><p><strong>优点</strong><br>计算复杂度不高，可以处理不相关特征数据，对中间数据的缺省值不敏感<br><strong>缺点</strong><br>会产生过度匹配问题</p><h2 id="信息论划分数据集"><a href="#信息论划分数据集" class="headerlink" title="信息论划分数据集"></a>信息论划分数据集</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""划分数据集的伪代码"""</span></span><br><span class="line">检测数据集是否属于同一类：</span><br><span class="line">    <span class="keyword">if</span> so  <span class="keyword">return</span> 类标签</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        寻找划分数据集的最好特征</span><br><span class="line">        划分数据集</span><br><span class="line">        创建分支节点</span><br><span class="line">            <span class="keyword">for</span> 每个划分的子类</span><br><span class="line">                调用函数createBranch并增加返回节点到结果上</span><br><span class="line">        <span class="keyword">return</span> 分支节点</span><br></pre></td></tr></table></figure><h2 id="决策树的流程"><a href="#决策树的流程" class="headerlink" title="决策树的流程"></a>决策树的流程</h2><ol><li>收集数据：可以使用任何方法</li><li>准备数据：<strong>树构造算法适用于标称型数据，如果数据是数值型数据，需要先把数据进行离散化</strong></li><li>分析数据：构造树完成，进行检查</li><li>训练算法：构造树的数据结构</li><li>测试算法：使用经验树计算错误率</li><li>使用算法</li></ol><h2 id="信息增益与信息熵"><a href="#信息增益与信息熵" class="headerlink" title="信息增益与信息熵"></a>信息增益与信息熵</h2><p><strong>划分数据集的最大原则是，将无序的数据变得更加有序</strong><br><strong>信息增益</strong>：划分数据集前后信息发生的变化称为信息增益<br>计算每个特征划分数据集获得的信息增益，获得信息增益最高的特征就是最好的选择<br><strong>如何计算信息增益？</strong><br>集合信息的度量方式称为<strong>香农熵</strong><br>熵定义为信息的期望值：<br>符号$x_i$的信息定义为$l(x_i) = -log_2p(x_i)$，p(x_i)是选择该分类的概率<br>则信息熵为：$H = -\sum\nolimits_{i=1}^{n}p(x_i)log_2p(x_i)$,其中n是分类的数目</p><h2 id="计算信息熵的源代码"><a href="#计算信息熵的源代码" class="headerlink" title="计算信息熵的源代码"></a>计算信息熵的源代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">用于计算给定的信息熵</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：计算给定数据集的经验熵（香农熵）</span></span><br><span class="line"><span class="string">        H = -SUM（kp*Log2（kp））</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    dataSet - 数据集</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    shannonEnt - 经验熵（香农熵）</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calcShannonEnt</span><span class="params">(dataSet)</span>:</span></span><br><span class="line">    <span class="comment"># 返回数据集的行数</span></span><br><span class="line">    numEntires = len(dataSet)</span><br><span class="line">    <span class="comment"># 保存每个标签（Label）出现次数的“字典”</span></span><br><span class="line">    labelCounts = &#123;&#125;</span><br><span class="line">    <span class="comment"># 对每组特征向量进行统计</span></span><br><span class="line">    <span class="keyword">for</span> featVec <span class="keyword">in</span> dataSet:     <span class="comment"># 按行进行遍历</span></span><br><span class="line">        <span class="comment"># 提取标签（Label）信息</span></span><br><span class="line">        currentLabel = featVec[<span class="number">-1</span>]    <span class="comment"># 取每一行最后一列特征值</span></span><br><span class="line">        <span class="comment"># 如果标签（Label）没有放入统计次数的字典，添加进去</span></span><br><span class="line">        <span class="keyword">if</span> currentLabel <span class="keyword">not</span> <span class="keyword">in</span> labelCounts.keys():</span><br><span class="line">            <span class="comment"># 创建一个新的键值对，键为currentLabel值为0</span></span><br><span class="line">            labelCounts[currentLabel] = <span class="number">0</span></span><br><span class="line">        <span class="comment"># Label计数</span></span><br><span class="line">        labelCounts[currentLabel] += <span class="number">1</span></span><br><span class="line">    <span class="comment"># 经验熵（香农熵）</span></span><br><span class="line">    shannonEnt = <span class="number">0.0</span></span><br><span class="line">    <span class="comment"># 计算香农熵</span></span><br><span class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> labelCounts:</span><br><span class="line">        <span class="comment"># 选择该标签（Label）的概率</span></span><br><span class="line">        prob = float(labelCounts[key]) / numEntires</span><br><span class="line">        <span class="comment"># 利用公式计算</span></span><br><span class="line">        shannonEnt -= prob*log(prob, <span class="number">2</span>)</span><br><span class="line">    <span class="comment"># 返回经验熵（香农熵）</span></span><br><span class="line">    <span class="keyword">return</span> shannonEnt</span><br></pre></td></tr></table></figure><p><strong>创建数据集</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">createDataSet</span><span class="params">()</span>：</span></span><br><span class="line">    dataSet = [[1, ,1 , 'yes'],[1, 1, 'yes'],[1, 0, 'no'],[0, 1, 'no'],[0, 1, 'no']]</span><br><span class="line">    labels = [<span class="string">'no surfacing'</span>, <span class="string">'flippers'</span>]</span><br><span class="line">    <span class="keyword">return</span> dataSet, labels</span><br><span class="line"></span><br><span class="line">&gt;&gt; reload(trees.py)</span><br><span class="line">&gt;&gt; myDat, labels = trees.createDataSet()</span><br><span class="line">&gt;&gt; trees.calcShannonEnt(mydata)</span><br></pre></td></tr></table></figure><h2 id="划分数据集的算法与代码"><a href="#划分数据集的算法与代码" class="headerlink" title="划分数据集的算法与代码"></a>划分数据集的算法与代码</h2><p>一般可用二分法划分数据集，这里采用<strong>ID3算法</strong>进行划分数据集<br>香农熵可用来度量数据集的无序度，数据无序度越大，香农熵值越大。<br>分类算法除了需要测量信息熵还需要一个<strong>度量数据划分准确度的熵值</strong>，这就像在二维坐标中画直线进行划分平面坐标系、</p><ol><li><strong>按照给定特征划分数据集</strong><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数：按照给定的特征划分数据集</span></span><br><span class="line"><span class="string">输入：</span></span><br><span class="line"><span class="string">    dataSet,数据集</span></span><br><span class="line"><span class="string">    axis, 划分数据集的特征</span></span><br><span class="line"><span class="string">    value, 需要返回的特征值</span></span><br><span class="line"><span class="string">Return:</span></span><br><span class="line"><span class="string">    retDataSet,划分的数据集</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">splitDataSet</span><span class="params">(dataSet, axis, value)</span>:</span></span><br><span class="line">    retDataSet = []</span><br><span class="line">    <span class="keyword">for</span> featVec <span class="keyword">in</span> dataSet:  <span class="comment"># 按行遍历数据集</span></span><br><span class="line">        <span class="keyword">if</span> featVec[axis] == value:   <span class="comment"># 去掉特征为axis的数据集</span></span><br><span class="line">            reducedFeatVec = featVec[:axis]</span><br><span class="line">            reducedFeatVec.extend(featVec[axis+<span class="number">1</span>:])  <span class="comment"># 扩展列表元素</span></span><br><span class="line">            retDataSet.append(reducedFeatVec)  <span class="comment"># 添加嵌套列表</span></span><br><span class="line">    <span class="keyword">return</span> retDataSet</span><br><span class="line"></span><br><span class="line">&gt;&gt; <span class="keyword">import</span> DecisionTree <span class="keyword">as</span> DT</span><br><span class="line">&gt;&gt; mydat, labels = DT.createDataSet()</span><br><span class="line">&gt;&gt; DT.splitDataSet(mydat, <span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line">&gt;&gt; DT.splitDataSet(mydat, <span class="number">0</span>, <span class="number">1</span>)</span><br></pre></td></tr></table></figure></li><li>选择最好的数据集划分方式<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数：选择最好的数据集划分方式</span></span><br><span class="line"><span class="string">Para:</span></span><br><span class="line"><span class="string">    dataSet:数据集</span></span><br><span class="line"><span class="string">return:</span></span><br><span class="line"><span class="string">    bestFeature:最好的特征的索引值</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">chooseBestFeatureToSplit</span><span class="params">(dataSet)</span>:</span></span><br><span class="line"></span><br><span class="line">    numFeatures = len(dataSet[<span class="number">0</span>]) - <span class="number">1</span>  <span class="comment"># 特征的个数-1</span></span><br><span class="line">    baseEntropy = calcShannonEnt(dataSet)  <span class="comment"># 计算数据集的香农熵</span></span><br><span class="line">    bestInfoGain = <span class="number">0.0</span> ; bestFeature = <span class="number">-1</span>  <span class="comment"># 最大信息增益和最优划分特征的索引值</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(numFeatures): <span class="comment"># 遍历特征</span></span><br><span class="line">        featList = [example[i] <span class="keyword">for</span> example <span class="keyword">in</span> dataSet] <span class="comment"># 列表生成式生成特征所有的取值</span></span><br><span class="line">        uniqueVals = set(featList) <span class="comment"># 删去重复值</span></span><br><span class="line">        newEntropy = <span class="number">0.0</span> <span class="comment"># 香农熵</span></span><br><span class="line">        <span class="keyword">for</span> values <span class="keyword">in</span> uniqueVals:  <span class="comment"># 遍历特征值</span></span><br><span class="line">            subDataSet = splitDataSet(dataset, i , value)  <span class="comment"># 划分数据集</span></span><br><span class="line">            prob = len(subDataSet) / float(len(dataSet))  <span class="comment"># 计算概率</span></span><br><span class="line">            newEntropy += prob * calcShannonEnt(subDataSet)  <span class="comment"># 计算经验条件熵</span></span><br><span class="line">        infoGain = baseEntropy - newEntropy  <span class="comment"># 信息增益值</span></span><br><span class="line">        print(<span class="string">"第%d个特征的增益为%.3f"</span> % (i, infoGain)) <span class="comment"># 打印每个特征的信息增益，取正</span></span><br><span class="line">        <span class="keyword">if</span>(infoGain &gt; baseEntropy):    <span class="comment"># 找到对应最大信息增益的特征</span></span><br><span class="line">            baseInfoGain = infoGain</span><br><span class="line">            bestFeature = i</span><br><span class="line">    <span class="keyword">return</span> bestFeature</span><br><span class="line"></span><br><span class="line">&gt;&gt; DecisionTree.chooseBestFeaturToSplit(mydat)</span><br></pre></td></tr></table></figure><h2 id="递归构建决策树"><a href="#递归构建决策树" class="headerlink" title="递归构建决策树"></a>递归构建决策树</h2><div align = center><img src = "https://img.vim-cn.com/81/18e71a83e22a268a8899ee9aff50fe083ddbd4.png"></div></li></ol><p>当特征值多与两个的时候，就可能存在大于两个分支的数据集划分，这时我们就通过递归调用来实现它！<br><strong>递归结束的条件</strong><br>程序遍历完所有划分数据的属性，或者每个分支下的所有实例都具有相同的分类。如果所有实例都具有相同的分类，则得到一个叶子节点或者终止快。任何到达叶子结点所属的分类必然属于叶子节点的类。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：统计classList中出现次数最多的元素（类标签）</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    classList - 类标签列表</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    sortedClassCount[0][0] - 出现次数最多的元素（类标签）</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">"""</span>   </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">majorityCnt</span><span class="params">(classList)</span>:</span></span><br><span class="line">    classCount = &#123;&#125;</span><br><span class="line">    <span class="comment"># 统计classList中每个元素出现的次数</span></span><br><span class="line">    <span class="keyword">for</span> vote <span class="keyword">in</span> classList:</span><br><span class="line">        <span class="keyword">if</span> vote <span class="keyword">not</span> <span class="keyword">in</span> classCount.keys():</span><br><span class="line">            classCount[vote] = <span class="number">0</span></span><br><span class="line">        classCount[vote] += <span class="number">1</span></span><br><span class="line">    <span class="comment"># 根据字典的值降序排序</span></span><br><span class="line">    <span class="comment"># operator.itemgetter(1)获取对象的第1列的值</span></span><br><span class="line">    sortedClassCount = sorted(classCount.items(), key = operator.itemgetter(<span class="number">1</span>), reverse = <span class="literal">True</span>)</span><br><span class="line">    <span class="comment"># 返回classList中出现次数最多的元素</span></span><br><span class="line">    <span class="keyword">return</span> sortedClassCount[<span class="number">0</span>][<span class="number">0</span>]</span><br></pre></td></tr></table></figure><p><strong>创建决策树的代码</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：创建决策树（ID3算法）</span></span><br><span class="line"><span class="string">        递归有两个终止条件：1、所有的类标签完全相同，直接返回类标签</span></span><br><span class="line"><span class="string">                        2、用完所有标签但是得不到唯一类别的分组，即特征不够用，挑选出现数量最多的类别作为返回</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    dataSet - 训练数据集</span></span><br><span class="line"><span class="string">    labels - 分类属性标签</span></span><br><span class="line"><span class="string">    featLabels - 存储选择的最优特征标签</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    myTree - 决策树</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">createTree</span><span class="params">(dataSet, labels, featLabels)</span>:</span></span><br><span class="line">    classList = [example[<span class="number">-1</span>] <span class="keyword">for</span> example <span class="keyword">in</span> dataSet]   <span class="comment"># 取分类标签（是否放贷：yes or no）</span></span><br><span class="line">    <span class="keyword">if</span> classList.count(classList[<span class="number">0</span>]) == len(classList):  <span class="comment"># 如果类别完全相同则停止继续划分</span></span><br><span class="line">        <span class="keyword">return</span> classList[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">if</span> len(dataSet[<span class="number">0</span>]) == <span class="number">1</span>:  <span class="comment"># 遍历完所有特征时返回出现次数最多的类标签</span></span><br><span class="line">        <span class="keyword">return</span> majorityCnt(classList)</span><br><span class="line">    bestFeat = chooseBestFeatureToSplit(dataSet) <span class="comment"># 选择最优特征</span></span><br><span class="line">    bestFeatLabel = labels[bestFeat]  <span class="comment"># 最优特征的标签</span></span><br><span class="line">    featLabels.append(bestFeatLabel)</span><br><span class="line">    myTree = &#123;bestFeatLabel:&#123;&#125;&#125; <span class="comment"># 根据最优特征的标签生成树</span></span><br><span class="line">    <span class="keyword">del</span>(labels[bestFeat])      <span class="comment"># 删除已经使用的特征标签</span></span><br><span class="line">    featValues = [example[bestFeat] <span class="keyword">for</span> example <span class="keyword">in</span> dataSet] <span class="comment"># 得到训练集中所有最优解特征的属性值</span></span><br><span class="line">    uniqueVals = set(featValues) <span class="comment"># 去掉重复的属性值</span></span><br><span class="line">    <span class="keyword">for</span> value <span class="keyword">in</span> uniqueVals: <span class="comment"># 遍历特征，创建决策树</span></span><br><span class="line">        myTree[bestFeatLabel][value] = createTree(splitDataSet(dataSet, bestFeat, value), labels, featLabels)</span><br><span class="line">    <span class="keyword">return</span> myTree</span><br><span class="line"></span><br><span class="line">&gt;&gt; my tree = DecisionTree.createTree(mydata,labels)</span><br><span class="line">&gt;&gt; my tree</span><br></pre></td></tr></table></figure><h2 id="测试算法与分类器"><a href="#测试算法与分类器" class="headerlink" title="测试算法与分类器"></a>测试算法与分类器</h2><h3 id="测试算法构造分类器"><a href="#测试算法构造分类器" class="headerlink" title="测试算法构造分类器"></a>测试算法构造分类器</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数：使用决策树的分类函数</span></span><br><span class="line"><span class="string">para:</span></span><br><span class="line"><span class="string">    inputree,</span></span><br><span class="line"><span class="string">    featLabels,</span></span><br><span class="line"><span class="string">    testVec</span></span><br><span class="line"><span class="string">return:</span></span><br><span class="line"><span class="string">    classlabel,分类器</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">classify</span><span class="params">(inputTree, featLabels, testVec)</span>:</span></span><br><span class="line">    <span class="comment"># 获取决策树结点</span></span><br><span class="line">    firstStr = next(iter(inputTree))</span><br><span class="line">    <span class="comment"># 下一个字典</span></span><br><span class="line">    secondDict = inputTree[firstStr]</span><br><span class="line">    featIndex = featLabels.index(firstStr)</span><br><span class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> secondDict.keys():</span><br><span class="line">        <span class="keyword">if</span> testVec[featIndex] == key:</span><br><span class="line">            <span class="keyword">if</span> type(secondDict[key]).__name__ == <span class="string">'dict'</span>:</span><br><span class="line">                classLabel = classify(secondDict[key], featLabels, testVec)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                classLabel = secondDict[key]</span><br><span class="line">    <span class="keyword">return</span> classLabel</span><br></pre></td></tr></table></figure><h3 id="使用算法"><a href="#使用算法" class="headerlink" title="使用算法"></a>使用算法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：存储决策树</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    inputTree - 已经生成的决策树</span></span><br><span class="line"><span class="string">    filename - 决策树的存储文件名</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    None</span></span><br><span class="line"><span class="string">"""</span>   </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">storeTree</span><span class="params">(inputTree, filename)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> open(filename, <span class="string">'wb'</span>) <span class="keyword">as</span> fw:</span><br><span class="line">        pickle.dump(inputTree, fw)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：读取决策树</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    filename - 决策树的存储文件名</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    pickle.load(fr) - 决策树字典</span></span><br><span class="line"><span class="string">"""</span> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">grabTree</span><span class="params">(filename)</span>:</span></span><br><span class="line">    fr = open(filename, <span class="string">'rb'</span>)</span><br><span class="line">    <span class="keyword">return</span> pickle.load(fr)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;决策树&quot;&gt;&lt;a href=&quot;#决策树&quot; class=&quot;headerlink&quot; title=&quot;决策树&quot;&gt;&lt;/a&gt;决策树&lt;/h1&gt;&lt;p&gt;决策树本质上是一种流程图，长方形代表&lt;strong&gt;判断模块&lt;/strong&gt;，椭圆代表&lt;strong&gt;终止模块&lt;/strong&gt;，
      
    
    </summary>
    
    
      <category term="Machine_Learning" scheme="https://shyshy903.github.io/categories/Machine-Learning/"/>
    
    
      <category term="ML" scheme="https://shyshy903.github.io/tags/ML/"/>
    
  </entry>
  
  <entry>
    <title>《机器学习实战》《西瓜书》笔记（三）- KNN</title>
    <link href="https://shyshy903.github.io/2019/11/26/Machine_Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%883-KNN)/"/>
    <id>https://shyshy903.github.io/2019/11/26/Machine_Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%883-KNN)/</id>
    <published>2019-11-26T07:30:00.000Z</published>
    <updated>2020-02-11T08:48:55.551Z</updated>
    
    <content type="html"><![CDATA[<h1 id="《机器学习实战》《西瓜书》笔记（三）-KNN"><a href="#《机器学习实战》《西瓜书》笔记（三）-KNN" class="headerlink" title="《机器学习实战》《西瓜书》笔记（三）- KNN"></a>《机器学习实战》《西瓜书》笔记（三）- KNN</h1><h2 id="KNN原理"><a href="#KNN原理" class="headerlink" title="KNN原理"></a>KNN原理</h2><ol><li>输入带有标签的训练集</li><li>输入没有标签的新数据</li><li>算法将输入数据的特征与训练集的数据的特征进行比较</li><li>求新数据与样本集中数据的距离</li><li>算法提取样本集中最相似数据（最近邻）的分类标签，只选择前K个最相似的数据</li><li>选取k个相似数据频率最多的分类属性作为新数据的分类属性</li></ol><h2 id="KNN伪代码"><a href="#KNN伪代码" class="headerlink" title="KNN伪代码"></a>KNN伪代码</h2><ol><li>计算已知类别数据集中点与当前点的距离</li><li>按照距离从小到大递增排序</li><li>选取与当前点距离最小的k个点</li><li>确定前k个点所在类别出现的频率</li><li>返回前k个点出现频率最高的类别作为当前点的预测分类</li></ol><h2 id="KNN源代码"><a href="#KNN源代码" class="headerlink" title="KNN源代码"></a>KNN源代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">classify0</span><span class="params">(inX, dataSet, labels, k)</span>:</span></span><br><span class="line">    <span class="comment"># numpy函数shape[0]返回dataSet的行数</span></span><br><span class="line">    dataSetSize = dataSet.shape[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># 将inX重复dataSetSize次并排成一列</span></span><br><span class="line">    diffMat = np.tile(inX, (dataSetSize, <span class="number">1</span>)) - dataSet</span><br><span class="line">    <span class="comment"># 二维特征相减后平方（用diffMat的转置乘diffMat）</span></span><br><span class="line">    sqDiffMat = diffMat**<span class="number">2</span></span><br><span class="line">    <span class="comment"># sum()所有元素相加，sum(0)列相加，sum(1)行相加</span></span><br><span class="line">    sqDistances = sqDiffMat.sum(axis=<span class="number">1</span>)</span><br><span class="line">    <span class="comment"># 开方，计算出距离</span></span><br><span class="line">    distances = sqDistances**<span class="number">0.5</span></span><br><span class="line">    <span class="comment"># argsort函数返回的是distances值从小到大的--索引值</span></span><br><span class="line">    sortedDistIndicies = distances.argsort()</span><br><span class="line">    <span class="comment"># 定义一个记录类别次数的字典</span></span><br><span class="line">    classCount = &#123;&#125;</span><br><span class="line">    <span class="comment"># 选择距离最小的k个点</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(k):</span><br><span class="line">        <span class="comment"># 取出前k个元素的类别</span></span><br><span class="line">        voteIlabel = labels[sortedDistIndicies[i]]</span><br><span class="line">        <span class="comment"># 字典的get()方法，返回指定键的值，如果值不在字典中返回0</span></span><br><span class="line">        <span class="comment"># 计算类别次数</span></span><br><span class="line">        classCount[voteIlabel] = classCount.get(voteIlabel, <span class="number">0</span>) + <span class="number">1</span></span><br><span class="line">    <span class="comment"># python3中用items()替换python2中的iteritems()</span></span><br><span class="line">    <span class="comment"># key = operator.itemgetter(1)根据字典的值进行排序</span></span><br><span class="line">    <span class="comment"># key = operator.itemgetter(0)根据字典的键进行排序</span></span><br><span class="line">    <span class="comment"># reverse降序排序字典</span></span><br><span class="line">    sortedClassCount = sorted(classCount.items(),\</span><br><span class="line">                              key = operator.itemgetter(<span class="number">1</span>), reverse = <span class="literal">True</span>)</span><br><span class="line">    <span class="comment"># 返回次数最多的类别，即所要分类的类别</span></span><br><span class="line">    <span class="keyword">return</span> sortedClassCount[<span class="number">0</span>][<span class="number">0</span>]</span><br></pre></td></tr></table></figure><p><strong>越预测数据所在的分类</strong><br>在终端中的交互解释器执行：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt; classify([<span class="number">1.0</span>, <span class="number">1.0</span>], group, lables, <span class="number">5</span>)</span><br></pre></td></tr></table></figure><p>即可测试得到一个结果</p><h2 id="简单的一个示例"><a href="#简单的一个示例" class="headerlink" title="简单的一个示例"></a>简单的一个示例</h2><h3 id="数据的准备"><a href="#数据的准备" class="headerlink" title="数据的准备"></a>数据的准备</h3><p>在KNN的模块中添加一个实现数据样本的函数，代码如下所示：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> operator</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">creatDataSet</span><span class="params">()</span>:</span></span><br><span class="line">    group = np.array([<span class="number">1</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">1.1</span>], [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0.1</span>])</span><br><span class="line">    labels = [<span class="string">'A'</span>, <span class="string">'A'</span>, <span class="string">'B'</span>, <span class="string">'B'</span>]</span><br><span class="line">    <span class="keyword">return</span> group, labels</span><br></pre></td></tr></table></figure><p>在交互解释器中执行:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt; <span class="keyword">import</span> KNN</span><br><span class="line">&gt;&gt; group, lables = KNN.creatDataSet()</span><br><span class="line">&gt;&gt; KNN.classify0([<span class="number">0</span>,<span class="number">0</span>], group, labels, <span class="number">3</span>)</span><br><span class="line">&gt;&gt; B</span><br></pre></td></tr></table></figure><p>可生成一个初步应用于KNN的4维2列的数据集</p><h2 id="如何测试分类器"><a href="#如何测试分类器" class="headerlink" title="如何测试分类器"></a>如何测试分类器</h2><p>使用分类器的错误率，即分类器给出的错误结果除以测试执行的综述来判断分类器的好坏</p><h2 id="示例1-KNN进行约会匹配"><a href="#示例1-KNN进行约会匹配" class="headerlink" title="示例1 KNN进行约会匹配"></a>示例1 KNN进行约会匹配</h2><h3 id="执行流程"><a href="#执行流程" class="headerlink" title="执行流程"></a>执行流程</h3><ol><li>收集数据 ： 导入文本文件</li><li>准备数据: 使用python解析</li><li>分析数据： matplotlib绘图</li><li>训练算法：k-近邻不适用</li><li>测试算法</li><li>使用算法<h3 id="准备数据"><a href="#准备数据" class="headerlink" title="准备数据"></a>准备数据</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：打开解析文件，对数据进行分类，1代表不喜欢，2代表魅力一般，3代表极具魅力</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    filename - 文件名</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    returnMat - 特征矩阵</span></span><br><span class="line"><span class="string">    classLabelVector - 分类label向量</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">file2matrix</span><span class="params">(filename)</span>:</span></span><br><span class="line">    <span class="comment"># 打开文件</span></span><br><span class="line">    fr = open(filename)</span><br><span class="line">    <span class="comment"># 读取文件所有内容</span></span><br><span class="line">    arrayOlines = fr.readlines()</span><br><span class="line">    <span class="comment"># 得到文件行数</span></span><br><span class="line">    numberOfLines = len(arrayOlines)</span><br><span class="line">    <span class="comment"># 返回的NumPy矩阵numberOfLines行，3列</span></span><br><span class="line">    returnMat = np.zeros((numberOfLines, <span class="number">3</span>))</span><br><span class="line">    <span class="comment"># 创建分类标签向量</span></span><br><span class="line">    classLabelVector = []</span><br><span class="line">    <span class="comment"># 行的索引值</span></span><br><span class="line">    index = <span class="number">0</span></span><br><span class="line">    <span class="comment"># 读取每一行</span></span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> arrayOlines:</span><br><span class="line">        <span class="comment"># 去掉每一行首尾的空白符，例如'\n','\r','\t',' '</span></span><br><span class="line">        line = line.strip()</span><br><span class="line">        <span class="comment"># 将每一行内容根据'\t'符进行切片,本例中一共有4列</span></span><br><span class="line">        listFromLine = line.split(<span class="string">'\t'</span>)</span><br><span class="line">        <span class="comment"># 将数据的前3列进行提取保存在returnMat矩阵中，也就是特征矩阵</span></span><br><span class="line">        returnMat[index,:] = listFromLine[<span class="number">0</span>:<span class="number">3</span>]</span><br><span class="line">        <span class="comment"># 根据文本内容进行分类1：不喜欢；2：一般；3：喜欢</span></span><br><span class="line">        <span class="keyword">if</span> listFromLine[<span class="number">-1</span>] == <span class="string">'didntLike'</span>:</span><br><span class="line">            classLabelVector.append(<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">elif</span> listFromLine[<span class="number">-1</span>] == <span class="string">'smallDoses'</span>:</span><br><span class="line">            classLabelVector.append(<span class="number">2</span>)</span><br><span class="line">        <span class="keyword">elif</span> listFromLine[<span class="number">-1</span>] == <span class="string">'largeDoses'</span>:</span><br><span class="line">            classLabelVector.append(<span class="number">3</span>)</span><br><span class="line">        index += <span class="number">1</span></span><br><span class="line">    <span class="comment"># 返回标签列向量以及特征矩阵</span></span><br><span class="line">    <span class="keyword">return</span> returnMat, classLabelVector</span><br></pre></td></tr></table></figure></li></ol><h3 id="分析数据，使用matplotlib进行画图"><a href="#分析数据，使用matplotlib进行画图" class="headerlink" title="分析数据，使用matplotlib进行画图"></a>分析数据，使用matplotlib进行画图</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：可视化数据</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    datingDataMat - 特征矩阵</span></span><br><span class="line"><span class="string">    datingLabels - 分类Label</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    None</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Modify:</span></span><br><span class="line"><span class="string">    2018-07-13</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">showdatas</span><span class="params">(datingDataMat, datingLabels)</span>:</span></span><br><span class="line">    <span class="comment"># 设置汉字格式为14号简体字</span></span><br><span class="line">    font = FontProperties(fname=<span class="string">r"C:\Windows\Fonts\simsun.ttc"</span>, size=<span class="number">14</span>)</span><br><span class="line">    <span class="comment"># 将fig画布分隔成1行1列，不共享x轴和y轴，fig画布的大小为（13，8）</span></span><br><span class="line">    <span class="comment"># 当nrows=2，ncols=2时，代表fig画布被分为4个区域，axs[0][0]代表第一行第一个区域</span></span><br><span class="line">    fig, axs = plt.subplots(nrows=<span class="number">2</span>, ncols=<span class="number">2</span>, sharex=<span class="literal">False</span>, sharey=<span class="literal">False</span>, figsize=(<span class="number">13</span>, <span class="number">8</span>))</span><br><span class="line">    <span class="comment"># 获取datingLabels的行数作为label的个数</span></span><br><span class="line">    <span class="comment"># numberOfLabels = len(datingLabels)</span></span><br><span class="line">    <span class="comment"># label的颜色配置矩阵</span></span><br><span class="line">    LabelsColors = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> datingLabels:</span><br><span class="line">        <span class="comment"># didntLike</span></span><br><span class="line">        <span class="keyword">if</span> i == <span class="number">1</span>:</span><br><span class="line">            LabelsColors.append(<span class="string">'black'</span>)</span><br><span class="line">        <span class="comment"># smallDoses</span></span><br><span class="line">        <span class="keyword">if</span> i == <span class="number">2</span>:</span><br><span class="line">            LabelsColors.append(<span class="string">'orange'</span>)</span><br><span class="line">        <span class="comment"># largeDoses</span></span><br><span class="line">        <span class="keyword">if</span> i == <span class="number">3</span>:</span><br><span class="line">            LabelsColors.append(<span class="string">'red'</span>)</span><br><span class="line">    <span class="comment"># 画出散点图，以datingDataMat矩阵第一列为x，第二列为y，散点大小为15, 透明度为0.5</span></span><br><span class="line">    axs[<span class="number">0</span>][<span class="number">0</span>].scatter(x=datingDataMat[:,<span class="number">0</span>], y=datingDataMat[:,<span class="number">1</span>], color=LabelsColors, s=<span class="number">15</span>, alpha=<span class="number">.5</span>)</span><br><span class="line">    <span class="comment"># 设置标题，x轴label， y轴label</span></span><br><span class="line">    axs0_title_text = axs[<span class="number">0</span>][<span class="number">0</span>].set_title(<span class="string">u'每年获得的飞行常客里程数与玩视频游戏所消耗时间占比'</span>, FontProperties=font)</span><br><span class="line">    axs0_xlabel_text = axs[<span class="number">0</span>][<span class="number">0</span>].set_xlabel(<span class="string">u'每年获得的飞行常客里程数'</span>, FontProperties=font)</span><br><span class="line">    axs0_ylabel_text = axs[<span class="number">0</span>][<span class="number">0</span>].set_ylabel(<span class="string">u'玩视频游戏所消耗时间占比'</span>, FontProperties=font)</span><br><span class="line">    plt.setp(axs0_title_text, size=<span class="number">9</span>, weight=<span class="string">'bold'</span>, color=<span class="string">'red'</span>)</span><br><span class="line">    plt.setp(axs0_xlabel_text, size=<span class="number">7</span>, weight=<span class="string">'bold'</span>, color=<span class="string">'black'</span>)</span><br><span class="line">    plt.setp(axs0_ylabel_text, size=<span class="number">7</span>, weight=<span class="string">'bold'</span>, color=<span class="string">'black'</span>)</span><br><span class="line">    <span class="comment"># 画出散点图，以datingDataMat矩阵第一列为x，第三列为y，散点大小为15, 透明度为0.5</span></span><br><span class="line">    axs[<span class="number">0</span>][<span class="number">1</span>].scatter(x=datingDataMat[:,<span class="number">0</span>], y=datingDataMat[:,<span class="number">2</span>], color=LabelsColors, s=<span class="number">15</span>, alpha=<span class="number">.5</span>)</span><br><span class="line">    <span class="comment"># 设置标题，x轴label， y轴label</span></span><br><span class="line">    axs1_title_text = axs[<span class="number">0</span>][<span class="number">1</span>].set_title(<span class="string">u'每年获得的飞行常客里程数与每周消费的冰淇淋公升数'</span>, FontProperties=font)</span><br><span class="line">    axs1_xlabel_text = axs[<span class="number">0</span>][<span class="number">1</span>].set_xlabel(<span class="string">u'每年获得的飞行常客里程数'</span>, FontProperties=font)</span><br><span class="line">    axs1_ylabel_text = axs[<span class="number">0</span>][<span class="number">1</span>].set_ylabel(<span class="string">u'每周消费的冰淇淋公升数'</span>, FontProperties=font)</span><br><span class="line">    plt.setp(axs1_title_text, size=<span class="number">9</span>, weight=<span class="string">'bold'</span>, color=<span class="string">'red'</span>)</span><br><span class="line">    plt.setp(axs1_xlabel_text, size=<span class="number">7</span>, weight=<span class="string">'bold'</span>, color=<span class="string">'black'</span>)</span><br><span class="line">    plt.setp(axs1_ylabel_text, size=<span class="number">7</span>, weight=<span class="string">'bold'</span>, color=<span class="string">'black'</span>)</span><br><span class="line">    <span class="comment"># 画出散点图，以datingDataMat矩阵第二列为x，第三列为y，散点大小为15, 透明度为0.5</span></span><br><span class="line">    axs[<span class="number">1</span>][<span class="number">0</span>].scatter(x=datingDataMat[:,<span class="number">1</span>], y=datingDataMat[:,<span class="number">2</span>], color=LabelsColors, s=<span class="number">15</span>, alpha=<span class="number">.5</span>)</span><br><span class="line">    <span class="comment"># 设置标题，x轴label， y轴label</span></span><br><span class="line">    axs2_title_text = axs[<span class="number">1</span>][<span class="number">0</span>].set_title(<span class="string">u'玩视频游戏所消耗时间占比与每周消费的冰淇淋公升数'</span>, FontProperties=font)</span><br><span class="line">    axs2_xlabel_text = axs[<span class="number">1</span>][<span class="number">0</span>].set_xlabel(<span class="string">u'玩视频游戏所消耗时间占比'</span>, FontProperties=font)</span><br><span class="line">    axs2_ylabel_text = axs[<span class="number">1</span>][<span class="number">0</span>].set_ylabel(<span class="string">u'每周消费的冰淇淋公升数'</span>, FontProperties=font)</span><br><span class="line">    plt.setp(axs2_title_text, size=<span class="number">9</span>, weight=<span class="string">'bold'</span>, color=<span class="string">'red'</span>)</span><br><span class="line">    plt.setp(axs2_xlabel_text, size=<span class="number">7</span>, weight=<span class="string">'bold'</span>, color=<span class="string">'black'</span>)</span><br><span class="line">    plt.setp(axs2_ylabel_text, size=<span class="number">7</span>, weight=<span class="string">'bold'</span>, color=<span class="string">'black'</span>)</span><br><span class="line">    <span class="comment"># 设置图例</span></span><br><span class="line">    didntLike = mlines.Line2D([], [], color=<span class="string">'black'</span>, marker=<span class="string">'.'</span>, markersize=<span class="number">6</span>, label=<span class="string">'didntLike'</span>)</span><br><span class="line">    smallDoses = mlines.Line2D([], [], color=<span class="string">'orange'</span>, marker=<span class="string">'.'</span>, markersize=<span class="number">6</span>, label=<span class="string">'smallDoses'</span>)</span><br><span class="line">    largeDoses = mlines.Line2D([], [], color=<span class="string">'red'</span>, marker=<span class="string">'.'</span>, markersize=<span class="number">6</span>, label=<span class="string">'largeDoses'</span>)</span><br><span class="line">    <span class="comment"># 添加图例</span></span><br><span class="line">    axs[<span class="number">0</span>][<span class="number">0</span>].legend(handles=[didntLike, smallDoses, largeDoses])</span><br><span class="line">    axs[<span class="number">0</span>][<span class="number">1</span>].legend(handles=[didntLike, smallDoses, largeDoses])</span><br><span class="line">    axs[<span class="number">1</span>][<span class="number">0</span>].legend(handles=[didntLike, smallDoses, largeDoses])</span><br><span class="line">    <span class="comment"># 显示图片</span></span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure><h3 id="准备数据，归一化"><a href="#准备数据，归一化" class="headerlink" title="准备数据，归一化"></a>准备数据，归一化</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：对数据进行归一化</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    dataSet - 特征矩阵</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    normDataSet - 归一化后的特征矩阵</span></span><br><span class="line"><span class="string">    ranges - 数据范围</span></span><br><span class="line"><span class="string">    minVals - 数据最小值</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Modify:</span></span><br><span class="line"><span class="string">    2018-07-13</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">autoNorm</span><span class="params">(dataSet)</span>:</span></span><br><span class="line">    <span class="comment"># 获取数据的最小值</span></span><br><span class="line">    minVals = dataSet.min(<span class="number">0</span>)</span><br><span class="line">    <span class="comment"># 获取数据的最大值</span></span><br><span class="line">    maxVals = dataSet.max(<span class="number">0</span>)</span><br><span class="line">    <span class="comment"># 最大值和最小值的范围</span></span><br><span class="line">    ranges = maxVals - minVals</span><br><span class="line">    <span class="comment"># shape(dataSet)返回dataSet的矩阵行列数</span></span><br><span class="line">    normDataSet = np.zeros(np.shape(dataSet))</span><br><span class="line">    <span class="comment"># numpy函数shape[0]返回dataSet的行数</span></span><br><span class="line">    m = dataSet.shape[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># 原始值减去最小值（x-xmin）</span></span><br><span class="line">    normDataSet = dataSet - np.tile(minVals, (m, <span class="number">1</span>))</span><br><span class="line">    <span class="comment"># 差值处以最大值和最小值的差值（x-xmin）/（xmax-xmin）</span></span><br><span class="line">    normDataSet = normDataSet / np.tile(ranges, (m, <span class="number">1</span>))</span><br><span class="line">    <span class="comment"># 归一化数据结果，数据范围，最小值</span></span><br><span class="line">    <span class="keyword">return</span> normDataSet, ranges, minVals</span><br></pre></td></tr></table></figure><h3 id="测试算法，作为完整程序验证分类器"><a href="#测试算法，作为完整程序验证分类器" class="headerlink" title="测试算法，作为完整程序验证分类器"></a>测试算法，作为完整程序验证分类器</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：分类器测试函数</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    None</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    normDataSet - 归一化后的特征矩阵</span></span><br><span class="line"><span class="string">    ranges - 数据范围</span></span><br><span class="line"><span class="string">    minVals - 数据最小值</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Modify:</span></span><br><span class="line"><span class="string">    2018-07-13</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">datingClassTest</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="comment"># 打开文件名</span></span><br><span class="line">    filename = <span class="string">"datingTestSet.txt"</span></span><br><span class="line">    <span class="comment"># 将返回的特征矩阵和分类向量分别存储到datingDataMat和datingLabels中</span></span><br><span class="line">    datingDataMat, datingLabels = file2matrix(filename)</span><br><span class="line">    <span class="comment"># 取所有数据的10% hoRatio越小，错误率越低</span></span><br><span class="line">    hoRatio = <span class="number">0.10</span></span><br><span class="line">    <span class="comment"># 数据归一化，返回归一化数据结果，数据范围，最小值</span></span><br><span class="line">    normMat, ranges, minVals = autoNorm(datingDataMat)</span><br><span class="line">    <span class="comment"># 获取normMat的行数</span></span><br><span class="line">    m = normMat.shape[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># 10%的测试数据的个数</span></span><br><span class="line">    numTestVecs = int(m * hoRatio)</span><br><span class="line">    <span class="comment"># 分类错误计数</span></span><br><span class="line">    errorCount = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(numTestVecs):</span><br><span class="line">        <span class="comment"># 前numTestVecs个数据作为测试集，后m-numTestVecs个数据作为训练集</span></span><br><span class="line">        <span class="comment"># k选择label数+1（结果比较好）</span></span><br><span class="line">        classifierResult = classify0(normMat[i,:], normMat[numTestVecs:m,:],\</span><br><span class="line">                                     datingLabels[numTestVecs:m], <span class="number">4</span>)</span><br><span class="line">        print(<span class="string">"分类结果:%d\t真实类别:%d"</span> % (classifierResult, datingLabels[i]))</span><br><span class="line">        <span class="keyword">if</span> classifierResult != datingLabels[i]:</span><br><span class="line">            errorCount += <span class="number">1.0</span></span><br><span class="line">    print(<span class="string">"错误率:%f%%"</span> % (errorCount/float(numTestVecs)*<span class="number">100</span>))</span><br></pre></td></tr></table></figure><h3 id="使用算法"><a href="#使用算法" class="headerlink" title="使用算法"></a>使用算法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：通过输入一个人的三围特征，进行分类输出</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    None</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    None</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Modify:</span></span><br><span class="line"><span class="string">    2018-07-14</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">classifyPerson</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="comment"># 输出结果</span></span><br><span class="line">    resultList = [<span class="string">'讨厌'</span>, <span class="string">'有些喜欢'</span>, <span class="string">'非常喜欢'</span>]</span><br><span class="line">    <span class="comment"># 三维特征用户输入</span></span><br><span class="line">    percentTats = float(input(<span class="string">"玩视频游戏所消耗时间百分比："</span>))</span><br><span class="line">    ffMiles = float(input(<span class="string">"每年获得的飞行常客里程数："</span>))</span><br><span class="line">    iceCream = float(input(<span class="string">"每周消费的冰淇淋公升数："</span>))</span><br><span class="line">    <span class="comment"># 打开的文件名</span></span><br><span class="line">    filename = <span class="string">"datingTestSet.txt"</span></span><br><span class="line">    <span class="comment"># 打开并处理数据</span></span><br><span class="line">    datingDataMat, datingLabels = file2matrix(filename)</span><br><span class="line">    <span class="comment"># 训练集归一化</span></span><br><span class="line">    normMat, ranges, minVals = autoNorm(datingDataMat)</span><br><span class="line">    <span class="comment"># 生成NumPy数组，测试集</span></span><br><span class="line">    inArr = np.array([percentTats, ffMiles, iceCream])</span><br><span class="line">    <span class="comment"># 测试集归一化</span></span><br><span class="line">    norminArr = (inArr - minVals) / ranges</span><br><span class="line">    <span class="comment"># 返回分类结果</span></span><br><span class="line">    classifierResult = classify0(norminArr, normMat, datingLabels, <span class="number">4</span>)</span><br><span class="line">    <span class="comment"># 打印结果</span></span><br><span class="line">    print(<span class="string">"你可能%s这个人"</span> % (resultList[classifierResult - <span class="number">1</span>]))</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;《机器学习实战》《西瓜书》笔记（三）-KNN&quot;&gt;&lt;a href=&quot;#《机器学习实战》《西瓜书》笔记（三）-KNN&quot; class=&quot;headerlink&quot; title=&quot;《机器学习实战》《西瓜书》笔记（三）- KNN&quot;&gt;&lt;/a&gt;《机器学习实战》《西瓜书》笔记（三）-
      
    
    </summary>
    
    
      <category term="Machine_Learning" scheme="https://shyshy903.github.io/categories/Machine-Learning/"/>
    
    
      <category term="ML" scheme="https://shyshy903.github.io/tags/ML/"/>
    
  </entry>
  
</feed>
