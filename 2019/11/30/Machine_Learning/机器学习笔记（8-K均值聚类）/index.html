<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  
  <title>《机器学习实战》《西瓜书》笔记（八）- K均值聚类 | Try Your Best!</title>
  
  
  <meta name="description" content="https://img.vim-cn.com/33/461edfd8f8283ad38990aa7a83131b4494eb2c.jpg">
  

  
  <link rel="alternate" href="/atom.xml" title="Try Your Best!">
  

  <meta name="HandheldFriendly" content="True" />
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <!-- meta -->
  

  <!-- link -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css" />
  
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-waves@0.7.6/dist/waves.min.css">
  
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.10.1/css/all.min.css">
  

  

  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-material-x@20.2.11/css/style.css">

  

  <script>
    function setLoadingBarProgress(num) {
      document.getElementById('loading-bar').style.width=num+"%";
    }
  </script>

  
  
<meta name="generator" content="Hexo 4.2.0"><link rel="alternate" href="/atom.xml" title="Try Your Best!" type="application/atom+xml">
</head>

<body>
  
  
  <div class="cover-wrapper">
    <cover class='cover post half'>
      
        
  <h1 class='title'>shylab</h1>


  <div class="m_search">
    <form name="searchform" class="form u-search-form">
      <input type="text" class="input u-search-input" placeholder="" />
      <i class="icon fas fa-search fa-fw"></i>
    </form>
  </div>

<div class='menu navgation'>
  <ul class='h-list'>
    
      
        <li>
          <a class="nav home" href="/"
            
            
            id="home">
            <i class='fas fa-rss fa-fw'></i>&nbsp;Blogs
          </a>
        </li>
      
        <li>
          <a class="nav home" href="/archives/"
            
              rel="nofollow"
            
            
            id="archives">
            <i class='fas fa-archive fa-fw'></i>&nbsp;Archives
          </a>
        </li>
      
        <li>
          <a class="nav home" href="/tags/"
            
              rel="nofollow"
            
            
            id="tags">
            <i class='fas fa-tags fa-fw'></i>&nbsp;Tags
          </a>
        </li>
      
        <li>
          <a class="nav home" href="https://github.com/shyshy903"
            
            
            id="https:github.comshyshy903">
            <i class='fab fa-github fa-fw'></i>&nbsp;Github
          </a>
        </li>
      
    
  </ul>
</div>

      
    </cover>
    <header class="l_header pure">
  <div id="loading-bar-wrapper">
    <div id="loading-bar" class="pure"></div>
  </div>

	<div class='wrapper'>
		<div class="nav-main container container--flex">
      <a class="logo flat-box" target="_self" href='/' >
        
          Try Your Best!
        
      </a>
			<div class='menu navgation'>
				<ul class='h-list'>
          
  					
  						<li>
								<a class="nav flat-box" href="/categories/"
                  
                    rel="nofollow"
                  
                  
                  id="categories">
									<i class='fas fa-folder-open fa-fw'></i>&nbsp;分类
								</a>
							</li>
      			
  						<li>
								<a class="nav flat-box" href="/tags/"
                  
                    rel="nofollow"
                  
                  
                  id="tags">
									<i class='fas fa-tags fa-fw'></i>&nbsp;标签
								</a>
							</li>
      			
  						<li>
								<a class="nav flat-box" href="/archives/"
                  
                    rel="nofollow"
                  
                  
                  id="archives">
									<i class='fas fa-archive fa-fw'></i>&nbsp;归档
								</a>
							</li>
      			
      		
				</ul>
			</div>

			
				<div class="m_search">
					<form name="searchform" class="form u-search-form">
						<input type="text" class="input u-search-input" placeholder="Search" />
						<i class="icon fas fa-search fa-fw"></i>
					</form>
				</div>
			
			<ul class='switcher h-list'>
				
					<li class='s-search'><a class="fas fa-search fa-fw" target="_self" href='javascript:void(0)'></a></li>
				
				<li class='s-menu'><a class="fas fa-bars fa-fw" target="_self" href='javascript:void(0)'></a></li>
			</ul>
		</div>

		<div class='nav-sub container container--flex'>
			<a class="logo flat-box"></a>
			<ul class='switcher h-list'>
				<li class='s-comment'><a class="flat-btn fas fa-comments fa-fw" target="_self" href='javascript:void(0)'></a></li>
        
          <li class='s-toc'><a class="flat-btn fas fa-list fa-fw" target="_self" href='javascript:void(0)'></a></li>
        
			</ul>
		</div>
	</div>
</header>
	<aside class="menu-phone">
    <header>
		<nav class="menu navgation">
      <ul>
        
          
            <li>
							<a class="nav flat-box" href="/"
                
                
                id="home">
								<i class='fas fa-clock fa-fw'></i>&nbsp;近期文章
							</a>
            </li>
          
            <li>
							<a class="nav flat-box" href="/archives/"
                
                  rel="nofollow"
                
                
                id="archives">
								<i class='fas fa-archive fa-fw'></i>&nbsp;文章归档
							</a>
            </li>
          
       
      </ul>
		</nav>
    </header>
	</aside>
<script>setLoadingBarProgress(40);</script>

  </div>


  <div class="l_body">
    <div class='body-wrapper'>
      <div class='l_main'>
  

  <article id="post" class="post white-box article-type-post" itemscope itemprop="blogPost">
    


  <section class='meta'>
    
    
    <div class="meta" id="header-meta">
      
        
  
    <h1 class="title">
      <a href="/2019/11/30/Machine_Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%888-K%E5%9D%87%E5%80%BC%E8%81%9A%E7%B1%BB%EF%BC%89/">
        《机器学习实战》《西瓜书》笔记（八）- K均值聚类
      </a>
    </h1>
  


      
      <div class='new-meta-box'>
        
          
        
          
            
  <div class='new-meta-item author'>
    
      <a href="https://shyshy903.github.io" rel="nofollow">
        
          <i class="fas fa-user" aria-hidden="true"></i>
        
        <p>Haiyang Song</p>
      </a>
    
  </div>


          
        
          
            <div class="new-meta-item date">
  <a class='notlink'>
    <i class="fas fa-calendar-alt" aria-hidden="true"></i>
    <p>2019-11-30</p>
  </a>
</div>

          
        
          
            
  
  <div class='new-meta-item category'>
    <a href='/categories/Machine-Learning/' rel="nofollow">
      <i class="fas fa-folder-open" aria-hidden="true"></i>
      <p>Machine_Learning</p>
    </a>
  </div>


          
        
          
            
  
    <div class="new-meta-item browse busuanzi">
      <a class='notlink'>
        <i class="fas fa-eye" aria-hidden="true"></i>
        <p>
          <span id="busuanzi_value_page_pv">
            <i class="fas fa-spinner fa-spin fa-fw" aria-hidden="true"></i>
          </span>
        </p>
      </a>
    </div>
  


          
        
          
            
  

          
        
          
            

          
        
      </div>
      
        <hr>
      
    </div>
  </section>


    <section class="article typo">
      <div class="article-entry" itemprop="articleBody">
        <h1 id="K均值聚类"><a href="#K均值聚类" class="headerlink" title="K均值聚类"></a>K均值聚类</h1><p>算法伪代码：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">创建k个点作为起始质心（经常是随机选择）</span><br><span class="line">当任意一个点的簇分配结果发生改变时</span><br><span class="line">    对数据集中的每个数据点</span><br><span class="line">        对每个质心</span><br><span class="line">            计算质心与数据点之间的距离</span><br><span class="line">        将数据点分配到距离其最近的簇</span><br><span class="line">    对每一个簇，计算簇中所有点的均值，并且将该值作为质心</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：k-means聚类算法</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    dataSet - 用于聚类的数据集</span></span><br><span class="line"><span class="string">    k - 选取k个质心</span></span><br><span class="line"><span class="string">    distMeas - 距离计算方法,默认欧氏距离distEclud()</span></span><br><span class="line"><span class="string">    createCent - 获取k个质心的方法,默认随机获取randCent()</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    centroids - k个聚类的聚类结果</span></span><br><span class="line"><span class="string">    clusterAssment - 聚类误差</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">kMeans</span><span class="params">(dataSet, k, distMeas=distEclud, createCent=randCent)</span>:</span></span><br><span class="line">    <span class="comment"># 获取数据集样本数</span></span><br><span class="line">    m = np.shape(dataSet)[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># 初始化一个（m,2）全零矩阵</span></span><br><span class="line">    clusterAssment = np.mat(np.zeros((m, <span class="number">2</span>)))</span><br><span class="line">    <span class="comment"># 创建初始的k个质心向量</span></span><br><span class="line">    centroids = createCent(dataSet, k)</span><br><span class="line">    <span class="comment"># 聚类结果是否发生变化的布尔类型</span></span><br><span class="line">    clusterChanged = <span class="literal">True</span></span><br><span class="line">    <span class="comment"># 只要聚类结果一直发生变化，就一直执行聚类算法，直至所有数据点聚类结果不发生变化</span></span><br><span class="line">    <span class="keyword">while</span> clusterChanged:</span><br><span class="line">        <span class="comment"># 聚类结果变化布尔类型置为False</span></span><br><span class="line">        clusterChanged = <span class="literal">False</span></span><br><span class="line">        <span class="comment"># 遍历数据集每一个样本向量</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">            <span class="comment"># 初始化最小距离为正无穷，最小距离对应的索引为-1</span></span><br><span class="line">            minDist = float(<span class="string">'inf'</span>)</span><br><span class="line">            minIndex = <span class="number">-1</span></span><br><span class="line">            <span class="comment"># 循环k个类的质心</span></span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(k):</span><br><span class="line">                <span class="comment"># 计算数据点到质心的欧氏距离</span></span><br><span class="line">                distJI = distMeas(centroids[j, :], dataSet[i, :])</span><br><span class="line">                <span class="comment"># 如果距离小于当前最小距离</span></span><br><span class="line">                <span class="keyword">if</span> distJI &lt; minDist:</span><br><span class="line">                    <span class="comment"># 当前距离为最小距离，最小距离对应索引应为j(第j个类)</span></span><br><span class="line">                    minDist = distJI</span><br><span class="line">                    minIndex = j</span><br><span class="line">            <span class="comment"># 当前聚类结果中第i个样本的聚类结果发生变化：布尔值置为True，继续聚类算法</span></span><br><span class="line">            <span class="keyword">if</span> clusterAssment[i, <span class="number">0</span>] != minIndex: </span><br><span class="line">                clusterChanged = <span class="literal">True</span></span><br><span class="line">            <span class="comment"># 更新当前变化样本的聚类结果和平方误差</span></span><br><span class="line">            clusterAssment[i, :] = minIndex, minDist**<span class="number">2</span></span><br><span class="line">            <span class="comment"># 打印k-means聚类的质心</span></span><br><span class="line">        <span class="comment"># print(centroids)</span></span><br><span class="line">        <span class="comment"># 遍历每一个质心</span></span><br><span class="line">        <span class="keyword">for</span> cent <span class="keyword">in</span> range(k):</span><br><span class="line">            <span class="comment"># 将数据集中所有属于当前质心类的样本通过条件过滤筛选出来</span></span><br><span class="line">            ptsInClust = dataSet[np.nonzero(clusterAssment[:, <span class="number">0</span>].A == cent)[<span class="number">0</span>]]</span><br><span class="line">            <span class="comment"># 计算这些数据的均值(axis=0:求列均值)，作为该类质心向量</span></span><br><span class="line">            centroids[cent, :] = np.mean(ptsInClust, axis=<span class="number">0</span>)</span><br><span class="line">    <span class="comment"># 返回k个聚类，聚类结果及误差</span></span><br><span class="line">    <span class="keyword">return</span> centroids, clusterAssment</span><br></pre></td></tr></table></figure>
<h2 id="源代码"><a href="#源代码" class="headerlink" title="源代码"></a>源代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Created on Thu Aug  2 21:20:03 2018</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">@author: wzy</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：将文本文档中的数据读入到python中</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    fileName - 文件名</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    dataMat - 数据矩阵</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadDataSet</span><span class="params">(fileName)</span>:</span></span><br><span class="line">    dataMat = []</span><br><span class="line">    fr = open(fileName)</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> fr.readlines():</span><br><span class="line">        curLine = line.strip().split(<span class="string">'\t'</span>)</span><br><span class="line">        fltLine = list(map(float, curLine))</span><br><span class="line">        dataMat.append(fltLine)</span><br><span class="line">    <span class="keyword">return</span> dataMat</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：数据向量计算欧式距离</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    vecA - 数据向量A</span></span><br><span class="line"><span class="string">    vecB - 数据向量B</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    两个向量之间的欧几里德距离</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Modify:</span></span><br><span class="line"><span class="string">    2018-08-02</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">distEclud</span><span class="params">(vecA, vecB)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> np.sqrt(np.sum(np.power(vecA - vecB, <span class="number">2</span>)))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：随机初始化k个质心（质心满足数据边界之内）</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    dataSet - 输入的数据集</span></span><br><span class="line"><span class="string">    k - 选取k个质心</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    centroids - 返回初始化得到的k个质心向量</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">randCent</span><span class="params">(dataSet, k)</span>:</span></span><br><span class="line">    <span class="comment"># 得到数据样本的维度</span></span><br><span class="line">    n = np.shape(dataSet)[<span class="number">1</span>]</span><br><span class="line">    <span class="comment"># 初始化为一个(k,n)的全零矩阵</span></span><br><span class="line">    centroids = np.mat(np.zeros((k, n)))</span><br><span class="line">    <span class="comment"># 遍历数据集的每一个维度</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(n):</span><br><span class="line">        <span class="comment"># 得到该列数据的最小值,最大值</span></span><br><span class="line">        minJ = np.min(dataSet[:, j])</span><br><span class="line">        maxJ = np.max(dataSet[:, j])</span><br><span class="line">        <span class="comment"># 得到该列数据的范围(最大值-最小值)</span></span><br><span class="line">        rangeJ = float(maxJ - minJ)</span><br><span class="line">        <span class="comment"># k个质心向量的第j维数据值随机为位于(最小值，最大值)内的某一值</span></span><br><span class="line">        <span class="comment"># Create an array of the given shape and populate it with random samples from a uniform distribution over [0, 1).</span></span><br><span class="line">        centroids[:, j] = minJ + rangeJ * np.random.rand(k, <span class="number">1</span>)</span><br><span class="line">    <span class="comment"># 返回初始化得到的k个质心向量</span></span><br><span class="line">    <span class="keyword">return</span> centroids</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：k-means聚类算法</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    dataSet - 用于聚类的数据集</span></span><br><span class="line"><span class="string">    k - 选取k个质心</span></span><br><span class="line"><span class="string">    distMeas - 距离计算方法,默认欧氏距离distEclud()</span></span><br><span class="line"><span class="string">    createCent - 获取k个质心的方法,默认随机获取randCent()</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    centroids - k个聚类的聚类结果</span></span><br><span class="line"><span class="string">    clusterAssment - 聚类误差</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">kMeans</span><span class="params">(dataSet, k, distMeas=distEclud, createCent=randCent)</span>:</span></span><br><span class="line">    <span class="comment"># 获取数据集样本数</span></span><br><span class="line">    m = np.shape(dataSet)[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># 初始化一个（m,2）全零矩阵</span></span><br><span class="line">    clusterAssment = np.mat(np.zeros((m, <span class="number">2</span>)))</span><br><span class="line">    <span class="comment"># 创建初始的k个质心向量</span></span><br><span class="line">    centroids = createCent(dataSet, k)</span><br><span class="line">    <span class="comment"># 聚类结果是否发生变化的布尔类型</span></span><br><span class="line">    clusterChanged = <span class="literal">True</span></span><br><span class="line">    <span class="comment"># 只要聚类结果一直发生变化，就一直执行聚类算法，直至所有数据点聚类结果不发生变化</span></span><br><span class="line">    <span class="keyword">while</span> clusterChanged:</span><br><span class="line">        <span class="comment"># 聚类结果变化布尔类型置为False</span></span><br><span class="line">        clusterChanged = <span class="literal">False</span></span><br><span class="line">        <span class="comment"># 遍历数据集每一个样本向量</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">            <span class="comment"># 初始化最小距离为正无穷，最小距离对应的索引为-1</span></span><br><span class="line">            minDist = float(<span class="string">'inf'</span>)</span><br><span class="line">            minIndex = <span class="number">-1</span></span><br><span class="line">            <span class="comment"># 循环k个类的质心</span></span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(k):</span><br><span class="line">                <span class="comment"># 计算数据点到质心的欧氏距离</span></span><br><span class="line">                distJI = distMeas(centroids[j, :], dataSet[i, :])</span><br><span class="line">                <span class="comment"># 如果距离小于当前最小距离</span></span><br><span class="line">                <span class="keyword">if</span> distJI &lt; minDist:</span><br><span class="line">                    <span class="comment"># 当前距离为最小距离，最小距离对应索引应为j(第j个类)</span></span><br><span class="line">                    minDist = distJI</span><br><span class="line">                    minIndex = j</span><br><span class="line">            <span class="comment"># 当前聚类结果中第i个样本的聚类结果发生变化：布尔值置为True，继续聚类算法</span></span><br><span class="line">            <span class="keyword">if</span> clusterAssment[i, <span class="number">0</span>] != minIndex: </span><br><span class="line">                clusterChanged = <span class="literal">True</span></span><br><span class="line">            <span class="comment"># 更新当前变化样本的聚类结果和平方误差</span></span><br><span class="line">            clusterAssment[i, :] = minIndex, minDist**<span class="number">2</span></span><br><span class="line">            <span class="comment"># 打印k-means聚类的质心</span></span><br><span class="line">        <span class="comment"># print(centroids)</span></span><br><span class="line">        <span class="comment"># 遍历每一个质心</span></span><br><span class="line">        <span class="keyword">for</span> cent <span class="keyword">in</span> range(k):</span><br><span class="line">            <span class="comment"># 将数据集中所有属于当前质心类的样本通过条件过滤筛选出来</span></span><br><span class="line">            ptsInClust = dataSet[np.nonzero(clusterAssment[:, <span class="number">0</span>].A == cent)[<span class="number">0</span>]]</span><br><span class="line">            <span class="comment"># 计算这些数据的均值(axis=0:求列均值)，作为该类质心向量</span></span><br><span class="line">            centroids[cent, :] = np.mean(ptsInClust, axis=<span class="number">0</span>)</span><br><span class="line">    <span class="comment"># 返回k个聚类，聚类结果及误差</span></span><br><span class="line">    <span class="keyword">return</span> centroids, clusterAssment</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：绘制数据集</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    fileName - 文件名</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    None</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plotDataSet</span><span class="params">(filename)</span>:</span></span><br><span class="line">    <span class="comment"># 导入数据</span></span><br><span class="line">    datMat = np.mat(loadDataSet(filename))</span><br><span class="line">    <span class="comment"># 进行k-means算法其中k为4</span></span><br><span class="line">    myCentroids, clustAssing = kMeans(datMat, <span class="number">4</span>)</span><br><span class="line">    clustAssing = clustAssing.tolist()</span><br><span class="line">    myCentroids = myCentroids.tolist()</span><br><span class="line">    xcord = [[], [], [], []]</span><br><span class="line">    ycord = [[], [], [], []]</span><br><span class="line">    datMat = datMat.tolist()</span><br><span class="line">    m = len(clustAssing)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">        <span class="keyword">if</span> int(clustAssing[i][<span class="number">0</span>]) == <span class="number">0</span>:</span><br><span class="line">            xcord[<span class="number">0</span>].append(datMat[i][<span class="number">0</span>])</span><br><span class="line">            ycord[<span class="number">0</span>].append(datMat[i][<span class="number">1</span>])</span><br><span class="line">        <span class="keyword">elif</span> int(clustAssing[i][<span class="number">0</span>]) == <span class="number">1</span>:</span><br><span class="line">            xcord[<span class="number">1</span>].append(datMat[i][<span class="number">0</span>])</span><br><span class="line">            ycord[<span class="number">1</span>].append(datMat[i][<span class="number">1</span>])</span><br><span class="line">        <span class="keyword">elif</span> int(clustAssing[i][<span class="number">0</span>]) == <span class="number">2</span>:</span><br><span class="line">            xcord[<span class="number">2</span>].append(datMat[i][<span class="number">0</span>])</span><br><span class="line">            ycord[<span class="number">2</span>].append(datMat[i][<span class="number">1</span>])</span><br><span class="line">        <span class="keyword">elif</span> int(clustAssing[i][<span class="number">0</span>]) == <span class="number">3</span>:</span><br><span class="line">            xcord[<span class="number">3</span>].append(datMat[i][<span class="number">0</span>])</span><br><span class="line">            ycord[<span class="number">3</span>].append(datMat[i][<span class="number">1</span>])</span><br><span class="line">    fig = plt.figure()</span><br><span class="line">    ax = fig.add_subplot(<span class="number">111</span>)</span><br><span class="line">    <span class="comment"># 绘制样本点</span></span><br><span class="line">    ax.scatter(xcord[<span class="number">0</span>], ycord[<span class="number">0</span>], s=<span class="number">20</span>, c=<span class="string">'b'</span>, marker=<span class="string">'*'</span>, alpha=<span class="number">.5</span>)</span><br><span class="line">    ax.scatter(xcord[<span class="number">1</span>], ycord[<span class="number">1</span>], s=<span class="number">20</span>, c=<span class="string">'r'</span>, marker=<span class="string">'D'</span>, alpha=<span class="number">.5</span>)</span><br><span class="line">    ax.scatter(xcord[<span class="number">2</span>], ycord[<span class="number">2</span>], s=<span class="number">20</span>, c=<span class="string">'c'</span>, marker=<span class="string">'&gt;'</span>, alpha=<span class="number">.5</span>)</span><br><span class="line">    ax.scatter(xcord[<span class="number">3</span>], ycord[<span class="number">3</span>], s=<span class="number">20</span>, c=<span class="string">'k'</span>, marker=<span class="string">'o'</span>, alpha=<span class="number">.5</span>)</span><br><span class="line">    <span class="comment"># 绘制质心</span></span><br><span class="line">    ax.scatter(myCentroids[<span class="number">0</span>][<span class="number">0</span>], myCentroids[<span class="number">0</span>][<span class="number">1</span>], s=<span class="number">100</span>, c=<span class="string">'k'</span>, marker=<span class="string">'+'</span>, alpha=<span class="number">.5</span>)</span><br><span class="line">    ax.scatter(myCentroids[<span class="number">1</span>][<span class="number">0</span>], myCentroids[<span class="number">1</span>][<span class="number">1</span>], s=<span class="number">100</span>, c=<span class="string">'k'</span>, marker=<span class="string">'+'</span>, alpha=<span class="number">.5</span>)</span><br><span class="line">    ax.scatter(myCentroids[<span class="number">2</span>][<span class="number">0</span>], myCentroids[<span class="number">2</span>][<span class="number">1</span>], s=<span class="number">100</span>, c=<span class="string">'k'</span>, marker=<span class="string">'+'</span>, alpha=<span class="number">.5</span>)</span><br><span class="line">    ax.scatter(myCentroids[<span class="number">3</span>][<span class="number">0</span>], myCentroids[<span class="number">3</span>][<span class="number">1</span>], s=<span class="number">100</span>, c=<span class="string">'k'</span>, marker=<span class="string">'+'</span>, alpha=<span class="number">.5</span>)</span><br><span class="line">    plt.title(<span class="string">'DataSet'</span>)</span><br><span class="line">    plt.xlabel(<span class="string">'X'</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    plotDataSet(<span class="string">'testSet.txt'</span>)</span><br></pre></td></tr></table></figure>
<h1 id="二分K均值聚类"><a href="#二分K均值聚类" class="headerlink" title="二分K均值聚类"></a>二分K均值聚类</h1><p>算法伪代码：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">将所有点看成一个簇</span><br><span class="line">当簇数目小于K时</span><br><span class="line">    对每一个簇</span><br><span class="line">        计算总误差</span><br><span class="line">        在给定的簇上面进行K-均值聚类（k&#x3D;2)</span><br><span class="line">        计算将该簇一分为二之后的总误差</span><br><span class="line">    选择使得误差最小的那个簇进行划分操作</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：二分k-means聚类算法</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    dataSet - 用于聚类的数据集</span></span><br><span class="line"><span class="string">    k - 选取k个质心</span></span><br><span class="line"><span class="string">    distMeas - 距离计算方法,默认欧氏距离distEclud()</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    centList - k个聚类的聚类结果</span></span><br><span class="line"><span class="string">    clusterAssment - 聚类误差</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">biKmeans</span><span class="params">(dataSet, k, distMeas=distEclud)</span>:</span></span><br><span class="line">    <span class="comment"># 获取数据集的样本数</span></span><br><span class="line">    m = np.shape(dataSet)[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># 初始化一个元素均值0的(m, 2)矩阵</span></span><br><span class="line">    clusterAssment = np.mat(np.zeros((m, <span class="number">2</span>)))</span><br><span class="line">    <span class="comment"># 获取数据集每一列数据的均值，组成一个列表</span></span><br><span class="line">    centroid0 = np.mean(dataSet, axis=<span class="number">0</span>).tolist()[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># 当前聚类列表为将数据集聚为一类</span></span><br><span class="line">    centList = [centroid0]</span><br><span class="line">    <span class="comment"># 遍历每个数据集样本</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(m):</span><br><span class="line">        <span class="comment"># 计算当前聚为一类时各个数据点距离质心的平方距离</span></span><br><span class="line">        clusterAssment[j, <span class="number">1</span>] = distMeas(np.mat(centroid0), dataSet[j, :])**<span class="number">2</span></span><br><span class="line">    <span class="comment"># 循环，直至二分k-Means值达到k类为止</span></span><br><span class="line">    <span class="keyword">while</span> (len(centList) &lt; k):</span><br><span class="line">        <span class="comment"># 将当前最小平方误差置为正无穷</span></span><br><span class="line">        lowerSSE = float(<span class="string">'inf'</span>)</span><br><span class="line">        <span class="comment"># 遍历当前每个聚类</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(centList)):</span><br><span class="line">            <span class="comment"># 通过数组过滤筛选出属于第i类的数据集合</span></span><br><span class="line">            ptsInCurrCluster = dataSet[np.nonzero(clusterAssment[:, <span class="number">0</span>].A == i)[<span class="number">0</span>], :]</span><br><span class="line">            <span class="comment"># 对该类利用二分k-means算法进行划分，返回划分后的结果以及误差</span></span><br><span class="line">            centroidMat, splitClustAss = kMeans(ptsInCurrCluster, <span class="number">2</span>, distMeas)</span><br><span class="line">            <span class="comment"># 计算该类划分后两个类的误差平方和</span></span><br><span class="line">            sseSplit = np.sum(splitClustAss[:, <span class="number">1</span>])</span><br><span class="line">            <span class="comment"># 计算数据集中不属于该类的数据的误差平方和</span></span><br><span class="line">            sseNotSplit = np.sum(clusterAssment[np.nonzero(clusterAssment[:, <span class="number">0</span>].A != i)[<span class="number">0</span>], <span class="number">1</span>])</span><br><span class="line">            <span class="comment"># 打印这两项误差值</span></span><br><span class="line">            print(<span class="string">'sseSplit = %f, and notSplit = %f'</span> % (sseSplit, sseNotSplit))</span><br><span class="line">            <span class="comment"># 划分第i类后总误差小于当前最小总误差</span></span><br><span class="line">            <span class="keyword">if</span> (sseSplit + sseNotSplit) &lt; lowerSSE:</span><br><span class="line">                <span class="comment"># 第i类作为本次划分类</span></span><br><span class="line">                bestCentToSplit = i</span><br><span class="line">                <span class="comment"># 第i类划分后得到的两个质心向量</span></span><br><span class="line">                bestNewCents = centroidMat</span><br><span class="line">                <span class="comment"># 复制第i类中数据点的聚类结果即误差值</span></span><br><span class="line">                bestClustAss = splitClustAss.copy()</span><br><span class="line">                <span class="comment"># 将划分第i类后的总误差作为当前最小误差</span></span><br><span class="line">                lowerSSE = sseSplit + sseNotSplit</span><br><span class="line">        <span class="comment"># 数组过滤选出本次2-means聚类划分后类编号为1数据点，将这些数据点类编号变为</span></span><br><span class="line">        <span class="comment"># 当前类个数+1， 作为新的一个聚类</span></span><br><span class="line">        bestClustAss[np.nonzero(bestClustAss[:, <span class="number">0</span>].A == <span class="number">1</span>)[<span class="number">0</span>], <span class="number">0</span>] = len(centList)</span><br><span class="line">        <span class="comment"># 同理，将划分数据中类编号为0的数据点的类编号仍置为被划分的类编号，使类编号</span></span><br><span class="line">        <span class="comment"># 连续不出现空缺</span></span><br><span class="line">        bestClustAss[np.nonzero(bestClustAss[:, <span class="number">0</span>].A == <span class="number">0</span>)[<span class="number">0</span>], <span class="number">0</span>] = bestCentToSplit</span><br><span class="line">        <span class="comment"># 打印本次执行2-means聚类算法的类</span></span><br><span class="line">        print(<span class="string">'the bestCentToSplit is %d'</span> % bestCentToSplit)</span><br><span class="line">        <span class="comment"># 打印被划分的类的数据个数</span></span><br><span class="line">        print(<span class="string">'the len of bestClustAss is %d'</span> % len(bestClustAss))</span><br><span class="line">        <span class="comment"># 更新质心列表中变化后的质心向量</span></span><br><span class="line">        centList[bestCentToSplit] = bestNewCents[<span class="number">0</span>, :]</span><br><span class="line">        <span class="comment"># 添加新的类的质心向量</span></span><br><span class="line">        centList.append(bestNewCents[<span class="number">1</span>, :])</span><br><span class="line">        <span class="comment"># 更新clusterAssment列表中参与2-means聚类数据点变化后的分类编号，及数据该类的误差平方</span></span><br><span class="line">        clusterAssment[np.nonzero(clusterAssment[:, <span class="number">0</span>].A == bestCentToSplit)[<span class="number">0</span>], :] = bestClustAss</span><br><span class="line">    <span class="comment"># 返回聚类结果</span></span><br><span class="line">    <span class="keyword">return</span> centList, clusterAssment</span><br></pre></td></tr></table></figure>
<h2 id="源代码-1"><a href="#源代码-1" class="headerlink" title="源代码"></a>源代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Created on Fri Aug  3 13:53:40 2018</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">@author: wzy</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：将文本文档中的数据读入到python中</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    fileName - 文件名</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    dataMat - 数据矩阵</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadDataSet</span><span class="params">(fileName)</span>:</span></span><br><span class="line">    dataMat = []</span><br><span class="line">    fr = open(fileName)</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> fr.readlines():</span><br><span class="line">        curLine = line.strip().split(<span class="string">'\t'</span>)</span><br><span class="line">        fltLine = list(map(float, curLine))</span><br><span class="line">        dataMat.append(fltLine)</span><br><span class="line">    <span class="keyword">return</span> dataMat</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：数据向量计算欧式距离</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    vecA - 数据向量A</span></span><br><span class="line"><span class="string">    vecB - 数据向量B</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    两个向量之间的欧几里德距离</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">distEclud</span><span class="params">(vecA, vecB)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> np.sqrt(np.sum(np.power(vecA - vecB, <span class="number">2</span>)))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：随机初始化k个质心（质心满足数据边界之内）</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    dataSet - 输入的数据集</span></span><br><span class="line"><span class="string">    k - 选取k个质心</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    centroids - 返回初始化得到的k个质心向量</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">randCent</span><span class="params">(dataSet, k)</span>:</span></span><br><span class="line">    <span class="comment"># 得到数据样本的维度</span></span><br><span class="line">    n = np.shape(dataSet)[<span class="number">1</span>]</span><br><span class="line">    <span class="comment"># 初始化为一个(k,n)的全零矩阵</span></span><br><span class="line">    centroids = np.mat(np.zeros((k, n)))</span><br><span class="line">    <span class="comment"># 遍历数据集的每一个维度</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(n):</span><br><span class="line">        <span class="comment"># 得到该列数据的最小值,最大值</span></span><br><span class="line">        minJ = np.min(dataSet[:, j])</span><br><span class="line">        maxJ = np.max(dataSet[:, j])</span><br><span class="line">        <span class="comment"># 得到该列数据的范围(最大值-最小值)</span></span><br><span class="line">        rangeJ = float(maxJ - minJ)</span><br><span class="line">        <span class="comment"># k个质心向量的第j维数据值随机为位于(最小值，最大值)内的某一值</span></span><br><span class="line">        <span class="comment"># Create an array of the given shape and populate it with random samples from a uniform distribution over [0, 1).</span></span><br><span class="line">        centroids[:, j] = minJ + rangeJ * np.random.rand(k, <span class="number">1</span>)</span><br><span class="line">    <span class="comment"># 返回初始化得到的k个质心向量</span></span><br><span class="line">    <span class="keyword">return</span> centroids</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：k-means聚类算法</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    dataSet - 用于聚类的数据集</span></span><br><span class="line"><span class="string">    k - 选取k个质心</span></span><br><span class="line"><span class="string">    distMeas - 距离计算方法,默认欧氏距离distEclud()</span></span><br><span class="line"><span class="string">    createCent - 获取k个质心的方法,默认随机获取randCent()</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    centroids - k个聚类的聚类结果</span></span><br><span class="line"><span class="string">    clusterAssment - 聚类误差</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">kMeans</span><span class="params">(dataSet, k, distMeas=distEclud, createCent=randCent)</span>:</span></span><br><span class="line">    <span class="comment"># 获取数据集样本数</span></span><br><span class="line">    m = np.shape(dataSet)[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># 初始化一个（m,2）全零矩阵</span></span><br><span class="line">    clusterAssment = np.mat(np.zeros((m, <span class="number">2</span>)))</span><br><span class="line">    <span class="comment"># 创建初始的k个质心向量</span></span><br><span class="line">    centroids = createCent(dataSet, k)</span><br><span class="line">    <span class="comment"># 聚类结果是否发生变化的布尔类型</span></span><br><span class="line">    clusterChanged = <span class="literal">True</span></span><br><span class="line">    <span class="comment"># 只要聚类结果一直发生变化，就一直执行聚类算法，直至所有数据点聚类结果不发生变化</span></span><br><span class="line">    <span class="keyword">while</span> clusterChanged:</span><br><span class="line">        <span class="comment"># 聚类结果变化布尔类型置为False</span></span><br><span class="line">        clusterChanged = <span class="literal">False</span></span><br><span class="line">        <span class="comment"># 遍历数据集每一个样本向量</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">            <span class="comment"># 初始化最小距离为正无穷，最小距离对应的索引为-1</span></span><br><span class="line">            minDist = float(<span class="string">'inf'</span>)</span><br><span class="line">            minIndex = <span class="number">-1</span></span><br><span class="line">            <span class="comment"># 循环k个类的质心</span></span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(k):</span><br><span class="line">                <span class="comment"># 计算数据点到质心的欧氏距离</span></span><br><span class="line">                distJI = distMeas(centroids[j, :], dataSet[i, :])</span><br><span class="line">                <span class="comment"># 如果距离小于当前最小距离</span></span><br><span class="line">                <span class="keyword">if</span> distJI &lt; minDist:</span><br><span class="line">                    <span class="comment"># 当前距离为最小距离，最小距离对应索引应为j(第j个类)</span></span><br><span class="line">                    minDist = distJI</span><br><span class="line">                    minIndex = j</span><br><span class="line">            <span class="comment"># 当前聚类结果中第i个样本的聚类结果发生变化：布尔值置为True，继续聚类算法</span></span><br><span class="line">            <span class="keyword">if</span> clusterAssment[i, <span class="number">0</span>] != minIndex: </span><br><span class="line">                clusterChanged = <span class="literal">True</span></span><br><span class="line">            <span class="comment"># 更新当前变化样本的聚类结果和平方误差</span></span><br><span class="line">            clusterAssment[i, :] = minIndex, minDist**<span class="number">2</span></span><br><span class="line">            <span class="comment"># 打印k-means聚类的质心</span></span><br><span class="line">        <span class="comment"># print(centroids)</span></span><br><span class="line">        <span class="comment"># 遍历每一个质心</span></span><br><span class="line">        <span class="keyword">for</span> cent <span class="keyword">in</span> range(k):</span><br><span class="line">            <span class="comment"># 将数据集中所有属于当前质心类的样本通过条件过滤筛选出来</span></span><br><span class="line">            ptsInClust = dataSet[np.nonzero(clusterAssment[:, <span class="number">0</span>].A == cent)[<span class="number">0</span>]]</span><br><span class="line">            <span class="comment"># 计算这些数据的均值(axis=0:求列均值)，作为该类质心向量</span></span><br><span class="line">            centroids[cent, :] = np.mean(ptsInClust, axis=<span class="number">0</span>)</span><br><span class="line">    <span class="comment"># 返回k个聚类，聚类结果及误差</span></span><br><span class="line">    <span class="keyword">return</span> centroids, clusterAssment</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：二分k-means聚类算法</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    dataSet - 用于聚类的数据集</span></span><br><span class="line"><span class="string">    k - 选取k个质心</span></span><br><span class="line"><span class="string">    distMeas - 距离计算方法,默认欧氏距离distEclud()</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    centList - k个聚类的聚类结果</span></span><br><span class="line"><span class="string">    clusterAssment - 聚类误差</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">biKmeans</span><span class="params">(dataSet, k, distMeas=distEclud)</span>:</span></span><br><span class="line">    <span class="comment"># 获取数据集的样本数</span></span><br><span class="line">    m = np.shape(dataSet)[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># 初始化一个元素均值0的(m, 2)矩阵</span></span><br><span class="line">    clusterAssment = np.mat(np.zeros((m, <span class="number">2</span>)))</span><br><span class="line">    <span class="comment"># 获取数据集每一列数据的均值，组成一个列表</span></span><br><span class="line">    centroid0 = np.mean(dataSet, axis=<span class="number">0</span>).tolist()[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># 当前聚类列表为将数据集聚为一类</span></span><br><span class="line">    centList = [centroid0]</span><br><span class="line">    <span class="comment"># 遍历每个数据集样本</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(m):</span><br><span class="line">        <span class="comment"># 计算当前聚为一类时各个数据点距离质心的平方距离</span></span><br><span class="line">        clusterAssment[j, <span class="number">1</span>] = distMeas(np.mat(centroid0), dataSet[j, :])**<span class="number">2</span></span><br><span class="line">    <span class="comment"># 循环，直至二分k-Means值达到k类为止</span></span><br><span class="line">    <span class="keyword">while</span> (len(centList) &lt; k):</span><br><span class="line">        <span class="comment"># 将当前最小平方误差置为正无穷</span></span><br><span class="line">        lowerSSE = float(<span class="string">'inf'</span>)</span><br><span class="line">        <span class="comment"># 遍历当前每个聚类</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(centList)):</span><br><span class="line">            <span class="comment"># 通过数组过滤筛选出属于第i类的数据集合</span></span><br><span class="line">            ptsInCurrCluster = dataSet[np.nonzero(clusterAssment[:, <span class="number">0</span>].A == i)[<span class="number">0</span>], :]</span><br><span class="line">            <span class="comment"># 对该类利用二分k-means算法进行划分，返回划分后的结果以及误差</span></span><br><span class="line">            centroidMat, splitClustAss = kMeans(ptsInCurrCluster, <span class="number">2</span>, distMeas)</span><br><span class="line">            <span class="comment"># 计算该类划分后两个类的误差平方和</span></span><br><span class="line">            sseSplit = np.sum(splitClustAss[:, <span class="number">1</span>])</span><br><span class="line">            <span class="comment"># 计算数据集中不属于该类的数据的误差平方和</span></span><br><span class="line">            sseNotSplit = np.sum(clusterAssment[np.nonzero(clusterAssment[:, <span class="number">0</span>].A != i)[<span class="number">0</span>], <span class="number">1</span>])</span><br><span class="line">            <span class="comment"># 打印这两项误差值</span></span><br><span class="line">            print(<span class="string">'sseSplit = %f, and notSplit = %f'</span> % (sseSplit, sseNotSplit))</span><br><span class="line">            <span class="comment"># 划分第i类后总误差小于当前最小总误差</span></span><br><span class="line">            <span class="keyword">if</span> (sseSplit + sseNotSplit) &lt; lowerSSE:</span><br><span class="line">                <span class="comment"># 第i类作为本次划分类</span></span><br><span class="line">                bestCentToSplit = i</span><br><span class="line">                <span class="comment"># 第i类划分后得到的两个质心向量</span></span><br><span class="line">                bestNewCents = centroidMat</span><br><span class="line">                <span class="comment"># 复制第i类中数据点的聚类结果即误差值</span></span><br><span class="line">                bestClustAss = splitClustAss.copy()</span><br><span class="line">                <span class="comment"># 将划分第i类后的总误差作为当前最小误差</span></span><br><span class="line">                lowerSSE = sseSplit + sseNotSplit</span><br><span class="line">        <span class="comment"># 数组过滤选出本次2-means聚类划分后类编号为1数据点，将这些数据点类编号变为</span></span><br><span class="line">        <span class="comment"># 当前类个数+1， 作为新的一个聚类</span></span><br><span class="line">        bestClustAss[np.nonzero(bestClustAss[:, <span class="number">0</span>].A == <span class="number">1</span>)[<span class="number">0</span>], <span class="number">0</span>] = len(centList)</span><br><span class="line">        <span class="comment"># 同理，将划分数据中类编号为0的数据点的类编号仍置为被划分的类编号，使类编号</span></span><br><span class="line">        <span class="comment"># 连续不出现空缺</span></span><br><span class="line">        bestClustAss[np.nonzero(bestClustAss[:, <span class="number">0</span>].A == <span class="number">0</span>)[<span class="number">0</span>], <span class="number">0</span>] = bestCentToSplit</span><br><span class="line">        <span class="comment"># 打印本次执行2-means聚类算法的类</span></span><br><span class="line">        print(<span class="string">'the bestCentToSplit is %d'</span> % bestCentToSplit)</span><br><span class="line">        <span class="comment"># 打印被划分的类的数据个数</span></span><br><span class="line">        print(<span class="string">'the len of bestClustAss is %d'</span> % len(bestClustAss))</span><br><span class="line">        <span class="comment"># 更新质心列表中变化后的质心向量</span></span><br><span class="line">        centList[bestCentToSplit] = bestNewCents[<span class="number">0</span>, :]</span><br><span class="line">        <span class="comment"># 添加新的类的质心向量</span></span><br><span class="line">        centList.append(bestNewCents[<span class="number">1</span>, :])</span><br><span class="line">        <span class="comment"># 更新clusterAssment列表中参与2-means聚类数据点变化后的分类编号，及数据该类的误差平方</span></span><br><span class="line">        clusterAssment[np.nonzero(clusterAssment[:, <span class="number">0</span>].A == bestCentToSplit)[<span class="number">0</span>], :] = bestClustAss</span><br><span class="line">    <span class="comment"># 返回聚类结果</span></span><br><span class="line">    <span class="keyword">return</span> centList, clusterAssment</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：绘制数据集</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    fileName - 文件名</span></span><br><span class="line"><span class="string">    k - 选取k个质心</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    None</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plotDataSet</span><span class="params">(filename, k)</span>:</span></span><br><span class="line">    <span class="comment"># 导入数据</span></span><br><span class="line">    datMat = np.mat(loadDataSet(filename))</span><br><span class="line">    <span class="comment"># 进行k-means算法其中k为4</span></span><br><span class="line">    centList, clusterAssment = biKmeans(datMat, k)</span><br><span class="line">    clusterAssment = clusterAssment.tolist()</span><br><span class="line">    xcord = [[], [], []]</span><br><span class="line">    ycord = [[], [], []]</span><br><span class="line">    datMat = datMat.tolist()</span><br><span class="line">    m = len(clusterAssment)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">        <span class="keyword">if</span> int(clusterAssment[i][<span class="number">0</span>]) == <span class="number">0</span>:</span><br><span class="line">            xcord[<span class="number">0</span>].append(datMat[i][<span class="number">0</span>])</span><br><span class="line">            ycord[<span class="number">0</span>].append(datMat[i][<span class="number">1</span>])</span><br><span class="line">        <span class="keyword">elif</span> int(clusterAssment[i][<span class="number">0</span>]) == <span class="number">1</span>:</span><br><span class="line">            xcord[<span class="number">1</span>].append(datMat[i][<span class="number">0</span>])</span><br><span class="line">            ycord[<span class="number">1</span>].append(datMat[i][<span class="number">1</span>])</span><br><span class="line">        <span class="keyword">elif</span> int(clusterAssment[i][<span class="number">0</span>]) == <span class="number">2</span>:</span><br><span class="line">            xcord[<span class="number">2</span>].append(datMat[i][<span class="number">0</span>])</span><br><span class="line">            ycord[<span class="number">2</span>].append(datMat[i][<span class="number">1</span>])</span><br><span class="line">    fig = plt.figure()</span><br><span class="line">    ax = fig.add_subplot(<span class="number">111</span>)</span><br><span class="line">    <span class="comment"># 绘制样本点</span></span><br><span class="line">    ax.scatter(xcord[<span class="number">0</span>], ycord[<span class="number">0</span>], s=<span class="number">20</span>, c=<span class="string">'b'</span>, marker=<span class="string">'*'</span>, alpha=<span class="number">.5</span>)</span><br><span class="line">    ax.scatter(xcord[<span class="number">1</span>], ycord[<span class="number">1</span>], s=<span class="number">20</span>, c=<span class="string">'r'</span>, marker=<span class="string">'D'</span>, alpha=<span class="number">.5</span>)</span><br><span class="line">    ax.scatter(xcord[<span class="number">2</span>], ycord[<span class="number">2</span>], s=<span class="number">20</span>, c=<span class="string">'c'</span>, marker=<span class="string">'&gt;'</span>, alpha=<span class="number">.5</span>)</span><br><span class="line">    <span class="comment"># 绘制质心</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(k):</span><br><span class="line">        ax.scatter(centList[i].tolist()[<span class="number">0</span>][<span class="number">0</span>], centList[i].tolist()[<span class="number">0</span>][<span class="number">1</span>], s=<span class="number">100</span>, c=<span class="string">'k'</span>, marker=<span class="string">'+'</span>, alpha=<span class="number">.5</span>)</span><br><span class="line">    <span class="comment"># ax.scatter(centList[0].tolist()[0][0], centList[0].tolist()[0][1], s=100, c='k', marker='+', alpha=.5)</span></span><br><span class="line">    <span class="comment"># ax.scatter(centList[1].tolist()[0][0], centList[1].tolist()[0][1], s=100, c='k', marker='+', alpha=.5)</span></span><br><span class="line">    <span class="comment"># ax.scatter(centList[2].tolist()[0][0], centList[2].tolist()[0][1], s=100, c='k', marker='+', alpha=.5)</span></span><br><span class="line">    plt.title(<span class="string">'DataSet'</span>)</span><br><span class="line">    plt.xlabel(<span class="string">'X'</span>)</span><br><span class="line">    plt.show()</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    datMat = np.mat(loadDataSet(<span class="string">'testSet2.txt'</span>))</span><br><span class="line">    centList, myNewAssments = biKmeans(datMat, <span class="number">3</span>)</span><br><span class="line">    plotDataSet(<span class="string">'testSet2.txt'</span>, <span class="number">3</span>)</span><br></pre></td></tr></table></figure>
      </div>
      
      
        <br>
        


  <section class='meta' id="footer-meta">
    <div class='new-meta-box'>
      
        
          <div class="new-meta-item date" itemprop="dateUpdated" datetime="2020-02-11T16:48:55+08:00">
  <a class='notlink'>
    <i class="fas fa-clock" aria-hidden="true"></i>
    <p>updated at Feb 11, 2020</p>
  </a>
</div>

        
      
        
          
  
  <div class="new-meta-item meta-tags"><a class="tag" href="/tags/ML/" rel="nofollow"><i class="fas fa-tag" aria-hidden="true"></i><p>ML</p></a></div>


        
      
        
          
  <div class="new-meta-item share -mob-share-list">
  <div class="-mob-share-list share-body">
    
      
        <a class="-mob-share-qq" title="QQ好友" rel="external nofollow noopener noreferrer"
          
          href="http://connect.qq.com/widget/shareqq/index.html?url=https://shyshy903.github.io/2019/11/30/Machine_Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%888-K%E5%9D%87%E5%80%BC%E8%81%9A%E7%B1%BB%EF%BC%89/&title=《机器学习实战》《西瓜书》笔记（八）- K均值聚类 | Try Your Best!&summary="
          
          >
          
            <img src="https://cdn.jsdelivr.net/gh/xaoxuu/assets@19.1.9/logo/128/qq.png">
          
        </a>
      
    
      
        <a class="-mob-share-qzone" title="QQ空间" rel="external nofollow noopener noreferrer"
          
          href="https://sns.qzone.qq.com/cgi-bin/qzshare/cgi_qzshare_onekey?url=https://shyshy903.github.io/2019/11/30/Machine_Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%888-K%E5%9D%87%E5%80%BC%E8%81%9A%E7%B1%BB%EF%BC%89/&title=《机器学习实战》《西瓜书》笔记（八）- K均值聚类 | Try Your Best!&summary="
          
          >
          
            <img src="https://cdn.jsdelivr.net/gh/xaoxuu/assets@19.1.9/logo/128/qzone.png">
          
        </a>
      
    
      
        <a class="-mob-share-weibo" title="微博" rel="external nofollow noopener noreferrer"
          
          href="http://service.weibo.com/share/share.php?url=https://shyshy903.github.io/2019/11/30/Machine_Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%888-K%E5%9D%87%E5%80%BC%E8%81%9A%E7%B1%BB%EF%BC%89/&title=《机器学习实战》《西瓜书》笔记（八）- K均值聚类 | Try Your Best!&summary="
          
          >
          
            <img src="https://cdn.jsdelivr.net/gh/xaoxuu/assets@19.1.9/logo/128/weibo.png">
          
        </a>
      
    
  </div>
</div>



        
      
    </div>
  </section>


      
      
          <div class="prev-next">
              
                  <section class="prev">
                      <span class="art-item-left">
                          <h6><i class="fas fa-chevron-left" aria-hidden="true"></i>&nbsp;Previous</h6>
                          <h4>
                              <a href="/2020/01/15/SQL/SQL%E8%AF%AD%E8%A8%80%EF%BC%88%E4%B8%80%EF%BC%89/" rel="prev" title="SQL语言基础">
                                
                                    SQL语言基础
                                
                              </a>
                          </h4>
                          
                              
                              <h6 class="tags">
                                  <a class="tag" href="/tags/SQL/"><i class="fas fa-tag fa-fw" aria-hidden="true"></i> SQL</a>
                              </h6>
                          
                      </span>
                  </section>
              
              
                  <section class="next">
                      <span class="art-item-right" aria-hidden="true">
                          <h6>Next&nbsp;<i class="fas fa-chevron-right" aria-hidden="true"></i></h6>
                          <h4>
                              <a href="/2019/11/30/Machine_Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%887%20-SVM)/" rel="prev" title="《机器学习实战》《西瓜书》笔记（七）- SVM">
                                  
                                      《机器学习实战》《西瓜书》笔记（七）- SVM
                                  
                              </a>
                          </h4>
                          
                              
                              <h6 class="tags">
                                  <a class="tag" href="/tags/ML/"><i class="fas fa-tag fa-fw" aria-hidden="true"></i> ML</a>
                              </h6>
                          
                      </span>
                  </section>
              
          </div>
      
    </section>
  </article>



  <!-- 显示推荐文章和评论 -->



  <article class="post white-box comments">
    <section class="article typo">
      <h4><i class="fas fa-comments fa-fw" aria-hidden="true"></i>&nbsp;Comments</h4>
      
      
      
      
        <section id="comments">
          <div id="valine_container" class="valine_thread">
            <i class="fas fa-spinner fa-spin fa-fw"></i>
          </div>
        </section>
      
    </section>
  </article>






<!-- 根据页面mathjax变量决定是否加载MathJax数学公式js -->



  <script>
    window.subData = {
      title: '《机器学习实战》《西瓜书》笔记（八）- K均值聚类',
      tools: true
    }
  </script>


</div>
<aside class='l_side'>
  
    
    
      
      
        
          
          
        
          
          
        
          
          
        
          
          
            
              
  <section class='widget toc-wrapper'>
    
<header class='pure'>
  <div><i class="fas fa-list fa-fw" aria-hidden="true"></i>&nbsp;&nbsp;TOC</div>
  
    <!-- <div class='wrapper'><a class="s-toc rightBtn" rel="external nofollow noopener noreferrer" href="javascript:void(0)"><i class="fas fa-thumbtack fa-fw"></i></a></div> -->
  
</header>

    <div class='content pure'>
      <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#K均值聚类"><span class="toc-text">K均值聚类</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#源代码"><span class="toc-text">源代码</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#二分K均值聚类"><span class="toc-text">二分K均值聚类</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#源代码-1"><span class="toc-text">源代码</span></a></li></ol></li></ol>
    </div>
  </section>


            
          
        
      
        
          
          
        
          
          
            
              
  <section class='widget category'>
    
<header class='pure'>
  <div><i class="fas fa-folder-open fa-fw" aria-hidden="true"></i>&nbsp;&nbsp;Categories</div>
  
    <a class="rightBtn"
    
      rel="nofollow"
    
    
    href="/categories/"
    title="categories/">
    <i class="fas fa-expand-arrows-alt fa-fw"></i></a>
  
</header>

    <div class='content pure'>
      <ul class="entry">
        
          <li><a class="flat-box" title="/categories/Linux/" href="/categories/Linux/"><div class='name'>Linux</div><div class='badge'>(2)</div></a></li>
        
          <li><a class="flat-box" title="/categories/Machine-Learning/" href="/categories/Machine-Learning/"><div class='name'>Machine_Learning</div><div class='badge'>(8)</div></a></li>
        
          <li><a class="flat-box" title="/categories/SQL/" href="/categories/SQL/"><div class='name'>SQL</div><div class='badge'>(2)</div></a></li>
        
          <li><a class="flat-box" title="/categories/deep-learning/" href="/categories/deep-learning/"><div class='name'>deep_learning</div><div class='badge'>(11)</div></a></li>
        
          <li><a class="flat-box" title="/categories/hexo/" href="/categories/hexo/"><div class='name'>hexo</div><div class='badge'>(1)</div></a></li>
        
          <li><a class="flat-box" title="/categories/java/" href="/categories/java/"><div class='name'>java</div><div class='badge'>(5)</div></a></li>
        
          <li><a class="flat-box" title="/categories/python/" href="/categories/python/"><div class='name'>python</div><div class='badge'>(1)</div></a></li>
        
          <li><a class="flat-box" title="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/" href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"><div class='name'>数据结构与算法</div><div class='badge'>(6)</div></a></li>
        
          <li><a class="flat-box" title="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/" href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"><div class='name'>计算机网络</div><div class='badge'>(6)</div></a></li>
        
          <li><a class="flat-box" title="/categories/%E8%AE%BE%E8%AE%A1/" href="/categories/%E8%AE%BE%E8%AE%A1/"><div class='name'>设计</div><div class='badge'>(1)</div></a></li>
        
          <li><a class="flat-box" title="/categories/%E9%87%8F%E5%AD%90%E8%AE%A1%E7%AE%97/" href="/categories/%E9%87%8F%E5%AD%90%E8%AE%A1%E7%AE%97/"><div class='name'>量子计算</div><div class='badge'>(1)</div></a></li>
        
      </ul>
    </div>
  </section>


            
          
        
          
          
        
          
          
        
      
        
          
          
        
          
          
        
          
          
            
              
  <section class='widget tagcloud'>
    
<header class='pure'>
  <div><i class="fas fa-tags fa-fw" aria-hidden="true"></i>&nbsp;&nbsp;Hot Tags</div>
  
    <a class="rightBtn"
    
      rel="nofollow"
    
    
    href="/tags/"
    title="tags/">
    <i class="fas fa-expand-arrows-alt fa-fw"></i></a>
  
</header>

    <div class='content pure'>
      <a href="/tags/DL/" style="font-size: 24px; color: #555">DL</a> <a href="/tags/ML/" style="font-size: 22px; color: #636363">ML</a> <a href="/tags/SQL/" style="font-size: 16px; color: #8b8b8b">SQL</a> <a href="/tags/color/" style="font-size: 14px; color: #999">color</a> <a href="/tags/hexo/" style="font-size: 14px; color: #999">hexo</a> <a href="/tags/java/" style="font-size: 18px; color: #7e7e7e">java</a> <a href="/tags/linux/" style="font-size: 16px; color: #8b8b8b">linux</a> <a href="/tags/python/" style="font-size: 14px; color: #999">python</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/" style="font-size: 20px; color: #707070">数据结构与算法</a> <a href="/tags/%E8%AE%A1%E7%BD%91/" style="font-size: 20px; color: #707070">计网</a> <a href="/tags/%E9%87%8F%E5%AD%90%E8%AE%A1%E7%AE%97/" style="font-size: 14px; color: #999">量子计算</a>
    </div>
  </section>


            
          
        
          
          
        
      
    

  
</aside>

<footer id="footer" class="clearfix">
  
  
    <div class="social-wrapper">
      
        
          <a href="/atom.xml"
            class="social fas fa-rss flat-btn"
            target="_blank"
            rel="external nofollow noopener noreferrer">
          </a>
        
      
        
          <a href="mailto:121166704@qq.com"
            class="social fas fa-envelope flat-btn"
            target="_blank"
            rel="external nofollow noopener noreferrer">
          </a>
        
      
        
          <a href="https://github.com/shyshy903"
            class="social fab fa-github flat-btn"
            target="_blank"
            rel="external nofollow noopener noreferrer">
          </a>
        
      
    </div>
  
  <br>
  <div><p>Blog content follows the <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en" target="_blank" rel="noopener">Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License</a></p>
</div>
  <div>
    Use
    <a href="https://xaoxuu.com/wiki/material-x/" target="_blank" class="codename">Material X</a>
    as theme
    
      , 
      total visits
      <span id="busuanzi_value_site_pv"><i class="fas fa-spinner fa-spin fa-fw" aria-hidden="true"></i></span>
      times
    
    . 
  </div>
</footer>
<script>setLoadingBarProgress(80);</script>


      <script>setLoadingBarProgress(60);</script>
    </div>
    <a class="s-top fas fa-arrow-up fa-fw" href='javascript:void(0)'></a>
  </div>
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script>

  <script>
    
    var SEARCH_SERVICE = "hexo" || "hexo";
    var ROOT = "/" || "/";
    if (!ROOT.endsWith('/')) ROOT += '/';
  </script>

<script src="//instant.page/1.2.2" type="module" integrity="sha384-2xV8M5griQmzyiY3CDqh1dn4z3llDVqZDqzjzcY+jCBCk/a5fXJmuZ/40JJAPeoU"></script>


  <script src="https://cdn.jsdelivr.net/npm/scrollreveal@4.0.5/dist/scrollreveal.min.js"></script>
  <script type="text/javascript">
    $(function() {
      const $reveal = $('.reveal');
      if ($reveal.length === 0) return;
      const sr = ScrollReveal({ distance: 0 });
      sr.reveal('.reveal');
    });
  </script>


  <script src="https://cdn.jsdelivr.net/npm/node-waves@0.7.6/dist/waves.min.js"></script>
  <script type="text/javascript">
    $(function() {
      Waves.attach('.flat-btn', ['waves-button']);
      Waves.attach('.float-btn', ['waves-button', 'waves-float']);
      Waves.attach('.float-btn-light', ['waves-button', 'waves-float', 'waves-light']);
      Waves.attach('.flat-box', ['waves-block']);
      Waves.attach('.float-box', ['waves-block', 'waves-float']);
      Waves.attach('.waves-image');
      Waves.init();
    });
  </script>


  <script async src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-busuanzi@2.3/js/busuanzi.pure.mini.js"></script>




  
  
  
    <script src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-material-x@20.2/js/backstretch.min.js"></script>
    <script type="text/javascript">
      $(function(){
        if ('') {
          $('').backstretch(
          ["https://img.vim-cn.com/c5/4673c36a1dd2a6d3c747f01b404dab64d009eb.jpg"],
          {
            duration: "6000",
            fade: "2500"
          });
        } else {
          $.backstretch(
          ["https://img.vim-cn.com/c5/4673c36a1dd2a6d3c747f01b404dab64d009eb.jpg"],
          {
            duration: "6000",
            fade: "2500"
          });
        }
      });
    </script>
  









  <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
  
    
      
<script src="https://cdn.jsdelivr.net/gh/xaoxuu/volantis@1.0.6/js/volantis.min.js"></script>

    
  
  <script>
  var GUEST_INFO = ['nick','mail','link'];
  var guest_info = 'nick,mail,link'.split(',').filter(function(item){
    return GUEST_INFO.indexOf(item) > -1
  });
  var notify = 'true' == true;
  var verify = 'true' == true;
  var valine = new Valine();
  valine.init({
    el: '#valine_container',
    notify: notify,
    verify: verify,
    guest_info: guest_info,
    
    appId: "DGEVoyKVeVmx0Hsn098Pkquo-gzGzoHsz",
    appKey: "mkq3mUCepHlNs9LOIDsdR8VE",
    placeholder: "快来评论吧~",
    pageSize:'10',
    avatar:'mp',
    lang:'zh-cn',
    highlight:'true'
  })
  </script>



  
<script src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-material-x@20.2/js/app.js"></script>



  
<script src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-material-x@20.2/js/search.js"></script>







<!-- 复制 -->
<script src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js"></script>
<script>
  let COPY_SUCCESS = "Copied";
  let COPY_FAILURE = "Copy failed";
  /*页面载入完成后，创建复制按钮*/
  !function (e, t, a) {
    /* code */
    var initCopyCode = function(){
      var copyHtml = '';
      copyHtml += '<button class="btn-copy" data-clipboard-snippet="">';
      copyHtml += '  <i class="fa fa-copy"></i><span>Copy</span>';
      copyHtml += '</button>';
      $(".highlight .code pre").before(copyHtml);
      var clipboard = new ClipboardJS('.btn-copy', {
        target: function(trigger) {
          return trigger.nextElementSibling;
        }
      });

      clipboard.on('success', function(e) {
        //您可以加入成功提示
        console.info('Action:', e.action);
        console.info('Text:', e.text);
        console.info('Trigger:', e.trigger);
        success_prompt(COPY_SUCCESS);
        e.clearSelection();
      });
      clipboard.on('error', function(e) {
        //您可以加入失败提示
        console.error('Action:', e.action);
        console.error('Trigger:', e.trigger);
        fail_prompt(COPY_FAILURE);
      });
    }
    initCopyCode();

  }(window, document);

  /**
   * 弹出式提示框，默认1.5秒自动消失
   * @param message 提示信息
   * @param style 提示样式，有alert-success、alert-danger、alert-warning、alert-info
   * @param time 消失时间
   */
  var prompt = function (message, style, time)
  {
      style = (style === undefined) ? 'alert-success' : style;
      time = (time === undefined) ? 1500 : time*1000;
      $('<div>')
          .appendTo('body')
          .addClass('alert ' + style)
          .html(message)
          .show()
          .delay(time)
          .fadeOut();
  };

  // 成功提示
  var success_prompt = function(message, time)
  {
      prompt(message, 'alert-success', time);
  };

  // 失败提示
  var fail_prompt = function(message, time)
  {
      prompt(message, 'alert-danger', time);
  };

  // 提醒
  var warning_prompt = function(message, time)
  {
      prompt(message, 'alert-warning', time);
  };

  // 信息提示
  var info_prompt = function(message, time)
  {
      prompt(message, 'alert-info', time);
  };

</script>


<!-- fancybox -->
<script src="https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js"></script>
<script>
  let LAZY_LOAD_IMAGE = "";
  $(".article-entry").find("fancybox").find("img").each(function () {
      var element = document.createElement("a");
      $(element).attr("data-fancybox", "gallery");
      $(element).attr("href", $(this).attr("src"));
      /* 图片采用懒加载处理时,
       * 一般图片标签内会有个属性名来存放图片的真实地址，比如 data-original,
       * 那么此处将原本的属性名src替换为对应属性名data-original,
       * 修改如下
       */
       if (LAZY_LOAD_IMAGE) {
         $(element).attr("href", $(this).attr("data-original"));
       }
      $(this).wrap(element);
  });
</script>





  <script>setLoadingBarProgress(100);</script>
</body>
</html>
