<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  
  <title>《机器学习实战》《西瓜书》笔记（六）- logist回归 | 问渠哪得清如许？</title>
  
  
  <meta name="description" content="https://img.vim-cn.com/33/461edfd8f8283ad38990aa7a83131b4494eb2c.jpg">
  

  
  <link rel="alternate" href="/atom.xml" title="问渠哪得清如许？">
  

  <meta name="HandheldFriendly" content="True" />
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <!-- meta -->
  

  <!-- link -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css" />
  
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-waves@0.7.6/dist/waves.min.css">
  
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.10.1/css/all.min.css">
  

  

  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-material-x@20.2.11/css/style.css">

  

  <script>
    function setLoadingBarProgress(num) {
      document.getElementById('loading-bar').style.width=num+"%";
    }
  </script>

  
  
<meta name="generator" content="Hexo 4.2.0"><link rel="alternate" href="/atom.xml" title="问渠哪得清如许？" type="application/atom+xml">
</head>

<body>
  
  
  <div class="cover-wrapper">
    <cover class='cover post half'>
      
        
  <h1 class='title'>shylab</h1>


  <div class="m_search">
    <form name="searchform" class="form u-search-form">
      <input type="text" class="input u-search-input" placeholder="" />
      <i class="icon fas fa-search fa-fw"></i>
    </form>
  </div>

<div class='menu navgation'>
  <ul class='h-list'>
    
      
        <li>
          <a class="nav home" href="/"
            
            
            id="home">
            <i class='fas fa-rss fa-fw'></i>&nbsp;Blogs
          </a>
        </li>
      
        <li>
          <a class="nav home" href="/archives/"
            
              rel="nofollow"
            
            
            id="archives">
            <i class='fas fa-archive fa-fw'></i>&nbsp;Archives
          </a>
        </li>
      
        <li>
          <a class="nav home" href="/tags/"
            
              rel="nofollow"
            
            
            id="tags">
            <i class='fas fa-tags fa-fw'></i>&nbsp;Tags
          </a>
        </li>
      
        <li>
          <a class="nav home" href="https://github.com/shyshy903"
            
            
            id="https:github.comshyshy903">
            <i class='fab fa-github fa-fw'></i>&nbsp;Github
          </a>
        </li>
      
    
  </ul>
</div>

      
    </cover>
    <header class="l_header pure">
  <div id="loading-bar-wrapper">
    <div id="loading-bar" class="pure"></div>
  </div>

	<div class='wrapper'>
		<div class="nav-main container container--flex">
      <a class="logo flat-box" target="_self" href='/' >
        
          问渠哪得清如许？
        
      </a>
			<div class='menu navgation'>
				<ul class='h-list'>
          
  					
  						<li>
								<a class="nav flat-box" href="/categories/"
                  
                    rel="nofollow"
                  
                  
                  id="categories">
									<i class='fas fa-folder-open fa-fw'></i>&nbsp;分类
								</a>
							</li>
      			
  						<li>
								<a class="nav flat-box" href="/tags/"
                  
                    rel="nofollow"
                  
                  
                  id="tags">
									<i class='fas fa-tags fa-fw'></i>&nbsp;标签
								</a>
							</li>
      			
  						<li>
								<a class="nav flat-box" href="/archives/"
                  
                    rel="nofollow"
                  
                  
                  id="archives">
									<i class='fas fa-archive fa-fw'></i>&nbsp;归档
								</a>
							</li>
      			
      		
				</ul>
			</div>

			
				<div class="m_search">
					<form name="searchform" class="form u-search-form">
						<input type="text" class="input u-search-input" placeholder="Search" />
						<i class="icon fas fa-search fa-fw"></i>
					</form>
				</div>
			
			<ul class='switcher h-list'>
				
					<li class='s-search'><a class="fas fa-search fa-fw" target="_self" href='javascript:void(0)'></a></li>
				
				<li class='s-menu'><a class="fas fa-bars fa-fw" target="_self" href='javascript:void(0)'></a></li>
			</ul>
		</div>

		<div class='nav-sub container container--flex'>
			<a class="logo flat-box"></a>
			<ul class='switcher h-list'>
				<li class='s-comment'><a class="flat-btn fas fa-comments fa-fw" target="_self" href='javascript:void(0)'></a></li>
        
          <li class='s-toc'><a class="flat-btn fas fa-list fa-fw" target="_self" href='javascript:void(0)'></a></li>
        
			</ul>
		</div>
	</div>
</header>
	<aside class="menu-phone">
    <header>
		<nav class="menu navgation">
      <ul>
        
          
            <li>
							<a class="nav flat-box" href="/"
                
                
                id="home">
								<i class='fas fa-clock fa-fw'></i>&nbsp;近期文章
							</a>
            </li>
          
            <li>
							<a class="nav flat-box" href="/archives/"
                
                  rel="nofollow"
                
                
                id="archives">
								<i class='fas fa-archive fa-fw'></i>&nbsp;文章归档
							</a>
            </li>
          
       
      </ul>
		</nav>
    </header>
	</aside>
<script>setLoadingBarProgress(40);</script>

  </div>


  <div class="l_body">
    <div class='body-wrapper'>
      <div class='l_main'>
  

  <article id="post" class="post white-box article-type-post" itemscope itemprop="blogPost">
    


  <section class='meta'>
    
    
    <div class="meta" id="header-meta">
      
        
  
    <h1 class="title">
      <a href="/2019/11/28/Machine_Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%886-%20Logistic%E5%9B%9E%E5%BD%92%EF%BC%89/">
        《机器学习实战》《西瓜书》笔记（六）- logist回归
      </a>
    </h1>
  


      
      <div class='new-meta-box'>
        
          
        
          
            
  <div class='new-meta-item author'>
    
      <a href="https://shyshy903.github.io" rel="nofollow">
        
          <i class="fas fa-user" aria-hidden="true"></i>
        
        <p>Haiyang Song</p>
      </a>
    
  </div>


          
        
          
            <div class="new-meta-item date">
  <a class='notlink'>
    <i class="fas fa-calendar-alt" aria-hidden="true"></i>
    <p>2019-11-28</p>
  </a>
</div>

          
        
          
            
  
  <div class='new-meta-item category'>
    <a href='/categories/Machine-Learning/' rel="nofollow">
      <i class="fas fa-folder-open" aria-hidden="true"></i>
      <p>Machine_Learning</p>
    </a>
  </div>


          
        
          
            
  
    <div class="new-meta-item browse busuanzi">
      <a class='notlink'>
        <i class="fas fa-eye" aria-hidden="true"></i>
        <p>
          <span id="busuanzi_value_page_pv">
            <i class="fas fa-spinner fa-spin fa-fw" aria-hidden="true"></i>
          </span>
        </p>
      </a>
    </div>
  


          
        
          
            
  

          
        
          
            

          
        
      </div>
      
        <hr>
      
    </div>
  </section>


    <section class="article typo">
      <div class="article-entry" itemprop="articleBody">
        <h1 id="logist回归"><a href="#logist回归" class="headerlink" title="logist回归"></a>logist回归</h1><h2 id="最佳回归系数与Sigmod函数"><a href="#最佳回归系数与Sigmod函数" class="headerlink" title="最佳回归系数与Sigmod函数"></a>最佳回归系数与Sigmod函数</h2><p>$\sigma = 1/(1 + e^{-z})$<br>$z = w_0x_0+ w_1x_1+ w_2x_2+ ….w_nx_n$<br>$z = w^TX$</p>
<h3 id="梯度上升法"><a href="#梯度上升法" class="headerlink" title="梯度上升法"></a>梯度上升法</h3><p>$w = w + α* grad f(w)$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：梯度上升算法测试函数</span></span><br><span class="line"><span class="string">        求函数f(x) = -x^2+4x的极大值</span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    None</span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    None</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">Gradient_Ascent_test</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="comment"># f(x)的导数</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">f_prime</span><span class="params">(x_old)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">-2</span> * x_old + <span class="number">4</span></span><br><span class="line">    <span class="comment"># 初始值，给一个小于x_new的值</span></span><br><span class="line">    x_old = <span class="number">-1</span></span><br><span class="line">    <span class="comment"># 梯度上升算法初始值，即从(0, 0)开始</span></span><br><span class="line">    x_new = <span class="number">0</span></span><br><span class="line">    <span class="comment"># 步长，也就是学习速率，控制更新的幅度</span></span><br><span class="line">    alpha = <span class="number">0.01</span></span><br><span class="line">    <span class="comment"># 精度，也就是更新阈值</span></span><br><span class="line">    presision = <span class="number">0.00000001</span></span><br><span class="line">    <span class="keyword">while</span> abs(x_new - x_old) &gt; presision:</span><br><span class="line">        x_old = x_new</span><br><span class="line">        <span class="comment"># 利用上面的公式</span></span><br><span class="line">        x_new = x_old + alpha * f_prime(x_old)</span><br><span class="line">    <span class="comment"># 打印最终求解的极值近似值</span></span><br><span class="line">    print(x_new)</span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：sigmoid函数</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    inX - 数据</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    sigmoid函数</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span><span class="params">(inX)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1.0</span> / (<span class="number">1</span> + np.exp(-inX))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：梯度上升法</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    dataMath - 数据集</span></span><br><span class="line"><span class="string">    classLabels - 数据标签</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    weights.getA() - 求得的权重数组（最优参数）</span></span><br><span class="line"><span class="string">    weights_array - 每次更新的回归系数</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gradAscent</span><span class="params">(dataMath, classLabels)</span>:</span></span><br><span class="line">    <span class="comment"># 转换成numpy的mat(矩阵)</span></span><br><span class="line">    dataMatrix = np.mat(dataMath)</span><br><span class="line">    <span class="comment"># 转换成numpy的mat(矩阵)并进行转置</span></span><br><span class="line">    labelMat = np.mat(classLabels).transpose()</span><br><span class="line">    <span class="comment"># 返回dataMatrix的大小，m为行数，n为列数</span></span><br><span class="line">    m, n = np.shape(dataMatrix)</span><br><span class="line">    <span class="comment"># 移动步长，也就是学习效率，控制更新的幅度</span></span><br><span class="line">    alpha = <span class="number">0.01</span></span><br><span class="line">    <span class="comment"># 最大迭代次数</span></span><br><span class="line">    maxCycles = <span class="number">500</span></span><br><span class="line">    weights = np.ones((n, <span class="number">1</span>))</span><br><span class="line">    weights_array = np.array([])</span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> range(maxCycles):</span><br><span class="line">        <span class="comment"># 梯度上升矢量化公式</span></span><br><span class="line">        h = sigmoid(dataMatrix * weights)</span><br><span class="line">        error = labelMat - h</span><br><span class="line">        weights = weights + alpha * dataMatrix.transpose() * error</span><br><span class="line">        <span class="comment"># numpy.append(arr, values, axis=None):就是arr和values会重新组合成一个新的数组，做为返回值。</span></span><br><span class="line">        <span class="comment"># 当axis无定义时，是横向加成，返回总是为一维数组</span></span><br><span class="line">        weights_array = np.append(weights_array, weights)</span><br><span class="line">    weights_array = weights_array.reshape(maxCycles, n)</span><br><span class="line">    <span class="comment"># 将矩阵转换为数组，返回权重数组</span></span><br><span class="line">    <span class="comment"># mat.getA()将自身矩阵变量转化为ndarray类型变量</span></span><br><span class="line">    <span class="keyword">return</span> weights.getA(), weights_array</span><br></pre></td></tr></table></figure>
<h3 id="绘制决策边界"><a href="#绘制决策边界" class="headerlink" title="绘制决策边界"></a>绘制决策边界</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：绘制数据集</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    weights - 权重参数数组</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    None</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plotBestFit</span><span class="params">(weights)</span>:</span></span><br><span class="line">    <span class="comment"># 加载数据集</span></span><br><span class="line">    dataMat, labelMat = loadDataSet()</span><br><span class="line">    <span class="comment"># 转换成numpy的array数组</span></span><br><span class="line">    dataArr = np.array(dataMat)</span><br><span class="line">    <span class="comment"># 数据个数</span></span><br><span class="line">    <span class="comment"># 例如建立一个4*2的矩阵c，c.shape[1]为第一维的长度2， c.shape[0]为第二维的长度4</span></span><br><span class="line">    n = np.shape(dataMat)[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># 正样本</span></span><br><span class="line">    xcord1 = []</span><br><span class="line">    ycord1 = []</span><br><span class="line">    <span class="comment"># 负样本</span></span><br><span class="line">    xcord2 = []</span><br><span class="line">    ycord2 = []</span><br><span class="line">    <span class="comment"># 根据数据集标签进行分类</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(n):</span><br><span class="line">        <span class="keyword">if</span> int(labelMat[i]) == <span class="number">1</span>:</span><br><span class="line">            <span class="comment"># 1为正样本</span></span><br><span class="line">            xcord1.append(dataArr[i, <span class="number">1</span>])</span><br><span class="line">            ycord1.append(dataArr[i, <span class="number">2</span>])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 0为负样本</span></span><br><span class="line">            xcord2.append(dataArr[i, <span class="number">1</span>])</span><br><span class="line">            ycord2.append(dataArr[i, <span class="number">2</span>])</span><br><span class="line">    <span class="comment"># 新建图框</span></span><br><span class="line">    fig = plt.figure()</span><br><span class="line">    <span class="comment"># 添加subplot</span></span><br><span class="line">    ax = fig.add_subplot(<span class="number">111</span>)</span><br><span class="line">    <span class="comment"># 绘制正样本</span></span><br><span class="line">    ax.scatter(xcord1, ycord1, s=<span class="number">20</span>, c=<span class="string">'red'</span>, marker=<span class="string">'s'</span>, alpha=<span class="number">.5</span>)</span><br><span class="line">    <span class="comment"># 绘制负样本</span></span><br><span class="line">    ax.scatter(xcord2, ycord2, s=<span class="number">20</span>, c=<span class="string">'green'</span>, alpha=<span class="number">.5</span>)</span><br><span class="line">    <span class="comment"># x轴坐标</span></span><br><span class="line">    x = np.arange(<span class="number">-3.0</span>, <span class="number">3.0</span>, <span class="number">0.1</span>)</span><br><span class="line">    <span class="comment"># w0*x0 + w1*x1 * w2*x2 = 0</span></span><br><span class="line">    <span class="comment"># x0 = 1, x1 = x, x2 = y</span></span><br><span class="line">    y = (-weights[<span class="number">0</span>] - weights[<span class="number">1</span>] * x) / weights[<span class="number">2</span>]</span><br><span class="line">    ax.plot(x, y)</span><br><span class="line">    <span class="comment"># 绘制title</span></span><br><span class="line">    plt.title(<span class="string">'BestFit'</span>)</span><br><span class="line">    <span class="comment"># 绘制label</span></span><br><span class="line">    plt.xlabel(<span class="string">'x1'</span>)</span><br><span class="line">    plt.ylabel(<span class="string">'y2'</span>)</span><br><span class="line">    <span class="comment"># 显示</span></span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>
<h3 id="随机梯度上升法"><a href="#随机梯度上升法" class="headerlink" title="随机梯度上升法"></a>随机梯度上升法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：改进的随机梯度上升法</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    dataMatrix - 数据数组</span></span><br><span class="line"><span class="string">    classLabels - 数据标签</span></span><br><span class="line"><span class="string">    numIter - 迭代次数</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    weights - 求得的回归系数数组（最优参数）</span></span><br><span class="line"><span class="string">    weights_array - 每次更新的回归系数</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">stocGradAscent1</span><span class="params">(dataMatrix, classLabels, numIter=<span class="number">150</span>)</span>:</span></span><br><span class="line">    <span class="comment"># 返回dataMatrix的大小，m为行数，n为列数</span></span><br><span class="line">    m, n = np.shape(dataMatrix)</span><br><span class="line">    <span class="comment"># 参数初始化</span></span><br><span class="line">    weights = np.ones(n)</span><br><span class="line">    weights_array = np.array([])</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(numIter):</span><br><span class="line">        dataIndex = list(range(m))</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">            <span class="comment"># 每次都降低alpha的大小</span></span><br><span class="line">            alpha = <span class="number">4</span>/(<span class="number">1.0</span>+j+i)+<span class="number">0.01</span></span><br><span class="line">            <span class="comment"># 随机选择样本</span></span><br><span class="line">            randIndex = int(random.uniform(<span class="number">0</span>, len(dataIndex)))</span><br><span class="line">            <span class="comment"># 随机选择一个样本计算h</span></span><br><span class="line">            h = sigmoid(sum(dataMatrix[randIndex] * weights))</span><br><span class="line">            <span class="comment"># 计算误差</span></span><br><span class="line">            error = classLabels[randIndex] - h</span><br><span class="line">            <span class="comment"># 更新回归系数</span></span><br><span class="line">            weights = weights + alpha * error * dataMatrix[randIndex]</span><br><span class="line">            <span class="comment"># 添加返回系数到数组中当axis为0时，数组是加在下面（列数要相同）</span></span><br><span class="line">            weights_array = np.append(weights_array, weights, axis=<span class="number">0</span>)</span><br><span class="line">            <span class="comment"># 删除已使用的样本</span></span><br><span class="line">            <span class="keyword">del</span>(dataIndex[randIndex])</span><br><span class="line">    <span class="comment"># 改变维度</span></span><br><span class="line">    weights_array = weights_array.reshape(numIter*m, n)</span><br><span class="line">    <span class="comment"># 返回</span></span><br><span class="line">    <span class="keyword">return</span> weights, weights_array</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：绘制回归系数与迭代次数的关系</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    weights_array1 - 回归系数数组1</span></span><br><span class="line"><span class="string">    weights_array2 - 回归系数数组2</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    None</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plotWeights</span><span class="params">(weights_array1, weights_array2)</span>:</span></span><br><span class="line">    <span class="comment"># 设置汉字格式为14号简体字</span></span><br><span class="line">    font = FontProperties(fname=<span class="string">r"C:\Windows\Fonts\simsun.ttc"</span>, size=<span class="number">14</span>)</span><br><span class="line">    <span class="comment"># 将fig画布分隔成1行1列，不共享x轴和y轴，fig画布的大小为（20, 10）</span></span><br><span class="line">    <span class="comment"># 当nrows=3，ncols=2时，代表fig画布被分为6个区域，axs[0][0]代表第一行第一个区域</span></span><br><span class="line">    fig, axs = plt.subplots(nrows=<span class="number">3</span>, ncols=<span class="number">2</span>, sharex=<span class="literal">False</span>, sharey=<span class="literal">False</span>, figsize=(<span class="number">20</span>, <span class="number">10</span>))</span><br><span class="line">    <span class="comment"># x1坐标轴的范围</span></span><br><span class="line">    x1 = np.arange(<span class="number">0</span>, len(weights_array1), <span class="number">1</span>)</span><br><span class="line">    <span class="comment"># 绘制w0与迭代次数的关系</span></span><br><span class="line">    axs[<span class="number">0</span>][<span class="number">0</span>].plot(x1, weights_array1[:, <span class="number">0</span>])</span><br><span class="line">    axs0_title_text = axs[<span class="number">0</span>][<span class="number">0</span>].set_title(<span class="string">u'改进的梯度上升算法，回归系数与迭代次数关系'</span>, FontProperties=font)</span><br><span class="line">    axs0_ylabel_text = axs[<span class="number">0</span>][<span class="number">0</span>].set_ylabel(<span class="string">u'w0'</span>, FontProperties=font)</span><br><span class="line">    plt.setp(axs0_title_text, size=<span class="number">20</span>, weight=<span class="string">'bold'</span>, color=<span class="string">'black'</span>)</span><br><span class="line">    plt.setp(axs0_ylabel_text, size=<span class="number">20</span>, weight=<span class="string">'bold'</span>, color=<span class="string">'black'</span>)</span><br><span class="line">    <span class="comment"># 绘制w1与迭代次数的关系</span></span><br><span class="line">    axs[<span class="number">1</span>][<span class="number">0</span>].plot(x1, weights_array1[:, <span class="number">1</span>])</span><br><span class="line">    axs1_ylabel_text = axs[<span class="number">1</span>][<span class="number">0</span>].set_ylabel(<span class="string">u'w1'</span>, FontProperties=font)</span><br><span class="line">    plt.setp(axs1_ylabel_text, size=<span class="number">20</span>, weight=<span class="string">'bold'</span>, color=<span class="string">'black'</span>)</span><br><span class="line">    <span class="comment"># 绘制w2与迭代次数的关系</span></span><br><span class="line">    axs[<span class="number">2</span>][<span class="number">0</span>].plot(x1, weights_array1[:, <span class="number">2</span>])</span><br><span class="line">    axs2_title_text = axs[<span class="number">2</span>][<span class="number">0</span>].set_title(<span class="string">u'迭代次数'</span>, FontProperties=font)</span><br><span class="line">    axs2_ylabel_text = axs[<span class="number">2</span>][<span class="number">0</span>].set_ylabel(<span class="string">u'w2'</span>, FontProperties=font)</span><br><span class="line">    plt.setp(axs2_title_text, size=<span class="number">20</span>, weight=<span class="string">'bold'</span>, color=<span class="string">'black'</span>)</span><br><span class="line">    plt.setp(axs2_ylabel_text, size=<span class="number">20</span>, weight=<span class="string">'bold'</span>, color=<span class="string">'black'</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># x2坐标轴的范围</span></span><br><span class="line">    x2 = np.arange(<span class="number">0</span>, len(weights_array2), <span class="number">1</span>)</span><br><span class="line">    <span class="comment"># 绘制w0与迭代次数的关系</span></span><br><span class="line">    axs[<span class="number">0</span>][<span class="number">1</span>].plot(x2, weights_array2[:, <span class="number">0</span>])</span><br><span class="line">    axs0_title_text = axs[<span class="number">0</span>][<span class="number">1</span>].set_title(<span class="string">u'梯度上升算法，回归系数与迭代次数关系'</span>, FontProperties=font)</span><br><span class="line">    axs0_ylabel_text = axs[<span class="number">0</span>][<span class="number">1</span>].set_ylabel(<span class="string">u'w0'</span>, FontProperties=font)</span><br><span class="line">    plt.setp(axs0_title_text, size=<span class="number">20</span>, weight=<span class="string">'bold'</span>, color=<span class="string">'black'</span>)</span><br><span class="line">    plt.setp(axs0_ylabel_text, size=<span class="number">20</span>, weight=<span class="string">'bold'</span>, color=<span class="string">'black'</span>)</span><br><span class="line">    <span class="comment"># 绘制w1与迭代次数的关系</span></span><br><span class="line">    axs[<span class="number">1</span>][<span class="number">1</span>].plot(x2, weights_array2[:, <span class="number">1</span>])</span><br><span class="line">    axs1_ylabel_text = axs[<span class="number">1</span>][<span class="number">1</span>].set_ylabel(<span class="string">u'w1'</span>, FontProperties=font)</span><br><span class="line">    plt.setp(axs1_ylabel_text, size=<span class="number">20</span>, weight=<span class="string">'bold'</span>, color=<span class="string">'black'</span>)</span><br><span class="line">    <span class="comment"># 绘制w2与迭代次数的关系</span></span><br><span class="line">    axs[<span class="number">2</span>][<span class="number">1</span>].plot(x2, weights_array2[:, <span class="number">2</span>])</span><br><span class="line">    axs2_title_text = axs[<span class="number">2</span>][<span class="number">1</span>].set_title(<span class="string">u'迭代次数'</span>, FontProperties=font)</span><br><span class="line">    axs2_ylabel_text = axs[<span class="number">2</span>][<span class="number">1</span>].set_ylabel(<span class="string">u'w2'</span>, FontProperties=font)</span><br><span class="line">    plt.setp(axs2_title_text, size=<span class="number">20</span>, weight=<span class="string">'bold'</span>, color=<span class="string">'black'</span>)</span><br><span class="line">    plt.setp(axs2_ylabel_text, size=<span class="number">20</span>, weight=<span class="string">'bold'</span>, color=<span class="string">'black'</span>)</span><br><span class="line">    </span><br><span class="line">    plt.show()</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="comment"># 测试简单梯度上升法</span></span><br><span class="line">    <span class="comment"># Gradient_Ascent_test()</span></span><br><span class="line">    <span class="comment"># 加载数据集</span></span><br><span class="line">    dataMat, labelMat = loadDataSet()</span><br><span class="line">    <span class="comment"># 训练权重</span></span><br><span class="line">    weights2, weights_array2 = gradAscent(dataMat, labelMat)</span><br><span class="line">    <span class="comment"># 新方法训练权重</span></span><br><span class="line">    weights1, weights_array1 = stocGradAscent1(np.array(dataMat), labelMat)</span><br><span class="line">    <span class="comment"># 绘制数据集中的y和x的散点图</span></span><br><span class="line">    <span class="comment"># plotBestFit(weights)</span></span><br><span class="line">    <span class="comment"># print(gradAscent(dataMat, labelMat))</span></span><br><span class="line">    plotWeights(weights_array1, weights_array2)</span><br></pre></td></tr></table></figure>
<h2 id="梯度下降法"><a href="#梯度下降法" class="headerlink" title="梯度下降法"></a>梯度下降法</h2><p>$w = w - α*gradf(w)$</p>

      </div>
      
      
        <br>
        


  <section class='meta' id="footer-meta">
    <div class='new-meta-box'>
      
        
          <div class="new-meta-item date" itemprop="dateUpdated" datetime="2020-02-11T16:48:55+08:00">
  <a class='notlink'>
    <i class="fas fa-clock" aria-hidden="true"></i>
    <p>updated at Feb 11, 2020</p>
  </a>
</div>

        
      
        
          
  
  <div class="new-meta-item meta-tags"><a class="tag" href="/tags/ML/" rel="nofollow"><i class="fas fa-tag" aria-hidden="true"></i><p>ML</p></a></div>


        
      
        
          
  <div class="new-meta-item share -mob-share-list">
  <div class="-mob-share-list share-body">
    
      
        <a class="-mob-share-qq" title="QQ好友" rel="external nofollow noopener noreferrer"
          
          href="http://connect.qq.com/widget/shareqq/index.html?url=https://shyshy903.github.io/2019/11/28/Machine_Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%886-%20Logistic%E5%9B%9E%E5%BD%92%EF%BC%89/&title=《机器学习实战》《西瓜书》笔记（六）- logist回归 | 问渠哪得清如许？&summary="
          
          >
          
            <img src="https://cdn.jsdelivr.net/gh/xaoxuu/assets@19.1.9/logo/128/qq.png">
          
        </a>
      
    
      
        <a class="-mob-share-qzone" title="QQ空间" rel="external nofollow noopener noreferrer"
          
          href="https://sns.qzone.qq.com/cgi-bin/qzshare/cgi_qzshare_onekey?url=https://shyshy903.github.io/2019/11/28/Machine_Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%886-%20Logistic%E5%9B%9E%E5%BD%92%EF%BC%89/&title=《机器学习实战》《西瓜书》笔记（六）- logist回归 | 问渠哪得清如许？&summary="
          
          >
          
            <img src="https://cdn.jsdelivr.net/gh/xaoxuu/assets@19.1.9/logo/128/qzone.png">
          
        </a>
      
    
      
        <a class="-mob-share-weibo" title="微博" rel="external nofollow noopener noreferrer"
          
          href="http://service.weibo.com/share/share.php?url=https://shyshy903.github.io/2019/11/28/Machine_Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%886-%20Logistic%E5%9B%9E%E5%BD%92%EF%BC%89/&title=《机器学习实战》《西瓜书》笔记（六）- logist回归 | 问渠哪得清如许？&summary="
          
          >
          
            <img src="https://cdn.jsdelivr.net/gh/xaoxuu/assets@19.1.9/logo/128/weibo.png">
          
        </a>
      
    
  </div>
</div>



        
      
    </div>
  </section>


      
      
          <div class="prev-next">
              
                  <section class="prev">
                      <span class="art-item-left">
                          <h6><i class="fas fa-chevron-left" aria-hidden="true"></i>&nbsp;Previous</h6>
                          <h4>
                              <a href="/2019/11/30/Machine_Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%887%20-SVM)/" rel="prev" title="《机器学习实战》《西瓜书》笔记（七）- SVM">
                                
                                    《机器学习实战》《西瓜书》笔记（七）- SVM
                                
                              </a>
                          </h4>
                          
                              
                              <h6 class="tags">
                                  <a class="tag" href="/tags/ML/"><i class="fas fa-tag fa-fw" aria-hidden="true"></i> ML</a>
                              </h6>
                          
                      </span>
                  </section>
              
              
                  <section class="next">
                      <span class="art-item-right" aria-hidden="true">
                          <h6>Next&nbsp;<i class="fas fa-chevron-right" aria-hidden="true"></i></h6>
                          <h4>
                              <a href="/2019/11/28/Machine_Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%885-%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%EF%BC%89/" rel="prev" title="《机器学习实战》《西瓜书》笔记（五）- 朴素贝叶斯">
                                  
                                      《机器学习实战》《西瓜书》笔记（五）- 朴素贝叶斯
                                  
                              </a>
                          </h4>
                          
                              
                              <h6 class="tags">
                                  <a class="tag" href="/tags/ML/"><i class="fas fa-tag fa-fw" aria-hidden="true"></i> ML</a>
                              </h6>
                          
                      </span>
                  </section>
              
          </div>
      
    </section>
  </article>



  <!-- 显示推荐文章和评论 -->



  <article class="post white-box comments">
    <section class="article typo">
      <h4><i class="fas fa-comments fa-fw" aria-hidden="true"></i>&nbsp;Comments</h4>
      
      
      
      
        <section id="comments">
          <div id="valine_container" class="valine_thread">
            <i class="fas fa-spinner fa-spin fa-fw"></i>
          </div>
        </section>
      
    </section>
  </article>






<!-- 根据页面mathjax变量决定是否加载MathJax数学公式js -->



  <script>
    window.subData = {
      title: '《机器学习实战》《西瓜书》笔记（六）- logist回归',
      tools: true
    }
  </script>


</div>
<aside class='l_side'>
  
    
    
      
      
        
          
          
        
          
          
        
          
          
        
          
          
            
              
  <section class='widget toc-wrapper'>
    
<header class='pure'>
  <div><i class="fas fa-list fa-fw" aria-hidden="true"></i>&nbsp;&nbsp;TOC</div>
  
    <!-- <div class='wrapper'><a class="s-toc rightBtn" rel="external nofollow noopener noreferrer" href="javascript:void(0)"><i class="fas fa-thumbtack fa-fw"></i></a></div> -->
  
</header>

    <div class='content pure'>
      <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#logist回归"><span class="toc-text">logist回归</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#最佳回归系数与Sigmod函数"><span class="toc-text">最佳回归系数与Sigmod函数</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#梯度上升法"><span class="toc-text">梯度上升法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#绘制决策边界"><span class="toc-text">绘制决策边界</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#随机梯度上升法"><span class="toc-text">随机梯度上升法</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#梯度下降法"><span class="toc-text">梯度下降法</span></a></li></ol></li></ol>
    </div>
  </section>


            
          
        
      
        
          
          
        
          
          
            
              
  <section class='widget category'>
    
<header class='pure'>
  <div><i class="fas fa-folder-open fa-fw" aria-hidden="true"></i>&nbsp;&nbsp;Categories</div>
  
    <a class="rightBtn"
    
      rel="nofollow"
    
    
    href="/categories/"
    title="categories/">
    <i class="fas fa-expand-arrows-alt fa-fw"></i></a>
  
</header>

    <div class='content pure'>
      <ul class="entry">
        
          <li><a class="flat-box" title="/categories/Linux/" href="/categories/Linux/"><div class='name'>Linux</div><div class='badge'>(1)</div></a></li>
        
          <li><a class="flat-box" title="/categories/Machine-Learning/" href="/categories/Machine-Learning/"><div class='name'>Machine_Learning</div><div class='badge'>(8)</div></a></li>
        
          <li><a class="flat-box" title="/categories/SQL/" href="/categories/SQL/"><div class='name'>SQL</div><div class='badge'>(2)</div></a></li>
        
          <li><a class="flat-box" title="/categories/deep-learning/" href="/categories/deep-learning/"><div class='name'>deep_learning</div><div class='badge'>(11)</div></a></li>
        
          <li><a class="flat-box" title="/categories/hexo/" href="/categories/hexo/"><div class='name'>hexo</div><div class='badge'>(1)</div></a></li>
        
          <li><a class="flat-box" title="/categories/java/" href="/categories/java/"><div class='name'>java</div><div class='badge'>(5)</div></a></li>
        
          <li><a class="flat-box" title="/categories/python/" href="/categories/python/"><div class='name'>python</div><div class='badge'>(1)</div></a></li>
        
          <li><a class="flat-box" title="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/" href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"><div class='name'>数据结构与算法</div><div class='badge'>(2)</div></a></li>
        
          <li><a class="flat-box" title="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/" href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"><div class='name'>计算机网络</div><div class='badge'>(6)</div></a></li>
        
          <li><a class="flat-box" title="/categories/%E8%AE%BE%E8%AE%A1/" href="/categories/%E8%AE%BE%E8%AE%A1/"><div class='name'>设计</div><div class='badge'>(1)</div></a></li>
        
          <li><a class="flat-box" title="/categories/%E9%87%8F%E5%AD%90%E8%AE%A1%E7%AE%97/" href="/categories/%E9%87%8F%E5%AD%90%E8%AE%A1%E7%AE%97/"><div class='name'>量子计算</div><div class='badge'>(1)</div></a></li>
        
      </ul>
    </div>
  </section>


            
          
        
          
          
        
          
          
        
      
        
          
          
        
          
          
        
          
          
            
              
  <section class='widget tagcloud'>
    
<header class='pure'>
  <div><i class="fas fa-tags fa-fw" aria-hidden="true"></i>&nbsp;&nbsp;Hot Tags</div>
  
    <a class="rightBtn"
    
      rel="nofollow"
    
    
    href="/tags/"
    title="tags/">
    <i class="fas fa-expand-arrows-alt fa-fw"></i></a>
  
</header>

    <div class='content pure'>
      <a href="/tags/DL/" style="font-size: 24px; color: #555">DL</a> <a href="/tags/ML/" style="font-size: 22px; color: #636363">ML</a> <a href="/tags/SQL/" style="font-size: 16px; color: #8b8b8b">SQL</a> <a href="/tags/color/" style="font-size: 14px; color: #999">color</a> <a href="/tags/hexo/" style="font-size: 14px; color: #999">hexo</a> <a href="/tags/java/" style="font-size: 18px; color: #7e7e7e">java</a> <a href="/tags/linux/" style="font-size: 14px; color: #999">linux</a> <a href="/tags/python/" style="font-size: 14px; color: #999">python</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/" style="font-size: 16px; color: #8b8b8b">数据结构与算法</a> <a href="/tags/%E8%AE%A1%E7%BD%91/" style="font-size: 20px; color: #707070">计网</a> <a href="/tags/%E9%87%8F%E5%AD%90%E8%AE%A1%E7%AE%97/" style="font-size: 14px; color: #999">量子计算</a>
    </div>
  </section>


            
          
        
          
          
        
      
    

  
</aside>

<footer id="footer" class="clearfix">
  
  
    <div class="social-wrapper">
      
        
          <a href="/atom.xml"
            class="social fas fa-rss flat-btn"
            target="_blank"
            rel="external nofollow noopener noreferrer">
          </a>
        
      
        
          <a href="mailto:121166704@qq.com"
            class="social fas fa-envelope flat-btn"
            target="_blank"
            rel="external nofollow noopener noreferrer">
          </a>
        
      
        
          <a href="https://github.com/shyshy903"
            class="social fab fa-github flat-btn"
            target="_blank"
            rel="external nofollow noopener noreferrer">
          </a>
        
      
    </div>
  
  <br>
  <div><p>Blog content follows the <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en" target="_blank" rel="noopener">Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License</a></p>
</div>
  <div>
    Use
    <a href="https://xaoxuu.com/wiki/material-x/" target="_blank" class="codename">Material X</a>
    as theme
    
      , 
      total visits
      <span id="busuanzi_value_site_pv"><i class="fas fa-spinner fa-spin fa-fw" aria-hidden="true"></i></span>
      times
    
    . 
  </div>
</footer>
<script>setLoadingBarProgress(80);</script>


      <script>setLoadingBarProgress(60);</script>
    </div>
    <a class="s-top fas fa-arrow-up fa-fw" href='javascript:void(0)'></a>
  </div>
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script>

  <script>
    
    var SEARCH_SERVICE = "hexo" || "hexo";
    var ROOT = "/" || "/";
    if (!ROOT.endsWith('/')) ROOT += '/';
  </script>

<script src="//instant.page/1.2.2" type="module" integrity="sha384-2xV8M5griQmzyiY3CDqh1dn4z3llDVqZDqzjzcY+jCBCk/a5fXJmuZ/40JJAPeoU"></script>


  <script src="https://cdn.jsdelivr.net/npm/scrollreveal@4.0.5/dist/scrollreveal.min.js"></script>
  <script type="text/javascript">
    $(function() {
      const $reveal = $('.reveal');
      if ($reveal.length === 0) return;
      const sr = ScrollReveal({ distance: 0 });
      sr.reveal('.reveal');
    });
  </script>


  <script src="https://cdn.jsdelivr.net/npm/node-waves@0.7.6/dist/waves.min.js"></script>
  <script type="text/javascript">
    $(function() {
      Waves.attach('.flat-btn', ['waves-button']);
      Waves.attach('.float-btn', ['waves-button', 'waves-float']);
      Waves.attach('.float-btn-light', ['waves-button', 'waves-float', 'waves-light']);
      Waves.attach('.flat-box', ['waves-block']);
      Waves.attach('.float-box', ['waves-block', 'waves-float']);
      Waves.attach('.waves-image');
      Waves.init();
    });
  </script>


  <script async src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-busuanzi@2.3/js/busuanzi.pure.mini.js"></script>




  
  
  
    <script src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-material-x@20.2/js/backstretch.min.js"></script>
    <script type="text/javascript">
      $(function(){
        if ('') {
          $('').backstretch(
          ["https://img.vim-cn.com/c5/4673c36a1dd2a6d3c747f01b404dab64d009eb.jpg"],
          {
            duration: "6000",
            fade: "2500"
          });
        } else {
          $.backstretch(
          ["https://img.vim-cn.com/c5/4673c36a1dd2a6d3c747f01b404dab64d009eb.jpg"],
          {
            duration: "6000",
            fade: "2500"
          });
        }
      });
    </script>
  









  <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
  
    
      
<script src="https://cdn.jsdelivr.net/gh/xaoxuu/volantis@1.0.6/js/volantis.min.js"></script>

    
  
  <script>
  var GUEST_INFO = ['nick','mail','link'];
  var guest_info = 'nick,mail,link'.split(',').filter(function(item){
    return GUEST_INFO.indexOf(item) > -1
  });
  var notify = 'true' == true;
  var verify = 'true' == true;
  var valine = new Valine();
  valine.init({
    el: '#valine_container',
    notify: notify,
    verify: verify,
    guest_info: guest_info,
    
    appId: "DGEVoyKVeVmx0Hsn098Pkquo-gzGzoHsz",
    appKey: "mkq3mUCepHlNs9LOIDsdR8VE",
    placeholder: "快来评论吧~",
    pageSize:'10',
    avatar:'mp',
    lang:'zh-cn',
    highlight:'true'
  })
  </script>



  
<script src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-material-x@20.2/js/app.js"></script>



  
<script src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-material-x@20.2/js/search.js"></script>







<!-- 复制 -->
<script src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js"></script>
<script>
  let COPY_SUCCESS = "Copied";
  let COPY_FAILURE = "Copy failed";
  /*页面载入完成后，创建复制按钮*/
  !function (e, t, a) {
    /* code */
    var initCopyCode = function(){
      var copyHtml = '';
      copyHtml += '<button class="btn-copy" data-clipboard-snippet="">';
      copyHtml += '  <i class="fa fa-copy"></i><span>Copy</span>';
      copyHtml += '</button>';
      $(".highlight .code pre").before(copyHtml);
      var clipboard = new ClipboardJS('.btn-copy', {
        target: function(trigger) {
          return trigger.nextElementSibling;
        }
      });

      clipboard.on('success', function(e) {
        //您可以加入成功提示
        console.info('Action:', e.action);
        console.info('Text:', e.text);
        console.info('Trigger:', e.trigger);
        success_prompt(COPY_SUCCESS);
        e.clearSelection();
      });
      clipboard.on('error', function(e) {
        //您可以加入失败提示
        console.error('Action:', e.action);
        console.error('Trigger:', e.trigger);
        fail_prompt(COPY_FAILURE);
      });
    }
    initCopyCode();

  }(window, document);

  /**
   * 弹出式提示框，默认1.5秒自动消失
   * @param message 提示信息
   * @param style 提示样式，有alert-success、alert-danger、alert-warning、alert-info
   * @param time 消失时间
   */
  var prompt = function (message, style, time)
  {
      style = (style === undefined) ? 'alert-success' : style;
      time = (time === undefined) ? 1500 : time*1000;
      $('<div>')
          .appendTo('body')
          .addClass('alert ' + style)
          .html(message)
          .show()
          .delay(time)
          .fadeOut();
  };

  // 成功提示
  var success_prompt = function(message, time)
  {
      prompt(message, 'alert-success', time);
  };

  // 失败提示
  var fail_prompt = function(message, time)
  {
      prompt(message, 'alert-danger', time);
  };

  // 提醒
  var warning_prompt = function(message, time)
  {
      prompt(message, 'alert-warning', time);
  };

  // 信息提示
  var info_prompt = function(message, time)
  {
      prompt(message, 'alert-info', time);
  };

</script>


<!-- fancybox -->
<script src="https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js"></script>
<script>
  let LAZY_LOAD_IMAGE = "";
  $(".article-entry").find("fancybox").find("img").each(function () {
      var element = document.createElement("a");
      $(element).attr("data-fancybox", "gallery");
      $(element).attr("href", $(this).attr("src"));
      /* 图片采用懒加载处理时,
       * 一般图片标签内会有个属性名来存放图片的真实地址，比如 data-original,
       * 那么此处将原本的属性名src替换为对应属性名data-original,
       * 修改如下
       */
       if (LAZY_LOAD_IMAGE) {
         $(element).attr("href", $(this).attr("data-original"));
       }
      $(this).wrap(element);
  });
</script>





  <script>setLoadingBarProgress(100);</script>
</body>
</html>
