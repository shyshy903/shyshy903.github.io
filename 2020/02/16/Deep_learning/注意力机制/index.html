<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  
  <title>æ³¨æ„åŠ›æœºåˆ¶ï¼ˆAttention) | what hurts more, the pain of hard work or the pain of regret?</title>
  
  
  <meta name="description" content="https://img.vim-cn.com/33/461edfd8f8283ad38990aa7a83131b4494eb2c.jpg">
  

  
  <link rel="alternate" href="/atom.xml" title="what hurts more, the pain of hard work or the pain of regret?">
  

  <meta name="HandheldFriendly" content="True" />
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <!-- meta -->
  

  <!-- link -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css" />
  
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-waves@0.7.6/dist/waves.min.css">
  
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.10.1/css/all.min.css">
  

  

  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-material-x@20.2.11/css/style.css">

  

  <script>
    function setLoadingBarProgress(num) {
      document.getElementById('loading-bar').style.width=num+"%";
    }
  </script>

  
  
<meta name="generator" content="Hexo 4.2.0"><link rel="alternate" href="/atom.xml" title="what hurts more, the pain of hard work or the pain of regret?" type="application/atom+xml">
</head>

<body>
  
  
  <div class="cover-wrapper">
    <cover class='cover post half'>
      
        
  <h1 class='title'>shylab</h1>


  <div class="m_search">
    <form name="searchform" class="form u-search-form">
      <input type="text" class="input u-search-input" placeholder="" />
      <i class="icon fas fa-search fa-fw"></i>
    </form>
  </div>

<div class='menu navgation'>
  <ul class='h-list'>
    
      
        <li>
          <a class="nav home" href="/"
            
            
            id="home">
            <i class='fas fa-rss fa-fw'></i>&nbsp;Blogs
          </a>
        </li>
      
        <li>
          <a class="nav home" href="/archives/"
            
              rel="nofollow"
            
            
            id="archives">
            <i class='fas fa-archive fa-fw'></i>&nbsp;Archives
          </a>
        </li>
      
        <li>
          <a class="nav home" href="/tags/"
            
              rel="nofollow"
            
            
            id="tags">
            <i class='fas fa-tags fa-fw'></i>&nbsp;Tags
          </a>
        </li>
      
        <li>
          <a class="nav home" href="https://github.com/shyshy903"
            
            
            id="https:github.comshyshy903">
            <i class='fab fa-github fa-fw'></i>&nbsp;Github
          </a>
        </li>
      
    
  </ul>
</div>

      
    </cover>
    <header class="l_header pure">
  <div id="loading-bar-wrapper">
    <div id="loading-bar" class="pure"></div>
  </div>

	<div class='wrapper'>
		<div class="nav-main container container--flex">
      <a class="logo flat-box" target="_self" href='/' >
        
          what hurts more, the pain of hard work or the pain of regret?
        
      </a>
			<div class='menu navgation'>
				<ul class='h-list'>
          
  					
  						<li>
								<a class="nav flat-box" href="/categories/"
                  
                    rel="nofollow"
                  
                  
                  id="categories">
									<i class='fas fa-folder-open fa-fw'></i>&nbsp;åˆ†ç±»
								</a>
							</li>
      			
  						<li>
								<a class="nav flat-box" href="/tags/"
                  
                    rel="nofollow"
                  
                  
                  id="tags">
									<i class='fas fa-tags fa-fw'></i>&nbsp;æ ‡ç­¾
								</a>
							</li>
      			
  						<li>
								<a class="nav flat-box" href="/archives/"
                  
                    rel="nofollow"
                  
                  
                  id="archives">
									<i class='fas fa-archive fa-fw'></i>&nbsp;å½’æ¡£
								</a>
							</li>
      			
      		
				</ul>
			</div>

			
				<div class="m_search">
					<form name="searchform" class="form u-search-form">
						<input type="text" class="input u-search-input" placeholder="Search" />
						<i class="icon fas fa-search fa-fw"></i>
					</form>
				</div>
			
			<ul class='switcher h-list'>
				
					<li class='s-search'><a class="fas fa-search fa-fw" target="_self" href='javascript:void(0)'></a></li>
				
				<li class='s-menu'><a class="fas fa-bars fa-fw" target="_self" href='javascript:void(0)'></a></li>
			</ul>
		</div>

		<div class='nav-sub container container--flex'>
			<a class="logo flat-box"></a>
			<ul class='switcher h-list'>
				<li class='s-comment'><a class="flat-btn fas fa-comments fa-fw" target="_self" href='javascript:void(0)'></a></li>
        
          <li class='s-toc'><a class="flat-btn fas fa-list fa-fw" target="_self" href='javascript:void(0)'></a></li>
        
			</ul>
		</div>
	</div>
</header>
	<aside class="menu-phone">
    <header>
		<nav class="menu navgation">
      <ul>
        
          
            <li>
							<a class="nav flat-box" href="/"
                
                
                id="home">
								<i class='fas fa-clock fa-fw'></i>&nbsp;è¿‘æœŸæ–‡ç« 
							</a>
            </li>
          
            <li>
							<a class="nav flat-box" href="/archives/"
                
                  rel="nofollow"
                
                
                id="archives">
								<i class='fas fa-archive fa-fw'></i>&nbsp;æ–‡ç« å½’æ¡£
							</a>
            </li>
          
       
      </ul>
		</nav>
    </header>
	</aside>
<script>setLoadingBarProgress(40);</script>

  </div>


  <div class="l_body">
    <div class='body-wrapper'>
      <div class='l_main'>
  

  <article id="post" class="post white-box article-type-post" itemscope itemprop="blogPost">
    


  <section class='meta'>
    
    
    <div class="meta" id="header-meta">
      
        
  
    <h1 class="title">
      <a href="/2020/02/16/Deep_learning/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/">
        æ³¨æ„åŠ›æœºåˆ¶ï¼ˆAttention)
      </a>
    </h1>
  


      
      <div class='new-meta-box'>
        
          
        
          
            
  <div class='new-meta-item author'>
    
      <a href="https://shyshy903.github.io" rel="nofollow">
        
          <i class="fas fa-user" aria-hidden="true"></i>
        
        <p>Haiyang Song</p>
      </a>
    
  </div>


          
        
          
            <div class="new-meta-item date">
  <a class='notlink'>
    <i class="fas fa-calendar-alt" aria-hidden="true"></i>
    <p>2020-02-16</p>
  </a>
</div>

          
        
          
            
  
  <div class='new-meta-item category'>
    <a href='/categories/deep-learning/' rel="nofollow">
      <i class="fas fa-folder-open" aria-hidden="true"></i>
      <p>deep_learning</p>
    </a>
  </div>


          
        
          
            
  
    <div class="new-meta-item browse busuanzi">
      <a class='notlink'>
        <i class="fas fa-eye" aria-hidden="true"></i>
        <p>
          <span id="busuanzi_value_page_pv">
            <i class="fas fa-spinner fa-spin fa-fw" aria-hidden="true"></i>
          </span>
        </p>
      </a>
    </div>
  


          
        
          
            
  

          
        
          
            

          
        
      </div>
      
        <hr>
      
    </div>
  </section>


    <section class="article typo">
      <div class="article-entry" itemprop="articleBody">
        <h1 id="æ³¨æ„åŠ›æœºåˆ¶"><a href="#æ³¨æ„åŠ›æœºåˆ¶" class="headerlink" title="æ³¨æ„åŠ›æœºåˆ¶"></a>æ³¨æ„åŠ›æœºåˆ¶</h1><p>åœ¨â€œç¼–ç å™¨â€”è§£ç å™¨ï¼ˆseq2seqï¼‰â€â¼€èŠ‚â¾¥ï¼Œè§£ç å™¨åœ¨å„ä¸ªæ—¶é—´æ­¥ä¾èµ–ç›¸åŒçš„èƒŒæ™¯å˜é‡ï¼ˆcontext vectorï¼‰æ¥è·å–è¾“â¼Šåºåˆ—ä¿¡æ¯ã€‚å½“ç¼–ç å™¨ä¸ºå¾ªç¯ç¥ç»â½¹ç»œæ—¶ï¼ŒèƒŒæ™¯å˜é‡æ¥â¾ƒå®ƒæœ€ç»ˆæ—¶é—´æ­¥çš„éšè—çŠ¶æ€ã€‚å°†æºåºåˆ—è¾“å…¥ä¿¡æ¯ä»¥å¾ªç¯å•ä½çŠ¶æ€ç¼–ç ï¼Œç„¶åå°†å…¶ä¼ é€’ç»™è§£ç å™¨ä»¥ç”Ÿæˆç›®æ ‡åºåˆ—ã€‚ç„¶è€Œè¿™ç§ç»“æ„å­˜åœ¨ç€é—®é¢˜ï¼Œå°¤å…¶æ˜¯RNNæœºåˆ¶å®é™…ä¸­å­˜åœ¨é•¿ç¨‹æ¢¯åº¦æ¶ˆå¤±çš„é—®é¢˜ï¼Œå¯¹äºè¾ƒé•¿çš„å¥å­ï¼Œæˆ‘ä»¬å¾ˆéš¾å¯„å¸Œæœ›äºå°†è¾“å…¥çš„åºåˆ—è½¬åŒ–ä¸ºå®šé•¿çš„å‘é‡è€Œä¿å­˜æ‰€æœ‰çš„æœ‰æ•ˆä¿¡æ¯ï¼Œæ‰€ä»¥éšç€æ‰€éœ€ç¿»è¯‘å¥å­çš„é•¿åº¦çš„å¢åŠ ï¼Œè¿™ç§ç»“æ„çš„æ•ˆæœä¼šæ˜¾è‘—ä¸‹é™ã€‚</p>
<p><img src="https://i.bmp.ovh/imgs/2020/02/0d5061d054b296a1.png" alt=""></p>
<p>ä¸æ­¤åŒæ—¶ï¼Œè§£ç çš„ç›®æ ‡è¯è¯­å¯èƒ½åªä¸åŸè¾“å…¥çš„éƒ¨åˆ†è¯è¯­æœ‰å…³ï¼Œè€Œå¹¶ä¸æ˜¯ä¸æ‰€æœ‰çš„è¾“å…¥æœ‰å…³ã€‚ä¾‹å¦‚ï¼Œå½“æŠŠâ€œHello worldâ€ç¿»è¯‘æˆâ€œBonjour le mondeâ€æ—¶ï¼Œâ€œHelloâ€æ˜ å°„æˆâ€œBonjourâ€ï¼Œâ€œworldâ€æ˜ å°„æˆâ€œmondeâ€ã€‚åœ¨seq2seqæ¨¡å‹ä¸­ï¼Œè§£ç å™¨åªèƒ½éšå¼åœ°ä»ç¼–ç å™¨çš„æœ€ç»ˆçŠ¶æ€ä¸­é€‰æ‹©ç›¸åº”çš„ä¿¡æ¯ã€‚ç„¶è€Œï¼Œæ³¨æ„åŠ›æœºåˆ¶å¯ä»¥å°†è¿™ç§é€‰æ‹©è¿‡ç¨‹æ˜¾å¼åœ°å»ºæ¨¡ã€‚<br><img src="https://img-blog.csdnimg.cn/20200216222846156.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDU3ODAzMg==,size_16,color_FFFFFF,t_70" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p>
<h2 id="æ³¨æ„åŠ›æœºåˆ¶æ¡†æ¶"><a href="#æ³¨æ„åŠ›æœºåˆ¶æ¡†æ¶" class="headerlink" title="æ³¨æ„åŠ›æœºåˆ¶æ¡†æ¶"></a>æ³¨æ„åŠ›æœºåˆ¶æ¡†æ¶</h2><p>Attention æ˜¯ä¸€ç§é€šç”¨çš„å¸¦æƒæ± åŒ–æ–¹æ³•ï¼Œè¾“å…¥ç”±ä¸¤éƒ¨åˆ†æ„æˆï¼šè¯¢é—®ï¼ˆqueryï¼‰å’Œé”®å€¼å¯¹ï¼ˆkey-value pairsï¼‰ã€‚ Query  , attention layerå¾—åˆ°è¾“å‡ºä¸valueçš„ç»´åº¦ä¸€è‡´ . å¯¹äºä¸€ä¸ªqueryæ¥è¯´ï¼Œattention layer ä¼šä¸æ¯ä¸€ä¸ªkeyè®¡ç®—æ³¨æ„åŠ›åˆ†æ•°å¹¶è¿›è¡Œæƒé‡çš„å½’ä¸€åŒ–ï¼Œè¾“å‡ºçš„å‘é‡åˆ™æ˜¯valueçš„åŠ æƒæ±‚å’Œï¼Œè€Œæ¯ä¸ªkeyè®¡ç®—çš„æƒé‡ä¸valueä¸€ä¸€å¯¹åº”ã€‚</p>
<p>ä¸ºäº†è®¡ç®—è¾“å‡ºï¼Œæˆ‘ä»¬é¦–å…ˆå‡è®¾æœ‰ä¸€ä¸ªå‡½æ•° ç”¨äºè®¡ç®—queryå’Œkeyçš„ç›¸ä¼¼æ€§ï¼Œç„¶åå¯ä»¥è®¡ç®—æ‰€æœ‰çš„ attention scores ${a_1, \ldots, a_n }$by</p>
<script type="math/tex; mode=display">a_i = \alpha(\mathbf q, \mathbf k_i)</script><p>æˆ‘ä»¬ä½¿ç”¨ softmaxå‡½æ•° è·å¾—æ³¨æ„åŠ›æƒé‡ï¼š</p>
<script type="math/tex; mode=display">b_1, \ldots, b_n = \textrm{softmax}(a_1, \ldots, a_n)</script><p>æœ€ç»ˆçš„è¾“å‡ºå°±æ˜¯valueçš„åŠ æƒæ±‚å’Œï¼š</p>
<script type="math/tex; mode=display">\mathbf o = \sum_{i=1}^n b_i \mathbf v_i</script><p><img src="https://img-blog.csdnimg.cn/20200216224849212.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDU3ODAzMg==,size_16,color_FFFFFF,t_70" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p>
<p>ä¸åŒçš„attetion layerçš„åŒºåˆ«åœ¨äºscoreå‡½æ•°çš„é€‰æ‹©ï¼Œåœ¨æœ¬èŠ‚çš„å…¶ä½™éƒ¨åˆ†ï¼Œæˆ‘ä»¬å°†è®¨è®ºä¸¤ä¸ªå¸¸ç”¨çš„æ³¨æ„å±‚ Dot-product Attention å’Œ Multilayer Perceptron Attentionï¼›éšåæˆ‘ä»¬å°†å®ç°ä¸€ä¸ªå¼•å…¥attentionçš„seq2seqæ¨¡å‹å¹¶åœ¨è‹±æ³•ç¿»è¯‘è¯­æ–™ä¸Šè¿›è¡Œè®­ç»ƒä¸æµ‹è¯•ã€‚</p>
<h3 id="softmaxçš„å±è”½"><a href="#softmaxçš„å±è”½" class="headerlink" title="softmaxçš„å±è”½"></a>softmaxçš„å±è”½</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">SequenceMask</span><span class="params">(X, X_len,value=<span class="number">-1e6</span>)</span>:</span></span><br><span class="line">    maxlen = X.size(<span class="number">1</span>)</span><br><span class="line">    <span class="comment">#print(X.size(),torch.arange((maxlen),dtype=torch.float)[None, :],'\n',X_len[:, None] )</span></span><br><span class="line">    mask = torch.arange((maxlen),dtype=torch.float)[<span class="literal">None</span>, :] &gt;= X_len[:, <span class="literal">None</span>]   </span><br><span class="line">    <span class="comment">#print(mask)</span></span><br><span class="line">    X[mask]=value</span><br><span class="line">    <span class="keyword">return</span> X</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">masked_softmax</span><span class="params">(X, valid_length)</span>:</span></span><br><span class="line">    <span class="comment"># X: 3-D tensor, valid_length: 1-D or 2-D tensor</span></span><br><span class="line">    softmax = nn.Softmax(dim=<span class="number">-1</span>)</span><br><span class="line">    <span class="keyword">if</span> valid_length <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">return</span> softmax(X)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        shape = X.shape</span><br><span class="line">        <span class="keyword">if</span> valid_length.dim() == <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                valid_length = torch.FloatTensor(valid_length.numpy().repeat(shape[<span class="number">1</span>], axis=<span class="number">0</span>))<span class="comment">#[2,2,3,3]</span></span><br><span class="line">            <span class="keyword">except</span>:</span><br><span class="line">                valid_length = torch.FloatTensor(valid_length.cpu().numpy().repeat(shape[<span class="number">1</span>], axis=<span class="number">0</span>))<span class="comment">#[2,2,3,3]</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            valid_length = valid_length.reshape((<span class="number">-1</span>,))</span><br><span class="line">        <span class="comment"># fill masked elements with a large negative, whose exp is 0</span></span><br><span class="line">        X = SequenceMask(X.reshape((<span class="number">-1</span>, shape[<span class="number">-1</span>])), valid_length)</span><br><span class="line"> </span><br><span class="line">        <span class="keyword">return</span> softmax(X).reshape(shape)</span><br><span class="line"></span><br><span class="line">masked_softmax(torch.rand((<span class="number">2</span>,<span class="number">2</span>,<span class="number">4</span>),dtype=torch.float), torch.FloatTensor([<span class="number">2</span>,<span class="number">3</span>]))</span><br></pre></td></tr></table></figure>
<h3 id="è¶…å‡ºäºŒç»´çŸ©é˜µçš„ä¹˜æ³•"><a href="#è¶…å‡ºäºŒç»´çŸ©é˜µçš„ä¹˜æ³•" class="headerlink" title="è¶…å‡ºäºŒç»´çŸ©é˜µçš„ä¹˜æ³•"></a>è¶…å‡ºäºŒç»´çŸ©é˜µçš„ä¹˜æ³•</h3><p> Xå’Œ  Yæ˜¯ç»´åº¦åˆ†åˆ«ä¸º(b,n,m)å’Œ(b, m, k)çš„å¼ é‡ï¼Œè¿›è¡Œ bæ¬¡äºŒç»´çŸ©é˜µä¹˜æ³•åå¾—åˆ° , ç»´åº¦ä¸º (b, n, k)ã€‚</p>
<script type="math/tex; mode=display">Z[i,:,:] = dot(X[i,:,:], Y[i,:,:])\qquad for\ i= 1,â€¦,n\</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.bmm(torch.ones((<span class="number">2</span>,<span class="number">1</span>,<span class="number">3</span>), dtype = torch.float), torch.ones((<span class="number">2</span>,<span class="number">3</span>,<span class="number">2</span>), dtype = torch.float))</span><br></pre></td></tr></table></figure>
<h2 id="ç‚¹ç§¯æ³¨æ„åŠ›"><a href="#ç‚¹ç§¯æ³¨æ„åŠ›" class="headerlink" title="ç‚¹ç§¯æ³¨æ„åŠ›"></a>ç‚¹ç§¯æ³¨æ„åŠ›</h2><p>The dot product å‡è®¾queryå’Œkeysæœ‰ç›¸åŒçš„ç»´åº¦, å³ . é€šè¿‡è®¡ç®—queryå’Œkeyè½¬ç½®çš„ä¹˜ç§¯æ¥è®¡ç®—attention score,é€šå¸¸è¿˜ä¼šé™¤å»sqrt{d}å‡å°‘è®¡ç®—å‡ºæ¥çš„scoreå¯¹ç»´åº¦ğ‘‘çš„ä¾èµ–æ€§ï¼Œå¦‚ä¸‹<br>ğ›¼(ğª,ğ¤)=âŸ¨ğª,ğ¤âŸ©/ \sqrt{d}<br>å‡è®¾ğâˆˆâ„^{ğ‘šÃ—ğ‘‘}æœ‰mä¸ªqueryï¼Œ æœ‰nä¸ªkeys. æˆ‘ä»¬å¯ä»¥é€šè¿‡çŸ©é˜µè¿ç®—çš„æ–¹å¼è®¡ç®—æ‰€æœ‰mnä¸ªscoreï¼š<br>ğ›¼(ğ,ğŠ)=ğğŠ^ğ‘‡/\sqrt{d}<br>ç°åœ¨è®©æˆ‘ä»¬å®ç°è¿™ä¸ªå±‚ï¼Œå®ƒæ”¯æŒä¸€æ‰¹æŸ¥è¯¢å’Œé”®å€¼å¯¹ã€‚æ­¤å¤–ï¼Œå®ƒæ”¯æŒä½œä¸ºæ­£åˆ™åŒ–éšæœºåˆ é™¤ä¸€äº›æ³¨æ„åŠ›æƒé‡.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DotProductAttention</span><span class="params">(nn.Module)</span>:</span> </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, dropout, **kwargs)</span>:</span></span><br><span class="line">        super(DotProductAttention, self).__init__(**kwargs)</span><br><span class="line">        self.dropout = nn.Dropout(dropout)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># query: (batch_size, #queries, d)</span></span><br><span class="line">    <span class="comment"># key: (batch_size, #kv_pairs, d)</span></span><br><span class="line">    <span class="comment"># value: (batch_size, #kv_pairs, dim_v)</span></span><br><span class="line">    <span class="comment"># valid_length: either (batch_size, ) or (batch_size, xx)</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, query, key, value, valid_length=None)</span>:</span></span><br><span class="line">        d = query.shape[<span class="number">-1</span>]</span><br><span class="line">        <span class="comment"># set transpose_b=True to swap the last two dimensions of key</span></span><br><span class="line">        </span><br><span class="line">        scores = torch.bmm(query, key.transpose(<span class="number">1</span>,<span class="number">2</span>)) / math.sqrt(d)</span><br><span class="line">        attention_weights = self.dropout(masked_softmax(scores, valid_length))</span><br><span class="line">        print(<span class="string">"attention_weight\n"</span>,attention_weights)</span><br><span class="line">        <span class="keyword">return</span> torch.bmm(attention_weights, value)</span><br></pre></td></tr></table></figure>
<h2 id="å¤šå±‚æ„ŸçŸ¥æœºæ³¨æ„åŠ›"><a href="#å¤šå±‚æ„ŸçŸ¥æœºæ³¨æ„åŠ›" class="headerlink" title="å¤šå±‚æ„ŸçŸ¥æœºæ³¨æ„åŠ›"></a>å¤šå±‚æ„ŸçŸ¥æœºæ³¨æ„åŠ›</h2><p>å°†scoreå‡½æ•°å®šä¹‰:</p>
<script type="math/tex; mode=display">
a(\boldsymbol{s}, \boldsymbol{h}) = \boldsymbol{v}^\top \tanh(\boldsymbol{W}_s \boldsymbol{s} + \boldsymbol{W}_h \boldsymbol{h}),</script><p>. ç„¶åå°†key å’Œ value åœ¨ç‰¹å¾çš„ç»´åº¦ä¸Šåˆå¹¶ï¼ˆconcatenateï¼‰ï¼Œç„¶åé€è‡³ a single hidden layer perceptron è¿™å±‚ä¸­ hidden layer ä¸º â„ and è¾“å‡ºçš„sizeä¸º 1 .éšå±‚æ¿€æ´»å‡½æ•°ä¸ºtanhï¼Œæ— åç½®.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Save to the d2l package.</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MLPAttention</span><span class="params">(nn.Module)</span>:</span>  </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, units,ipt_dim,dropout, **kwargs)</span>:</span></span><br><span class="line">        super(MLPAttention, self).__init__(**kwargs)</span><br><span class="line">        <span class="comment"># Use flatten=True to keep query's and key's 3-D shapes.</span></span><br><span class="line">        self.W_k = nn.Linear(ipt_dim, units, bias=<span class="literal">False</span>)</span><br><span class="line">        self.W_q = nn.Linear(ipt_dim, units, bias=<span class="literal">False</span>)</span><br><span class="line">        self.v = nn.Linear(units, <span class="number">1</span>, bias=<span class="literal">False</span>)</span><br><span class="line">        self.dropout = nn.Dropout(dropout)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, query, key, value, valid_length)</span>:</span></span><br><span class="line">        query, key = self.W_k(query), self.W_q(key)</span><br><span class="line">        <span class="comment">#print("size",query.size(),key.size())</span></span><br><span class="line">        <span class="comment"># expand query to (batch_size, #querys, 1, units), and key to</span></span><br><span class="line">        <span class="comment"># (batch_size, 1, #kv_pairs, units). Then plus them with broadcast.</span></span><br><span class="line">        features = query.unsqueeze(<span class="number">2</span>) + key.unsqueeze(<span class="number">1</span>)</span><br><span class="line">        <span class="comment">#print("features:",features.size())  #--------------å¼€å¯</span></span><br><span class="line">        scores = self.v(features).squeeze(<span class="number">-1</span>) </span><br><span class="line">        attention_weights = self.dropout(masked_softmax(scores, valid_length))</span><br><span class="line">        <span class="keyword">return</span> torch.bmm(attention_weights, value)</span><br></pre></td></tr></table></figure>
<h3 id="è®¡ç®—èƒŒæ™¯å˜é‡"><a href="#è®¡ç®—èƒŒæ™¯å˜é‡" class="headerlink" title="è®¡ç®—èƒŒæ™¯å˜é‡"></a>è®¡ç®—èƒŒæ™¯å˜é‡</h3><p>æˆ‘ä»¬å…ˆæè¿°ç¬¬ä¸€ä¸ªå…³é”®ç‚¹ï¼Œå³è®¡ç®—èƒŒæ™¯å˜é‡ã€‚å›¾æç»˜äº†æ³¨æ„åŠ›æœºåˆ¶å¦‚ä½•ä¸ºè§£ç å™¨åœ¨æ—¶é—´æ­¥2è®¡ç®—èƒŒæ™¯å˜é‡ã€‚é¦–å…ˆï¼Œå‡½æ•°$a$æ ¹æ®è§£ç å™¨åœ¨æ—¶é—´æ­¥1çš„éšè—çŠ¶æ€å’Œç¼–ç å™¨åœ¨å„ä¸ªæ—¶é—´æ­¥çš„éšè—çŠ¶æ€è®¡ç®—softmaxè¿ç®—çš„è¾“å…¥ã€‚softmaxè¿ç®—è¾“å‡ºæ¦‚ç‡åˆ†å¸ƒå¹¶å¯¹ç¼–ç å™¨å„ä¸ªæ—¶é—´æ­¥çš„éšè—çŠ¶æ€åšåŠ æƒå¹³å‡ï¼Œä»è€Œå¾—åˆ°èƒŒæ™¯å˜é‡ã€‚<br><img src="https://img-blog.csdnimg.cn/20200216230638792.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDU3ODAzMg==,size_16,color_FFFFFF,t_70" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p>
<p>å…·ä½“æ¥è¯´ï¼Œä»¤ç¼–ç å™¨åœ¨æ—¶é—´æ­¥$t$çš„éšè—çŠ¶æ€ä¸º$\boldsymbol{h}_t$ï¼Œä¸”æ€»æ—¶é—´æ­¥æ•°ä¸º$T$ã€‚é‚£ä¹ˆè§£ç å™¨åœ¨æ—¶é—´æ­¥$tâ€™$çš„èƒŒæ™¯å˜é‡ä¸ºæ‰€æœ‰ç¼–ç å™¨éšè—çŠ¶æ€çš„åŠ æƒå¹³å‡ï¼š</p>
<script type="math/tex; mode=display">
\boldsymbol{c}_{t'} = \sum_{t=1}^T \alpha_{t' t} \boldsymbol{h}_t,</script><p>å…¶ä¸­ç»™å®š$tâ€™$æ—¶ï¼Œæƒé‡$\alpha_{tâ€™ t}$åœ¨$t=1,\ldots,T$çš„å€¼æ˜¯ä¸€ä¸ªæ¦‚ç‡åˆ†å¸ƒã€‚ä¸ºäº†å¾—åˆ°æ¦‚ç‡åˆ†å¸ƒï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨softmaxè¿ç®—:</p>
<script type="math/tex; mode=display">
\alpha_{t' t} = \frac{\exp(e_{t' t})}{ \sum_{k=1}^T \exp(e_{t' k}) },\quad t=1,\ldots,T.</script><p>ç°åœ¨ï¼Œæˆ‘ä»¬éœ€è¦å®šä¹‰å¦‚ä½•è®¡ç®—ä¸Šå¼ä¸­softmaxè¿ç®—çš„è¾“å…¥$e_{tâ€™ t}$ã€‚ç”±äº$e_{tâ€™ t}$åŒæ—¶å–å†³äºè§£ç å™¨çš„æ—¶é—´æ­¥$tâ€™$å’Œç¼–ç å™¨çš„æ—¶é—´æ­¥$t$ï¼Œæˆ‘ä»¬ä¸å¦¨ä»¥è§£ç å™¨åœ¨æ—¶é—´æ­¥$tâ€™-1$çš„éšè—çŠ¶æ€$\boldsymbol{s}_{tâ€™ - 1}$ä¸ç¼–ç å™¨åœ¨æ—¶é—´æ­¥$t$çš„éšè—çŠ¶æ€$\boldsymbol{h}_t$ä¸ºè¾“å…¥ï¼Œå¹¶é€šè¿‡å‡½æ•°$a$è®¡ç®—$e_{tâ€™ t}$ï¼š</p>
<script type="math/tex; mode=display">
e_{t' t} = a(\boldsymbol{s}_{t' - 1}, \boldsymbol{h}_t).</script><p>è¿™é‡Œå‡½æ•°$a$æœ‰å¤šç§é€‰æ‹©ï¼Œå¦‚æœä¸¤ä¸ªè¾“å…¥å‘é‡é•¿åº¦ç›¸åŒï¼Œä¸€ä¸ªç®€å•çš„é€‰æ‹©æ˜¯è®¡ç®—å®ƒä»¬çš„å†…ç§¯$a(\boldsymbol{s}, \boldsymbol{h})=\boldsymbol{s}^\top \boldsymbol{h}$ã€‚è€Œæœ€æ—©æå‡ºæ³¨æ„åŠ›æœºåˆ¶çš„è®ºæ–‡åˆ™å°†è¾“å…¥è¿ç»“åé€šè¿‡å«å•éšè—å±‚çš„å¤šå±‚æ„ŸçŸ¥æœºå˜æ¢ [1]ï¼š</p>
<script type="math/tex; mode=display">
a(\boldsymbol{s}, \boldsymbol{h}) = \boldsymbol{v}^\top \tanh(\boldsymbol{W}_s \boldsymbol{s} + \boldsymbol{W}_h \boldsymbol{h}),</script><p>å…¶ä¸­$\boldsymbol{v}$ã€$\boldsymbol{W}_s$ã€$\boldsymbol{W}_h$éƒ½æ˜¯å¯ä»¥å­¦ä¹ çš„æ¨¡å‹å‚æ•°ã€‚</p>
<h3 id="çŸ¢é‡åŒ–è®¡ç®—"><a href="#çŸ¢é‡åŒ–è®¡ç®—" class="headerlink" title="çŸ¢é‡åŒ–è®¡ç®—"></a>çŸ¢é‡åŒ–è®¡ç®—</h3><p>æˆ‘ä»¬è¿˜å¯ä»¥å¯¹æ³¨æ„åŠ›æœºåˆ¶é‡‡ç”¨æ›´é«˜æ•ˆçš„çŸ¢é‡åŒ–è®¡ç®—ã€‚å¹¿ä¹‰ä¸Šï¼Œæ³¨æ„åŠ›æœºåˆ¶çš„è¾“å…¥åŒ…æ‹¬æŸ¥è¯¢é¡¹ä»¥åŠä¸€ä¸€å¯¹åº”çš„é”®é¡¹å’Œå€¼é¡¹ï¼Œå…¶ä¸­å€¼é¡¹æ˜¯éœ€è¦åŠ æƒå¹³å‡çš„ä¸€ç»„é¡¹ã€‚åœ¨åŠ æƒå¹³å‡ä¸­ï¼Œå€¼é¡¹çš„æƒé‡æ¥è‡ªæŸ¥è¯¢é¡¹ä»¥åŠä¸è¯¥å€¼é¡¹å¯¹åº”çš„é”®é¡¹çš„è®¡ç®—ã€‚</p>
<p>åœ¨ä¸Šé¢çš„ä¾‹å­ä¸­ï¼ŒæŸ¥è¯¢é¡¹ä¸ºè§£ç å™¨çš„éšè—çŠ¶æ€ï¼Œé”®é¡¹å’Œå€¼é¡¹å‡ä¸ºç¼–ç å™¨çš„éšè—çŠ¶æ€ã€‚<br>è®©æˆ‘ä»¬è€ƒè™‘ä¸€ä¸ªå¸¸è§çš„ç®€å•æƒ…å½¢ï¼Œå³ç¼–ç å™¨å’Œè§£ç å™¨çš„éšè—å•å…ƒä¸ªæ•°å‡ä¸º$h$ï¼Œä¸”å‡½æ•°$a(\boldsymbol{s}, \boldsymbol{h})=\boldsymbol{s}^\top \boldsymbol{h}$ã€‚å‡è®¾æˆ‘ä»¬å¸Œæœ›æ ¹æ®è§£ç å™¨å•ä¸ªéšè—çŠ¶æ€$\boldsymbol{s}_{tâ€™ - 1} \in \mathbb{R}^{h}$å’Œç¼–ç å™¨æ‰€æœ‰éšè—çŠ¶æ€$\boldsymbol{h}_t \in \mathbb{R}^{h}, t = 1,\ldots,T$æ¥è®¡ç®—èƒŒæ™¯å‘é‡$\boldsymbol{c}_{tâ€™}\in \mathbb{R}^{h}$ã€‚<br>æˆ‘ä»¬å¯ä»¥å°†æŸ¥è¯¢é¡¹çŸ©é˜µ$\boldsymbol{Q} \in \mathbb{R}^{1 \times h}$è®¾ä¸º$\boldsymbol{s}_{tâ€™ - 1}^\top$ï¼Œå¹¶ä»¤é”®é¡¹çŸ©é˜µ$\boldsymbol{K} \in \mathbb{R}^{T \times h}$å’Œå€¼é¡¹çŸ©é˜µ$\boldsymbol{V} \in \mathbb{R}^{T \times h}$ç›¸åŒä¸”ç¬¬$t$è¡Œå‡ä¸º$\boldsymbol{h}_t^\top$ã€‚æ­¤æ—¶ï¼Œæˆ‘ä»¬åªéœ€è¦é€šè¿‡çŸ¢é‡åŒ–è®¡ç®—</p>
<script type="math/tex; mode=display">\text{softmax}(\boldsymbol{Q}\boldsymbol{K}^\top)\boldsymbol{V}</script><p>å³å¯ç®—å‡ºè½¬ç½®åçš„èƒŒæ™¯å‘é‡$\boldsymbol{c}_{tâ€™}^\top$ã€‚å½“æŸ¥è¯¢é¡¹çŸ©é˜µ$\boldsymbol{Q}$çš„è¡Œæ•°ä¸º$n$æ—¶ï¼Œä¸Šå¼å°†å¾—åˆ°$n$è¡Œçš„è¾“å‡ºçŸ©é˜µã€‚è¾“å‡ºçŸ©é˜µä¸æŸ¥è¯¢é¡¹çŸ©é˜µåœ¨ç›¸åŒè¡Œä¸Šä¸€ä¸€å¯¹åº”ã€‚</p>
<h2 id="å¼•å…¥æ³¨æ„åŠ›æœºåˆ¶çš„S2S"><a href="#å¼•å…¥æ³¨æ„åŠ›æœºåˆ¶çš„S2S" class="headerlink" title="å¼•å…¥æ³¨æ„åŠ›æœºåˆ¶çš„S2S"></a>å¼•å…¥æ³¨æ„åŠ›æœºåˆ¶çš„S2S</h2><p>æœ¬èŠ‚ä¸­å°†æ³¨æ„æœºåˆ¶æ·»åŠ åˆ°sequence to sequence æ¨¡å‹ä¸­ï¼Œä»¥æ˜¾å¼åœ°ä½¿ç”¨æƒé‡èšåˆstatesã€‚ä¸‹å›¾å±•ç¤ºencoding å’Œdecodingçš„æ¨¡å‹ç»“æ„ï¼Œåœ¨æ—¶é—´æ­¥ä¸ºtçš„æ—¶å€™ã€‚æ­¤åˆ»attention layerä¿å­˜ç€encoderingçœ‹åˆ°çš„æ‰€æœ‰ä¿¡æ¯â€”â€”å³encodingçš„æ¯ä¸€æ­¥è¾“å‡ºã€‚åœ¨decodingé˜¶æ®µï¼Œè§£ç å™¨çš„æ—¶åˆ»çš„éšè—çŠ¶æ€è¢«å½“ä½œqueryï¼Œencoderçš„æ¯ä¸ªæ—¶é—´æ­¥çš„hidden statesä½œä¸ºkeyå’Œvalueè¿›è¡Œattentionèšåˆ. Attetion modelçš„è¾“å‡ºå½“ä½œæˆä¸Šä¸‹æ–‡ä¿¡æ¯context vectorï¼Œå¹¶ä¸è§£ç å™¨è¾“å…¥æ‹¼æ¥èµ·æ¥ä¸€èµ·é€åˆ°è§£ç å™¨ï¼š<br><img src="https://img-blog.csdnimg.cn/2020021623101586.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDU3ODAzMg==,size_16,color_FFFFFF,t_70" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"><br>ä¸‹å›¾å±•ç¤ºäº†seq2seqæœºåˆ¶çš„æ‰€ä»¥å±‚çš„å…³ç³»ï¼Œä¸‹é¢å±•ç¤ºäº†encoderå’Œdecoderçš„layerç»“æ„<br><img src="https://img-blog.csdnimg.cn/20200216231034160.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDU3ODAzMg==,size_16,color_FFFFFF,t_70" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p>
<h3 id="Decoder"><a href="#Decoder" class="headerlink" title="Decoder"></a>Decoder</h3><p>ç”±äºå¸¦æœ‰æ³¨æ„æœºåˆ¶çš„seq2seqçš„ç¼–ç å™¨ä¸ä¹‹å‰ç« èŠ‚ä¸­çš„Seq2SeqEncoderç›¸åŒï¼Œæ‰€ä»¥åœ¨æ­¤å¤„æˆ‘ä»¬åªå…³æ³¨è§£ç å™¨ã€‚æˆ‘ä»¬æ·»åŠ äº†ä¸€ä¸ªMLPæ³¨æ„å±‚(MLPAttention)ï¼Œå®ƒçš„éšè—å¤§å°ä¸è§£ç å™¨ä¸­çš„LSTMå±‚ç›¸åŒã€‚ç„¶åæˆ‘ä»¬é€šè¿‡ä»ç¼–ç å™¨ä¼ é€’ä¸‰ä¸ªå‚æ•°æ¥åˆå§‹åŒ–è§£ç å™¨çš„çŠ¶æ€:</p>
<ul>
<li>the encoder outputs of all timestepsï¼šencoderè¾“å‡ºçš„å„ä¸ªçŠ¶æ€ï¼Œè¢«ç”¨äºattetion layerçš„memoryéƒ¨åˆ†ï¼Œæœ‰ç›¸åŒçš„keyå’Œvalues</li>
<li>the hidden state of the encoderâ€™s final timestepï¼šç¼–ç å™¨æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„éšè—çŠ¶æ€ï¼Œè¢«ç”¨äºåˆå§‹åŒ–decoder çš„hidden state</li>
<li>the encoder valid length: ç¼–ç å™¨çš„æœ‰æ•ˆé•¿åº¦ï¼Œå€Ÿæ­¤ï¼Œæ³¨æ„å±‚ä¸ä¼šè€ƒè™‘ç¼–ç å™¨è¾“å‡ºä¸­çš„å¡«å……æ ‡è®°ï¼ˆPaddingsï¼‰  </li>
</ul>
<p>åœ¨è§£ç çš„æ¯ä¸ªæ—¶é—´æ­¥ï¼Œæˆ‘ä»¬ä½¿ç”¨è§£ç å™¨çš„æœ€åä¸€ä¸ªRNNå±‚çš„è¾“å‡ºä½œä¸ºæ³¨æ„å±‚çš„queryã€‚ç„¶åï¼Œå°†æ³¨æ„åŠ›æ¨¡å‹çš„è¾“å‡ºä¸è¾“å…¥åµŒå…¥å‘é‡è¿æ¥èµ·æ¥ï¼Œè¾“å…¥åˆ°RNNå±‚ã€‚è™½ç„¶RNNå±‚éšè—çŠ¶æ€ä¹ŸåŒ…å«æ¥è‡ªè§£ç å™¨çš„å†å²ä¿¡æ¯ï¼Œä½†æ˜¯attention modelçš„è¾“å‡ºæ˜¾å¼åœ°é€‰æ‹©äº†enc_valid_lenä»¥å†…çš„ç¼–ç å™¨è¾“å‡ºï¼Œè¿™æ ·attentionæœºåˆ¶å°±ä¼šå°½å¯èƒ½æ’é™¤å…¶ä»–ä¸ç›¸å…³çš„ä¿¡æ¯ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Seq2SeqAttentionDecoder</span><span class="params">(d2l.Decoder)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, vocab_size, embed_size, num_hiddens, num_layers,</span></span></span><br><span class="line"><span class="function"><span class="params">                 dropout=<span class="number">0</span>, **kwargs)</span>:</span></span><br><span class="line">        super(Seq2SeqAttentionDecoder, self).__init__(**kwargs)</span><br><span class="line">        self.attention_cell = MLPAttention(num_hiddens,num_hiddens, dropout)</span><br><span class="line">        self.embedding = nn.Embedding(vocab_size, embed_size)</span><br><span class="line">        self.rnn = nn.LSTM(embed_size+ num_hiddens,num_hiddens, num_layers, dropout=dropout)</span><br><span class="line">        self.dense = nn.Linear(num_hiddens,vocab_size)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">init_state</span><span class="params">(self, enc_outputs, enc_valid_len, *args)</span>:</span></span><br><span class="line">        outputs, hidden_state = enc_outputs</span><br><span class="line"><span class="comment">#         print("first:",outputs.size(),hidden_state[0].size(),hidden_state[1].size())</span></span><br><span class="line">        <span class="comment"># Transpose outputs to (batch_size, seq_len, hidden_size)</span></span><br><span class="line">        <span class="keyword">return</span> (outputs.permute(<span class="number">1</span>,<span class="number">0</span>,<span class="number">-1</span>), hidden_state, enc_valid_len)</span><br><span class="line">        <span class="comment">#outputs.swapaxes(0, 1)</span></span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, X, state)</span>:</span></span><br><span class="line">        enc_outputs, hidden_state, enc_valid_len = state</span><br><span class="line">        <span class="comment">#("X.size",X.size())</span></span><br><span class="line">        X = self.embedding(X).transpose(<span class="number">0</span>,<span class="number">1</span>)</span><br><span class="line"><span class="comment">#         print("Xembeding.size2",X.size())</span></span><br><span class="line">        outputs = []</span><br><span class="line">        <span class="keyword">for</span> l, x <span class="keyword">in</span> enumerate(X):</span><br><span class="line"><span class="comment">#             print(f"\n&#123;l&#125;-th token")</span></span><br><span class="line"><span class="comment">#             print("x.first.size()",x.size())</span></span><br><span class="line">            <span class="comment"># query shape: (batch_size, 1, hidden_size)</span></span><br><span class="line">            <span class="comment"># select hidden state of the last rnn layer as query</span></span><br><span class="line">            query = hidden_state[<span class="number">0</span>][<span class="number">-1</span>].unsqueeze(<span class="number">1</span>) <span class="comment"># np.expand_dims(hidden_state[0][-1], axis=1)</span></span><br><span class="line">            <span class="comment"># context has same shape as query</span></span><br><span class="line"><span class="comment">#             print("query enc_outputs, enc_outputs:\n",query.size(), enc_outputs.size(), enc_outputs.size())</span></span><br><span class="line">            context = self.attention_cell(query, enc_outputs, enc_outputs, enc_valid_len)</span><br><span class="line">            <span class="comment"># Concatenate on the feature dimension</span></span><br><span class="line"><span class="comment">#             print("context.size:",context.size())</span></span><br><span class="line">            x = torch.cat((context, x.unsqueeze(<span class="number">1</span>)), dim=<span class="number">-1</span>)</span><br><span class="line">            <span class="comment"># Reshape x to (1, batch_size, embed_size+hidden_size)</span></span><br><span class="line"><span class="comment">#             print("rnn",x.size(), len(hidden_state))</span></span><br><span class="line">            out, hidden_state = self.rnn(x.transpose(<span class="number">0</span>,<span class="number">1</span>), hidden_state)</span><br><span class="line">            outputs.append(out)</span><br><span class="line">        outputs = self.dense(torch.cat(outputs, dim=<span class="number">0</span>))</span><br><span class="line">        <span class="keyword">return</span> outputs.transpose(<span class="number">0</span>, <span class="number">1</span>), [enc_outputs, hidden_state,</span><br><span class="line">                                        enc_valid_len]</span><br><span class="line"></span><br><span class="line">encoder = d2l.Seq2SeqEncoder(vocab_size=<span class="number">10</span>, embed_size=<span class="number">8</span>,</span><br><span class="line">                            num_hiddens=<span class="number">16</span>, num_layers=<span class="number">2</span>)</span><br><span class="line"><span class="comment"># encoder.initialize()</span></span><br><span class="line">decoder = Seq2SeqAttentionDecoder(vocab_size=<span class="number">10</span>, embed_size=<span class="number">8</span>,</span><br><span class="line">                                  num_hiddens=<span class="number">16</span>, num_layers=<span class="number">2</span>)</span><br><span class="line">X = torch.zeros((<span class="number">4</span>, <span class="number">7</span>),dtype=torch.long)</span><br><span class="line">print(<span class="string">"batch size=4\nseq_length=7\nhidden dim=16\nnum_layers=2\n"</span>)</span><br><span class="line">print(<span class="string">'encoder output size:'</span>, encoder(X)[<span class="number">0</span>].size())</span><br><span class="line">print(<span class="string">'encoder hidden size:'</span>, encoder(X)[<span class="number">1</span>][<span class="number">0</span>].size())</span><br><span class="line">print(<span class="string">'encoder memory size:'</span>, encoder(X)[<span class="number">1</span>][<span class="number">1</span>].size())</span><br><span class="line">state = decoder.init_state(encoder(X), <span class="literal">None</span>)</span><br><span class="line">out, state = decoder(X, state)</span><br><span class="line">out.shape, len(state), state[<span class="number">0</span>].shape, len(state[<span class="number">1</span>]), state[<span class="number">1</span>][<span class="number">0</span>].shape</span><br></pre></td></tr></table></figure>
      </div>
      
      
        <br>
        


  <section class='meta' id="footer-meta">
    <div class='new-meta-box'>
      
        
          <div class="new-meta-item date" itemprop="dateUpdated" datetime="2020-02-16T00:00:00+08:00">
  <a class='notlink'>
    <i class="fas fa-clock" aria-hidden="true"></i>
    <p>updated at Feb 16, 2020</p>
  </a>
</div>

        
      
        
          
  
  <div class="new-meta-item meta-tags"><a class="tag" href="/tags/DL/" rel="nofollow"><i class="fas fa-tag" aria-hidden="true"></i><p>DL</p></a></div>


        
      
        
          
  <div class="new-meta-item share -mob-share-list">
  <div class="-mob-share-list share-body">
    
      
        <a class="-mob-share-qq" title="QQå¥½å‹" rel="external nofollow noopener noreferrer"
          
          href="http://connect.qq.com/widget/shareqq/index.html?url=https://shyshy903.github.io/2020/02/16/Deep_learning/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/&title=æ³¨æ„åŠ›æœºåˆ¶ï¼ˆAttention) | what hurts more, the pain of hard work or the pain of regret?&summary="
          
          >
          
            <img src="https://cdn.jsdelivr.net/gh/xaoxuu/assets@19.1.9/logo/128/qq.png">
          
        </a>
      
    
      
        <a class="-mob-share-qzone" title="QQç©ºé—´" rel="external nofollow noopener noreferrer"
          
          href="https://sns.qzone.qq.com/cgi-bin/qzshare/cgi_qzshare_onekey?url=https://shyshy903.github.io/2020/02/16/Deep_learning/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/&title=æ³¨æ„åŠ›æœºåˆ¶ï¼ˆAttention) | what hurts more, the pain of hard work or the pain of regret?&summary="
          
          >
          
            <img src="https://cdn.jsdelivr.net/gh/xaoxuu/assets@19.1.9/logo/128/qzone.png">
          
        </a>
      
    
      
        <a class="-mob-share-weibo" title="å¾®åš" rel="external nofollow noopener noreferrer"
          
          href="http://service.weibo.com/share/share.php?url=https://shyshy903.github.io/2020/02/16/Deep_learning/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/&title=æ³¨æ„åŠ›æœºåˆ¶ï¼ˆAttention) | what hurts more, the pain of hard work or the pain of regret?&summary="
          
          >
          
            <img src="https://cdn.jsdelivr.net/gh/xaoxuu/assets@19.1.9/logo/128/weibo.png">
          
        </a>
      
    
  </div>
</div>



        
      
    </div>
  </section>


      
      
          <div class="prev-next">
              
                  <section class="prev">
                      <span class="art-item-left">
                          <h6><i class="fas fa-chevron-left" aria-hidden="true"></i>&nbsp;Previous</h6>
                          <h4>
                              <a href="/2020/02/17/Deep_learning/LeNet%E3%80%81AlexNet%E3%80%81VGG%E3%80%81NiN%E3%80%81GooLeNet/" rel="prev" title="LeNetã€AlexNetã€VGGã€NiNã€GoogLeNet">
                                
                                    LeNetã€AlexNetã€VGGã€NiNã€GoogLeNet
                                
                              </a>
                          </h4>
                          
                              
                              <h6 class="tags">
                                  <a class="tag" href="/tags/DL/"><i class="fas fa-tag fa-fw" aria-hidden="true"></i> DL</a>
                              </h6>
                          
                      </span>
                  </section>
              
              
                  <section class="next">
                      <span class="art-item-right" aria-hidden="true">
                          <h6>Next&nbsp;<i class="fas fa-chevron-right" aria-hidden="true"></i></h6>
                          <h4>
                              <a href="/2020/02/16/Deep_learning/%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9%E4%B8%8E%E8%BF%87%E6%8B%9F%E5%90%88%E3%80%81%E6%AC%A0%E6%8B%9F%E5%90%88/" rel="prev" title="æ¨¡å‹é€‰æ‹©ä¸è¿‡æ‹Ÿåˆä¸æ¬ æ‹Ÿåˆ">
                                  
                                      æ¨¡å‹é€‰æ‹©ä¸è¿‡æ‹Ÿåˆä¸æ¬ æ‹Ÿåˆ
                                  
                              </a>
                          </h4>
                          
                              
                              <h6 class="tags">
                                  <a class="tag" href="/tags/DL/"><i class="fas fa-tag fa-fw" aria-hidden="true"></i> DL</a>
                              </h6>
                          
                      </span>
                  </section>
              
          </div>
      
    </section>
  </article>



  <!-- æ˜¾ç¤ºæ¨èæ–‡ç« å’Œè¯„è®º -->



  <article class="post white-box comments">
    <section class="article typo">
      <h4><i class="fas fa-comments fa-fw" aria-hidden="true"></i>&nbsp;Comments</h4>
      
      
      
      
        <section id="comments">
          <div id="valine_container" class="valine_thread">
            <i class="fas fa-spinner fa-spin fa-fw"></i>
          </div>
        </section>
      
    </section>
  </article>






<!-- æ ¹æ®é¡µé¢mathjaxå˜é‡å†³å®šæ˜¯å¦åŠ è½½MathJaxæ•°å­¦å…¬å¼js -->



  <script>
    window.subData = {
      title: 'æ³¨æ„åŠ›æœºåˆ¶ï¼ˆAttention)',
      tools: true
    }
  </script>


</div>
<aside class='l_side'>
  
    
    
      
      
        
          
          
        
          
          
        
          
          
        
          
          
            
              
  <section class='widget toc-wrapper'>
    
<header class='pure'>
  <div><i class="fas fa-list fa-fw" aria-hidden="true"></i>&nbsp;&nbsp;TOC</div>
  
    <!-- <div class='wrapper'><a class="s-toc rightBtn" rel="external nofollow noopener noreferrer" href="javascript:void(0)"><i class="fas fa-thumbtack fa-fw"></i></a></div> -->
  
</header>

    <div class='content pure'>
      <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#æ³¨æ„åŠ›æœºåˆ¶"><span class="toc-text">æ³¨æ„åŠ›æœºåˆ¶</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#æ³¨æ„åŠ›æœºåˆ¶æ¡†æ¶"><span class="toc-text">æ³¨æ„åŠ›æœºåˆ¶æ¡†æ¶</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#softmaxçš„å±è”½"><span class="toc-text">softmaxçš„å±è”½</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#è¶…å‡ºäºŒç»´çŸ©é˜µçš„ä¹˜æ³•"><span class="toc-text">è¶…å‡ºäºŒç»´çŸ©é˜µçš„ä¹˜æ³•</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#ç‚¹ç§¯æ³¨æ„åŠ›"><span class="toc-text">ç‚¹ç§¯æ³¨æ„åŠ›</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#å¤šå±‚æ„ŸçŸ¥æœºæ³¨æ„åŠ›"><span class="toc-text">å¤šå±‚æ„ŸçŸ¥æœºæ³¨æ„åŠ›</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#è®¡ç®—èƒŒæ™¯å˜é‡"><span class="toc-text">è®¡ç®—èƒŒæ™¯å˜é‡</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#çŸ¢é‡åŒ–è®¡ç®—"><span class="toc-text">çŸ¢é‡åŒ–è®¡ç®—</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#å¼•å…¥æ³¨æ„åŠ›æœºåˆ¶çš„S2S"><span class="toc-text">å¼•å…¥æ³¨æ„åŠ›æœºåˆ¶çš„S2S</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Decoder"><span class="toc-text">Decoder</span></a></li></ol></li></ol></li></ol>
    </div>
  </section>


            
          
        
      
        
          
          
        
          
          
            
              
  <section class='widget category'>
    
<header class='pure'>
  <div><i class="fas fa-folder-open fa-fw" aria-hidden="true"></i>&nbsp;&nbsp;Categories</div>
  
    <a class="rightBtn"
    
      rel="nofollow"
    
    
    href="/categories/"
    title="categories/">
    <i class="fas fa-expand-arrows-alt fa-fw"></i></a>
  
</header>

    <div class='content pure'>
      <ul class="entry">
        
          <li><a class="flat-box" title="/categories/Linux/" href="/categories/Linux/"><div class='name'>Linux</div><div class='badge'>(2)</div></a></li>
        
          <li><a class="flat-box" title="/categories/Machine-Learning/" href="/categories/Machine-Learning/"><div class='name'>Machine_Learning</div><div class='badge'>(8)</div></a></li>
        
          <li><a class="flat-box" title="/categories/SQL/" href="/categories/SQL/"><div class='name'>SQL</div><div class='badge'>(2)</div></a></li>
        
          <li><a class="flat-box" title="/categories/deep-learning/" href="/categories/deep-learning/"><div class='name'>deep_learning</div><div class='badge'>(11)</div></a></li>
        
          <li><a class="flat-box" title="/categories/hexo/" href="/categories/hexo/"><div class='name'>hexo</div><div class='badge'>(1)</div></a></li>
        
          <li><a class="flat-box" title="/categories/java/" href="/categories/java/"><div class='name'>java</div><div class='badge'>(5)</div></a></li>
        
          <li><a class="flat-box" title="/categories/python/" href="/categories/python/"><div class='name'>python</div><div class='badge'>(1)</div></a></li>
        
          <li><a class="flat-box" title="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/" href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"><div class='name'>æ•°æ®ç»“æ„ä¸ç®—æ³•</div><div class='badge'>(3)</div></a></li>
        
          <li><a class="flat-box" title="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/" href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"><div class='name'>è®¡ç®—æœºç½‘ç»œ</div><div class='badge'>(6)</div></a></li>
        
          <li><a class="flat-box" title="/categories/%E8%AE%BE%E8%AE%A1/" href="/categories/%E8%AE%BE%E8%AE%A1/"><div class='name'>è®¾è®¡</div><div class='badge'>(1)</div></a></li>
        
          <li><a class="flat-box" title="/categories/%E9%87%8F%E5%AD%90%E8%AE%A1%E7%AE%97/" href="/categories/%E9%87%8F%E5%AD%90%E8%AE%A1%E7%AE%97/"><div class='name'>é‡å­è®¡ç®—</div><div class='badge'>(1)</div></a></li>
        
      </ul>
    </div>
  </section>


            
          
        
          
          
        
          
          
        
      
        
          
          
        
          
          
        
          
          
            
              
  <section class='widget tagcloud'>
    
<header class='pure'>
  <div><i class="fas fa-tags fa-fw" aria-hidden="true"></i>&nbsp;&nbsp;Hot Tags</div>
  
    <a class="rightBtn"
    
      rel="nofollow"
    
    
    href="/tags/"
    title="tags/">
    <i class="fas fa-expand-arrows-alt fa-fw"></i></a>
  
</header>

    <div class='content pure'>
      <a href="/tags/DL/" style="font-size: 24px; color: #555">DL</a> <a href="/tags/ML/" style="font-size: 22.33px; color: #606060">ML</a> <a href="/tags/SQL/" style="font-size: 15.67px; color: #8e8e8e">SQL</a> <a href="/tags/color/" style="font-size: 14px; color: #999">color</a> <a href="/tags/hexo/" style="font-size: 14px; color: #999">hexo</a> <a href="/tags/java/" style="font-size: 19px; color: #777">java</a> <a href="/tags/linux/" style="font-size: 15.67px; color: #8e8e8e">linux</a> <a href="/tags/python/" style="font-size: 14px; color: #999">python</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/" style="font-size: 17.33px; color: #828282">æ•°æ®ç»“æ„ä¸ç®—æ³•</a> <a href="/tags/%E8%AE%A1%E7%BD%91/" style="font-size: 20.67px; color: #6c6c6c">è®¡ç½‘</a> <a href="/tags/%E9%87%8F%E5%AD%90%E8%AE%A1%E7%AE%97/" style="font-size: 14px; color: #999">é‡å­è®¡ç®—</a>
    </div>
  </section>


            
          
        
          
          
        
      
    

  
</aside>

<footer id="footer" class="clearfix">
  
  
    <div class="social-wrapper">
      
        
          <a href="/atom.xml"
            class="social fas fa-rss flat-btn"
            target="_blank"
            rel="external nofollow noopener noreferrer">
          </a>
        
      
        
          <a href="mailto:121166704@qq.com"
            class="social fas fa-envelope flat-btn"
            target="_blank"
            rel="external nofollow noopener noreferrer">
          </a>
        
      
        
          <a href="https://github.com/shyshy903"
            class="social fab fa-github flat-btn"
            target="_blank"
            rel="external nofollow noopener noreferrer">
          </a>
        
      
    </div>
  
  <br>
  <div><p>Blog content follows the <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en" target="_blank" rel="noopener">Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License</a></p>
</div>
  <div>
    Use
    <a href="https://xaoxuu.com/wiki/material-x/" target="_blank" class="codename">Material X</a>
    as theme
    
      , 
      total visits
      <span id="busuanzi_value_site_pv"><i class="fas fa-spinner fa-spin fa-fw" aria-hidden="true"></i></span>
      times
    
    . 
  </div>
</footer>
<script>setLoadingBarProgress(80);</script>


      <script>setLoadingBarProgress(60);</script>
    </div>
    <a class="s-top fas fa-arrow-up fa-fw" href='javascript:void(0)'></a>
  </div>
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script>

  <script>
    
    var SEARCH_SERVICE = "hexo" || "hexo";
    var ROOT = "/" || "/";
    if (!ROOT.endsWith('/')) ROOT += '/';
  </script>

<script src="//instant.page/1.2.2" type="module" integrity="sha384-2xV8M5griQmzyiY3CDqh1dn4z3llDVqZDqzjzcY+jCBCk/a5fXJmuZ/40JJAPeoU"></script>


  <script src="https://cdn.jsdelivr.net/npm/scrollreveal@4.0.5/dist/scrollreveal.min.js"></script>
  <script type="text/javascript">
    $(function() {
      const $reveal = $('.reveal');
      if ($reveal.length === 0) return;
      const sr = ScrollReveal({ distance: 0 });
      sr.reveal('.reveal');
    });
  </script>


  <script src="https://cdn.jsdelivr.net/npm/node-waves@0.7.6/dist/waves.min.js"></script>
  <script type="text/javascript">
    $(function() {
      Waves.attach('.flat-btn', ['waves-button']);
      Waves.attach('.float-btn', ['waves-button', 'waves-float']);
      Waves.attach('.float-btn-light', ['waves-button', 'waves-float', 'waves-light']);
      Waves.attach('.flat-box', ['waves-block']);
      Waves.attach('.float-box', ['waves-block', 'waves-float']);
      Waves.attach('.waves-image');
      Waves.init();
    });
  </script>


  <script async src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-busuanzi@2.3/js/busuanzi.pure.mini.js"></script>




  
  
  
    <script src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-material-x@20.2/js/backstretch.min.js"></script>
    <script type="text/javascript">
      $(function(){
        if ('') {
          $('').backstretch(
          ["https://img.vim-cn.com/c5/4673c36a1dd2a6d3c747f01b404dab64d009eb.jpg"],
          {
            duration: "6000",
            fade: "2500"
          });
        } else {
          $.backstretch(
          ["https://img.vim-cn.com/c5/4673c36a1dd2a6d3c747f01b404dab64d009eb.jpg"],
          {
            duration: "6000",
            fade: "2500"
          });
        }
      });
    </script>
  









  <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
  
    
      
<script src="https://cdn.jsdelivr.net/gh/xaoxuu/volantis@1.0.6/js/volantis.min.js"></script>

    
  
  <script>
  var GUEST_INFO = ['nick','mail','link'];
  var guest_info = 'nick,mail,link'.split(',').filter(function(item){
    return GUEST_INFO.indexOf(item) > -1
  });
  var notify = 'true' == true;
  var verify = 'true' == true;
  var valine = new Valine();
  valine.init({
    el: '#valine_container',
    notify: notify,
    verify: verify,
    guest_info: guest_info,
    
    appId: "DGEVoyKVeVmx0Hsn098Pkquo-gzGzoHsz",
    appKey: "mkq3mUCepHlNs9LOIDsdR8VE",
    placeholder: "å¿«æ¥è¯„è®ºå§~",
    pageSize:'10',
    avatar:'mp',
    lang:'zh-cn',
    highlight:'true'
  })
  </script>



  
<script src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-material-x@20.2/js/app.js"></script>



  
<script src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-material-x@20.2/js/search.js"></script>







<!-- å¤åˆ¶ -->
<script src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js"></script>
<script>
  let COPY_SUCCESS = "Copied";
  let COPY_FAILURE = "Copy failed";
  /*é¡µé¢è½½å…¥å®Œæˆåï¼Œåˆ›å»ºå¤åˆ¶æŒ‰é’®*/
  !function (e, t, a) {
    /* code */
    var initCopyCode = function(){
      var copyHtml = '';
      copyHtml += '<button class="btn-copy" data-clipboard-snippet="">';
      copyHtml += '  <i class="fa fa-copy"></i><span>Copy</span>';
      copyHtml += '</button>';
      $(".highlight .code pre").before(copyHtml);
      var clipboard = new ClipboardJS('.btn-copy', {
        target: function(trigger) {
          return trigger.nextElementSibling;
        }
      });

      clipboard.on('success', function(e) {
        //æ‚¨å¯ä»¥åŠ å…¥æˆåŠŸæç¤º
        console.info('Action:', e.action);
        console.info('Text:', e.text);
        console.info('Trigger:', e.trigger);
        success_prompt(COPY_SUCCESS);
        e.clearSelection();
      });
      clipboard.on('error', function(e) {
        //æ‚¨å¯ä»¥åŠ å…¥å¤±è´¥æç¤º
        console.error('Action:', e.action);
        console.error('Trigger:', e.trigger);
        fail_prompt(COPY_FAILURE);
      });
    }
    initCopyCode();

  }(window, document);

  /**
   * å¼¹å‡ºå¼æç¤ºæ¡†ï¼Œé»˜è®¤1.5ç§’è‡ªåŠ¨æ¶ˆå¤±
   * @param message æç¤ºä¿¡æ¯
   * @param style æç¤ºæ ·å¼ï¼Œæœ‰alert-successã€alert-dangerã€alert-warningã€alert-info
   * @param time æ¶ˆå¤±æ—¶é—´
   */
  var prompt = function (message, style, time)
  {
      style = (style === undefined) ? 'alert-success' : style;
      time = (time === undefined) ? 1500 : time*1000;
      $('<div>')
          .appendTo('body')
          .addClass('alert ' + style)
          .html(message)
          .show()
          .delay(time)
          .fadeOut();
  };

  // æˆåŠŸæç¤º
  var success_prompt = function(message, time)
  {
      prompt(message, 'alert-success', time);
  };

  // å¤±è´¥æç¤º
  var fail_prompt = function(message, time)
  {
      prompt(message, 'alert-danger', time);
  };

  // æé†’
  var warning_prompt = function(message, time)
  {
      prompt(message, 'alert-warning', time);
  };

  // ä¿¡æ¯æç¤º
  var info_prompt = function(message, time)
  {
      prompt(message, 'alert-info', time);
  };

</script>


<!-- fancybox -->
<script src="https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js"></script>
<script>
  let LAZY_LOAD_IMAGE = "";
  $(".article-entry").find("fancybox").find("img").each(function () {
      var element = document.createElement("a");
      $(element).attr("data-fancybox", "gallery");
      $(element).attr("href", $(this).attr("src"));
      /* å›¾ç‰‡é‡‡ç”¨æ‡’åŠ è½½å¤„ç†æ—¶,
       * ä¸€èˆ¬å›¾ç‰‡æ ‡ç­¾å†…ä¼šæœ‰ä¸ªå±æ€§åæ¥å­˜æ”¾å›¾ç‰‡çš„çœŸå®åœ°å€ï¼Œæ¯”å¦‚ data-original,
       * é‚£ä¹ˆæ­¤å¤„å°†åŸæœ¬çš„å±æ€§åsrcæ›¿æ¢ä¸ºå¯¹åº”å±æ€§ådata-original,
       * ä¿®æ”¹å¦‚ä¸‹
       */
       if (LAZY_LOAD_IMAGE) {
         $(element).attr("href", $(this).attr("data-original"));
       }
      $(this).wrap(element);
  });
</script>





  <script>setLoadingBarProgress(100);</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>
</body>
</html>
