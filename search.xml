<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>卷积神经网络基础（CNN)</title>
      <link href="/2020/02/17/Deep_learning/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%EF%BC%88CNN)/"/>
      <url>/2020/02/17/Deep_learning/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%EF%BC%88CNN)/</url>
      
        <content type="html"><![CDATA[<h1 id="卷积神经网络基础"><a href="#卷积神经网络基础" class="headerlink" title="卷积神经网络基础"></a>卷积神经网络基础</h1><h3 id="二维互相关运算"><a href="#二维互相关运算" class="headerlink" title="二维互相关运算"></a>二维互相关运算</h3><p>虽然卷积层得名于卷积（convolution）运算，但我们通常在卷积层中使用更加直观的互相关（cross-correlation）运算。在二维卷积层中，一个二维输入数组和一个二维核（kernel）数组通过互相关运算输出一个二维数组。<br>我们用一个具体例子来解释二维互相关运算的含义。如图5.1所示，输入是一个高和宽均为3的二维数组。我们将该数组的形状记为$3 \times 3$或（3，3）。核数组的高和宽分别为2。该数组在卷积计算中又称卷积核或过滤器（filter）。卷积核窗口（又称卷积窗口）的形状取决于卷积核的高和宽，即$2 \times 2$。图5.1中的阴影部分为第一个输出元素及其计算所使用的输入和核数组元素：$0\times0+1\times1+3\times2+4\times3=19$。</p><div align=center><img width="250" src="https://cdn.kesci.com/upload/image/q5nfdbhcw5.png?imageView2/0/w/640/h/640"/></div><div align=center>图5.1 二维互相关运算</div><p>在二维互相关运算中，卷积窗口从输入数组的最左上方开始，按从左往右、从上往下的顺序，依次在输入数组上滑动。当卷积窗口滑动到某一位置时，窗口中的输入子数组与核数组按元素相乘并求和，得到输出数组中相应位置的元素。图5.1中的输出数组高和宽分别为2，其中的4个元素由二维互相关运算得出：</p><script type="math/tex; mode=display">0\times0+1\times1+3\times2+4\times3=19,\\1\times0+2\times1+4\times2+5\times3=25,\\3\times0+4\times1+6\times2+7\times3=37,\\4\times0+5\times1+7\times2+8\times3=43.\\</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 二维互相关运算核心示例</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch </span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">corr2d</span><span class="params">(X, K)</span>:</span></span><br><span class="line">    H, W = X.shape</span><br><span class="line">    h, w = K.shape</span><br><span class="line">    Y = torch.zeros(H - h + <span class="number">1</span>, W - w + <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(Y.shape[<span class="number">0</span>]):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(Y.shape[<span class="number">1</span>]):</span><br><span class="line">            Y[i, j] = (X[i: i + h, j: j + w] * K).sum()</span><br><span class="line">    <span class="keyword">return</span> Y</span><br></pre></td></tr></table></figure><h2 id="二维卷积层"><a href="#二维卷积层" class="headerlink" title="二维卷积层"></a>二维卷积层</h2><p>二维卷积层将输入和卷积核做互相关运算，并加上一个标量偏置来得到输出。卷积层的模型参数包括卷积核和标量偏置。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 二维卷积层的pytorch示例</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Conv2D</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, kernel_size)</span>:</span></span><br><span class="line">        super(Conv2D, self).__init__()</span><br><span class="line">        self.weight = nn.Parameter(torch.randn(kernel_size))</span><br><span class="line">        self.bias = nn.Parameter(torch.randn(<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> corr2d(x, self.weight) + self.bias</span><br></pre></td></tr></table></figure><h2 id="互相关运算与卷积运算"><a href="#互相关运算与卷积运算" class="headerlink" title="互相关运算与卷积运算"></a>互相关运算与卷积运算</h2><p>实际上，卷积运算与互相关运算类似。<strong>为了得到卷积运算的输出，我们只需将核数组左右翻转并上下翻转，再与输入数组做互相关运算</strong>。可见，卷积运算和互相关运算虽然类似，但如果它们使用相同的核数组，对于同一个输入，输出往往并不相同。</p><p>那么，你也许会好奇卷积层为何能使用互相关运算替代卷积运算。其实，在深度学习中核数组都是学出来的：卷积层无论使用互相关运算或卷积运算都不影响模型预测时的输出。为了解释这一点，假设卷积层使用互相关运算学出图5.1中的核数组。设其他条件不变，使用卷积运算学出的核数组即图5.1中的核数组按上下、左右翻转。也就是说，输入与学出的已翻转的核数组再做卷积运算时，依然得到图5.1中的输出。为了与大多数深度学习文献一致，如无特别说明，本书中提到的卷积运算均指互相关运算。</p><h2 id="特征图和感受野"><a href="#特征图和感受野" class="headerlink" title="特征图和感受野"></a>特征图和感受野</h2><p>二维卷积层输出的二维数组可以看作是输入在空间维度（宽和高）上某一级的表征，也叫特征图（feature map）。影响元素$x$的前向计算的所有可能输入区域（可能大于输入的实际尺寸）叫做$x$的感受野（receptive field）。以图5.1为例，输入中阴影部分的四个元素是输出中阴影部分元素的感受野。我们将图5.1中形状为$2 \times 2$的输出记为$Y$，并考虑一个更深的卷积神经网络：将$Y$与另一个形状为$2 \times 2$的核数组做互相关运算，输出单个元素$z$。那么，$z$在$Y$上的感受野包括$Y$的全部四个元素，在输入上的感受野包括其中全部9个元素。可见，我们可以通过更深的卷积神经网络使特征图中单个元素的感受野变得更加广阔，从而捕捉输入上更大尺寸的特征。</p><p>我们常使用“元素”一词来描述数组或矩阵中的成员。在神经网络的术语中，这些元素也可称为“单元”。当含义明确时，本书不对这两个术语做严格区分。</p><h2 id="填充和步幅"><a href="#填充和步幅" class="headerlink" title="填充和步幅"></a>填充和步幅</h2><p>我们使用高和宽为3的输入与高和宽为2的卷积核得到高和宽为2的输出。一般来说，假设输入形状是$n_h\times n_w$，卷积核窗口形状是$k_h\times k_w$，那么输出形状将会是</p><script type="math/tex; mode=display">(n_h-k_h+1) \times (n_w-k_w+1).</script><p>所以卷积层的输出形状由输入形状和卷积核窗口形状决定。本节我们将介绍卷积层的两个超参数，即填充和步幅。它们可以对给定形状的输入和卷积核改变输出形状。</p><h3 id="填充"><a href="#填充" class="headerlink" title="填充"></a>填充</h3><p>填充（padding）是指在输入高和宽的两侧填充元素（通常是0元素），图2里我们在原输入高和宽的两侧分别添加了值为0的元素。</p><div align='center'><img src="https://cdn.kesci.com/upload/image/q5nfl6ejy4.png?imageView2/0/w/640/h/640"></img>    </div><p>一般来说，如果在高的两侧一共填充$p_h$行，在宽的两侧一共填充$p_w$列，那么输出形状将会是</p><script type="math/tex; mode=display">(n_h-k_h+p_h+1)\times(n_w-k_w+p_w+1),</script><p>也就是说，输出的高和宽会分别增加$p_h$和$p_w$。</p><p>在很多情况下，我们会设置$p_h=k_h-1$和$p_w=k_w-1$来使输入和输出具有相同的高和宽。这样会方便在构造网络时推测每个层的输出形状。假设这里$k_h$是奇数，我们会在高的两侧分别填充$p_h/2$行。如果$k_h$是偶数，一种可能是在输入的顶端一侧填充$\lceil p_h/2\rceil$行，而在底端一侧填充$\lfloor p_h/2\rfloor$行。在宽的两侧填充同理。</p><p>卷积神经网络经常使用奇数高宽的卷积核，如1、3、5和7，所以两端上的填充个数相等。对任意的二维数组<code>X</code>，设它的第<code>i</code>行第<code>j</code>列的元素为<code>X[i,j]</code>。当两端上的填充个数相等，并使输入和输出具有相同的高和宽时，我们就知道输出<code>Y[i,j]</code>是由输入以<code>X[i,j]</code>为中心的窗口同卷积核进行互相关计算得到的。</p><h3 id="步幅"><a href="#步幅" class="headerlink" title="步幅"></a>步幅</h3><p>卷积窗口从输入数组的最左上方开始，按从左往右、从上往下的顺序，依次在输入数组上滑动。我们将每次滑动的行数和列数称为步幅（stride）。</p><p>目前我们看到的例子里，在高和宽两个方向上步幅均为1。我们也可以使用更大步幅。图5.3展示了在高上步幅为3、在宽上步幅为2的二维互相关运算。可以看到，输出第一列第二个元素时，卷积窗口向下滑动了3行，而在输出第一行第二个元素时卷积窗口向右滑动了2列。当卷积窗口在输入上再向右滑动2列时，由于输入元素无法填满窗口，无结果输出。图5.3中的阴影部分为输出元素及其计算所使用的输入和核数组元素：$0\times0+0\times1+1\times2+2\times3=8$、$0\times0+6\times1+0\times2+0\times3=6$。</p><div align=center><img width="400" src="https://cdn.kesci.com/upload/image/q5nflohnqg.png?imageView2/0/w/640/h/640"/></div><div align=center>高和宽上步幅分别为3和2的二维互相关运算</div><p>一般来说，当高上步幅为$s_h$，宽上步幅为$s_w$时，输出形状为</p><script type="math/tex; mode=display">\lfloor(n_h-k_h+p_h+s_h)/s_h\rfloor \times \lfloor(n_w-k_w+p_w+s_w)/s_w\rfloor.</script><p>如果设置$p_h=k_h-1$和$p_w=k_w-1$，那么输出形状将简化为$\lfloor(n_h+s_h-1)/s_h\rfloor \times \lfloor(n_w+s_w-1)/s_w\rfloor$。更进一步，如果输入的高和宽能分别被高和宽上的步幅整除，那么输出形状将是$(n_h/s_h) \times (n_w/s_w)$。</p><h2 id="多输入通道和多输出通道"><a href="#多输入通道和多输出通道" class="headerlink" title="多输入通道和多输出通道"></a>多输入通道和多输出通道</h2><p>输入和输出都是二维数组，但真实数据的维度经常更高。例如，彩色图像在高和宽2个维度外还有RGB（红、绿、蓝）3个颜色通道。假设彩色图像的高和宽分别是$h$和$w$（像素），那么它可以表示为一个$3\times h\times w$的多维数组。我们将大小为3的这一维称为通道（channel）维。本节我们将介绍含多个输入通道或多个输出通道的卷积核。</p><h3 id="多输入通道"><a href="#多输入通道" class="headerlink" title="多输入通道"></a>多输入通道</h3><p>当输入数据含多个通道时，我们需要构造一个输入通道数与输入数据的通道数相同的卷积核，从而能够与含多通道的输入数据做互相关运算。假设输入数据的通道数为$c_i$，那么卷积核的输入通道数同样为$c_i$。设卷积核窗口形状为$k_h\times k_w$。当$c_i=1$时，我们知道卷积核只包含一个形状为$k_h\times k_w$的二维数组。当$c_i &gt; 1$时，我们将会为每个输入通道各分配一个形状为$k_h\times k_w$的核数组。把这$c_i$个数组在输入通道维上连结，即得到一个形状为$c_i\times k_h\times k_w$的卷积核。由于输入和卷积核各有$c_i$个通道，我们可以在各个通道上对输入的二维数组和卷积核的二维核数组做互相关运算，再将这$c_i$个互相关运算的二维输出按通道相加，得到一个二维数组。这就是含多个通道的输入数据与多输入通道的卷积核做二维互相关运算的输出。</p><p>图5.4展示了含2个输入通道的二维互相关计算的例子。在每个通道上，二维输入数组与二维核数组做互相关运算，再按通道相加即得到输出。图5.4中阴影部分为第一个输出元素及其计算所使用的输入和核数组元素：$(1\times1+2\times2+4\times3+5\times4)+(0\times0+1\times1+3\times2+4\times3)=56$。</p><div align=center><img width="400" src="https://cdn.kesci.com/upload/image/q5nfmdnwbq.png?imageView2/0/w/640/h/640"/></div><div align=center>图5.4 含2个输入通道的互相关计算</div><h3 id="多输出通道"><a href="#多输出通道" class="headerlink" title="多输出通道"></a>多输出通道</h3><p>当输入通道有多个时，因为我们对各个通道的结果做了累加，所以不论输入通道数是多少，输出通道数总是为1。设卷积核输入通道数和输出通道数分别为$c_i$和$c_o$，高和宽分别为$k_h$和$k_w$。如果希望得到含多个通道的输出，我们可以为每个输出通道分别创建形状为$c_i\times k_h\times k_w$的核数组。将它们在输出通道维上连结，卷积核的形状即$c_o\times c_i\times k_h\times k_w$。在做互相关运算时，每个输出通道上的结果由卷积核在该输出通道上的核数组与整个输入数组计算而来。</p><h2 id="1x1卷积层"><a href="#1x1卷积层" class="headerlink" title="1x1卷积层"></a>1x1卷积层</h2><p>卷积窗口形状为$1\times 1$（$k_h=k_w=1$）的多通道卷积层。我们通常称之为$1\times 1$卷积层，并将其中的卷积运算称为$1\times 1$卷积。因为使用了最小窗口，$1\times 1$卷积失去了卷积层可以识别高和宽维度上相邻元素构成的模式的功能。实际上，$1\times 1$卷积的主要计算发生在通道维上。图5.5展示了使用输入通道数为3、输出通道数为2的$1\times 1$卷积核的互相关计算。值得注意的是，输入和输出具有相同的高和宽。输出中的每个元素来自输入中在高和宽上相同位置的元素在不同通道之间的按权重累加。假设我们将通道维当作特征维，将高和宽维度上的元素当成数据样本，<strong>那么$1\times 1$卷积层的作用与全连接层等价</strong>。</p><div align=center><img width="400" src="https://cdn.kesci.com/upload/image/q5nfmq980r.png?imageView2/0/w/640/h/640"/></div><div align=center> 1x1卷积核的互相关计算。输入和输出具有相同的高和宽</div><h2 id="卷积层与全连接层的比较"><a href="#卷积层与全连接层的比较" class="headerlink" title="卷积层与全连接层的比较"></a>卷积层与全连接层的比较</h2><p>二维卷积层经常用于处理图像，与此前的全连接层相比，它主要有两个优势：</p><ul><li><p>一是全连接层把图像展平成一个向量，在输入图像上相邻的元素可能因为展平操作不再相邻，网络难以捕捉局部信息。而卷积层的设计，天然地具有提取局部信息的能力。</p></li><li><p>二是卷积层的参数量更少。使用卷积层可以以较少的参数数量来处理更大的图像。</p></li></ul><h2 id="卷积层的pytorch实现"><a href="#卷积层的pytorch实现" class="headerlink" title="卷积层的pytorch实现"></a>卷积层的pytorch实现</h2><ul><li>in_channels (python:int) – Number of channels in the input imag</li><li>out_channels (python:int) – Number of channels produced by the convolution</li><li>kernel_size (python:int or tuple) – Size of the convolving kernel</li><li>stride (python:int or tuple, optional) – Stride of the convolution. Default: 1</li><li>padding (python:int or tuple, optional) – Zero-padding added to both sides of the input. Default: 0</li><li>bias (bool, optional) – If True, adds a learnable bias to the output. Default: True</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">X = torch.rand(<span class="number">4</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">5</span>)</span><br><span class="line">print(X.shape)</span><br><span class="line"></span><br><span class="line">conv2d = nn.Conv2d(in_channels=<span class="number">2</span>, out_channels=<span class="number">3</span>, kernel_size=(<span class="number">3</span>, <span class="number">5</span>), stride=<span class="number">1</span>, padding=(<span class="number">1</span>, <span class="number">2</span>))</span><br><span class="line">Y = conv2d(X)</span><br><span class="line">print(<span class="string">'Y.shape: '</span>, Y.shape)</span><br><span class="line">print(<span class="string">'weight.shape: '</span>, conv2d.weight.shape)</span><br><span class="line">print(<span class="string">'bias.shape: '</span>, conv2d.bias.shape)</span><br></pre></td></tr></table></figure><h2 id="池化层"><a href="#池化层" class="headerlink" title="池化层"></a>池化层</h2><h3 id="二维池化层"><a href="#二维池化层" class="headerlink" title="二维池化层"></a>二维池化层</h3><ul><li>二维最大池化层<br>同卷积层一样，池化层每次对输入数据的一个固定形状窗口（又称池化窗口）中的元素计算输出。不同于卷积层里计算输入和核的互相关性，池化层直接计算池化窗口内元素的最大值或者平均值。该运算也分别叫做最大池化或平均池化。在二维最大池化中，池化窗口从输入数组的最左上方开始，按从左往右、从上往下的顺序，依次在输入数组上滑动。当池化窗口滑动到某一位置时，窗口中的输入子数组的最大值即输出数组中相应位置的元素。<br><div align=center><img width="300" src="https://cdn.kesci.com/upload/image/q5nfob3odo.png?imageView2/0/w/640/h/640"/></div><br><div align=center>图5.6 池化窗口形状为 2 x 2 的最大池化</div><br>池化窗口形状为$2\times 2$的最大池化，阴影部分为第一个输出元素及其计算所使用的输入元素。输出数组的高和宽分别为2，其中的4个元素由取最大值运算$\text{max}$得出：</li></ul><script type="math/tex; mode=display">\max(0,1,3,4)=4,\\\max(1,2,4,5)=5,\\\max(3,4,6,7)=7,\\\max(4,5,7,8)=8.\\</script><ul><li>二维平均池化层</li></ul><p>二维平均池化的工作原理与二维最大池化类似，但将最大运算符替换成平均运算符。池化窗口形状为$p \times q$的池化层称为$p \times q$池化层，其中的池化运算叫作$p \times q$池化。</p><p>让我们再次回到本节开始提到的物体边缘检测的例子。现在我们将卷积层的输出作为$2\times 2$最大池化的输入。设该卷积层输入是<code>X</code>、池化层输出为<code>Y</code>。无论是<code>X[i, j]</code>和<code>X[i, j+1]</code>值不同，还是<code>X[i, j+1]</code>和<code>X[i, j+2]</code>不同，池化层输出均有<code>Y[i, j]=1</code>。也就是说，使用$2\times 2$最大池化层时，只要卷积层识别的模式在高和宽上移动不超过一个元素，我们依然可以将它检测出来。</p><h3 id="池化层的pytorch实现"><a href="#池化层的pytorch实现" class="headerlink" title="池化层的pytorch实现"></a>池化层的pytorch实现</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">X = torch.arange(<span class="number">32</span>, dtype=torch.float32).view(<span class="number">1</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 平均池化层使用的是nn.AvgPool2d，使用方法与nn.MaxPool2d相同。</span></span><br><span class="line"></span><br><span class="line">pool2d = nn.MaxPool2d(kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>, stride=(<span class="number">2</span>, <span class="number">1</span>))</span><br><span class="line">Y = pool2d(X)</span><br><span class="line">print(X)</span><br><span class="line">print(Y)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> deep_learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>注意力机制（Attention)</title>
      <link href="/2020/02/16/Deep_learning/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/"/>
      <url>/2020/02/16/Deep_learning/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/</url>
      
        <content type="html"><![CDATA[<h1 id="注意力机制"><a href="#注意力机制" class="headerlink" title="注意力机制"></a>注意力机制</h1><p>在“编码器—解码器（seq2seq）”⼀节⾥，解码器在各个时间步依赖相同的背景变量（context vector）来获取输⼊序列信息。当编码器为循环神经⽹络时，背景变量来⾃它最终时间步的隐藏状态。将源序列输入信息以循环单位状态编码，然后将其传递给解码器以生成目标序列。然而这种结构存在着问题，尤其是RNN机制实际中存在长程梯度消失的问题，对于较长的句子，我们很难寄希望于将输入的序列转化为定长的向量而保存所有的有效信息，所以随着所需翻译句子的长度的增加，这种结构的效果会显著下降。</p><p>与此同时，解码的目标词语可能只与原输入的部分词语有关，而并不是与所有的输入有关。例如，当把“Hello world”翻译成“Bonjour le monde”时，“Hello”映射成“Bonjour”，“world”映射成“monde”。在seq2seq模型中，解码器只能隐式地从编码器的最终状态中选择相应的信息。然而，注意力机制可以将这种选择过程显式地建模。<br><img src="https://img-blog.csdnimg.cn/20200216222846156.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDU3ODAzMg==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h2 id="注意力机制框架"><a href="#注意力机制框架" class="headerlink" title="注意力机制框架"></a>注意力机制框架</h2><p>Attention 是一种通用的带权池化方法，输入由两部分构成：询问（query）和键值对（key-value pairs）。 Query  , attention layer得到输出与value的维度一致 . 对于一个query来说，attention layer 会与每一个key计算注意力分数并进行权重的归一化，输出的向量则是value的加权求和，而每个key计算的权重与value一一对应。</p><p>为了计算输出，我们首先假设有一个函数 用于计算query和key的相似性，然后可以计算所有的 attention scores ${a_1, \ldots, a_n }$by</p><script type="math/tex; mode=display">a_i = \alpha(\mathbf q, \mathbf k_i)</script><p>我们使用 softmax函数 获得注意力权重：</p><script type="math/tex; mode=display">b_1, \ldots, b_n = \textrm{softmax}(a_1, \ldots, a_n)</script><p>最终的输出就是value的加权求和：</p><script type="math/tex; mode=display">\mathbf o = \sum_{i=1}^n b_i \mathbf v_i</script><p><img src="https://img-blog.csdnimg.cn/20200216224849212.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDU3ODAzMg==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><p>不同的attetion layer的区别在于score函数的选择，在本节的其余部分，我们将讨论两个常用的注意层 Dot-product Attention 和 Multilayer Perceptron Attention；随后我们将实现一个引入attention的seq2seq模型并在英法翻译语料上进行训练与测试。</p><h3 id="softmax的屏蔽"><a href="#softmax的屏蔽" class="headerlink" title="softmax的屏蔽"></a>softmax的屏蔽</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">SequenceMask</span><span class="params">(X, X_len,value=<span class="number">-1e6</span>)</span>:</span></span><br><span class="line">    maxlen = X.size(<span class="number">1</span>)</span><br><span class="line">    <span class="comment">#print(X.size(),torch.arange((maxlen),dtype=torch.float)[None, :],'\n',X_len[:, None] )</span></span><br><span class="line">    mask = torch.arange((maxlen),dtype=torch.float)[<span class="literal">None</span>, :] &gt;= X_len[:, <span class="literal">None</span>]   </span><br><span class="line">    <span class="comment">#print(mask)</span></span><br><span class="line">    X[mask]=value</span><br><span class="line">    <span class="keyword">return</span> X</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">masked_softmax</span><span class="params">(X, valid_length)</span>:</span></span><br><span class="line">    <span class="comment"># X: 3-D tensor, valid_length: 1-D or 2-D tensor</span></span><br><span class="line">    softmax = nn.Softmax(dim=<span class="number">-1</span>)</span><br><span class="line">    <span class="keyword">if</span> valid_length <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">return</span> softmax(X)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        shape = X.shape</span><br><span class="line">        <span class="keyword">if</span> valid_length.dim() == <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                valid_length = torch.FloatTensor(valid_length.numpy().repeat(shape[<span class="number">1</span>], axis=<span class="number">0</span>))<span class="comment">#[2,2,3,3]</span></span><br><span class="line">            <span class="keyword">except</span>:</span><br><span class="line">                valid_length = torch.FloatTensor(valid_length.cpu().numpy().repeat(shape[<span class="number">1</span>], axis=<span class="number">0</span>))<span class="comment">#[2,2,3,3]</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            valid_length = valid_length.reshape((<span class="number">-1</span>,))</span><br><span class="line">        <span class="comment"># fill masked elements with a large negative, whose exp is 0</span></span><br><span class="line">        X = SequenceMask(X.reshape((<span class="number">-1</span>, shape[<span class="number">-1</span>])), valid_length)</span><br><span class="line"> </span><br><span class="line">        <span class="keyword">return</span> softmax(X).reshape(shape)</span><br><span class="line"></span><br><span class="line">masked_softmax(torch.rand((<span class="number">2</span>,<span class="number">2</span>,<span class="number">4</span>),dtype=torch.float), torch.FloatTensor([<span class="number">2</span>,<span class="number">3</span>]))</span><br></pre></td></tr></table></figure><h3 id="超出二维矩阵的乘法"><a href="#超出二维矩阵的乘法" class="headerlink" title="超出二维矩阵的乘法"></a>超出二维矩阵的乘法</h3><p> X和  Y是维度分别为(b,n,m)和(b, m, k)的张量，进行 b次二维矩阵乘法后得到 , 维度为 (b, n, k)。</p><script type="math/tex; mode=display">Z[i,:,:] = dot(X[i,:,:], Y[i,:,:])\qquad for\ i= 1,…,n\</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.bmm(torch.ones((<span class="number">2</span>,<span class="number">1</span>,<span class="number">3</span>), dtype = torch.float), torch.ones((<span class="number">2</span>,<span class="number">3</span>,<span class="number">2</span>), dtype = torch.float))</span><br></pre></td></tr></table></figure><h2 id="点积注意力"><a href="#点积注意力" class="headerlink" title="点积注意力"></a>点积注意力</h2><p>The dot product 假设query和keys有相同的维度, 即 . 通过计算query和key转置的乘积来计算attention score,通常还会除去sqrt{d}减少计算出来的score对维度𝑑的依赖性，如下<br>𝛼(𝐪,𝐤)=⟨𝐪,𝐤⟩/ \sqrt{d}<br>假设𝐐∈ℝ^{𝑚×𝑑}有m个query， 有n个keys. 我们可以通过矩阵运算的方式计算所有mn个score：<br>𝛼(𝐐,𝐊)=𝐐𝐊^𝑇/\sqrt{d}<br>现在让我们实现这个层，它支持一批查询和键值对。此外，它支持作为正则化随机删除一些注意力权重.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DotProductAttention</span><span class="params">(nn.Module)</span>:</span> </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, dropout, **kwargs)</span>:</span></span><br><span class="line">        super(DotProductAttention, self).__init__(**kwargs)</span><br><span class="line">        self.dropout = nn.Dropout(dropout)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># query: (batch_size, #queries, d)</span></span><br><span class="line">    <span class="comment"># key: (batch_size, #kv_pairs, d)</span></span><br><span class="line">    <span class="comment"># value: (batch_size, #kv_pairs, dim_v)</span></span><br><span class="line">    <span class="comment"># valid_length: either (batch_size, ) or (batch_size, xx)</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, query, key, value, valid_length=None)</span>:</span></span><br><span class="line">        d = query.shape[<span class="number">-1</span>]</span><br><span class="line">        <span class="comment"># set transpose_b=True to swap the last two dimensions of key</span></span><br><span class="line">        </span><br><span class="line">        scores = torch.bmm(query, key.transpose(<span class="number">1</span>,<span class="number">2</span>)) / math.sqrt(d)</span><br><span class="line">        attention_weights = self.dropout(masked_softmax(scores, valid_length))</span><br><span class="line">        print(<span class="string">"attention_weight\n"</span>,attention_weights)</span><br><span class="line">        <span class="keyword">return</span> torch.bmm(attention_weights, value)</span><br></pre></td></tr></table></figure><h2 id="多层感知机注意力"><a href="#多层感知机注意力" class="headerlink" title="多层感知机注意力"></a>多层感知机注意力</h2><p>将score函数定义:</p><script type="math/tex; mode=display">a(\boldsymbol{s}, \boldsymbol{h}) = \boldsymbol{v}^\top \tanh(\boldsymbol{W}_s \boldsymbol{s} + \boldsymbol{W}_h \boldsymbol{h}),</script><p>. 然后将key 和 value 在特征的维度上合并（concatenate），然后送至 a single hidden layer perceptron 这层中 hidden layer 为 ℎ and 输出的size为 1 .隐层激活函数为tanh，无偏置.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Save to the d2l package.</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MLPAttention</span><span class="params">(nn.Module)</span>:</span>  </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, units,ipt_dim,dropout, **kwargs)</span>:</span></span><br><span class="line">        super(MLPAttention, self).__init__(**kwargs)</span><br><span class="line">        <span class="comment"># Use flatten=True to keep query's and key's 3-D shapes.</span></span><br><span class="line">        self.W_k = nn.Linear(ipt_dim, units, bias=<span class="literal">False</span>)</span><br><span class="line">        self.W_q = nn.Linear(ipt_dim, units, bias=<span class="literal">False</span>)</span><br><span class="line">        self.v = nn.Linear(units, <span class="number">1</span>, bias=<span class="literal">False</span>)</span><br><span class="line">        self.dropout = nn.Dropout(dropout)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, query, key, value, valid_length)</span>:</span></span><br><span class="line">        query, key = self.W_k(query), self.W_q(key)</span><br><span class="line">        <span class="comment">#print("size",query.size(),key.size())</span></span><br><span class="line">        <span class="comment"># expand query to (batch_size, #querys, 1, units), and key to</span></span><br><span class="line">        <span class="comment"># (batch_size, 1, #kv_pairs, units). Then plus them with broadcast.</span></span><br><span class="line">        features = query.unsqueeze(<span class="number">2</span>) + key.unsqueeze(<span class="number">1</span>)</span><br><span class="line">        <span class="comment">#print("features:",features.size())  #--------------开启</span></span><br><span class="line">        scores = self.v(features).squeeze(<span class="number">-1</span>) </span><br><span class="line">        attention_weights = self.dropout(masked_softmax(scores, valid_length))</span><br><span class="line">        <span class="keyword">return</span> torch.bmm(attention_weights, value)</span><br></pre></td></tr></table></figure><h3 id="计算背景变量"><a href="#计算背景变量" class="headerlink" title="计算背景变量"></a>计算背景变量</h3><p>我们先描述第一个关键点，即计算背景变量。图描绘了注意力机制如何为解码器在时间步2计算背景变量。首先，函数$a$根据解码器在时间步1的隐藏状态和编码器在各个时间步的隐藏状态计算softmax运算的输入。softmax运算输出概率分布并对编码器各个时间步的隐藏状态做加权平均，从而得到背景变量。<br><img src="https://img-blog.csdnimg.cn/20200216230638792.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDU3ODAzMg==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><p>具体来说，令编码器在时间步$t$的隐藏状态为$\boldsymbol{h}_t$，且总时间步数为$T$。那么解码器在时间步$t’$的背景变量为所有编码器隐藏状态的加权平均：</p><script type="math/tex; mode=display">\boldsymbol{c}_{t'} = \sum_{t=1}^T \alpha_{t' t} \boldsymbol{h}_t,</script><p>其中给定$t’$时，权重$\alpha_{t’ t}$在$t=1,\ldots,T$的值是一个概率分布。为了得到概率分布，我们可以使用softmax运算:</p><script type="math/tex; mode=display">\alpha_{t' t} = \frac{\exp(e_{t' t})}{ \sum_{k=1}^T \exp(e_{t' k}) },\quad t=1,\ldots,T.</script><p>现在，我们需要定义如何计算上式中softmax运算的输入$e_{t’ t}$。由于$e_{t’ t}$同时取决于解码器的时间步$t’$和编码器的时间步$t$，我们不妨以解码器在时间步$t’-1$的隐藏状态$\boldsymbol{s}_{t’ - 1}$与编码器在时间步$t$的隐藏状态$\boldsymbol{h}_t$为输入，并通过函数$a$计算$e_{t’ t}$：</p><script type="math/tex; mode=display">e_{t' t} = a(\boldsymbol{s}_{t' - 1}, \boldsymbol{h}_t).</script><p>这里函数$a$有多种选择，如果两个输入向量长度相同，一个简单的选择是计算它们的内积$a(\boldsymbol{s}, \boldsymbol{h})=\boldsymbol{s}^\top \boldsymbol{h}$。而最早提出注意力机制的论文则将输入连结后通过含单隐藏层的多层感知机变换 [1]：</p><script type="math/tex; mode=display">a(\boldsymbol{s}, \boldsymbol{h}) = \boldsymbol{v}^\top \tanh(\boldsymbol{W}_s \boldsymbol{s} + \boldsymbol{W}_h \boldsymbol{h}),</script><p>其中$\boldsymbol{v}$、$\boldsymbol{W}_s$、$\boldsymbol{W}_h$都是可以学习的模型参数。</p><h3 id="矢量化计算"><a href="#矢量化计算" class="headerlink" title="矢量化计算"></a>矢量化计算</h3><p>我们还可以对注意力机制采用更高效的矢量化计算。广义上，注意力机制的输入包括查询项以及一一对应的键项和值项，其中值项是需要加权平均的一组项。在加权平均中，值项的权重来自查询项以及与该值项对应的键项的计算。</p><p>在上面的例子中，查询项为解码器的隐藏状态，键项和值项均为编码器的隐藏状态。<br>让我们考虑一个常见的简单情形，即编码器和解码器的隐藏单元个数均为$h$，且函数$a(\boldsymbol{s}, \boldsymbol{h})=\boldsymbol{s}^\top \boldsymbol{h}$。假设我们希望根据解码器单个隐藏状态$\boldsymbol{s}_{t’ - 1} \in \mathbb{R}^{h}$和编码器所有隐藏状态$\boldsymbol{h}_t \in \mathbb{R}^{h}, t = 1,\ldots,T$来计算背景向量$\boldsymbol{c}_{t’}\in \mathbb{R}^{h}$。<br>我们可以将查询项矩阵$\boldsymbol{Q} \in \mathbb{R}^{1 \times h}$设为$\boldsymbol{s}_{t’ - 1}^\top$，并令键项矩阵$\boldsymbol{K} \in \mathbb{R}^{T \times h}$和值项矩阵$\boldsymbol{V} \in \mathbb{R}^{T \times h}$相同且第$t$行均为$\boldsymbol{h}_t^\top$。此时，我们只需要通过矢量化计算</p><script type="math/tex; mode=display">\text{softmax}(\boldsymbol{Q}\boldsymbol{K}^\top)\boldsymbol{V}</script><p>即可算出转置后的背景向量$\boldsymbol{c}_{t’}^\top$。当查询项矩阵$\boldsymbol{Q}$的行数为$n$时，上式将得到$n$行的输出矩阵。输出矩阵与查询项矩阵在相同行上一一对应。</p><h2 id="引入注意力机制的S2S"><a href="#引入注意力机制的S2S" class="headerlink" title="引入注意力机制的S2S"></a>引入注意力机制的S2S</h2><p>本节中将注意机制添加到sequence to sequence 模型中，以显式地使用权重聚合states。下图展示encoding 和decoding的模型结构，在时间步为t的时候。此刻attention layer保存着encodering看到的所有信息——即encoding的每一步输出。在decoding阶段，解码器的时刻的隐藏状态被当作query，encoder的每个时间步的hidden states作为key和value进行attention聚合. Attetion model的输出当作成上下文信息context vector，并与解码器输入拼接起来一起送到解码器：<br><img src="https://img-blog.csdnimg.cn/2020021623101586.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDU3ODAzMg==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>下图展示了seq2seq机制的所以层的关系，下面展示了encoder和decoder的layer结构<br><img src="https://img-blog.csdnimg.cn/20200216231034160.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDU3ODAzMg==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h3 id="Decoder"><a href="#Decoder" class="headerlink" title="Decoder"></a>Decoder</h3><p>由于带有注意机制的seq2seq的编码器与之前章节中的Seq2SeqEncoder相同，所以在此处我们只关注解码器。我们添加了一个MLP注意层(MLPAttention)，它的隐藏大小与解码器中的LSTM层相同。然后我们通过从编码器传递三个参数来初始化解码器的状态:</p><ul><li>the encoder outputs of all timesteps：encoder输出的各个状态，被用于attetion layer的memory部分，有相同的key和values</li><li>the hidden state of the encoder’s final timestep：编码器最后一个时间步的隐藏状态，被用于初始化decoder 的hidden state</li><li>the encoder valid length: 编码器的有效长度，借此，注意层不会考虑编码器输出中的填充标记（Paddings）  </li></ul><p>在解码的每个时间步，我们使用解码器的最后一个RNN层的输出作为注意层的query。然后，将注意力模型的输出与输入嵌入向量连接起来，输入到RNN层。虽然RNN层隐藏状态也包含来自解码器的历史信息，但是attention model的输出显式地选择了enc_valid_len以内的编码器输出，这样attention机制就会尽可能排除其他不相关的信息。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Seq2SeqAttentionDecoder</span><span class="params">(d2l.Decoder)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, vocab_size, embed_size, num_hiddens, num_layers,</span></span></span><br><span class="line"><span class="function"><span class="params">                 dropout=<span class="number">0</span>, **kwargs)</span>:</span></span><br><span class="line">        super(Seq2SeqAttentionDecoder, self).__init__(**kwargs)</span><br><span class="line">        self.attention_cell = MLPAttention(num_hiddens,num_hiddens, dropout)</span><br><span class="line">        self.embedding = nn.Embedding(vocab_size, embed_size)</span><br><span class="line">        self.rnn = nn.LSTM(embed_size+ num_hiddens,num_hiddens, num_layers, dropout=dropout)</span><br><span class="line">        self.dense = nn.Linear(num_hiddens,vocab_size)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">init_state</span><span class="params">(self, enc_outputs, enc_valid_len, *args)</span>:</span></span><br><span class="line">        outputs, hidden_state = enc_outputs</span><br><span class="line"><span class="comment">#         print("first:",outputs.size(),hidden_state[0].size(),hidden_state[1].size())</span></span><br><span class="line">        <span class="comment"># Transpose outputs to (batch_size, seq_len, hidden_size)</span></span><br><span class="line">        <span class="keyword">return</span> (outputs.permute(<span class="number">1</span>,<span class="number">0</span>,<span class="number">-1</span>), hidden_state, enc_valid_len)</span><br><span class="line">        <span class="comment">#outputs.swapaxes(0, 1)</span></span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, X, state)</span>:</span></span><br><span class="line">        enc_outputs, hidden_state, enc_valid_len = state</span><br><span class="line">        <span class="comment">#("X.size",X.size())</span></span><br><span class="line">        X = self.embedding(X).transpose(<span class="number">0</span>,<span class="number">1</span>)</span><br><span class="line"><span class="comment">#         print("Xembeding.size2",X.size())</span></span><br><span class="line">        outputs = []</span><br><span class="line">        <span class="keyword">for</span> l, x <span class="keyword">in</span> enumerate(X):</span><br><span class="line"><span class="comment">#             print(f"\n&#123;l&#125;-th token")</span></span><br><span class="line"><span class="comment">#             print("x.first.size()",x.size())</span></span><br><span class="line">            <span class="comment"># query shape: (batch_size, 1, hidden_size)</span></span><br><span class="line">            <span class="comment"># select hidden state of the last rnn layer as query</span></span><br><span class="line">            query = hidden_state[<span class="number">0</span>][<span class="number">-1</span>].unsqueeze(<span class="number">1</span>) <span class="comment"># np.expand_dims(hidden_state[0][-1], axis=1)</span></span><br><span class="line">            <span class="comment"># context has same shape as query</span></span><br><span class="line"><span class="comment">#             print("query enc_outputs, enc_outputs:\n",query.size(), enc_outputs.size(), enc_outputs.size())</span></span><br><span class="line">            context = self.attention_cell(query, enc_outputs, enc_outputs, enc_valid_len)</span><br><span class="line">            <span class="comment"># Concatenate on the feature dimension</span></span><br><span class="line"><span class="comment">#             print("context.size:",context.size())</span></span><br><span class="line">            x = torch.cat((context, x.unsqueeze(<span class="number">1</span>)), dim=<span class="number">-1</span>)</span><br><span class="line">            <span class="comment"># Reshape x to (1, batch_size, embed_size+hidden_size)</span></span><br><span class="line"><span class="comment">#             print("rnn",x.size(), len(hidden_state))</span></span><br><span class="line">            out, hidden_state = self.rnn(x.transpose(<span class="number">0</span>,<span class="number">1</span>), hidden_state)</span><br><span class="line">            outputs.append(out)</span><br><span class="line">        outputs = self.dense(torch.cat(outputs, dim=<span class="number">0</span>))</span><br><span class="line">        <span class="keyword">return</span> outputs.transpose(<span class="number">0</span>, <span class="number">1</span>), [enc_outputs, hidden_state,</span><br><span class="line">                                        enc_valid_len]</span><br><span class="line"></span><br><span class="line">encoder = d2l.Seq2SeqEncoder(vocab_size=<span class="number">10</span>, embed_size=<span class="number">8</span>,</span><br><span class="line">                            num_hiddens=<span class="number">16</span>, num_layers=<span class="number">2</span>)</span><br><span class="line"><span class="comment"># encoder.initialize()</span></span><br><span class="line">decoder = Seq2SeqAttentionDecoder(vocab_size=<span class="number">10</span>, embed_size=<span class="number">8</span>,</span><br><span class="line">                                  num_hiddens=<span class="number">16</span>, num_layers=<span class="number">2</span>)</span><br><span class="line">X = torch.zeros((<span class="number">4</span>, <span class="number">7</span>),dtype=torch.long)</span><br><span class="line">print(<span class="string">"batch size=4\nseq_length=7\nhidden dim=16\nnum_layers=2\n"</span>)</span><br><span class="line">print(<span class="string">'encoder output size:'</span>, encoder(X)[<span class="number">0</span>].size())</span><br><span class="line">print(<span class="string">'encoder hidden size:'</span>, encoder(X)[<span class="number">1</span>][<span class="number">0</span>].size())</span><br><span class="line">print(<span class="string">'encoder memory size:'</span>, encoder(X)[<span class="number">1</span>][<span class="number">1</span>].size())</span><br><span class="line">state = decoder.init_state(encoder(X), <span class="literal">None</span>)</span><br><span class="line">out, state = decoder(X, state)</span><br><span class="line">out.shape, len(state), state[<span class="number">0</span>].shape, len(state[<span class="number">1</span>]), state[<span class="number">1</span>][<span class="number">0</span>].shape</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> deep_learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>模型选择与过拟合与欠拟合</title>
      <link href="/2020/02/16/Deep_learning/%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9%E4%B8%8E%E8%BF%87%E6%8B%9F%E5%90%88%E3%80%81%E6%AC%A0%E6%8B%9F%E5%90%88/"/>
      <url>/2020/02/16/Deep_learning/%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9%E4%B8%8E%E8%BF%87%E6%8B%9F%E5%90%88%E3%80%81%E6%AC%A0%E6%8B%9F%E5%90%88/</url>
      
        <content type="html"><![CDATA[<h1 id="模型选择与过拟合与欠拟合"><a href="#模型选择与过拟合与欠拟合" class="headerlink" title="模型选择与过拟合与欠拟合"></a>模型选择与过拟合与欠拟合</h1><h2 id="训练误差与泛化误差"><a href="#训练误差与泛化误差" class="headerlink" title="训练误差与泛化误差"></a>训练误差与泛化误差</h2><p>训练误差（training error）指模型在训练数据集上表现出的误差。<br>泛化误差（generalization error）指模型在任意一个测试数据样本上表现出的误差的期望，并常常通过测试数据集上的误差来近似。<br>计算训练误差和泛化误差可以使用之前介绍过的损失函数，例如线性回归用到的平方损失函数和softmax回归用到的交叉熵损失函数。<br>所以，训练误差的期望小于或等于泛化误差。也就是说，一般情况下，由训练数据集学到的模型参数会使模型在训练数据集上的表现优于或等于在测试数据集上的表现。由于无法从训练误差估计泛化误差，一味地降低训练误差并不意味着泛化误差一定会降低。</p><p>机器学习模型应关注降低泛化误差。</p><h2 id="模型选择"><a href="#模型选择" class="headerlink" title="模型选择"></a>模型选择</h2><h3 id="验证集"><a href="#验证集" class="headerlink" title="验证集"></a>验证集</h3><p>测试集只能在所有超参数和模型参数选定后使用一次。不可以使用测试数据选择模型，如调参。<br>预留一部分在训练数据集和测试数据集以外的数据来进行模型选择。这部分数据被称为验证数据集，简称验证集（validation set）</p><h3 id="K折交叉验证"><a href="#K折交叉验证" class="headerlink" title="K折交叉验证"></a>K折交叉验证</h3><p>由于验证数据集不参与模型训练，当训练数据不够用时，预留大量的验证数据显得太奢侈。一种改善的方法是$K$折交叉验证（$K$-fold cross-validation）。在$K$折交叉验证中，我们把原始训练数据集分割成$K$个不重合的子数据集，然后我们做$K$次模型训练和验证。每一次，我们使用一个子数据集验证模型，并使用其他$K-1$个子数据集来训练模型。在这$K$次训练和验证中，每次用来验证模型的子数据集都不同。最后，我们对这$K$次训练误差和验证误差分别求平均。</p><h2 id="欠拟合与过拟合"><a href="#欠拟合与过拟合" class="headerlink" title="欠拟合与过拟合"></a>欠拟合与过拟合</h2><ul><li>一类是模型无法得到较低的训练误差，我们将这一现象称作欠拟合（underfitting）；</li><li>另一类是模型的训练误差远小于它在测试数据集上的误差，我们称该现象为过拟合（overfitting）。 在实践中，我们要尽可能同时应对欠拟合和过拟合。虽然有很多因素可能导致这两种拟合问题，在这里我们重点讨论两个因素：模型复杂度和训练数据集大小。</li></ul><h3 id="模型复杂度"><a href="#模型复杂度" class="headerlink" title="模型复杂度"></a>模型复杂度</h3><div align=center><img width="350" src="https://i.bmp.ovh/imgs/2020/02/cf7248d423fab8a5.png"/></div><div align=center>图3.4 模型复杂度对欠拟合和过拟合的影响</div><p>影响欠拟合和过拟合的另一个重要因素是训练数据集的大小。一般来说，如果训练数据集中样本数过少，特别是比模型参数数量（按元素计）更少时，过拟合更容易发生。此外，泛化误差不会随训练数据集里样本数量增加而增大。因此，在计算资源允许的范围之内，我们通常希望训练数据集大一些，特别是在模型复杂度较高时，例如层数较多的深度学习模型。</p><h2 id="多项式拟合"><a href="#多项式拟合" class="headerlink" title="多项式拟合"></a>多项式拟合</h2><div align=center><img width="350" src="https://i.bmp.ovh/imgs/2020/02/aca411216e606cf8.png"/></div><div align=center>正常拟合</div><div align=center><img width="350" src="https://i.bmp.ovh/imgs/2020/02/4b81e7b5075cc20d.png"/></div><div align=center>欠拟合</div><div align=center><img width="350" src="https://i.bmp.ovh/imgs/2020/02/6ee4f9ffe1f7059f.png"/></div><div align=center>过拟合</div><h2 id="权重衰减"><a href="#权重衰减" class="headerlink" title="权重衰减"></a>权重衰减</h2><p>上一节中我们观察了过拟合现象，即模型的训练误差远小于它在测试集上的误差。虽然增大训练数据集可能会减轻过拟合，但是获取额外的训练数据往往代价高昂。本节介绍应对过拟合问题的常用方法：权重衰减（weight decay）。</p><h3 id="L2正则化"><a href="#L2正则化" class="headerlink" title="L2正则化"></a>L2正则化</h3><p>权重衰减等价于 $L_2$ 范数正则化（regularization）。正则化通过为模型损失函数添加惩罚项使学出的模型参数值较小，是应对过拟合的常用手段。我们先描述$L_2$范数正则化，再解释它为何又称权重衰减。</p><p>$L_2$范数正则化在模型原损失函数基础上添加$L_2$范数惩罚项，从而得到训练所需要最小化的函数。$L_2$范数惩罚项指的是模型权重参数每个元素的平方和与一个正的常数的乘积。以3.1节（线性回归）中的线性回归损失函数</p><script type="math/tex; mode=display">\ell(w_1, w_2, b) = \frac{1}{n} \sum_{i=1}^n \frac{1}{2}\left(x_1^{(i)} w_1 + x_2^{(i)} w_2 + b - y^{(i)}\right)^2</script><p>为例，其中$w_1, w_2$是权重参数，$b$是偏差参数，样本$i$的输入为$x_1^{(i)}, x_2^{(i)}$，标签为$y^{(i)}$，样本数为$n$。将权重参数用向量$\boldsymbol{w} = [w_1, w_2]$表示，带有$L_2$范数惩罚项的新损失函数为</p><script type="math/tex; mode=display">\ell(w_1, w_2, b) + \frac{\lambda}{2n} \|\boldsymbol{w}\|^2,</script><p>其中超参数$\lambda &gt; 0$。当权重参数均为0时，惩罚项最小。当$\lambda$较大时，惩罚项在损失函数中的比重较大，这通常会使学到的权重参数的元素较接近0。当$\lambda$设为0时，惩罚项完全不起作用。上式中$L_2$范数平方$|\boldsymbol{w}|^2$展开后得到$w_1^2 + w_2^2$。有了$L_2$范数惩罚项后，在小批量随机梯度下降中，我们将线性回归一节中权重$w_1$和$w_2$的迭代方式更改为</p><script type="math/tex; mode=display">\begin{aligned}w_1 &\leftarrow \left(1- \frac{\eta\lambda}{|\mathcal{B}|} \right)w_1 -   \frac{\eta}{|\mathcal{B}|} \sum_{i \in \mathcal{B}}x_1^{(i)} \left(x_1^{(i)} w_1 + x_2^{(i)} w_2 + b - y^{(i)}\right),\\w_2 &\leftarrow \left(1- \frac{\eta\lambda}{|\mathcal{B}|} \right)w_2 -   \frac{\eta}{|\mathcal{B}|} \sum_{i \in \mathcal{B}}x_2^{(i)} \left(x_1^{(i)} w_1 + x_2^{(i)} w_2 + b - y^{(i)}\right).\end{aligned}</script><p>可见，$L_2$范数正则化令权重$w_1$和$w_2$先自乘小于1的数，再减去不含惩罚项的梯度。因此，$L_2$范数正则化又叫权重衰减。权重衰减通过惩罚绝对值较大的模型参数为需要学习的模型增加了限制，这可能对过拟合有效。实际场景中，我们有时也在惩罚项中添加偏差元素的平方和。</p><h3 id="权重衰减的pytorch实现"><a href="#权重衰减的pytorch实现" class="headerlink" title="权重衰减的pytorch实现"></a>权重衰减的pytorch实现</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">sys.path.append(<span class="string">"."</span>)</span><br><span class="line"><span class="keyword">import</span> d2lzh_pytorch <span class="keyword">as</span> d2l</span><br><span class="line"></span><br><span class="line">print(torch.__version__)</span><br></pre></td></tr></table></figure><pre><code>1.3.1</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fit_and_plot_pytorch</span><span class="params">(wd)</span>:</span></span><br><span class="line">    <span class="comment"># 对权重参数衰减。权重名称一般是以weight结尾</span></span><br><span class="line">    net = nn.Linear(num_inputs, <span class="number">1</span>)</span><br><span class="line">    nn.init.normal_(net.weight, mean=<span class="number">0</span>, std=<span class="number">1</span>)</span><br><span class="line">    nn.init.normal_(net.bias, mean=<span class="number">0</span>, std=<span class="number">1</span>)</span><br><span class="line">    optimizer_w = torch.optim.SGD(params=[net.weight], lr=lr, weight_decay=wd) <span class="comment"># 对权重参数衰减</span></span><br><span class="line">    optimizer_b = torch.optim.SGD(params=[net.bias], lr=lr)  <span class="comment"># 不对偏差参数衰减</span></span><br><span class="line">    </span><br><span class="line">    train_ls, test_ls = [], []</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> range(num_epochs):</span><br><span class="line">        <span class="keyword">for</span> X, y <span class="keyword">in</span> train_iter:</span><br><span class="line">            l = loss(net(X), y).mean()</span><br><span class="line">            optimizer_w.zero_grad()</span><br><span class="line">            optimizer_b.zero_grad()</span><br><span class="line">            </span><br><span class="line">            l.backward()</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 对两个optimizer实例分别调用step函数，从而分别更新权重和偏差</span></span><br><span class="line">            optimizer_w.step()</span><br><span class="line">            optimizer_b.step()</span><br><span class="line">        train_ls.append(loss(net(train_features), train_labels).mean().item())</span><br><span class="line">        test_ls.append(loss(net(test_features), test_labels).mean().item())</span><br><span class="line">    d2l.semilogy(range(<span class="number">1</span>, num_epochs + <span class="number">1</span>), train_ls, <span class="string">'epochs'</span>, <span class="string">'loss'</span>,</span><br><span class="line">                 range(<span class="number">1</span>, num_epochs + <span class="number">1</span>), test_ls, [<span class="string">'train'</span>, <span class="string">'test'</span>])</span><br><span class="line">    print(<span class="string">'L2 norm of w:'</span>, net.weight.data.norm().item())</span><br></pre></td></tr></table></figure><h2 id="dropout"><a href="#dropout" class="headerlink" title="dropout"></a>dropout</h2><p>多层感知机的计算表达式为</p><script type="math/tex; mode=display">h_i = \phi\left(x_1 w_{1i} + x_2 w_{2i} + x_3 w_{3i} + x_4 w_{4i} + b_i\right)</script><p>这里$\phi$是激活函数，$x_1, \ldots, x_4$是输入，隐藏单元$i$的权重参数为$w_{1i}, \ldots, w_{4i}$，偏差参数为$b_i$。当对该隐藏层使用丢弃法时，该层的隐藏单元将有一定概率被丢弃掉。设丢弃概率为$p$，那么有$p$的概率$h_i$会被清零，有$1-p$的概率$h_i$会除以$1-p$做拉伸。丢弃概率是丢弃法的超参数。具体来说，设随机变量$\xi_i$为0和1的概率分别为$p$和$1-p$。使用丢弃法时我们计算新的隐藏单元$h_i’$</p><script type="math/tex; mode=display">h_i' = \frac{\xi_i}{1-p} h_i</script><p>由于$E(\xi_i) = 1-p$，因此</p><script type="math/tex; mode=display">E(h_i') = \frac{E(\xi_i)}{1-p}h_i = h_i</script><p>即<strong>丢弃法不改变其输入的期望值</strong>。</p><div align=center><img width="350" src="https://i.bmp.ovh/imgs/2020/02/ec3bfe47de764684.png"/></div><div align=center> 隐藏层使用了丢弃法的多层感知机</div><h3 id="dropout的pytorch实现"><a href="#dropout的pytorch实现" class="headerlink" title="dropout的pytorch实现"></a>dropout的pytorch实现</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">net = nn.Sequential(</span><br><span class="line">        d2l.FlattenLayer(),</span><br><span class="line">        nn.Linear(num_inputs, num_hiddens1),</span><br><span class="line">        nn.ReLU(),</span><br><span class="line">        nn.Dropout(drop_prob1),</span><br><span class="line">        nn.Linear(num_hiddens1, num_hiddens2), </span><br><span class="line">        nn.ReLU(),</span><br><span class="line">        nn.Dropout(drop_prob2),</span><br><span class="line">        nn.Linear(num_hiddens2, <span class="number">10</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> param <span class="keyword">in</span> net.parameters():</span><br><span class="line">    nn.init.normal_(param, mean=<span class="number">0</span>, std=<span class="number">0.01</span>)</span><br></pre></td></tr></table></figure><h1 id="梯度消失与梯度爆炸"><a href="#梯度消失与梯度爆炸" class="headerlink" title="梯度消失与梯度爆炸"></a>梯度消失与梯度爆炸</h1><p>当神经网络的层数较多时，模型的数值稳定性容易变差。假设一个层数为$L$的多层感知机的第$l$层$\boldsymbol{H}^{(l)}$的权重参数为$\boldsymbol{W}^{(l)}$，输出层$\boldsymbol{H}^{(L)}$的权重参数为$\boldsymbol{W}^{(L)}$。为了便于讨论，不考虑偏差参数，且设所有隐藏层的激活函数为恒等映射（identity mapping）$\phi(x) = x$。给定输入$\boldsymbol{X}$，多层感知机的第$l$层的输出$\boldsymbol{H}^{(l)} = \boldsymbol{X} \boldsymbol{W}^{(1)} \boldsymbol{W}^{(2)} \ldots \boldsymbol{W}^{(l)}$。此时，如果层数$l$较大，$\boldsymbol{H}^{(l)}$的计算可能会出现衰减或爆炸。举个例子，假设输入和所有层的权重参数都是标量，如权重参数为0.2和5，多层感知机的第30层输出为输入$\boldsymbol{X}$分别与$0.2^{30} \approx 1 \times 10^{-21}$（衰减）和$5^{30} \approx 9 \times 10^{20}$（爆炸）的乘积。类似地，当层数较多时，梯度的计算也更容易出现衰减或爆炸。</p><h1 id="随机初始化模型参数"><a href="#随机初始化模型参数" class="headerlink" title="随机初始化模型参数"></a>随机初始化模型参数</h1><h2 id="PyTorch的默认随机初始化"><a href="#PyTorch的默认随机初始化" class="headerlink" title="PyTorch的默认随机初始化"></a>PyTorch的默认随机初始化</h2><p>随机初始化模型参数的方法有很多。使用<code>torch.nn.init.normal_()</code>使模型<code>net</code>的权重参数采用正态分布的随机初始化方式。不过，PyTorch中<code>nn.Module</code>的模块参数都采取了较为合理的初始化策略（不同类型的layer具体采样的哪一种初始化方法的可参考<a href="https://github.com/pytorch/pytorch/tree/master/torch/nn/modules" target="_blank" rel="noopener">源代码</a>），因此一般不用我们考虑。</p><h2 id="Xavier随机初始化"><a href="#Xavier随机初始化" class="headerlink" title="Xavier随机初始化"></a>Xavier随机初始化</h2><p>还有一种比较常用的随机初始化方法叫作Xavier随机初始化[1]。<br>假设某全连接层的输入个数为$a$，输出个数为$b$，Xavier随机初始化将使该层中权重参数的每个元素都随机采样于均匀分布</p><script type="math/tex; mode=display">U\left(-\sqrt{\frac{6}{a+b}}, \sqrt{\frac{6}{a+b}}\right).</script><p>它的设计主要考虑到，模型参数初始化后，每层输出的方差不该受该层输入个数影响，且每层梯度的方差也不该受该层输出个数影响。</p><h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><ul><li>正则化通过为模型损失函数添加惩罚项使学出的模型参数值较小，是应对过拟合的常用手段。</li><li>权重衰减等价于$L_2$范数正则化，通常会使学到的权重参数的元素较接近0。</li><li>权重衰减可以通过优化器中的<code>weight_decay</code>超参数来指定。</li><li>可以定义多个优化器实例对不同的模型参数使用不同的迭代方法。</li><li>我们可以通过使用丢弃法应对过拟合。</li><li>丢弃法只在训练模型时使用</li><li>深度模型有关数值稳定性的典型问题是衰减和爆炸。当神经网络的层数较多时，模型的数值稳定性容易变差。</li><li>我们通常需要随机初始化神经网络的模型参数，如权重参数。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> deep_learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>机器翻译基础</title>
      <link href="/2020/02/16/Deep_learning/%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91/"/>
      <url>/2020/02/16/Deep_learning/%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91/</url>
      
        <content type="html"><![CDATA[<h1 id="机器翻译"><a href="#机器翻译" class="headerlink" title="机器翻译"></a>机器翻译</h1><p>机器翻译是指将一段文本从一种语言自动翻译到另一种语言。因为一段文本序列在不同语言中的长度不一定相同，所以我们使用机器翻译为例来介绍编码器—解码器和注意力机制的应用。</p><h2 id="读取和预处理数据"><a href="#读取和预处理数据" class="headerlink" title="读取和预处理数据"></a>读取和预处理数据</h2><h3 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h3><p>将数据集清洗、转化为神经网络的输入minbatch</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">%导入模块</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">sys.path.append(<span class="string">'.'</span>)</span><br><span class="line"><span class="keyword">import</span> collections</span><br><span class="line"><span class="keyword">import</span> d2lzh_pytorch <span class="keyword">as</span> d2l</span><br><span class="line"><span class="keyword">import</span> zipfile</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> torch.utils <span class="keyword">import</span> data</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> optim</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">preprocess_raw</span><span class="params">(text)</span>:</span></span><br><span class="line">    text = text.replace(<span class="string">'\u202f'</span>, <span class="string">' '</span>).replace(<span class="string">'\xa0'</span>, <span class="string">' '</span>)</span><br><span class="line">    out = <span class="string">''</span></span><br><span class="line">    <span class="keyword">for</span> i, char <span class="keyword">in</span> enumerate(text.lower()):</span><br><span class="line">        <span class="keyword">if</span> char <span class="keyword">in</span> (<span class="string">','</span>, <span class="string">'!'</span>, <span class="string">'.'</span>) <span class="keyword">and</span> i &gt; <span class="number">0</span> <span class="keyword">and</span> text[i<span class="number">-1</span>] != <span class="string">' '</span>:</span><br><span class="line">            out += <span class="string">' '</span></span><br><span class="line">        out += char</span><br><span class="line">    <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure><h3 id="分词"><a href="#分词" class="headerlink" title="分词"></a>分词</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">num_examples = <span class="number">50000</span></span><br><span class="line">source, target = [], []</span><br><span class="line"><span class="keyword">for</span> i, line <span class="keyword">in</span> enumerate(text.split(<span class="string">'\n'</span>)):</span><br><span class="line">    <span class="keyword">if</span> i &gt; num_examples:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    parts = line.split(<span class="string">'\t'</span>)</span><br><span class="line">    <span class="keyword">if</span> len(parts) &gt;= <span class="number">2</span>:</span><br><span class="line">        source.append(parts[<span class="number">0</span>].split(<span class="string">' '</span>))</span><br><span class="line">        target.append(parts[<span class="number">1</span>].split(<span class="string">' '</span>))</span><br><span class="line">        </span><br><span class="line">source[<span class="number">0</span>:<span class="number">3</span>], target[<span class="number">0</span>:<span class="number">3</span>]</span><br></pre></td></tr></table></figure><h3 id="建立词典"><a href="#建立词典" class="headerlink" title="建立词典"></a>建立词典</h3><p><img src="https://i.bmp.ovh/imgs/2020/02/46ee15360205c7fc.png" alt=""></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_vocab</span><span class="params">(tokens)</span>:</span></span><br><span class="line">    tokens = [token <span class="keyword">for</span> line <span class="keyword">in</span> tokens <span class="keyword">for</span> token <span class="keyword">in</span> line]</span><br><span class="line">    <span class="keyword">return</span> d2l.data.base.Vocab(tokens, min_freq=<span class="number">3</span>, use_special_tokens=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">src_vocab = build_vocab(source)</span><br><span class="line">len(src_vocab)</span><br></pre></td></tr></table></figure><h3 id="载入数据"><a href="#载入数据" class="headerlink" title="载入数据"></a>载入数据</h3><p><img src="https://i.bmp.ovh/imgs/2020/02/a1e6875ba2581929.png" alt=""></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pad</span><span class="params">(line, max_len, padding_token)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> len(line) &gt; max_len:</span><br><span class="line">        <span class="keyword">return</span> line[:max_len]</span><br><span class="line">    <span class="keyword">return</span> line + [padding_token] * (max_len - len(line))</span><br><span class="line">pad(src_vocab[source[<span class="number">0</span>]], <span class="number">10</span>, src_vocab.pad)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_array</span><span class="params">(lines, vocab, max_len, is_source)</span>:</span></span><br><span class="line">    lines = [vocab[line] <span class="keyword">for</span> line <span class="keyword">in</span> lines]</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> is_source:</span><br><span class="line">        lines = [[vocab.bos] + line + [vocab.eos] <span class="keyword">for</span> line <span class="keyword">in</span> lines]</span><br><span class="line">    array = torch.tensor([pad(line, max_len, vocab.pad) <span class="keyword">for</span> line <span class="keyword">in</span> lines])</span><br><span class="line">    valid_len = (array != vocab.pad).sum(<span class="number">1</span>) <span class="comment">#第一个维度</span></span><br><span class="line">    <span class="keyword">return</span> array, valid_len</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_data_nmt</span><span class="params">(batch_size, max_len)</span>:</span> <span class="comment"># This function is saved in d2l.</span></span><br><span class="line">    src_vocab, tgt_vocab = build_vocab(source), build_vocab(target)</span><br><span class="line">    src_array, src_valid_len = build_array(source, src_vocab, max_len, <span class="literal">True</span>)</span><br><span class="line">    tgt_array, tgt_valid_len = build_array(target, tgt_vocab, max_len, <span class="literal">False</span>)</span><br><span class="line">    train_data = data.TensorDataset(src_array, src_valid_len, tgt_array, tgt_valid_len)</span><br><span class="line">    train_iter = data.DataLoader(train_data, batch_size, shuffle=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> src_vocab, tgt_vocab, train_iter</span><br></pre></td></tr></table></figure><h2 id="encoder-decoder"><a href="#encoder-decoder" class="headerlink" title="encoder-decoder"></a>encoder-decoder</h2><p>可以应用在对话系统、生成式任务中。<br><img src="https://i.bmp.ovh/imgs/2020/02/e025e4ae861f8d1c.png" alt=""></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Encoder</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, **kwargs)</span>:</span></span><br><span class="line">        super(Encoder, self).__init__(**kwargs)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, X, *args)</span>:</span></span><br><span class="line">        <span class="keyword">raise</span> NotImplementedError</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Decoder</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, **kwargs)</span>:</span></span><br><span class="line">        super(Decoder, self).__init__(**kwargs)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">init_state</span><span class="params">(self, enc_outputs, *args)</span>:</span></span><br><span class="line">        <span class="keyword">raise</span> NotImplementedError</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, X, state)</span>:</span></span><br><span class="line">        <span class="keyword">raise</span> NotImplementedError</span><br><span class="line">        </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">EncoderDecoder</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, encoder, decoder, **kwargs)</span>:</span></span><br><span class="line">        super(EncoderDecoder, self).__init__(**kwargs)</span><br><span class="line">        self.encoder = encoder</span><br><span class="line">        self.decoder = decoder</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, enc_X, dec_X, *args)</span>:</span></span><br><span class="line">        enc_outputs = self.encoder(enc_X, *args)</span><br><span class="line">        dec_state = self.decoder.init_state(enc_outputs, *args)</span><br><span class="line">        <span class="keyword">return</span> self.decoder(dec_X, dec_state)</span><br></pre></td></tr></table></figure><h2 id="Seq2Seq"><a href="#Seq2Seq" class="headerlink" title="Seq2Seq"></a>Seq2Seq</h2><p><img src="https://i.bmp.ovh/imgs/2020/02/95d2ba1473ca6471.png" alt=""></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Seq2SeqEncoder</span><span class="params">(d2l.Encoder)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, vocab_size, embed_size, num_hiddens, num_layers,</span></span></span><br><span class="line"><span class="function"><span class="params">                 dropout=<span class="number">0</span>, **kwargs)</span>:</span></span><br><span class="line">        super(Seq2SeqEncoder, self).__init__(**kwargs)</span><br><span class="line">        self.num_hiddens=num_hiddens</span><br><span class="line">        self.num_layers=num_layers</span><br><span class="line">        self.embedding = nn.Embedding(vocab_size, embed_size)</span><br><span class="line">        self.rnn = nn.LSTM(embed_size,num_hiddens, num_layers, dropout=dropout)</span><br><span class="line">   </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">begin_state</span><span class="params">(self, batch_size, device)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> [torch.zeros(size=(self.num_layers, batch_size, self.num_hiddens),  device=device),</span><br><span class="line">                torch.zeros(size=(self.num_layers, batch_size, self.num_hiddens),  device=device)]</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, X, *args)</span>:</span></span><br><span class="line">        X = self.embedding(X) <span class="comment"># X shape: (batch_size, seq_len, embed_size)</span></span><br><span class="line">        X = X.transpose(<span class="number">0</span>, <span class="number">1</span>)  <span class="comment"># RNN needs first axes to be time</span></span><br><span class="line">        <span class="comment"># state = self.begin_state(X.shape[1], device=X.device)</span></span><br><span class="line">        out, state = self.rnn(X)</span><br><span class="line">        <span class="comment"># The shape of out is (seq_len, batch_size, num_hiddens).</span></span><br><span class="line">        <span class="comment"># state contains the hidden state and the memory cell</span></span><br><span class="line">        <span class="comment"># of the last time step, the shape is (num_layers, batch_size, num_hiddens)</span></span><br><span class="line">        <span class="keyword">return</span> out, state</span><br><span class="line">    </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Seq2SeqDecoder</span><span class="params">(d2l.Decoder)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, vocab_size, embed_size, num_hiddens, num_layers,</span></span></span><br><span class="line"><span class="function"><span class="params">                 dropout=<span class="number">0</span>, **kwargs)</span>:</span></span><br><span class="line">        super(Seq2SeqDecoder, self).__init__(**kwargs)</span><br><span class="line">        self.embedding = nn.Embedding(vocab_size, embed_size)</span><br><span class="line">        self.rnn = nn.LSTM(embed_size,num_hiddens, num_layers, dropout=dropout)</span><br><span class="line">        self.dense = nn.Linear(num_hiddens,vocab_size)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">init_state</span><span class="params">(self, enc_outputs, *args)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> enc_outputs[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, X, state)</span>:</span></span><br><span class="line">        X = self.embedding(X).transpose(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">        out, state = self.rnn(X, state)</span><br><span class="line">        <span class="comment"># Make the batch to be the first dimension to simplify loss computation.</span></span><br><span class="line">        out = self.dense(out).transpose(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> out, state</span><br></pre></td></tr></table></figure><h2 id="Beamsearch"><a href="#Beamsearch" class="headerlink" title="Beamsearch"></a>Beamsearch</h2><p><img src="attachment:image.png" alt="image.png"></p>]]></content>
      
      
      <categories>
          
          <category> deep_learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>文本预处理与语言模型</title>
      <link href="/2020/02/14/Deep_learning/%E6%96%87%E6%9C%AC%E9%A2%84%E5%A4%84%E7%90%86%E4%B8%8E%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/"/>
      <url>/2020/02/14/Deep_learning/%E6%96%87%E6%9C%AC%E9%A2%84%E5%A4%84%E7%90%86%E4%B8%8E%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/</url>
      
        <content type="html"><![CDATA[<h1 id="文本预处理"><a href="#文本预处理" class="headerlink" title="文本预处理"></a>文本预处理</h1><ol><li>读入文本</li><li>分词</li><li>建立字典，将每个词映射到一个唯一的索引（index）</li><li>将文本从词的序列转换为索引的序列，方便输入模型</li></ol><h2 id="读入文本"><a href="#读入文本" class="headerlink" title="读入文本"></a>读入文本</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> collections</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_time_machine</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">with</span> open(<span class="string">'/home/kesci/input/timemachine7163/timemachine.txt'</span>, <span class="string">'r'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        lines = [re.sub(<span class="string">'[^a-z]+'</span>, <span class="string">' '</span>, line.strip().lower()) <span class="keyword">for</span> line <span class="keyword">in</span> f]</span><br><span class="line">    <span class="keyword">return</span> lines</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">lines = read_time_machine()</span><br><span class="line">print(<span class="string">'# sentences %d'</span> % len(lines))</span><br></pre></td></tr></table></figure><h2 id="分词"><a href="#分词" class="headerlink" title="分词"></a>分词</h2><p>将一个句子划分为若干个<code>token</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tokenize</span><span class="params">(sentences, token=<span class="string">'word'</span>)</span>:</span></span><br><span class="line">    <span class="string">"""Split sentences into word or char tokens"""</span></span><br><span class="line">    <span class="keyword">if</span> token == <span class="string">'word'</span>:</span><br><span class="line">        <span class="keyword">return</span> [sentence.split(<span class="string">' '</span>) <span class="keyword">for</span> sentence <span class="keyword">in</span> sentences]</span><br><span class="line">    <span class="keyword">elif</span> token == <span class="string">'char'</span>:</span><br><span class="line">        <span class="keyword">return</span> [list(sentence) <span class="keyword">for</span> sentence <span class="keyword">in</span> sentences]</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        print(<span class="string">'ERROR: unkown token type '</span>+token)</span><br><span class="line"></span><br><span class="line">tokens = tokenize(lines)</span><br><span class="line">tokens[<span class="number">0</span>:<span class="number">2</span>]</span><br></pre></td></tr></table></figure><h2 id="建立字典"><a href="#建立字典" class="headerlink" title="建立字典"></a>建立字典</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Vocab</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, tokens, min_freq=<span class="number">0</span>, use_special_tokens=False)</span>:</span></span><br><span class="line">        counter = count_corpus(tokens)  <span class="comment"># : </span></span><br><span class="line">        self.token_freqs = list(counter.items())</span><br><span class="line">        self.idx_to_token = []</span><br><span class="line">        <span class="keyword">if</span> use_special_tokens:</span><br><span class="line">            <span class="comment"># padding, begin of sentence, end of sentence, unknown</span></span><br><span class="line">            self.pad, self.bos, self.eos, self.unk = (<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line">            self.idx_to_token += [<span class="string">''</span>, <span class="string">''</span>, <span class="string">''</span>, <span class="string">''</span>]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.unk = <span class="number">0</span></span><br><span class="line">            self.idx_to_token += [<span class="string">''</span>]</span><br><span class="line">        self.idx_to_token += [token <span class="keyword">for</span> token, freq <span class="keyword">in</span> self.token_freqs</span><br><span class="line">                        <span class="keyword">if</span> freq &gt;= min_freq <span class="keyword">and</span> token <span class="keyword">not</span> <span class="keyword">in</span> self.idx_to_token]</span><br><span class="line">        self.token_to_idx = dict()</span><br><span class="line">        <span class="keyword">for</span> idx, token <span class="keyword">in</span> enumerate(self.idx_to_token):</span><br><span class="line">            self.token_to_idx[token] = idx</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> len(self.idx_to_token)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span><span class="params">(self, tokens)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> isinstance(tokens, (list, tuple)):</span><br><span class="line">            <span class="keyword">return</span> self.token_to_idx.get(tokens, self.unk)</span><br><span class="line">        <span class="keyword">return</span> [self.__getitem__(token) <span class="keyword">for</span> token <span class="keyword">in</span> tokens]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">to_tokens</span><span class="params">(self, indices)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> isinstance(indices, (list, tuple)):</span><br><span class="line">            <span class="keyword">return</span> self.idx_to_token[indices]</span><br><span class="line">        <span class="keyword">return</span> [self.idx_to_token[index] <span class="keyword">for</span> index <span class="keyword">in</span> indices]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">count_corpus</span><span class="params">(sentences)</span>:</span></span><br><span class="line">    tokens = [tk <span class="keyword">for</span> st <span class="keyword">in</span> sentences <span class="keyword">for</span> tk <span class="keyword">in</span> st]</span><br><span class="line">    <span class="keyword">return</span> collections.Counter(tokens)  <span class="comment"># 返回一个字典，记录每个词的出现次数</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 将词转化为索引</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">8</span>, <span class="number">10</span>):</span><br><span class="line">    print(<span class="string">'words:'</span>, tokens[i])</span><br><span class="line">    print(<span class="string">'indices:'</span>, vocab[tokens[i]])</span><br></pre></td></tr></table></figure><h2 id="用现有工具包分词"><a href="#用现有工具包分词" class="headerlink" title="用现有工具包分词"></a>用现有工具包分词</h2><h3 id="NLTK"><a href="#NLTK" class="headerlink" title="NLTK"></a>NLTK</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">text = <span class="string">"Mr. Chen doesn't agree with my suggestion."</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> nltk.tokenize <span class="keyword">import</span> word_tokenize</span><br><span class="line"><span class="keyword">from</span> nltk <span class="keyword">import</span> data</span><br><span class="line">data.path.append(<span class="string">'/home/kesci/input/nltk_data3784/nltk_data'</span>)</span><br><span class="line">print(word_tokenize(text))</span><br></pre></td></tr></table></figure><h3 id="SPACY"><a href="#SPACY" class="headerlink" title="SPACY"></a>SPACY</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> spacy</span><br><span class="line">nlp = spacy.load(<span class="string">'en_core_web_sm'</span>)</span><br><span class="line">doc = nlp(text)</span><br><span class="line">print([token.text <span class="keyword">for</span> token <span class="keyword">in</span> doc])</span><br></pre></td></tr></table></figure><h1 id="语言模型（基于统计的语言模型）"><a href="#语言模型（基于统计的语言模型）" class="headerlink" title="语言模型（基于统计的语言模型）"></a>语言模型（基于统计的语言模型）</h1><p><img src="https://img.vim-cn.com/74/bb98fdc35dd04377837535271dcebd321dfa19.png" alt=""></p><h1 id="n元语法"><a href="#n元语法" class="headerlink" title="n元语法"></a>n元语法</h1><p><img src="https://img.vim-cn.com/14/04dcd7cd184f97d2cbaed69a419d20bdd74c96.png" alt=""></p><h2 id="相邻采样"><a href="#相邻采样" class="headerlink" title="相邻采样"></a>相邻采样</h2><p>在相邻采样中，相邻的两个随机小批量在原始序列上的位置相毗邻</p><h2 id="随机采样"><a href="#随机采样" class="headerlink" title="随机采样"></a>随机采样</h2><p>下面的代码每次从数据里随机采样一个小批量。其中批量大小<code>batch_size</code>是每个小批量的样本数，<code>num_steps</code>是每个样本所包含的时间步数。 在随机采样中，每个样本是原始序列上任意截取的一段序列，相邻的两个随机小批量在原始序列上的位置不一定相毗邻。</p>]]></content>
      
      
      <categories>
          
          <category> deep_learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>循环神经网络</title>
      <link href="/2020/02/14/Deep_learning/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
      <url>/2020/02/14/Deep_learning/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</url>
      
        <content type="html"><![CDATA[<h1 id="循环神经网络"><a href="#循环神经网络" class="headerlink" title="循环神经网络"></a>循环神经网络</h1><h2 id="简单循环神经网络的构造"><a href="#简单循环神经网络的构造" class="headerlink" title="简单循环神经网络的构造"></a>简单循环神经网络的构造</h2><p><img src="https://img.vim-cn.com/a8/d90fe522138ebfb79547e687f5fd82684648fa.png" alt=""></p><h2 id="裁剪梯度"><a href="#裁剪梯度" class="headerlink" title="裁剪梯度"></a>裁剪梯度</h2><p>循环神经网络中较容易出现梯度衰减或梯度爆炸，这会导致网络几乎无法训练。裁剪梯度（clip gradient）是一种应对梯度爆炸的方法。假设我们把所有模型参数的梯度拼接成一个向量  g ，并设裁剪的阈值是 θ 。裁剪后的梯度</p><h2 id="循环神经网络的pytorch实现"><a href="#循环神经网络的pytorch实现" class="headerlink" title="循环神经网络的pytorch实现"></a>循环神经网络的pytorch实现</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">sys.path.append(<span class="string">"/home/kesci/input"</span>)</span><br><span class="line"><span class="keyword">import</span> d2l_jay9460 <span class="keyword">as</span> d2l</span><br><span class="line">(corpus_indices, char_to_idx, idx_to_char, vocab_size) = d2l.load_data_jay_lyrics()</span><br><span class="line">device = torch.device(<span class="string">'cuda'</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">'cpu'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">rnn_layer = nn.RNN(input_size=vocab_size, hidden_size=num_hiddens)</span><br><span class="line">num_steps, batch_size = <span class="number">35</span>, <span class="number">2</span></span><br><span class="line">X = torch.rand(num_steps, batch_size, vocab_size)</span><br><span class="line">state = <span class="literal">None</span></span><br><span class="line">Y, state_new = rnn_layer(X, state)</span><br><span class="line">print(Y.shape, state_new.shape)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RNNModel</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, rnn_layer, vocab_size)</span>:</span></span><br><span class="line">        super(RNNModel, self).__init__()</span><br><span class="line">        self.rnn = rnn_layer</span><br><span class="line">        self.hidden_size = rnn_layer.hidden_size * (<span class="number">2</span> <span class="keyword">if</span> rnn_layer.bidirectional <span class="keyword">else</span> <span class="number">1</span>) </span><br><span class="line">        self.vocab_size = vocab_size</span><br><span class="line">        self.dense = nn.Linear(self.hidden_size, vocab_size)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, inputs, state)</span>:</span></span><br><span class="line">        <span class="comment"># inputs.shape: (batch_size, num_steps)</span></span><br><span class="line">        X = to_onehot(inputs, vocab_size)</span><br><span class="line">        X = torch.stack(X)  <span class="comment"># X.shape: (num_steps, batch_size, vocab_size)</span></span><br><span class="line">        hiddens, state = self.rnn(X, state)</span><br><span class="line">        hiddens = hiddens.view(<span class="number">-1</span>, hiddens.shape[<span class="number">-1</span>])  <span class="comment"># hiddens.shape: (num_steps * batch_size, hidden_size)</span></span><br><span class="line">        output = self.dense(hiddens)</span><br><span class="line">        <span class="keyword">return</span> output, state</span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict_rnn_pytorch</span><span class="params">(prefix, num_chars, model, vocab_size, device, idx_to_char,</span></span></span><br><span class="line"><span class="function"><span class="params">                      char_to_idx)</span>:</span></span><br><span class="line">    state = <span class="literal">None</span></span><br><span class="line">    output = [char_to_idx[prefix[<span class="number">0</span>]]]  <span class="comment"># output记录prefix加上预测的num_chars个字符</span></span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> range(num_chars + len(prefix) - <span class="number">1</span>):</span><br><span class="line">        X = torch.tensor([output[<span class="number">-1</span>]], device=device).view(<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        (Y, state) = model(X, state)  <span class="comment"># 前向计算不需要传入模型参数</span></span><br><span class="line">        <span class="keyword">if</span> t &lt; len(prefix) - <span class="number">1</span>:</span><br><span class="line">            output.append(char_to_idx[prefix[t + <span class="number">1</span>]])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            output.append(Y.argmax(dim=<span class="number">1</span>).item())</span><br><span class="line">    <span class="keyword">return</span> <span class="string">''</span>.join([idx_to_char[i] <span class="keyword">for</span> i <span class="keyword">in</span> output])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model = RNNModel(rnn_layer, vocab_size).to(device)</span><br><span class="line">predict_rnn_pytorch(<span class="string">'分开'</span>, <span class="number">10</span>, model, vocab_size, device, idx_to_char, char_to_idx)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_and_predict_rnn_pytorch</span><span class="params">(model, num_hiddens, vocab_size, device,</span></span></span><br><span class="line"><span class="function"><span class="params">                                corpus_indices, idx_to_char, char_to_idx,</span></span></span><br><span class="line"><span class="function"><span class="params">                                num_epochs, num_steps, lr, clipping_theta,</span></span></span><br><span class="line"><span class="function"><span class="params">                                batch_size, pred_period, pred_len, prefixes)</span>:</span></span><br><span class="line">    loss = nn.CrossEntropyLoss()</span><br><span class="line">    optimizer = torch.optim.Adam(model.parameters(), lr=lr)</span><br><span class="line">    model.to(device)</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(num_epochs):</span><br><span class="line">        l_sum, n, start = <span class="number">0.0</span>, <span class="number">0</span>, time.time()</span><br><span class="line">        data_iter = d2l.data_iter_consecutive(corpus_indices, batch_size, num_steps, device) <span class="comment"># 相邻采样</span></span><br><span class="line">        state = <span class="literal">None</span></span><br><span class="line">        <span class="keyword">for</span> X, Y <span class="keyword">in</span> data_iter:</span><br><span class="line">            <span class="keyword">if</span> state <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                <span class="comment"># 使用detach函数从计算图分离隐藏状态</span></span><br><span class="line">                <span class="keyword">if</span> isinstance (state, tuple): <span class="comment"># LSTM, state:(h, c)  </span></span><br><span class="line">                    state[<span class="number">0</span>].detach_()</span><br><span class="line">                    state[<span class="number">1</span>].detach_()</span><br><span class="line">                <span class="keyword">else</span>: </span><br><span class="line">                    state.detach_()</span><br><span class="line">            (output, state) = model(X, state) <span class="comment"># output.shape: (num_steps * batch_size, vocab_size)</span></span><br><span class="line">            y = torch.flatten(Y.T)</span><br><span class="line">            l = loss(output, y.long())</span><br><span class="line">            </span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            l.backward()</span><br><span class="line">            grad_clipping(model.parameters(), clipping_theta, device)</span><br><span class="line">            optimizer.step()</span><br><span class="line">            l_sum += l.item() * y.shape[<span class="number">0</span>]</span><br><span class="line">            n += y.shape[<span class="number">0</span>]</span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (epoch + <span class="number">1</span>) % pred_period == <span class="number">0</span>:</span><br><span class="line">            print(<span class="string">'epoch %d, perplexity %f, time %.2f sec'</span> % (</span><br><span class="line">                epoch + <span class="number">1</span>, math.exp(l_sum / n), time.time() - start))</span><br><span class="line">            <span class="keyword">for</span> prefix <span class="keyword">in</span> prefixes:</span><br><span class="line">                print(<span class="string">' -'</span>, predict_rnn_pytorch(</span><br><span class="line">                    prefix, pred_len, model, vocab_size, device, idx_to_char,</span><br><span class="line">                    char_to_idx))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">num_epochs, batch_size, lr, clipping_theta = <span class="number">250</span>, <span class="number">32</span>, <span class="number">1e-3</span>, <span class="number">1e-2</span></span><br><span class="line">pred_period, pred_len, prefixes = <span class="number">50</span>, <span class="number">50</span>, [<span class="string">'分开'</span>, <span class="string">'不分开'</span>]</span><br><span class="line">train_and_predict_rnn_pytorch(model, num_hiddens, vocab_size, device,</span><br><span class="line">                            corpus_indices, idx_to_char, char_to_idx,</span><br><span class="line">                            num_epochs, num_steps, lr, clipping_theta,</span><br><span class="line">                            batch_size, pred_period, pred_len, prefixes)</span><br></pre></td></tr></table></figure><p>RNN存在的问题：梯度较容易出现衰减或爆炸（BPTT）<br>⻔控循环神经⽹络：捕捉时间序列中时间步距离较⼤的依赖关系<br><img src="https://img.vim-cn.com/aa/5f1857a2a2320a5a6dd637d88c7018dffcbe43.png" alt="rnn1"></p><h3 id="GRU"><a href="#GRU" class="headerlink" title="GRU"></a>GRU</h3><p><img src="https://img.vim-cn.com/7d/cdb99137827b9038f1e5f34593f7169bbc3d87.png" alt="gru"></p><ul><li>重置⻔有助于捕捉时间序列⾥短期的依赖关系；</li><li>更新⻔有助于捕捉时间序列⾥⻓期的依赖关系</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">num_hiddens=<span class="number">256</span></span><br><span class="line">num_epochs, num_steps, batch_size, lr, clipping_theta = <span class="number">160</span>, <span class="number">35</span>, <span class="number">32</span>, <span class="number">1e2</span>, <span class="number">1e-2</span></span><br><span class="line">pred_period, pred_len, prefixes = <span class="number">40</span>, <span class="number">50</span>, [<span class="string">'分开'</span>, <span class="string">'不分开'</span>]</span><br><span class="line"></span><br><span class="line">lr = <span class="number">1e-2</span> <span class="comment"># 注意调整学习率</span></span><br><span class="line">gru_layer = nn.GRU(input_size=vocab_size, hidden_size=num_hiddens)</span><br><span class="line">model = d2l.RNNModel(gru_layer, vocab_size).to(device)</span><br><span class="line">d2l.train_and_predict_rnn_pytorch(model, num_hiddens, vocab_size, device,</span><br><span class="line">                                corpus_indices, idx_to_char, char_to_idx,</span><br><span class="line">                                num_epochs, num_steps, lr, clipping_theta,</span><br><span class="line">                                batch_size, pred_period, pred_len, prefixes)</span><br></pre></td></tr></table></figure><h3 id="LSTM"><a href="#LSTM" class="headerlink" title="LSTM"></a>LSTM</h3><ul><li>长短期记忆long short-term memory :</li><li>遗忘门:控制上一时间步的记忆细胞 输入门:控制当前时间步的输入</li><li>输出门:控制从记忆细胞到隐藏状态</li><li>记忆细胞：⼀种特殊的隐藏状态的信息的流动<br><img src="https://img.vim-cn.com/de/2d40e304a6f05b02fc8747d5e2a6f947fc064a.png" alt="lstm"></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">num_hiddens=<span class="number">256</span></span><br><span class="line">num_epochs, num_steps, batch_size, lr, clipping_theta = <span class="number">160</span>, <span class="number">35</span>, <span class="number">32</span>, <span class="number">1e2</span>, <span class="number">1e-2</span></span><br><span class="line">pred_period, pred_len, prefixes = <span class="number">40</span>, <span class="number">50</span>, [<span class="string">'分开'</span>, <span class="string">'不分开'</span>]</span><br><span class="line"></span><br><span class="line">lr = <span class="number">1e-2</span> <span class="comment"># 注意调整学习率</span></span><br><span class="line">lstm_layer = nn.LSTM(input_size=vocab_size, hidden_size=num_hiddens)</span><br><span class="line">model = d2l.RNNModel(lstm_layer, vocab_size)</span><br><span class="line">d2l.train_and_predict_rnn_pytorch(model, num_hiddens, vocab_size, device,</span><br><span class="line">                                corpus_indices, idx_to_char, char_to_idx,</span><br><span class="line">                                num_epochs, num_steps, lr, clipping_theta,</span><br><span class="line">                                batch_size, pred_period, pred_len, prefixes)</span><br></pre></td></tr></table></figure><h3 id="深度循环网络"><a href="#深度循环网络" class="headerlink" title="深度循环网络"></a>深度循环网络</h3><p>通过<code>num_layers</code>来进行控制</p><p><img src="https://img.vim-cn.com/d3/51bc59f0ae24e767576ee017fa06a031892f2b.png" alt=""></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">num_hiddens=<span class="number">256</span></span><br><span class="line">num_epochs, num_steps, batch_size, lr, clipping_theta = <span class="number">160</span>, <span class="number">35</span>, <span class="number">32</span>, <span class="number">1e2</span>, <span class="number">1e-2</span></span><br><span class="line">pred_period, pred_len, prefixes = <span class="number">40</span>, <span class="number">50</span>, [<span class="string">'分开'</span>, <span class="string">'不分开'</span>]</span><br><span class="line"></span><br><span class="line">lr = <span class="number">1e-2</span> <span class="comment"># 注意调整学习率</span></span><br><span class="line"></span><br><span class="line">gru_layer = nn.LSTM(input_size=vocab_size, hidden_size=num_hiddens,num_layers=<span class="number">2</span>)</span><br><span class="line">model = d2l.RNNModel(gru_layer, vocab_size).to(device)</span><br><span class="line">d2l.train_and_predict_rnn_pytorch(model, num_hiddens, vocab_size, device,</span><br><span class="line">                                corpus_indices, idx_to_char, char_to_idx,</span><br><span class="line">                                num_epochs, num_steps, lr, clipping_theta,</span><br><span class="line">                                batch_size, pred_period, pred_len, prefixes)</span><br></pre></td></tr></table></figure><h3 id="双向循环网络"><a href="#双向循环网络" class="headerlink" title="双向循环网络"></a>双向循环网络</h3><p><img src="https://img.vim-cn.com/4f/b21d208beaf51f1d33ef0455772236dc512ac0.png" alt=""></p><p>通过参数<code>bidirectional=True</code>来进行控制</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">num_hiddens=<span class="number">128</span></span><br><span class="line">num_epochs, num_steps, batch_size, lr, clipping_theta = <span class="number">160</span>, <span class="number">35</span>, <span class="number">32</span>, <span class="number">1e-2</span>, <span class="number">1e-2</span></span><br><span class="line">pred_period, pred_len, prefixes = <span class="number">40</span>, <span class="number">50</span>, [<span class="string">'分开'</span>, <span class="string">'不分开'</span>]</span><br><span class="line"></span><br><span class="line">lr = <span class="number">1e-2</span> <span class="comment"># 注意调整学习率</span></span><br><span class="line"></span><br><span class="line">gru_layer = nn.GRU(input_size=vocab_size, hidden_size=num_hiddens,bidirectional=<span class="literal">True</span>)</span><br><span class="line">model = d2l.RNNModel(gru_layer, vocab_size).to(device)</span><br><span class="line">d2l.train_and_predict_rnn_pytorch(model, num_hiddens, vocab_size, device,</span><br><span class="line">                                corpus_indices, idx_to_char, char_to_idx,</span><br><span class="line">                                num_epochs, num_steps, lr, clipping_theta,</span><br><span class="line">                                batch_size, pred_period, pred_len, prefixes)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> deep_learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Softmax与分类模型</title>
      <link href="/2020/02/13/Deep_learning/Softmax%E4%B8%8E%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B/"/>
      <url>/2020/02/13/Deep_learning/Softmax%E4%B8%8E%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B/</url>
      
        <content type="html"><![CDATA[<h1 id="softmax回归"><a href="#softmax回归" class="headerlink" title="softmax回归"></a>softmax回归</h1><p>前几节介绍的线性回归模型适用于输出为连续值的情景。在另一类情景中，模型输出可以是一个像图像类别这样的离散值。对于这样的离散值预测问题，我们可以使用诸如softmax回归在内的分类模型。和线性回归不同，softmax回归的输出单元从一个变成了多个，且引入了softmax运算使输出更适合离散值的预测和训练。本节以softmax回归模型为例，介绍神经网络中的分类模型。</p><h2 id="分类问题"><a href="#分类问题" class="headerlink" title="分类问题"></a>分类问题</h2><p>让我们考虑一个简单的图像分类问题，其输入图像的高和宽均为2像素，且色彩为灰度。这样每个像素值都可以用一个标量表示。我们将图像中的4像素分别记为$x_1, x_2, x_3, x_4$。假设训练数据集中图像的真实标签为狗、猫或鸡（假设可以用4像素表示出这3种动物），这些标签分别对应离散值$y_1, y_2, y_3$。</p><p>我们通常使用离散的数值来表示类别，例如$y_1=1, y_2=2, y_3=3$。如此，一张图像的标签为1、2和3这3个数值中的一个。虽然我们仍然可以使用回归模型来进行建模，并将预测值就近定点化到1、2和3这3个离散值之一，但这种连续值到离散值的转化通常会影响到分类质量。因此我们一般使用更加适合离散值输出的模型来解决分类问题。</p><h2 id="softmax回归模型"><a href="#softmax回归模型" class="headerlink" title="softmax回归模型"></a>softmax回归模型</h2><p>softmax回归跟线性回归一样将输入特征与权重做线性叠加。与线性回归的一个主要不同在于，softmax回归的输出值个数等于标签里的类别数。因为一共有4种特征和3种输出动物类别，所以权重包含12个标量（带下标的$w$）、偏差包含3个标量（带下标的$b$），且对每个输入计算$o_1, o_2, o_3$这3个输出：</p><script type="math/tex; mode=display">\begin{aligned}o_1 &= x_1 w_{11} + x_2 w_{21} + x_3 w_{31} + x_4 w_{41} + b_1,\\o_2 &= x_1 w_{12} + x_2 w_{22} + x_3 w_{32} + x_4 w_{42} + b_2,\\o_3 &= x_1 w_{13} + x_2 w_{23} + x_3 w_{33} + x_4 w_{43} + b_3.\end{aligned}</script><p>图3.2用神经网络图描绘了上面的计算。softmax回归同线性回归一样，也是一个单层神经网络。由于每个输出$o_1, o_2, o_3$的计算都要依赖于所有的输入$x_1, x_2, x_3, x_4$，softmax回归的输出层也是一个全连接层。</p><p><img src="../img/softmaxreg.svg" alt="softmax回归是一个单层神经网络"></p><h3 id="softmax运算"><a href="#softmax运算" class="headerlink" title="softmax运算"></a>softmax运算</h3><p>既然分类问题需要得到离散的预测输出，一个简单的办法是将输出值$o_i$当作预测类别是$i$的置信度，并将值最大的输出所对应的类作为预测输出，即输出$\operatorname*{argmax}_i o_i$。例如，如果$o_1,o_2,o_3$分别为$0.1,10,0.1$，由于$o_2$最大，那么预测类别为2，其代表猫。</p><p>然而，直接使用输出层的输出有两个问题。一方面，由于输出层的输出值的范围不确定，我们难以直观上判断这些值的意义。例如，刚才举的例子中的输出值10表示“很置信”图像类别为猫，因为该输出值是其他两类的输出值的100倍。但如果$o_1=o_3=10^3$，那么输出值10却又表示图像类别为猫的概率很低。另一方面，由于真实标签是离散值，这些离散值与不确定范围的输出值之间的误差难以衡量。</p><p>softmax运算符（softmax operator）解决了以上两个问题。它通过下式将输出值变换成值为正且和为1的概率分布：</p><script type="math/tex; mode=display">\hat{y}_1, \hat{y}_2, \hat{y}_3 = \text{softmax}(o_1, o_2, o_3),</script><p>其中</p><script type="math/tex; mode=display">\hat{y}_1 = \frac{ \exp(o_1)}{\sum_{i=1}^3 \exp(o_i)},\quad\hat{y}_2 = \frac{ \exp(o_2)}{\sum_{i=1}^3 \exp(o_i)},\quad\hat{y}_3 = \frac{ \exp(o_3)}{\sum_{i=1}^3 \exp(o_i)}.</script><p>容易看出$\hat{y}_1 + \hat{y}_2 + \hat{y}_3 = 1$且$0 \leq \hat{y}_1, \hat{y}_2, \hat{y}_3 \leq 1$，因此$\hat{y}_1, \hat{y}_2, \hat{y}_3$是一个合法的概率分布。这时候，如果$\hat{y}_2=0.8$，不管$\hat{y}_1$和$\hat{y}_3$的值是多少，我们都知道图像类别为猫的概率是80%。此外，我们注意到</p><script type="math/tex; mode=display">\operatorname*{argmax}_i o_i = \operatorname*{argmax}_i \hat y_i,</script><p>因此softmax运算不改变预测类别输出。</p><h2 id="单样本分类的矢量计算表达式"><a href="#单样本分类的矢量计算表达式" class="headerlink" title="单样本分类的矢量计算表达式"></a>单样本分类的矢量计算表达式</h2><p>为了提高计算效率，我们可以将单样本分类通过矢量计算来表达。在上面的图像分类问题中，假设softmax回归的权重和偏差参数分别为</p><script type="math/tex; mode=display">\boldsymbol{W} = \begin{bmatrix}    w_{11} & w_{12} & w_{13} \\    w_{21} & w_{22} & w_{23} \\    w_{31} & w_{32} & w_{33} \\    w_{41} & w_{42} & w_{43}\end{bmatrix},\quad\boldsymbol{b} = \begin{bmatrix}    b_1 & b_2 & b_3\end{bmatrix},</script><p>设高和宽分别为2个像素的图像样本$i$的特征为</p><script type="math/tex; mode=display">\boldsymbol{x}^{(i)} = \begin{bmatrix}x_1^{(i)} & x_2^{(i)} & x_3^{(i)} & x_4^{(i)}\end{bmatrix},</script><p>输出层的输出为</p><script type="math/tex; mode=display">\boldsymbol{o}^{(i)} = \begin{bmatrix}o_1^{(i)} & o_2^{(i)} & o_3^{(i)}\end{bmatrix},</script><p>预测为狗、猫或鸡的概率分布为</p><script type="math/tex; mode=display">\boldsymbol{\hat{y}}^{(i)} = \begin{bmatrix}\hat{y}_1^{(i)} & \hat{y}_2^{(i)} & \hat{y}_3^{(i)}\end{bmatrix}.</script><p>softmax回归对样本$i$分类的矢量计算表达式为</p><script type="math/tex; mode=display">\begin{aligned}\boldsymbol{o}^{(i)} &= \boldsymbol{x}^{(i)} \boldsymbol{W} + \boldsymbol{b},\\\boldsymbol{\hat{y}}^{(i)} &= \text{softmax}(\boldsymbol{o}^{(i)}).\end{aligned}</script><h2 id="小批量样本分类的矢量计算表达式"><a href="#小批量样本分类的矢量计算表达式" class="headerlink" title="小批量样本分类的矢量计算表达式"></a>小批量样本分类的矢量计算表达式</h2><p>为了进一步提升计算效率，我们通常对小批量数据做矢量计算。广义上讲，给定一个小批量样本，其批量大小为$n$，输入个数（特征数）为$d$，输出个数（类别数）为$q$。设批量特征为$\boldsymbol{X} \in \mathbb{R}^{n \times d}$。假设softmax回归的权重和偏差参数分别为$\boldsymbol{W} \in \mathbb{R}^{d \times q}$和$\boldsymbol{b} \in \mathbb{R}^{1 \times q}$。softmax回归的矢量计算表达式为</p><script type="math/tex; mode=display">\begin{aligned}\boldsymbol{O} &= \boldsymbol{X} \boldsymbol{W} + \boldsymbol{b},\\\boldsymbol{\hat{Y}} &= \text{softmax}(\boldsymbol{O}),\end{aligned}</script><p>其中的加法运算使用了广播机制，$\boldsymbol{O}, \boldsymbol{\hat{Y}} \in \mathbb{R}^{n \times q}$且这两个矩阵的第$i$行分别为样本$i$的输出$\boldsymbol{o}^{(i)}$和概率分布$\boldsymbol{\hat{y}}^{(i)}$。</p><h2 id="交叉熵损失函数"><a href="#交叉熵损失函数" class="headerlink" title="交叉熵损失函数"></a>交叉熵损失函数</h2><p>前面提到，使用softmax运算后可以更方便地与离散标签计算误差。我们已经知道，softmax运算将输出变换成一个合法的类别预测分布。实际上，真实标签也可以用类别分布表达：对于样本$i$，我们构造向量$\boldsymbol{y}^{(i)}\in \mathbb{R}^{q}$ ，使其第$y^{(i)}$（样本$i$类别的离散数值）个元素为1，其余为0。这样我们的训练目标可以设为使预测概率分布$\boldsymbol{\hat y}^{(i)}$尽可能接近真实的标签概率分布$\boldsymbol{y}^{(i)}$。</p><p>我们可以像线性回归那样使用平方损失函数$|\boldsymbol{\hat y}^{(i)}-\boldsymbol{y}^{(i)}|^2/2$。然而，想要预测分类结果正确，我们其实并不需要预测概率完全等于标签概率。例如，在图像分类的例子里，如果$y^{(i)}=3$，那么我们只需要$\hat{y}^{(i)}_3$比其他两个预测值$\hat{y}^{(i)}_1$和$\hat{y}^{(i)}_2$大就行了。即使$\hat{y}^{(i)}_3$值为0.6，不管其他两个预测值为多少，类别预测均正确。而平方损失则过于严格，例如$\hat y^{(i)}_1=\hat y^{(i)}_2=0.2$比$\hat y^{(i)}_1=0, \hat y^{(i)}_2=0.4$的损失要小很多，虽然两者都有同样正确的分类预测结果。</p><p>改善上述问题的一个方法是使用更适合衡量两个概率分布差异的测量函数。其中，交叉熵（cross entropy）是一个常用的衡量方法：</p><script type="math/tex; mode=display">H\left(\boldsymbol y^{(i)}, \boldsymbol {\hat y}^{(i)}\right ) = -\sum_{j=1}^q y_j^{(i)} \log \hat y_j^{(i)},</script><p>其中带下标的$y_j^{(i)}$是向量$\boldsymbol y^{(i)}$中非0即1的元素，需要注意将它与样本$i$类别的离散数值，即不带下标的$y^{(i)}$区分。在上式中，我们知道向量$\boldsymbol y^{(i)}$中只有第$y^{(i)}$个元素$y^{(i)}_{y^{(i)}}$为1，其余全为0，于是$H(\boldsymbol y^{(i)}, \boldsymbol {\hat y}^{(i)}) = -\log \hat y_{y^{(i)}}^{(i)}$。也就是说，交叉熵只关心对正确类别的预测概率，因为只要其值足够大，就可以确保分类结果正确。当然，遇到一个样本有多个标签时，例如图像里含有不止一个物体时，我们并不能做这一步简化。但即便对于这种情况，交叉熵同样只关心对图像中出现的物体类别的预测概率。</p><p>假设训练数据集的样本数为$n$，交叉熵损失函数定义为</p><script type="math/tex; mode=display">\ell(\boldsymbol{\Theta}) = \frac{1}{n} \sum_{i=1}^n H\left(\boldsymbol y^{(i)}, \boldsymbol {\hat y}^{(i)}\right ),</script><p>其中$\boldsymbol{\Theta}$代表模型参数。同样地，如果每个样本只有一个标签，那么交叉熵损失可以简写成$\ell(\boldsymbol{\Theta}) = -(1/n)  \sum_{i=1}^n \log \hat y_{y^{(i)}}^{(i)}$。从另一个角度来看，我们知道最小化$\ell(\boldsymbol{\Theta})$等价于最大化$\exp(-n\ell(\boldsymbol{\Theta}))=\prod_{i=1}^n \hat y_{y^{(i)}}^{(i)}$，即最小化交叉熵损失函数等价于最大化训练数据集所有标签类别的联合预测概率。</p><h1 id="softmax的pytorch实现"><a href="#softmax的pytorch实现" class="headerlink" title="softmax的pytorch实现"></a>softmax的pytorch实现</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 加载各种包或者模块</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> init</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">sys.path.append(<span class="string">r"D:\Documents\learning"</span>)</span><br><span class="line"><span class="comment"># import d2lzh as d2l</span></span><br><span class="line"></span><br><span class="line">print(torch.__version__)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成数据集</span></span><br><span class="line">batch_size = <span class="number">256</span></span><br><span class="line"><span class="comment"># train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, root='/home/kesci/input/FashionMNIST2065')</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义网络模型</span></span><br><span class="line">num_inputs = <span class="number">784</span></span><br><span class="line">num_outputs = <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LinearNet</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, num_inputs, num_outputs)</span>:</span></span><br><span class="line">        super(LinearNet, self).__init__()</span><br><span class="line">        self.linear = nn.Linear(num_inputs, num_outputs)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span> <span class="comment"># x 的形状: (batch, 1, 28, 28)</span></span><br><span class="line">        y = self.linear(x.view(x.shape[<span class="number">0</span>], <span class="number">-1</span>))</span><br><span class="line">        <span class="keyword">return</span> y</span><br><span class="line">    </span><br><span class="line"><span class="comment"># net = LinearNet(num_inputs, num_outputs)</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FlattenLayer</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(FlattenLayer, self).__init__()</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span> <span class="comment"># x 的形状: (batch, *, *, ...)</span></span><br><span class="line">        <span class="keyword">return</span> x.view(x.shape[<span class="number">0</span>], <span class="number">-1</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> OrderedDict</span><br><span class="line">net = nn.Sequential(</span><br><span class="line">        <span class="comment"># FlattenLayer(),</span></span><br><span class="line">        <span class="comment"># LinearNet(num_inputs, num_outputs) </span></span><br><span class="line">        OrderedDict([</span><br><span class="line">           (<span class="string">'flatten'</span>, FlattenLayer()),</span><br><span class="line">           (<span class="string">'linear'</span>, nn.Linear(num_inputs, num_outputs))]) <span class="comment"># 或者写成我们自己定义的 LinearNet(num_inputs, num_outputs) 也可以</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化模型参数</span></span><br><span class="line">init.normal_(net.linear.weight, mean=<span class="number">0</span>, std=<span class="number">0.01</span>)</span><br><span class="line">init.constant_(net.linear.bias, val=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义损失函数</span></span><br><span class="line">loss = nn.CrossEntropyLoss() <span class="comment"># 下面是他的函数原型</span></span><br><span class="line"><span class="comment"># class torch.nn.CrossEntropyLoss(weight=None, size_average=None, ignore_index=-100, reduce=None, reduction='mean')</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义优化函数</span></span><br></pre></td></tr></table></figure><pre><code>1.3.1</code></pre><h2 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">num_epochs = <span class="number">5</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_ch3</span><span class="params">(net, train_iter, test_iter, loss, num_epochs, batch_size,</span></span></span><br><span class="line"><span class="function"><span class="params">              params=None, lr=None, trainer=None)</span>:</span></span><br><span class="line">    <span class="string">"""Train and evaluate a model with CPU."""</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(num_epochs):</span><br><span class="line">        train_l_sum, train_acc_sum, n = <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> X, y <span class="keyword">in</span> train_iter:</span><br><span class="line">            <span class="keyword">with</span> autograd.record():</span><br><span class="line">                y_hat = net(X)</span><br><span class="line">                l = loss(y_hat, y).sum()</span><br><span class="line">            l.backward()</span><br><span class="line">            <span class="keyword">if</span> trainer <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">                sgd(params, lr, batch_size)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                trainer.step(batch_size)</span><br><span class="line">            y = y.astype(<span class="string">'float32'</span>)</span><br><span class="line">            train_l_sum += l.asscalar()</span><br><span class="line">            train_acc_sum += (y_hat.argmax(axis=<span class="number">1</span>) == y).sum().asscalar()</span><br><span class="line">            n += y.size</span><br><span class="line">        test_acc = evaluate_accuracy(test_iter, net)</span><br><span class="line">        print(<span class="string">'epoch %d, loss %.4f, train acc %.3f, test acc %.3f'</span></span><br><span class="line">              % (epoch + <span class="number">1</span>, train_l_sum / n, train_acc_sum / n, test_acc))</span><br><span class="line"></span><br><span class="line">train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size, <span class="literal">None</span>, <span class="literal">None</span>, optimizer)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> deep_learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>多层感知机</title>
      <link href="/2020/02/13/Deep_learning/%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/"/>
      <url>/2020/02/13/Deep_learning/%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/</url>
      
        <content type="html"><![CDATA[<h1 id="多层感知机"><a href="#多层感知机" class="headerlink" title="多层感知机"></a>多层感知机</h1><p>我们已经介绍了包括线性回归和softmax回归在内的单层神经网络。然而深度学习主要关注多层模型。在本节中，我们将以多层感知机（multilayer perceptron，MLP）为例，介绍多层神经网络的概念。</p><h2 id="隐藏层"><a href="#隐藏层" class="headerlink" title="隐藏层"></a>隐藏层</h2><p>多层感知机在单层神经网络的基础上引入了一到多个隐藏层（hidden layer）。隐藏层位于输入层和输出层之间。图3.3展示了一个多层感知机的神经网络图。</p><p><img src="https://img.vim-cn.com/2e/80d067a824cf71512d77c655855fe8c3488cc3.png" alt="带有隐藏层的多层感知机。它含有一个隐藏层，该层中有5个隐藏单元"></p><p>在图3.3所示的多层感知机中，输入和输出个数分别为4和3，中间的隐藏层中包含了5个隐藏单元（hidden unit）。由于输入层不涉及计算，图3.3中的多层感知机的层数为2。由图3.3可见，隐藏层中的神经元和输入层中各个输入完全连接，输出层中的神经元和隐藏层中的各个神经元也完全连接。因此，多层感知机中的隐藏层和输出层都是全连接层。</p><p>具体来说，给定一个小批量样本$\boldsymbol{X} \in \mathbb{R}^{n \times d}$，其批量大小为$n$，输入个数为$d$。假设多层感知机只有一个隐藏层，其中隐藏单元个数为$h$。记隐藏层的输出（也称为隐藏层变量或隐藏变量）为$\boldsymbol{H}$，有$\boldsymbol{H} \in \mathbb{R}^{n \times h}$。因为隐藏层和输出层均是全连接层，可以设隐藏层的权重参数和偏差参数分别为$\boldsymbol{W}_h \in \mathbb{R}^{d \times h}$和 $\boldsymbol{b}_h \in \mathbb{R}^{1 \times h}$，输出层的权重和偏差参数分别为$\boldsymbol{W}_o \in \mathbb{R}^{h \times q}$和$\boldsymbol{b}_o \in \mathbb{R}^{1 \times q}$。</p><p>我们先来看一种含单隐藏层的多层感知机的设计。其输出$\boldsymbol{O} \in \mathbb{R}^{n \times q}$的计算为</p><p>$$<br>\begin{aligned}<br>\boldsymbol{H} &amp;= \boldsymbol{X} \boldsymbol{W}_h + \boldsymbol{b}_h,\<br>\boldsymbol{O} &amp;= \boldsymbol{H} \boldsymbol{W}_o + \boldsymbol{b}_o,<br>\end{aligned}<br>$$</p><p>也就是将隐藏层的输出直接作为输出层的输入。如果将以上两个式子联立起来，可以得到</p><p>$$<br>\boldsymbol{O} = (\boldsymbol{X} \boldsymbol{W}_h + \boldsymbol{b}_h)\boldsymbol{W}_o + \boldsymbol{b}_o = \boldsymbol{X} \boldsymbol{W}_h\boldsymbol{W}_o + \boldsymbol{b}_h \boldsymbol{W}_o + \boldsymbol{b}_o.<br>$$</p><p>从联立后的式子可以看出，虽然神经网络引入了隐藏层，却依然等价于一个单层神经网络：其中输出层权重参数为$\boldsymbol{W}_h\boldsymbol{W}_o$，偏差参数为$\boldsymbol{b}_h \boldsymbol{W}_o + \boldsymbol{b}_o$。不难发现，即便再添加更多的隐藏层，以上设计依然只能与仅含输出层的单层神经网络等价。</p><h2 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h2><p>上述问题的根源在于全连接层只是对数据做仿射变换（affine transformation），而多个仿射变换的叠加仍然是一个仿射变换。解决问题的一个方法是引入非线性变换，例如对隐藏变量使用按元素运算的非线性函数进行变换，然后再作为下一个全连接层的输入。这个非线性函数被称为激活函数（activation function）。下面我们介绍几个常用的激活函数。</p><h3 id="ReLU函数"><a href="#ReLU函数" class="headerlink" title="ReLU函数"></a>ReLU函数</h3><p>ReLU（rectified linear unit）函数提供了一个很简单的非线性变换。给定元素$x$，该函数定义为</p><p>$$\text{ReLU}(x) = \max(x, 0).$$</p><p>可以看出，ReLU函数只保留正数元素，并将负数元素清零。为了直观地观察这一非线性变换，我们先定义一个绘图函数<code>xyplot</code>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">sys.path.insert(<span class="number">0</span>, <span class="string">'..'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">xyplot</span><span class="params">(x_vals,y_vals,name)</span>:</span></span><br><span class="line">    x_vals=x_vals.detach().numpy() <span class="comment"># we can't directly use var.numpy() because varibles might </span></span><br><span class="line">    y_vals=y_vals.detach().numpy() <span class="comment"># already required grad.,thus using var.detach().numpy() </span></span><br><span class="line">    plt.plot(x_vals,y_vals) </span><br><span class="line">    plt.xlabel(<span class="string">'x'</span>)</span><br><span class="line">    plt.ylabel(name+<span class="string">'(x)'</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x=Variable(torch.arange(<span class="number">-8.0</span>,<span class="number">8.0</span>,<span class="number">0.1</span>,dtype=torch.float32).reshape(int(<span class="number">16</span>/<span class="number">0.1</span>),<span class="number">1</span>),requires_grad=<span class="literal">True</span>)</span><br><span class="line">y=torch.nn.functional.relu(x)</span><br><span class="line">xyplot(x,y,<span class="string">'relu'</span>)</span><br></pre></td></tr></table></figure><p><img src="output_2_0.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y.backward(torch.ones_like(x),retain_graph=<span class="literal">True</span>)</span><br><span class="line">xyplot(x,x.grad,<span class="string">"grad of relu"</span>)</span><br></pre></td></tr></table></figure><p><img src="output_3_0.png" alt="png"></p><h3 id="sigmod函数"><a href="#sigmod函数" class="headerlink" title="sigmod函数"></a>sigmod函数</h3><p>sigmod函数可将元素的值变为0，1之间</p><p>$$\sigma(sigmod)= \frac{1}{1+exp^(-x)}$$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x=Variable(torch.arange(<span class="number">-8.0</span>,<span class="number">8.0</span>,<span class="number">0.1</span>,dtype=torch.float32).reshape(int(<span class="number">16</span>/<span class="number">0.1</span>),<span class="number">1</span>),requires_grad=<span class="literal">True</span>)</span><br><span class="line">y=torch.sigmoid(x)</span><br><span class="line">xyplot(x,y,<span class="string">'sigmoid'</span>)</span><br></pre></td></tr></table></figure><p><img src="output_5_0.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y.backward(torch.ones_like(x),retain_graph=<span class="literal">True</span>)</span><br><span class="line">xyplot(x,x.grad,<span class="string">'grad of sigmoid'</span>)</span><br></pre></td></tr></table></figure><p><img src="output_6_0.png" alt="png"></p><h3 id="tanh-函数"><a href="#tanh-函数" class="headerlink" title="tanh 函数"></a>tanh 函数</h3><p>tanh函数可以将元素的值变为-1，1之间<br>$$ tanh(x) = \frac{1-exp^(-2x)}{1+exp^(-2x)}$$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x=Variable(torch.arange(<span class="number">-8.0</span>,<span class="number">8.0</span>,<span class="number">0.1</span>,dtype=torch.float32).reshape(int(<span class="number">16</span>/<span class="number">0.1</span>),<span class="number">1</span>),requires_grad=<span class="literal">True</span>)</span><br><span class="line">y=torch.tanh(x)</span><br><span class="line">xyplot(x,y,<span class="string">"tanh"</span>)</span><br></pre></td></tr></table></figure><p><img src="output_8_0.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y.backward(torch.ones_like(x),retain_graph=<span class="literal">True</span>)</span><br><span class="line">xyplot(x,x.grad,<span class="string">"grad of tanh"</span>)</span><br></pre></td></tr></table></figure><p><img src="output_9_0.png" alt="png"></p><h3 id="关于激活函数的选择"><a href="#关于激活函数的选择" class="headerlink" title="关于激活函数的选择"></a>关于激活函数的选择</h3><p>ReLu函数是一个通用的激活函数，目前在大多数情况下使用。但是，ReLU函数只能在隐藏层中使用。</p><p>用于分类器时，sigmoid函数及其组合通常效果更好。由于梯度消失问题，有时要避免使用sigmoid和tanh函数。</p><p>在神经网络层数较多的时候，最好使用ReLu函数，ReLu函数比较简单计算量少，而sigmoid和tanh函数计算量大很多。</p><p>在选择激活函数的时候可以先选用ReLu函数如果效果不理想可以尝试其他激活函数。</p><h2 id="多层感知机的pytorch实现"><a href="#多层感知机的pytorch实现" class="headerlink" title="多层感知机的pytorch实现"></a>多层感知机的pytorch实现</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> init</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">sys.path.append(<span class="string">"."</span>) </span><br><span class="line"><span class="keyword">import</span> d2lzh_pytorch <span class="keyword">as</span> d2l</span><br><span class="line"></span><br><span class="line">print(torch.__version__)</span><br></pre></td></tr></table></figure><pre><code>1.3.1</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">num_inputs, num_outputs, num_hiddens = <span class="number">784</span>, <span class="number">10</span>, <span class="number">256</span></span><br><span class="line">    </span><br><span class="line">net = nn.Sequential(</span><br><span class="line">        d2l.FlattenLayer(),</span><br><span class="line">        nn.Linear(num_inputs, num_hiddens),</span><br><span class="line">        nn.ReLU(),</span><br><span class="line">        nn.Linear(num_hiddens, num_outputs), </span><br><span class="line">        )</span><br><span class="line">    </span><br><span class="line"><span class="keyword">for</span> params <span class="keyword">in</span> net.parameters():</span><br><span class="line">    init.normal_(params, mean=<span class="number">0</span>, std=<span class="number">0.01</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">batch_size = <span class="number">256</span></span><br><span class="line">train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)</span><br><span class="line">loss = torch.nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line">optimizer = torch.optim.SGD(net.parameters(), lr=<span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line">num_epochs = <span class="number">5</span></span><br><span class="line">d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size, <span class="literal">None</span>, <span class="literal">None</span>, optimizer)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">### 输出如下</span></span><br><span class="line">epoch <span class="number">1</span>, loss <span class="number">0.0031</span>, train acc <span class="number">0.703</span>, test acc <span class="number">0.757</span></span><br><span class="line">epoch <span class="number">2</span>, loss <span class="number">0.0019</span>, train acc <span class="number">0.824</span>, test acc <span class="number">0.822</span></span><br><span class="line">epoch <span class="number">3</span>, loss <span class="number">0.0016</span>, train acc <span class="number">0.845</span>, test acc <span class="number">0.825</span></span><br><span class="line">epoch <span class="number">4</span>, loss <span class="number">0.0015</span>, train acc <span class="number">0.855</span>, test acc <span class="number">0.811</span></span><br><span class="line">epoch <span class="number">5</span>, loss <span class="number">0.0014</span>, train acc <span class="number">0.865</span>, test acc <span class="number">0.846</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> deep_learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>线性回归</title>
      <link href="/2020/02/12/Deep_learning/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"/>
      <url>/2020/02/12/Deep_learning/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/</url>
      
        <content type="html"><![CDATA[<h1 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h1><ul><li><p>模型<br>$$y = wx + b$$</p></li><li><p>损失函数<br>$$\ell(w_1, w_2, b) =\frac{1}{n} \sum_{i=1}^n \ell^{(i)}(w_1, w_2, b) =\frac{1}{n} \sum_{i=1}^n \frac{1}{2}\left(x_1^{(i)} w_1 + x_2^{(i)} w_2 + b - y^{(i)}\right)^2.$$</p></li><li><p>优化函数<br>$$<br>\begin{aligned}<br>w_1 &amp;\leftarrow w_1 -   \frac{\eta}{|\mathcal{B}|} \sum_{i \in \mathcal{B}} \frac{ \partial \ell^{(i)}(w_1, w_2, b)  }{\partial w_1} = w_1 -   \frac{\eta}{|\mathcal{B}|} \sum_{i \in \mathcal{B}}x_1^{(i)} \left(x_1^{(i)} w_1 + x_2^{(i)} w_2 + b - y^{(i)}\right),\<br>w_2 &amp;\leftarrow w_2 -   \frac{\eta}{|\mathcal{B}|} \sum_{i \in \mathcal{B}} \frac{ \partial \ell^{(i)}(w_1, w_2, b)  }{\partial w_2} = w_2 -   \frac{\eta}{|\mathcal{B}|} \sum_{i \in \mathcal{B}}x_2^{(i)} \left(x_1^{(i)} w_1 + x_2^{(i)} w_2 + b - y^{(i)}\right),\<br>b &amp;\leftarrow b -   \frac{\eta}{|\mathcal{B}|} \sum_{i \in \mathcal{B}} \frac{ \partial \ell^{(i)}(w_1, w_2, b)  }{\partial b} = b -   \frac{\eta}{|\mathcal{B}|} \sum_{i \in \mathcal{B}}\left(x_1^{(i)} w_1 + x_2^{(i)} w_2 + b - y^{(i)}\right).<br>\end{aligned}<br>$$</p></li><li><p>神经网络图（单层神经网络）</p></li></ul><h2 id="线性回归的pytorch实现"><a href="#线性回归的pytorch实现" class="headerlink" title="线性回归的pytorch实现"></a>线性回归的pytorch实现</h2><h3 id="生成数据集"><a href="#生成数据集" class="headerlink" title="生成数据集"></a>生成数据集</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">num_inputs = <span class="number">2</span></span><br><span class="line">num_examples = <span class="number">1000</span></span><br><span class="line">true_w = [<span class="number">2</span>, <span class="number">-3.4</span>]</span><br><span class="line">true_b = <span class="number">4.2</span></span><br><span class="line">features = torch.randn(num_examples, num_inputs)</span><br><span class="line">labels = true_w[<span class="number">0</span>] * features[:, <span class="number">0</span>] + true_w[<span class="number">1</span>] * features[:, <span class="number">1</span>] + true_b</span><br><span class="line">labels += torch.normal(mean=torch.zeros(labels.shape), std=<span class="number">0.01</span>)</span><br></pre></td></tr></table></figure><h3 id="读取数据"><a href="#读取数据" class="headerlink" title="读取数据"></a>读取数据</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils <span class="keyword">import</span> data <span class="keyword">as</span> tdata</span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">10</span></span><br><span class="line"><span class="comment"># 将训练数据的特征和标签组合</span></span><br><span class="line">dataset = tdata.TensorDataset(features, labels)</span><br><span class="line"><span class="comment"># 随机读取小批量</span></span><br><span class="line">data_iter = tdata.DataLoader(dataset, batch_size, shuffle=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> X, y <span class="keyword">in</span> data_iter:</span><br><span class="line">    print(X, y)</span><br><span class="line">    <span class="keyword">break</span></span><br></pre></td></tr></table></figure><pre><code>tensor([[ 0.2115,  1.4861],        [-0.2630,  0.8898],        [ 0.8301, -2.6101],        [ 1.5199, -0.5050],        [-0.4478,  0.6990],        [ 1.4203,  1.1574],        [ 1.3185,  1.1949],        [ 2.0129,  0.8379],        [ 1.1585, -0.1882],        [ 0.9050,  0.0398]]) tensor([-0.4229,  0.6551, 14.7292,  8.9412,  0.9225,  3.1058,  2.7778,  5.3856,         7.1542,  5.8629])</code></pre><h3 id="定义模型"><a href="#定义模型" class="headerlink" title="定义模型"></a>定义模型</h3><p>先导入<code>nn</code>模块。实际上，<code>“nn”</code>是<code>neural networks</code>（神经网络）的缩写。顾名思义，该模块定义了大量神经网络的层。我们先定义一个模型变量<code>net</code>，它是一个<code>Sequential</code>实例。在<code>nn</code>中，<code>Sequential</code>实例可以看作是一个串联各个层的容器。在构造模型时，我们在该容器中依次添加层。当给定输入数据时，容器中的每一层将依次计算并将输出作为下一层的输入。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line">net = nn.Sequential()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"> <span class="comment"># 全连接层是一个线性层，特征数为2，输出个数为1</span></span><br><span class="line">net.add_module(<span class="string">'linear'</span>, nn.Linear(<span class="number">2</span>, <span class="number">1</span>))</span><br></pre></td></tr></table></figure><h3 id="初始化模型参数"><a href="#初始化模型参数" class="headerlink" title="初始化模型参数"></a>初始化模型参数</h3><p>这里主要是初始化线性回归模型中的权重与偏差。使用<code>nn.init</code>模块<br>如<code>nn.init.normal(tensor, std=0.01)</code>指定随机初始化将随机采样均值为0、标准差为0.01的正态分布。偏差初始化默认为0</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> init</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">params_init</span><span class="params">(model)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> isinstance(model, nn.Linear):</span><br><span class="line">        init.normal_(tensor=model.weight.data, std=<span class="number">0.01</span>)</span><br><span class="line">        init.constant_(tensor=model.bias.data, val=<span class="number">0</span>)</span><br><span class="line">        </span><br><span class="line">net.apply(params_init)</span><br></pre></td></tr></table></figure><pre><code>Sequential(  (linear): Linear(in_features=2, out_features=1, bias=True))</code></pre><h3 id="定义损失函数与优化算法"><a href="#定义损失函数与优化算法" class="headerlink" title="定义损失函数与优化算法"></a>定义损失函数与优化算法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">loss = nn.MSELoss() <span class="comment"># 均方误差损失函数</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> optim</span><br><span class="line"></span><br><span class="line">optimizer = optim.SGD(net.parameters(), lr=<span class="number">0.03</span>)  <span class="comment"># lr为学习率</span></span><br></pre></td></tr></table></figure><h3 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">num_epochs = <span class="number">5</span> <span class="comment"># 初始化训练周期</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">1</span>, num_epochs + <span class="number">1</span>):</span><br><span class="line">    <span class="keyword">for</span> X, y <span class="keyword">in</span> data_iter:</span><br><span class="line">        net.zero_grad()</span><br><span class="line">        l = loss(net(X), y.reshape(batch_size, <span class="number">-1</span>))  <span class="comment"># -1表示自动计算列</span></span><br><span class="line">        l.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        l = loss(net(features), labels.reshape(num_examples, <span class="number">-1</span>))</span><br><span class="line">        print(<span class="string">'epoch %d, loss: %f'</span> % (epoch, l.data.numpy()))</span><br></pre></td></tr></table></figure><pre><code>epoch 1, loss: 0.000093epoch 2, loss: 0.000094epoch 3, loss: 0.000094epoch 4, loss: 0.000093epoch 5, loss: 0.000093</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">linear = net[<span class="number">0</span>]</span><br><span class="line">true_w, linear.weight.data</span><br></pre></td></tr></table></figure><pre><code>([2, -3.4], tensor([[ 2.0001, -3.4001]]))</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">true_b, linear.bias.data</span><br></pre></td></tr></table></figure><pre><code>(4.2, tensor([4.2001]))</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">net</span><br></pre></td></tr></table></figure><pre><code>Sequential(  (linear): Linear(in_features=2, out_features=1, bias=True))</code></pre>]]></content>
      
      
      <categories>
          
          <category> deep_learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MYSQL安装配置</title>
      <link href="/2020/01/16/SQL/MySQL%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/"/>
      <url>/2020/01/16/SQL/MySQL%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/</url>
      
        <content type="html"><![CDATA[<h1 id="MySQL的安装与配置"><a href="#MySQL的安装与配置" class="headerlink" title="MySQL的安装与配置"></a>MySQL的安装与配置</h1><h2 id="下载软件与安装"><a href="#下载软件与安装" class="headerlink" title="下载软件与安装"></a>下载软件与安装</h2><ol><li>到<code>mySQL</code>的官网：<a href="https://dev.mysql.com/downloads/mysql/" target="_blank" rel="noopener">点击这里</a>，看到下图，下载即可。</li><li>解压缩到你所需要的路径<h2 id="MySQL配置"><a href="#MySQL配置" class="headerlink" title="MySQL配置"></a>MySQL配置</h2><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">[mysqld]</span></span><br><span class="line"><span class="comment"># 设置3306端口</span></span><br><span class="line"><span class="string">port=3306</span></span><br><span class="line"><span class="comment"># 设置mysql的安装目录</span></span><br><span class="line"><span class="string">basedir=&lt;你的路径&gt;\mysql-8.0.11-winx64</span></span><br><span class="line"><span class="comment"># 设置mysql数据库的数据的存放目录</span></span><br><span class="line"><span class="string">datadir=&lt;你的路径&gt;\mysql-8.0.11-winx64\\data</span></span><br><span class="line"><span class="comment"># 允许最大连接数</span></span><br><span class="line"><span class="string">max_connections=200</span></span><br><span class="line"><span class="comment"># 允许连接失败的次数。这是为了防止有人从该主机试图攻击数据库系统</span></span><br><span class="line"><span class="string">max_connect_errors=10000</span></span><br><span class="line"><span class="comment"># 服务端使用的字符集默认为UTF8</span></span><br><span class="line"><span class="string">character-set-server=utf8</span></span><br><span class="line"><span class="comment"># 创建新表时将使用的默认存储引擎</span></span><br><span class="line"><span class="string">default-storage-engine=INNODB</span></span><br><span class="line"><span class="string">wait_timeout=31536000</span></span><br><span class="line"><span class="string">interactive_timeout=31536000</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#sql_mode=ONLY_FULL_GROUP_BY,STRICT_TRANS_TABLES,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION</span></span><br><span class="line"><span class="string">[mysql]</span></span><br><span class="line"><span class="comment"># 设置mysql客户端默认字符集</span></span><br><span class="line"><span class="string">default-character-set=utf8</span></span><br><span class="line"></span><br><span class="line"><span class="string">[client]</span></span><br><span class="line"><span class="comment"># 设置mysql客户端连接服务端时默认使用的端口</span></span><br><span class="line"><span class="string">port=3306</span></span><br><span class="line"><span class="string">default-character-set=utf8</span></span><br></pre></td></tr></table></figure><h2 id="环境变量配置"><a href="#环境变量配置" class="headerlink" title="环境变量配置"></a>环境变量配置</h2></li><li><p>系统变量添加</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">MYSQL_HOME  :</span> <span class="string">path</span></span><br></pre></td></tr></table></figure></li><li><p>环境变量添加</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">%MYSQL_HOME%\bin</span></span><br></pre></td></tr></table></figure></li><li>如果上面2个方法都不想使用，可以使用下面这个方法：<br><img src="https://img-blog.csdn.net/20180416193135760?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L20wXzM3Nzg4MzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""></li></ol><h2 id="MySQL初始化"><a href="#MySQL初始化" class="headerlink" title="MySQL初始化"></a>MySQL初始化</h2><ol><li>CMD运行<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ mysqld --initialize --user=mysql --console</span><br></pre></td></tr></table></figure><img src="https://img-blog.csdn.net/20180416190435744?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L20wXzM3Nzg4MzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""><br>务必记住这个初始密码，一会需要用这个初始密码登录mysql；<br>修改密码如果emm你把他点没了 你只要把datadir配置的那个data的文件删除了，然后重新执行初始化即可然后输入：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysqld --install</span><br></pre></td></tr></table></figure>再打开服务：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">net start mysql</span><br></pre></td></tr></table></figure></li></ol><h2 id="修改默认密码"><a href="#修改默认密码" class="headerlink" title="修改默认密码"></a>修改默认密码</h2><p>执行：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql -u root -p</span><br></pre></td></tr></table></figure><br>登录,输入初始密码，接下来修改密码：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ALTER USER <span class="string">"root@"</span>localhost<span class="string">" IDENTIFIED BY "</span>your password<span class="string">"</span></span><br></pre></td></tr></table></figure></p><h2 id="其它"><a href="#其它" class="headerlink" title="其它"></a>其它</h2><p>如果你在数据库连接工具的时候出现错误，则可以再<code>my.ini</code>文件中的<code>mysqld</code>中加入：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ default_authentication_plugin=mysql_native_password</span><br></pre></td></tr></table></figure></p>]]></content>
      
      
      <categories>
          
          <category> SQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SQL语言基础</title>
      <link href="/2020/01/15/SQL/SQL%E8%AF%AD%E8%A8%80%EF%BC%88%E4%B8%80%EF%BC%89/"/>
      <url>/2020/01/15/SQL/SQL%E8%AF%AD%E8%A8%80%EF%BC%88%E4%B8%80%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<h1 id="SQL语言"><a href="#SQL语言" class="headerlink" title="SQL语言"></a>SQL语言</h1><p>简单来说，你需要在数据库上执行的操作大部分都要由SQL语句完成<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> websites</span><br></pre></td></tr></table></figure><br>但是，SQL语句并不对大小写敏感，同时我们在本例教程中，每个语句都加上分号<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; use RUNOOB;</span><br><span class="line">Database changed</span><br><span class="line"></span><br><span class="line">mysql&gt; set names utf8;</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; SELECT * FROM Websites;</span><br><span class="line">+<span class="comment">----+--------------+---------------------------+-------+---------+</span></span><br><span class="line">| id | name         | url                       | alexa | country |</span><br><span class="line">+<span class="comment">----+--------------+---------------------------+-------+---------+</span></span><br><span class="line">| 1  | Google       | https://www.google.cm/    | 1     | USA     |</span><br><span class="line">| 2  | 淘宝          | https://www.taobao.com/   | 13    | CN      |</span><br><span class="line">| 3  | 菜鸟教程      | http://www.runoob.com/    | 4689  | CN      |</span><br><span class="line">| 4  | 微博          | http://weibo.com/         | 20    | CN      |</span><br><span class="line">| 5  | Facebook     | https://www.facebook.com/ | 3     | USA     |</span><br><span class="line">+<span class="comment">----+--------------+---------------------------+-------+---------+</span></span><br><span class="line">5 rows in <span class="keyword">set</span> (<span class="number">0.01</span> sec)</span><br></pre></td></tr></table></figure><br>下面的大部分都是基于这个表格的</p><h2 id="SQL-SELECT-语句"><a href="#SQL-SELECT-语句" class="headerlink" title="SQL SELECT 语句"></a>SQL SELECT 语句</h2><p>SELECT语句用于从数据库中选取数据，结果被存在一个结果表中，称为结果集</p><h3 id="SELECT-语法"><a href="#SELECT-语法" class="headerlink" title="SELECT 语法"></a>SELECT 语法</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> column_name,column_name <span class="keyword">FROM</span> table_name;  <span class="comment"># 选出指定列</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> table_name;  <span class="comment"># 选出所有的列</span></span><br></pre></td></tr></table></figure><h2 id="SQL-SELECT-DISTINCT-语句"><a href="#SQL-SELECT-DISTINCT-语句" class="headerlink" title="SQL SELECT DISTINCT 语句"></a>SQL SELECT DISTINCT 语句</h2><p>在表中，一个列可能会包含多个重复值，DISTINCT关键词用于返回唯一不同的值,就是会删掉重复的值</p><h3 id="SQL-SELECT-DISTINCT-语法"><a href="#SQL-SELECT-DISTINCT-语法" class="headerlink" title="SQL SELECT DISTINCT 语法"></a>SQL SELECT DISTINCT 语法</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">DISTINCT</span> column_name, column_name <span class="keyword">FROM</span> table_name;</span><br></pre></td></tr></table></figure><h2 id="SELECT-WHERE子句"><a href="#SELECT-WHERE子句" class="headerlink" title="SELECT WHERE子句"></a>SELECT WHERE子句</h2><p>WHERE子句用于提取那些阿玛尼组指定条件的记录</p><h3 id="SQL-WHERE-语法"><a href="#SQL-WHERE-语法" class="headerlink" title="SQL WHERE 语法"></a>SQL WHERE 语法</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> column_name,column_name <span class="keyword">FROM</span> table_name <span class="keyword">WHERE</span> column_name <span class="keyword">operator</span> <span class="keyword">value</span>;</span><br></pre></td></tr></table></figure><h3 id="文本字段-vs-数值字段"><a href="#文本字段-vs-数值字段" class="headerlink" title="文本字段 vs 数值字段"></a>文本字段 vs 数值字段</h3><p>SQL中使用<strong>单引号</strong>来环绕文本数值，但是如果是数值就不用使用单引号了，如：<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> websites <span class="keyword">WHERE</span> <span class="keyword">id</span> = <span class="number">1</span>;</span><br><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> websites <span class="keyword">WHERE</span> country = <span class="string">'CN'</span>;</span><br></pre></td></tr></table></figure></p><h3 id="WHERE子句的运算符"><a href="#WHERE子句的运算符" class="headerlink" title="WHERE子句的运算符"></a>WHERE子句的运算符</h3><div class="table-container"><table><thead><tr><th>运算符</th><th>描述</th></tr></thead><tbody><tr><td>&lt;&gt;或者!=</td><td>不等于</td></tr><tr><td>BETWEEN</td><td>在某个范围内</td></tr><tr><td>LIKE</td><td>搜索某种模式</td></tr><tr><td>IN</td><td>指定针对某个列的可能值</td></tr></tbody></table></div><h2 id="SQL-AND-amp-OR-运算符"><a href="#SQL-AND-amp-OR-运算符" class="headerlink" title="SQL AND &amp; OR 运算符"></a>SQL AND &amp; OR 运算符</h2><p>AND &amp; OR 运算符基于一个以上条件对记录进行过滤  </p><ul><li>如果第一个条件与第二个条件都成立，则ADN运算符显示一条记录</li><li>如果第一个条件与第二个条件有一个成立，则OR运算符显示一条记录</li></ul><h3 id="SQL-AND-amp-OR-语法"><a href="#SQL-AND-amp-OR-语法" class="headerlink" title="SQL AND &amp; OR 语法"></a>SQL AND &amp; OR 语法</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> Websites <span class="keyword">WHERE</span> country = <span class="string">'CN'</span> <span class="keyword">AND</span> alexa &gt; <span class="number">50</span>;</span><br><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> websites <span class="keyword">WHERE</span> country = <span class="string">'USA'</span> <span class="keyword">OR</span> country = <span class="string">'CN'</span>;</span><br></pre></td></tr></table></figure><h3 id="结合AND-和-OR"><a href="#结合AND-和-OR" class="headerlink" title="结合AND 和 OR"></a>结合AND 和 OR</h3><p>用法示例如下：<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> websites <span class="keyword">WHERE</span> alexa &gt; <span class="number">15</span> </span><br><span class="line"><span class="keyword">AND</span> (country = <span class="string">'CN'</span> <span class="keyword">OR</span> country = <span class="string">'USA'</span>)</span><br></pre></td></tr></table></figure></p><h2 id="SQL-ORDER-BY-关键词"><a href="#SQL-ORDER-BY-关键词" class="headerlink" title="SQL ORDER BY 关键词"></a>SQL ORDER BY 关键词</h2><p>ORDER BY 关键词用于对于结果集按照一个列或者多个列进行排序</p><h3 id="SQL-ORDER-BY-的语法"><a href="#SQL-ORDER-BY-的语法" class="headerlink" title="SQL ORDER BY 的语法"></a>SQL ORDER BY 的语法</h3><p>ORDER BY关键词默认按照升序进行排列，如果需要降序，则可以使用DESC关键字<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> column_name, column_name <span class="keyword">FROM</span> table_name </span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> column_name, column_name <span class="keyword">ASC</span>|<span class="keyword">DESC</span>;</span><br></pre></td></tr></table></figure></p><h3 id="SQL-ORDER-BY-DESC-实例"><a href="#SQL-ORDER-BY-DESC-实例" class="headerlink" title="SQL ORDER BY(DESC)实例"></a>SQL ORDER BY(DESC)实例</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> websites <span class="keyword">ORDER</span> <span class="keyword">BY</span> alexa ;</span><br><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> websites <span class="keyword">ORDER</span> <span class="keyword">BY</span> alexa <span class="keyword">DESC</span>;</span><br></pre></td></tr></table></figure><h3 id="ORDER-BY-多列"><a href="#ORDER-BY-多列" class="headerlink" title="ORDER BY 多列"></a>ORDER BY 多列</h3><p>当有多列进行排序时，我们优先选择第一列<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> websites <span class="keyword">ORDER</span> <span class="keyword">BY</span> country,alexa;</span><br></pre></td></tr></table></figure></p><h2 id="SQL-INSERT-INTO语句"><a href="#SQL-INSERT-INTO语句" class="headerlink" title="SQL INSERT INTO语句"></a>SQL INSERT INTO语句</h2><p>INSERT INTO语句向表中插入新纪录</p><h3 id="SQL-INSERT-INTO语句的语法"><a href="#SQL-INSERT-INTO语句的语法" class="headerlink" title="SQL INSERT INTO语句的语法"></a>SQL INSERT INTO语句的语法</h3><p>INSERT 语句有两种编写形式：</p><ul><li>第一钟形式无需指定要插入数据的列名，只需要提供被插入的值即可：<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> table_name <span class="keyword">VALUES</span> (value1,value2,value3);</span><br></pre></td></tr></table></figure></li><li>第二种形式需要指定列名及被插入的值<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> table_name (column1, column2,column3) <span class="keyword">VALUES</span> (value1,value2,value3)</span><br></pre></td></tr></table></figure><h3 id="INSERT-INTO实例"><a href="#INSERT-INTO实例" class="headerlink" title="INSERT INTO实例"></a>INSERT INTO实例</h3>假设我们需要向‘websites’表钟插入一个新行<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> websites(<span class="keyword">name</span>, <span class="keyword">url</span>, alexa, country) <span class="keyword">VALUES</span>(<span class="string">'百度’, '</span>https://www.baidu.com/<span class="string">','</span><span class="number">4</span><span class="string">','</span>CN<span class="string">');</span></span><br></pre></td></tr></table></figure><h3 id="在指定的列插入数据"><a href="#在指定的列插入数据" class="headerlink" title="在指定的列插入数据"></a>在指定的列插入数据</h3>下面的SQL语句将插入一个新行，但是只在’name’、‘url’、’country‘列插入数据<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> websites(<span class="keyword">name</span>, <span class="keyword">url</span>, country) <span class="keyword">VALUES</span> (<span class="string">'stackoverflow'</span>, <span class="string">'http://stackoverflow.com/'</span>, <span class="string">'IND'</span>)</span><br></pre></td></tr></table></figure><h2 id="SQL-UPDATE-语句"><a href="#SQL-UPDATE-语句" class="headerlink" title="SQL UPDATE 语句"></a>SQL UPDATE 语句</h2>UPDATE语句用于更新表中已经存在的记录</li></ul><h3 id="UPDATE语句的语法"><a href="#UPDATE语句的语法" class="headerlink" title="UPDATE语句的语法"></a>UPDATE语句的语法</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">UPDATE</span> table_name <span class="keyword">SET</span> <span class="keyword">column</span> = value1, column2 = value2,... <span class="keyword">WHERE</span> some_column = some_value;</span><br></pre></td></tr></table></figure><h3 id="UPDATE实例"><a href="#UPDATE实例" class="headerlink" title="UPDATE实例"></a>UPDATE实例</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">UPADATE Websites <span class="keyword">SET</span> alexa = <span class="string">'500'</span>, country = <span class="string">'USA'</span> <span class="keyword">WHERE</span> <span class="keyword">name</span> = <span class="string">'菜鸟教程’;</span></span><br></pre></td></tr></table></figure><h2 id="SQL-DELETE"><a href="#SQL-DELETE" class="headerlink" title="SQL DELETE"></a>SQL DELETE</h2><p>DELET语句用于删除表中的行</p><h3 id="SQL-DELETE语法和实例"><a href="#SQL-DELETE语法和实例" class="headerlink" title="SQL DELETE语法和实例"></a>SQL DELETE语法和实例</h3><p>从表中删除网站名是百度且国家为CN的网站<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DELET FROM websites WHERE name = '百度' AND country = 'CN';</span><br></pre></td></tr></table></figure></p><h3 id="删除所有数据"><a href="#删除所有数据" class="headerlink" title="删除所有数据"></a>删除所有数据</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">DELETE</span> <span class="keyword">FROM</span> table_name;</span><br><span class="line"><span class="keyword">DELETE</span> * <span class="keyword">FROM</span> table_name;</span><br></pre></td></tr></table></figure><h2 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h2><p>非常感谢菜鸟教程，本文借鉴了菜鸟教程的表格和相关代码：<a href="https://www.runoob.com/sql/sql-syntax.html" target="_blank" rel="noopener">菜鸟教程</a>: <a href="https://www.runoob.com/sql/sql-syntax.html" target="_blank" rel="noopener">https://www.runoob.com/sql/sql-syntax.html</a></p>]]></content>
      
      
      <categories>
          
          <category> SQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>《机器学习实战》《西瓜书》笔记（八）- K均值聚类</title>
      <link href="/2019/11/30/Machine_Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%888-K%E5%9D%87%E5%80%BC%E8%81%9A%E7%B1%BB%EF%BC%89/"/>
      <url>/2019/11/30/Machine_Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%888-K%E5%9D%87%E5%80%BC%E8%81%9A%E7%B1%BB%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<h1 id="K均值聚类"><a href="#K均值聚类" class="headerlink" title="K均值聚类"></a>K均值聚类</h1><p>算法伪代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">创建k个点作为起始质心（经常是随机选择）</span><br><span class="line">当任意一个点的簇分配结果发生改变时</span><br><span class="line">    对数据集中的每个数据点</span><br><span class="line">        对每个质心</span><br><span class="line">            计算质心与数据点之间的距离</span><br><span class="line">        将数据点分配到距离其最近的簇</span><br><span class="line">    对每一个簇，计算簇中所有点的均值，并且将该值作为质心</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：k-means聚类算法</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    dataSet - 用于聚类的数据集</span></span><br><span class="line"><span class="string">    k - 选取k个质心</span></span><br><span class="line"><span class="string">    distMeas - 距离计算方法,默认欧氏距离distEclud()</span></span><br><span class="line"><span class="string">    createCent - 获取k个质心的方法,默认随机获取randCent()</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    centroids - k个聚类的聚类结果</span></span><br><span class="line"><span class="string">    clusterAssment - 聚类误差</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">kMeans</span><span class="params">(dataSet, k, distMeas=distEclud, createCent=randCent)</span>:</span></span><br><span class="line">    <span class="comment"># 获取数据集样本数</span></span><br><span class="line">    m = np.shape(dataSet)[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># 初始化一个（m,2）全零矩阵</span></span><br><span class="line">    clusterAssment = np.mat(np.zeros((m, <span class="number">2</span>)))</span><br><span class="line">    <span class="comment"># 创建初始的k个质心向量</span></span><br><span class="line">    centroids = createCent(dataSet, k)</span><br><span class="line">    <span class="comment"># 聚类结果是否发生变化的布尔类型</span></span><br><span class="line">    clusterChanged = <span class="literal">True</span></span><br><span class="line">    <span class="comment"># 只要聚类结果一直发生变化，就一直执行聚类算法，直至所有数据点聚类结果不发生变化</span></span><br><span class="line">    <span class="keyword">while</span> clusterChanged:</span><br><span class="line">        <span class="comment"># 聚类结果变化布尔类型置为False</span></span><br><span class="line">        clusterChanged = <span class="literal">False</span></span><br><span class="line">        <span class="comment"># 遍历数据集每一个样本向量</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">            <span class="comment"># 初始化最小距离为正无穷，最小距离对应的索引为-1</span></span><br><span class="line">            minDist = float(<span class="string">'inf'</span>)</span><br><span class="line">            minIndex = <span class="number">-1</span></span><br><span class="line">            <span class="comment"># 循环k个类的质心</span></span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(k):</span><br><span class="line">                <span class="comment"># 计算数据点到质心的欧氏距离</span></span><br><span class="line">                distJI = distMeas(centroids[j, :], dataSet[i, :])</span><br><span class="line">                <span class="comment"># 如果距离小于当前最小距离</span></span><br><span class="line">                <span class="keyword">if</span> distJI &lt; minDist:</span><br><span class="line">                    <span class="comment"># 当前距离为最小距离，最小距离对应索引应为j(第j个类)</span></span><br><span class="line">                    minDist = distJI</span><br><span class="line">                    minIndex = j</span><br><span class="line">            <span class="comment"># 当前聚类结果中第i个样本的聚类结果发生变化：布尔值置为True，继续聚类算法</span></span><br><span class="line">            <span class="keyword">if</span> clusterAssment[i, <span class="number">0</span>] != minIndex: </span><br><span class="line">                clusterChanged = <span class="literal">True</span></span><br><span class="line">            <span class="comment"># 更新当前变化样本的聚类结果和平方误差</span></span><br><span class="line">            clusterAssment[i, :] = minIndex, minDist**<span class="number">2</span></span><br><span class="line">            <span class="comment"># 打印k-means聚类的质心</span></span><br><span class="line">        <span class="comment"># print(centroids)</span></span><br><span class="line">        <span class="comment"># 遍历每一个质心</span></span><br><span class="line">        <span class="keyword">for</span> cent <span class="keyword">in</span> range(k):</span><br><span class="line">            <span class="comment"># 将数据集中所有属于当前质心类的样本通过条件过滤筛选出来</span></span><br><span class="line">            ptsInClust = dataSet[np.nonzero(clusterAssment[:, <span class="number">0</span>].A == cent)[<span class="number">0</span>]]</span><br><span class="line">            <span class="comment"># 计算这些数据的均值(axis=0:求列均值)，作为该类质心向量</span></span><br><span class="line">            centroids[cent, :] = np.mean(ptsInClust, axis=<span class="number">0</span>)</span><br><span class="line">    <span class="comment"># 返回k个聚类，聚类结果及误差</span></span><br><span class="line">    <span class="keyword">return</span> centroids, clusterAssment</span><br></pre></td></tr></table></figure><h2 id="源代码"><a href="#源代码" class="headerlink" title="源代码"></a>源代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Created on Thu Aug  2 21:20:03 2018</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">@author: wzy</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：将文本文档中的数据读入到python中</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    fileName - 文件名</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    dataMat - 数据矩阵</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadDataSet</span><span class="params">(fileName)</span>:</span></span><br><span class="line">    dataMat = []</span><br><span class="line">    fr = open(fileName)</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> fr.readlines():</span><br><span class="line">        curLine = line.strip().split(<span class="string">'\t'</span>)</span><br><span class="line">        fltLine = list(map(float, curLine))</span><br><span class="line">        dataMat.append(fltLine)</span><br><span class="line">    <span class="keyword">return</span> dataMat</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：数据向量计算欧式距离</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    vecA - 数据向量A</span></span><br><span class="line"><span class="string">    vecB - 数据向量B</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    两个向量之间的欧几里德距离</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Modify:</span></span><br><span class="line"><span class="string">    2018-08-02</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">distEclud</span><span class="params">(vecA, vecB)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> np.sqrt(np.sum(np.power(vecA - vecB, <span class="number">2</span>)))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：随机初始化k个质心（质心满足数据边界之内）</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    dataSet - 输入的数据集</span></span><br><span class="line"><span class="string">    k - 选取k个质心</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    centroids - 返回初始化得到的k个质心向量</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">randCent</span><span class="params">(dataSet, k)</span>:</span></span><br><span class="line">    <span class="comment"># 得到数据样本的维度</span></span><br><span class="line">    n = np.shape(dataSet)[<span class="number">1</span>]</span><br><span class="line">    <span class="comment"># 初始化为一个(k,n)的全零矩阵</span></span><br><span class="line">    centroids = np.mat(np.zeros((k, n)))</span><br><span class="line">    <span class="comment"># 遍历数据集的每一个维度</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(n):</span><br><span class="line">        <span class="comment"># 得到该列数据的最小值,最大值</span></span><br><span class="line">        minJ = np.min(dataSet[:, j])</span><br><span class="line">        maxJ = np.max(dataSet[:, j])</span><br><span class="line">        <span class="comment"># 得到该列数据的范围(最大值-最小值)</span></span><br><span class="line">        rangeJ = float(maxJ - minJ)</span><br><span class="line">        <span class="comment"># k个质心向量的第j维数据值随机为位于(最小值，最大值)内的某一值</span></span><br><span class="line">        <span class="comment"># Create an array of the given shape and populate it with random samples from a uniform distribution over [0, 1).</span></span><br><span class="line">        centroids[:, j] = minJ + rangeJ * np.random.rand(k, <span class="number">1</span>)</span><br><span class="line">    <span class="comment"># 返回初始化得到的k个质心向量</span></span><br><span class="line">    <span class="keyword">return</span> centroids</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：k-means聚类算法</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    dataSet - 用于聚类的数据集</span></span><br><span class="line"><span class="string">    k - 选取k个质心</span></span><br><span class="line"><span class="string">    distMeas - 距离计算方法,默认欧氏距离distEclud()</span></span><br><span class="line"><span class="string">    createCent - 获取k个质心的方法,默认随机获取randCent()</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    centroids - k个聚类的聚类结果</span></span><br><span class="line"><span class="string">    clusterAssment - 聚类误差</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">kMeans</span><span class="params">(dataSet, k, distMeas=distEclud, createCent=randCent)</span>:</span></span><br><span class="line">    <span class="comment"># 获取数据集样本数</span></span><br><span class="line">    m = np.shape(dataSet)[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># 初始化一个（m,2）全零矩阵</span></span><br><span class="line">    clusterAssment = np.mat(np.zeros((m, <span class="number">2</span>)))</span><br><span class="line">    <span class="comment"># 创建初始的k个质心向量</span></span><br><span class="line">    centroids = createCent(dataSet, k)</span><br><span class="line">    <span class="comment"># 聚类结果是否发生变化的布尔类型</span></span><br><span class="line">    clusterChanged = <span class="literal">True</span></span><br><span class="line">    <span class="comment"># 只要聚类结果一直发生变化，就一直执行聚类算法，直至所有数据点聚类结果不发生变化</span></span><br><span class="line">    <span class="keyword">while</span> clusterChanged:</span><br><span class="line">        <span class="comment"># 聚类结果变化布尔类型置为False</span></span><br><span class="line">        clusterChanged = <span class="literal">False</span></span><br><span class="line">        <span class="comment"># 遍历数据集每一个样本向量</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">            <span class="comment"># 初始化最小距离为正无穷，最小距离对应的索引为-1</span></span><br><span class="line">            minDist = float(<span class="string">'inf'</span>)</span><br><span class="line">            minIndex = <span class="number">-1</span></span><br><span class="line">            <span class="comment"># 循环k个类的质心</span></span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(k):</span><br><span class="line">                <span class="comment"># 计算数据点到质心的欧氏距离</span></span><br><span class="line">                distJI = distMeas(centroids[j, :], dataSet[i, :])</span><br><span class="line">                <span class="comment"># 如果距离小于当前最小距离</span></span><br><span class="line">                <span class="keyword">if</span> distJI &lt; minDist:</span><br><span class="line">                    <span class="comment"># 当前距离为最小距离，最小距离对应索引应为j(第j个类)</span></span><br><span class="line">                    minDist = distJI</span><br><span class="line">                    minIndex = j</span><br><span class="line">            <span class="comment"># 当前聚类结果中第i个样本的聚类结果发生变化：布尔值置为True，继续聚类算法</span></span><br><span class="line">            <span class="keyword">if</span> clusterAssment[i, <span class="number">0</span>] != minIndex: </span><br><span class="line">                clusterChanged = <span class="literal">True</span></span><br><span class="line">            <span class="comment"># 更新当前变化样本的聚类结果和平方误差</span></span><br><span class="line">            clusterAssment[i, :] = minIndex, minDist**<span class="number">2</span></span><br><span class="line">            <span class="comment"># 打印k-means聚类的质心</span></span><br><span class="line">        <span class="comment"># print(centroids)</span></span><br><span class="line">        <span class="comment"># 遍历每一个质心</span></span><br><span class="line">        <span class="keyword">for</span> cent <span class="keyword">in</span> range(k):</span><br><span class="line">            <span class="comment"># 将数据集中所有属于当前质心类的样本通过条件过滤筛选出来</span></span><br><span class="line">            ptsInClust = dataSet[np.nonzero(clusterAssment[:, <span class="number">0</span>].A == cent)[<span class="number">0</span>]]</span><br><span class="line">            <span class="comment"># 计算这些数据的均值(axis=0:求列均值)，作为该类质心向量</span></span><br><span class="line">            centroids[cent, :] = np.mean(ptsInClust, axis=<span class="number">0</span>)</span><br><span class="line">    <span class="comment"># 返回k个聚类，聚类结果及误差</span></span><br><span class="line">    <span class="keyword">return</span> centroids, clusterAssment</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：绘制数据集</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    fileName - 文件名</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    None</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plotDataSet</span><span class="params">(filename)</span>:</span></span><br><span class="line">    <span class="comment"># 导入数据</span></span><br><span class="line">    datMat = np.mat(loadDataSet(filename))</span><br><span class="line">    <span class="comment"># 进行k-means算法其中k为4</span></span><br><span class="line">    myCentroids, clustAssing = kMeans(datMat, <span class="number">4</span>)</span><br><span class="line">    clustAssing = clustAssing.tolist()</span><br><span class="line">    myCentroids = myCentroids.tolist()</span><br><span class="line">    xcord = [[], [], [], []]</span><br><span class="line">    ycord = [[], [], [], []]</span><br><span class="line">    datMat = datMat.tolist()</span><br><span class="line">    m = len(clustAssing)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">        <span class="keyword">if</span> int(clustAssing[i][<span class="number">0</span>]) == <span class="number">0</span>:</span><br><span class="line">            xcord[<span class="number">0</span>].append(datMat[i][<span class="number">0</span>])</span><br><span class="line">            ycord[<span class="number">0</span>].append(datMat[i][<span class="number">1</span>])</span><br><span class="line">        <span class="keyword">elif</span> int(clustAssing[i][<span class="number">0</span>]) == <span class="number">1</span>:</span><br><span class="line">            xcord[<span class="number">1</span>].append(datMat[i][<span class="number">0</span>])</span><br><span class="line">            ycord[<span class="number">1</span>].append(datMat[i][<span class="number">1</span>])</span><br><span class="line">        <span class="keyword">elif</span> int(clustAssing[i][<span class="number">0</span>]) == <span class="number">2</span>:</span><br><span class="line">            xcord[<span class="number">2</span>].append(datMat[i][<span class="number">0</span>])</span><br><span class="line">            ycord[<span class="number">2</span>].append(datMat[i][<span class="number">1</span>])</span><br><span class="line">        <span class="keyword">elif</span> int(clustAssing[i][<span class="number">0</span>]) == <span class="number">3</span>:</span><br><span class="line">            xcord[<span class="number">3</span>].append(datMat[i][<span class="number">0</span>])</span><br><span class="line">            ycord[<span class="number">3</span>].append(datMat[i][<span class="number">1</span>])</span><br><span class="line">    fig = plt.figure()</span><br><span class="line">    ax = fig.add_subplot(<span class="number">111</span>)</span><br><span class="line">    <span class="comment"># 绘制样本点</span></span><br><span class="line">    ax.scatter(xcord[<span class="number">0</span>], ycord[<span class="number">0</span>], s=<span class="number">20</span>, c=<span class="string">'b'</span>, marker=<span class="string">'*'</span>, alpha=<span class="number">.5</span>)</span><br><span class="line">    ax.scatter(xcord[<span class="number">1</span>], ycord[<span class="number">1</span>], s=<span class="number">20</span>, c=<span class="string">'r'</span>, marker=<span class="string">'D'</span>, alpha=<span class="number">.5</span>)</span><br><span class="line">    ax.scatter(xcord[<span class="number">2</span>], ycord[<span class="number">2</span>], s=<span class="number">20</span>, c=<span class="string">'c'</span>, marker=<span class="string">'&gt;'</span>, alpha=<span class="number">.5</span>)</span><br><span class="line">    ax.scatter(xcord[<span class="number">3</span>], ycord[<span class="number">3</span>], s=<span class="number">20</span>, c=<span class="string">'k'</span>, marker=<span class="string">'o'</span>, alpha=<span class="number">.5</span>)</span><br><span class="line">    <span class="comment"># 绘制质心</span></span><br><span class="line">    ax.scatter(myCentroids[<span class="number">0</span>][<span class="number">0</span>], myCentroids[<span class="number">0</span>][<span class="number">1</span>], s=<span class="number">100</span>, c=<span class="string">'k'</span>, marker=<span class="string">'+'</span>, alpha=<span class="number">.5</span>)</span><br><span class="line">    ax.scatter(myCentroids[<span class="number">1</span>][<span class="number">0</span>], myCentroids[<span class="number">1</span>][<span class="number">1</span>], s=<span class="number">100</span>, c=<span class="string">'k'</span>, marker=<span class="string">'+'</span>, alpha=<span class="number">.5</span>)</span><br><span class="line">    ax.scatter(myCentroids[<span class="number">2</span>][<span class="number">0</span>], myCentroids[<span class="number">2</span>][<span class="number">1</span>], s=<span class="number">100</span>, c=<span class="string">'k'</span>, marker=<span class="string">'+'</span>, alpha=<span class="number">.5</span>)</span><br><span class="line">    ax.scatter(myCentroids[<span class="number">3</span>][<span class="number">0</span>], myCentroids[<span class="number">3</span>][<span class="number">1</span>], s=<span class="number">100</span>, c=<span class="string">'k'</span>, marker=<span class="string">'+'</span>, alpha=<span class="number">.5</span>)</span><br><span class="line">    plt.title(<span class="string">'DataSet'</span>)</span><br><span class="line">    plt.xlabel(<span class="string">'X'</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    plotDataSet(<span class="string">'testSet.txt'</span>)</span><br></pre></td></tr></table></figure><h1 id="二分K均值聚类"><a href="#二分K均值聚类" class="headerlink" title="二分K均值聚类"></a>二分K均值聚类</h1><p>算法伪代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">将所有点看成一个簇</span><br><span class="line">当簇数目小于K时</span><br><span class="line">    对每一个簇</span><br><span class="line">        计算总误差</span><br><span class="line">        在给定的簇上面进行K-均值聚类（k&#x3D;2)</span><br><span class="line">        计算将该簇一分为二之后的总误差</span><br><span class="line">    选择使得误差最小的那个簇进行划分操作</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：二分k-means聚类算法</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    dataSet - 用于聚类的数据集</span></span><br><span class="line"><span class="string">    k - 选取k个质心</span></span><br><span class="line"><span class="string">    distMeas - 距离计算方法,默认欧氏距离distEclud()</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    centList - k个聚类的聚类结果</span></span><br><span class="line"><span class="string">    clusterAssment - 聚类误差</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">biKmeans</span><span class="params">(dataSet, k, distMeas=distEclud)</span>:</span></span><br><span class="line">    <span class="comment"># 获取数据集的样本数</span></span><br><span class="line">    m = np.shape(dataSet)[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># 初始化一个元素均值0的(m, 2)矩阵</span></span><br><span class="line">    clusterAssment = np.mat(np.zeros((m, <span class="number">2</span>)))</span><br><span class="line">    <span class="comment"># 获取数据集每一列数据的均值，组成一个列表</span></span><br><span class="line">    centroid0 = np.mean(dataSet, axis=<span class="number">0</span>).tolist()[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># 当前聚类列表为将数据集聚为一类</span></span><br><span class="line">    centList = [centroid0]</span><br><span class="line">    <span class="comment"># 遍历每个数据集样本</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(m):</span><br><span class="line">        <span class="comment"># 计算当前聚为一类时各个数据点距离质心的平方距离</span></span><br><span class="line">        clusterAssment[j, <span class="number">1</span>] = distMeas(np.mat(centroid0), dataSet[j, :])**<span class="number">2</span></span><br><span class="line">    <span class="comment"># 循环，直至二分k-Means值达到k类为止</span></span><br><span class="line">    <span class="keyword">while</span> (len(centList) &lt; k):</span><br><span class="line">        <span class="comment"># 将当前最小平方误差置为正无穷</span></span><br><span class="line">        lowerSSE = float(<span class="string">'inf'</span>)</span><br><span class="line">        <span class="comment"># 遍历当前每个聚类</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(centList)):</span><br><span class="line">            <span class="comment"># 通过数组过滤筛选出属于第i类的数据集合</span></span><br><span class="line">            ptsInCurrCluster = dataSet[np.nonzero(clusterAssment[:, <span class="number">0</span>].A == i)[<span class="number">0</span>], :]</span><br><span class="line">            <span class="comment"># 对该类利用二分k-means算法进行划分，返回划分后的结果以及误差</span></span><br><span class="line">            centroidMat, splitClustAss = kMeans(ptsInCurrCluster, <span class="number">2</span>, distMeas)</span><br><span class="line">            <span class="comment"># 计算该类划分后两个类的误差平方和</span></span><br><span class="line">            sseSplit = np.sum(splitClustAss[:, <span class="number">1</span>])</span><br><span class="line">            <span class="comment"># 计算数据集中不属于该类的数据的误差平方和</span></span><br><span class="line">            sseNotSplit = np.sum(clusterAssment[np.nonzero(clusterAssment[:, <span class="number">0</span>].A != i)[<span class="number">0</span>], <span class="number">1</span>])</span><br><span class="line">            <span class="comment"># 打印这两项误差值</span></span><br><span class="line">            print(<span class="string">'sseSplit = %f, and notSplit = %f'</span> % (sseSplit, sseNotSplit))</span><br><span class="line">            <span class="comment"># 划分第i类后总误差小于当前最小总误差</span></span><br><span class="line">            <span class="keyword">if</span> (sseSplit + sseNotSplit) &lt; lowerSSE:</span><br><span class="line">                <span class="comment"># 第i类作为本次划分类</span></span><br><span class="line">                bestCentToSplit = i</span><br><span class="line">                <span class="comment"># 第i类划分后得到的两个质心向量</span></span><br><span class="line">                bestNewCents = centroidMat</span><br><span class="line">                <span class="comment"># 复制第i类中数据点的聚类结果即误差值</span></span><br><span class="line">                bestClustAss = splitClustAss.copy()</span><br><span class="line">                <span class="comment"># 将划分第i类后的总误差作为当前最小误差</span></span><br><span class="line">                lowerSSE = sseSplit + sseNotSplit</span><br><span class="line">        <span class="comment"># 数组过滤选出本次2-means聚类划分后类编号为1数据点，将这些数据点类编号变为</span></span><br><span class="line">        <span class="comment"># 当前类个数+1， 作为新的一个聚类</span></span><br><span class="line">        bestClustAss[np.nonzero(bestClustAss[:, <span class="number">0</span>].A == <span class="number">1</span>)[<span class="number">0</span>], <span class="number">0</span>] = len(centList)</span><br><span class="line">        <span class="comment"># 同理，将划分数据中类编号为0的数据点的类编号仍置为被划分的类编号，使类编号</span></span><br><span class="line">        <span class="comment"># 连续不出现空缺</span></span><br><span class="line">        bestClustAss[np.nonzero(bestClustAss[:, <span class="number">0</span>].A == <span class="number">0</span>)[<span class="number">0</span>], <span class="number">0</span>] = bestCentToSplit</span><br><span class="line">        <span class="comment"># 打印本次执行2-means聚类算法的类</span></span><br><span class="line">        print(<span class="string">'the bestCentToSplit is %d'</span> % bestCentToSplit)</span><br><span class="line">        <span class="comment"># 打印被划分的类的数据个数</span></span><br><span class="line">        print(<span class="string">'the len of bestClustAss is %d'</span> % len(bestClustAss))</span><br><span class="line">        <span class="comment"># 更新质心列表中变化后的质心向量</span></span><br><span class="line">        centList[bestCentToSplit] = bestNewCents[<span class="number">0</span>, :]</span><br><span class="line">        <span class="comment"># 添加新的类的质心向量</span></span><br><span class="line">        centList.append(bestNewCents[<span class="number">1</span>, :])</span><br><span class="line">        <span class="comment"># 更新clusterAssment列表中参与2-means聚类数据点变化后的分类编号，及数据该类的误差平方</span></span><br><span class="line">        clusterAssment[np.nonzero(clusterAssment[:, <span class="number">0</span>].A == bestCentToSplit)[<span class="number">0</span>], :] = bestClustAss</span><br><span class="line">    <span class="comment"># 返回聚类结果</span></span><br><span class="line">    <span class="keyword">return</span> centList, clusterAssment</span><br></pre></td></tr></table></figure><h2 id="源代码-1"><a href="#源代码-1" class="headerlink" title="源代码"></a>源代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Created on Fri Aug  3 13:53:40 2018</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">@author: wzy</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：将文本文档中的数据读入到python中</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    fileName - 文件名</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    dataMat - 数据矩阵</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadDataSet</span><span class="params">(fileName)</span>:</span></span><br><span class="line">    dataMat = []</span><br><span class="line">    fr = open(fileName)</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> fr.readlines():</span><br><span class="line">        curLine = line.strip().split(<span class="string">'\t'</span>)</span><br><span class="line">        fltLine = list(map(float, curLine))</span><br><span class="line">        dataMat.append(fltLine)</span><br><span class="line">    <span class="keyword">return</span> dataMat</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：数据向量计算欧式距离</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    vecA - 数据向量A</span></span><br><span class="line"><span class="string">    vecB - 数据向量B</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    两个向量之间的欧几里德距离</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">distEclud</span><span class="params">(vecA, vecB)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> np.sqrt(np.sum(np.power(vecA - vecB, <span class="number">2</span>)))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：随机初始化k个质心（质心满足数据边界之内）</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    dataSet - 输入的数据集</span></span><br><span class="line"><span class="string">    k - 选取k个质心</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    centroids - 返回初始化得到的k个质心向量</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">randCent</span><span class="params">(dataSet, k)</span>:</span></span><br><span class="line">    <span class="comment"># 得到数据样本的维度</span></span><br><span class="line">    n = np.shape(dataSet)[<span class="number">1</span>]</span><br><span class="line">    <span class="comment"># 初始化为一个(k,n)的全零矩阵</span></span><br><span class="line">    centroids = np.mat(np.zeros((k, n)))</span><br><span class="line">    <span class="comment"># 遍历数据集的每一个维度</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(n):</span><br><span class="line">        <span class="comment"># 得到该列数据的最小值,最大值</span></span><br><span class="line">        minJ = np.min(dataSet[:, j])</span><br><span class="line">        maxJ = np.max(dataSet[:, j])</span><br><span class="line">        <span class="comment"># 得到该列数据的范围(最大值-最小值)</span></span><br><span class="line">        rangeJ = float(maxJ - minJ)</span><br><span class="line">        <span class="comment"># k个质心向量的第j维数据值随机为位于(最小值，最大值)内的某一值</span></span><br><span class="line">        <span class="comment"># Create an array of the given shape and populate it with random samples from a uniform distribution over [0, 1).</span></span><br><span class="line">        centroids[:, j] = minJ + rangeJ * np.random.rand(k, <span class="number">1</span>)</span><br><span class="line">    <span class="comment"># 返回初始化得到的k个质心向量</span></span><br><span class="line">    <span class="keyword">return</span> centroids</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：k-means聚类算法</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    dataSet - 用于聚类的数据集</span></span><br><span class="line"><span class="string">    k - 选取k个质心</span></span><br><span class="line"><span class="string">    distMeas - 距离计算方法,默认欧氏距离distEclud()</span></span><br><span class="line"><span class="string">    createCent - 获取k个质心的方法,默认随机获取randCent()</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    centroids - k个聚类的聚类结果</span></span><br><span class="line"><span class="string">    clusterAssment - 聚类误差</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">kMeans</span><span class="params">(dataSet, k, distMeas=distEclud, createCent=randCent)</span>:</span></span><br><span class="line">    <span class="comment"># 获取数据集样本数</span></span><br><span class="line">    m = np.shape(dataSet)[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># 初始化一个（m,2）全零矩阵</span></span><br><span class="line">    clusterAssment = np.mat(np.zeros((m, <span class="number">2</span>)))</span><br><span class="line">    <span class="comment"># 创建初始的k个质心向量</span></span><br><span class="line">    centroids = createCent(dataSet, k)</span><br><span class="line">    <span class="comment"># 聚类结果是否发生变化的布尔类型</span></span><br><span class="line">    clusterChanged = <span class="literal">True</span></span><br><span class="line">    <span class="comment"># 只要聚类结果一直发生变化，就一直执行聚类算法，直至所有数据点聚类结果不发生变化</span></span><br><span class="line">    <span class="keyword">while</span> clusterChanged:</span><br><span class="line">        <span class="comment"># 聚类结果变化布尔类型置为False</span></span><br><span class="line">        clusterChanged = <span class="literal">False</span></span><br><span class="line">        <span class="comment"># 遍历数据集每一个样本向量</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">            <span class="comment"># 初始化最小距离为正无穷，最小距离对应的索引为-1</span></span><br><span class="line">            minDist = float(<span class="string">'inf'</span>)</span><br><span class="line">            minIndex = <span class="number">-1</span></span><br><span class="line">            <span class="comment"># 循环k个类的质心</span></span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(k):</span><br><span class="line">                <span class="comment"># 计算数据点到质心的欧氏距离</span></span><br><span class="line">                distJI = distMeas(centroids[j, :], dataSet[i, :])</span><br><span class="line">                <span class="comment"># 如果距离小于当前最小距离</span></span><br><span class="line">                <span class="keyword">if</span> distJI &lt; minDist:</span><br><span class="line">                    <span class="comment"># 当前距离为最小距离，最小距离对应索引应为j(第j个类)</span></span><br><span class="line">                    minDist = distJI</span><br><span class="line">                    minIndex = j</span><br><span class="line">            <span class="comment"># 当前聚类结果中第i个样本的聚类结果发生变化：布尔值置为True，继续聚类算法</span></span><br><span class="line">            <span class="keyword">if</span> clusterAssment[i, <span class="number">0</span>] != minIndex: </span><br><span class="line">                clusterChanged = <span class="literal">True</span></span><br><span class="line">            <span class="comment"># 更新当前变化样本的聚类结果和平方误差</span></span><br><span class="line">            clusterAssment[i, :] = minIndex, minDist**<span class="number">2</span></span><br><span class="line">            <span class="comment"># 打印k-means聚类的质心</span></span><br><span class="line">        <span class="comment"># print(centroids)</span></span><br><span class="line">        <span class="comment"># 遍历每一个质心</span></span><br><span class="line">        <span class="keyword">for</span> cent <span class="keyword">in</span> range(k):</span><br><span class="line">            <span class="comment"># 将数据集中所有属于当前质心类的样本通过条件过滤筛选出来</span></span><br><span class="line">            ptsInClust = dataSet[np.nonzero(clusterAssment[:, <span class="number">0</span>].A == cent)[<span class="number">0</span>]]</span><br><span class="line">            <span class="comment"># 计算这些数据的均值(axis=0:求列均值)，作为该类质心向量</span></span><br><span class="line">            centroids[cent, :] = np.mean(ptsInClust, axis=<span class="number">0</span>)</span><br><span class="line">    <span class="comment"># 返回k个聚类，聚类结果及误差</span></span><br><span class="line">    <span class="keyword">return</span> centroids, clusterAssment</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：二分k-means聚类算法</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    dataSet - 用于聚类的数据集</span></span><br><span class="line"><span class="string">    k - 选取k个质心</span></span><br><span class="line"><span class="string">    distMeas - 距离计算方法,默认欧氏距离distEclud()</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    centList - k个聚类的聚类结果</span></span><br><span class="line"><span class="string">    clusterAssment - 聚类误差</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">biKmeans</span><span class="params">(dataSet, k, distMeas=distEclud)</span>:</span></span><br><span class="line">    <span class="comment"># 获取数据集的样本数</span></span><br><span class="line">    m = np.shape(dataSet)[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># 初始化一个元素均值0的(m, 2)矩阵</span></span><br><span class="line">    clusterAssment = np.mat(np.zeros((m, <span class="number">2</span>)))</span><br><span class="line">    <span class="comment"># 获取数据集每一列数据的均值，组成一个列表</span></span><br><span class="line">    centroid0 = np.mean(dataSet, axis=<span class="number">0</span>).tolist()[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># 当前聚类列表为将数据集聚为一类</span></span><br><span class="line">    centList = [centroid0]</span><br><span class="line">    <span class="comment"># 遍历每个数据集样本</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(m):</span><br><span class="line">        <span class="comment"># 计算当前聚为一类时各个数据点距离质心的平方距离</span></span><br><span class="line">        clusterAssment[j, <span class="number">1</span>] = distMeas(np.mat(centroid0), dataSet[j, :])**<span class="number">2</span></span><br><span class="line">    <span class="comment"># 循环，直至二分k-Means值达到k类为止</span></span><br><span class="line">    <span class="keyword">while</span> (len(centList) &lt; k):</span><br><span class="line">        <span class="comment"># 将当前最小平方误差置为正无穷</span></span><br><span class="line">        lowerSSE = float(<span class="string">'inf'</span>)</span><br><span class="line">        <span class="comment"># 遍历当前每个聚类</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(centList)):</span><br><span class="line">            <span class="comment"># 通过数组过滤筛选出属于第i类的数据集合</span></span><br><span class="line">            ptsInCurrCluster = dataSet[np.nonzero(clusterAssment[:, <span class="number">0</span>].A == i)[<span class="number">0</span>], :]</span><br><span class="line">            <span class="comment"># 对该类利用二分k-means算法进行划分，返回划分后的结果以及误差</span></span><br><span class="line">            centroidMat, splitClustAss = kMeans(ptsInCurrCluster, <span class="number">2</span>, distMeas)</span><br><span class="line">            <span class="comment"># 计算该类划分后两个类的误差平方和</span></span><br><span class="line">            sseSplit = np.sum(splitClustAss[:, <span class="number">1</span>])</span><br><span class="line">            <span class="comment"># 计算数据集中不属于该类的数据的误差平方和</span></span><br><span class="line">            sseNotSplit = np.sum(clusterAssment[np.nonzero(clusterAssment[:, <span class="number">0</span>].A != i)[<span class="number">0</span>], <span class="number">1</span>])</span><br><span class="line">            <span class="comment"># 打印这两项误差值</span></span><br><span class="line">            print(<span class="string">'sseSplit = %f, and notSplit = %f'</span> % (sseSplit, sseNotSplit))</span><br><span class="line">            <span class="comment"># 划分第i类后总误差小于当前最小总误差</span></span><br><span class="line">            <span class="keyword">if</span> (sseSplit + sseNotSplit) &lt; lowerSSE:</span><br><span class="line">                <span class="comment"># 第i类作为本次划分类</span></span><br><span class="line">                bestCentToSplit = i</span><br><span class="line">                <span class="comment"># 第i类划分后得到的两个质心向量</span></span><br><span class="line">                bestNewCents = centroidMat</span><br><span class="line">                <span class="comment"># 复制第i类中数据点的聚类结果即误差值</span></span><br><span class="line">                bestClustAss = splitClustAss.copy()</span><br><span class="line">                <span class="comment"># 将划分第i类后的总误差作为当前最小误差</span></span><br><span class="line">                lowerSSE = sseSplit + sseNotSplit</span><br><span class="line">        <span class="comment"># 数组过滤选出本次2-means聚类划分后类编号为1数据点，将这些数据点类编号变为</span></span><br><span class="line">        <span class="comment"># 当前类个数+1， 作为新的一个聚类</span></span><br><span class="line">        bestClustAss[np.nonzero(bestClustAss[:, <span class="number">0</span>].A == <span class="number">1</span>)[<span class="number">0</span>], <span class="number">0</span>] = len(centList)</span><br><span class="line">        <span class="comment"># 同理，将划分数据中类编号为0的数据点的类编号仍置为被划分的类编号，使类编号</span></span><br><span class="line">        <span class="comment"># 连续不出现空缺</span></span><br><span class="line">        bestClustAss[np.nonzero(bestClustAss[:, <span class="number">0</span>].A == <span class="number">0</span>)[<span class="number">0</span>], <span class="number">0</span>] = bestCentToSplit</span><br><span class="line">        <span class="comment"># 打印本次执行2-means聚类算法的类</span></span><br><span class="line">        print(<span class="string">'the bestCentToSplit is %d'</span> % bestCentToSplit)</span><br><span class="line">        <span class="comment"># 打印被划分的类的数据个数</span></span><br><span class="line">        print(<span class="string">'the len of bestClustAss is %d'</span> % len(bestClustAss))</span><br><span class="line">        <span class="comment"># 更新质心列表中变化后的质心向量</span></span><br><span class="line">        centList[bestCentToSplit] = bestNewCents[<span class="number">0</span>, :]</span><br><span class="line">        <span class="comment"># 添加新的类的质心向量</span></span><br><span class="line">        centList.append(bestNewCents[<span class="number">1</span>, :])</span><br><span class="line">        <span class="comment"># 更新clusterAssment列表中参与2-means聚类数据点变化后的分类编号，及数据该类的误差平方</span></span><br><span class="line">        clusterAssment[np.nonzero(clusterAssment[:, <span class="number">0</span>].A == bestCentToSplit)[<span class="number">0</span>], :] = bestClustAss</span><br><span class="line">    <span class="comment"># 返回聚类结果</span></span><br><span class="line">    <span class="keyword">return</span> centList, clusterAssment</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：绘制数据集</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    fileName - 文件名</span></span><br><span class="line"><span class="string">    k - 选取k个质心</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    None</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plotDataSet</span><span class="params">(filename, k)</span>:</span></span><br><span class="line">    <span class="comment"># 导入数据</span></span><br><span class="line">    datMat = np.mat(loadDataSet(filename))</span><br><span class="line">    <span class="comment"># 进行k-means算法其中k为4</span></span><br><span class="line">    centList, clusterAssment = biKmeans(datMat, k)</span><br><span class="line">    clusterAssment = clusterAssment.tolist()</span><br><span class="line">    xcord = [[], [], []]</span><br><span class="line">    ycord = [[], [], []]</span><br><span class="line">    datMat = datMat.tolist()</span><br><span class="line">    m = len(clusterAssment)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">        <span class="keyword">if</span> int(clusterAssment[i][<span class="number">0</span>]) == <span class="number">0</span>:</span><br><span class="line">            xcord[<span class="number">0</span>].append(datMat[i][<span class="number">0</span>])</span><br><span class="line">            ycord[<span class="number">0</span>].append(datMat[i][<span class="number">1</span>])</span><br><span class="line">        <span class="keyword">elif</span> int(clusterAssment[i][<span class="number">0</span>]) == <span class="number">1</span>:</span><br><span class="line">            xcord[<span class="number">1</span>].append(datMat[i][<span class="number">0</span>])</span><br><span class="line">            ycord[<span class="number">1</span>].append(datMat[i][<span class="number">1</span>])</span><br><span class="line">        <span class="keyword">elif</span> int(clusterAssment[i][<span class="number">0</span>]) == <span class="number">2</span>:</span><br><span class="line">            xcord[<span class="number">2</span>].append(datMat[i][<span class="number">0</span>])</span><br><span class="line">            ycord[<span class="number">2</span>].append(datMat[i][<span class="number">1</span>])</span><br><span class="line">    fig = plt.figure()</span><br><span class="line">    ax = fig.add_subplot(<span class="number">111</span>)</span><br><span class="line">    <span class="comment"># 绘制样本点</span></span><br><span class="line">    ax.scatter(xcord[<span class="number">0</span>], ycord[<span class="number">0</span>], s=<span class="number">20</span>, c=<span class="string">'b'</span>, marker=<span class="string">'*'</span>, alpha=<span class="number">.5</span>)</span><br><span class="line">    ax.scatter(xcord[<span class="number">1</span>], ycord[<span class="number">1</span>], s=<span class="number">20</span>, c=<span class="string">'r'</span>, marker=<span class="string">'D'</span>, alpha=<span class="number">.5</span>)</span><br><span class="line">    ax.scatter(xcord[<span class="number">2</span>], ycord[<span class="number">2</span>], s=<span class="number">20</span>, c=<span class="string">'c'</span>, marker=<span class="string">'&gt;'</span>, alpha=<span class="number">.5</span>)</span><br><span class="line">    <span class="comment"># 绘制质心</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(k):</span><br><span class="line">        ax.scatter(centList[i].tolist()[<span class="number">0</span>][<span class="number">0</span>], centList[i].tolist()[<span class="number">0</span>][<span class="number">1</span>], s=<span class="number">100</span>, c=<span class="string">'k'</span>, marker=<span class="string">'+'</span>, alpha=<span class="number">.5</span>)</span><br><span class="line">    <span class="comment"># ax.scatter(centList[0].tolist()[0][0], centList[0].tolist()[0][1], s=100, c='k', marker='+', alpha=.5)</span></span><br><span class="line">    <span class="comment"># ax.scatter(centList[1].tolist()[0][0], centList[1].tolist()[0][1], s=100, c='k', marker='+', alpha=.5)</span></span><br><span class="line">    <span class="comment"># ax.scatter(centList[2].tolist()[0][0], centList[2].tolist()[0][1], s=100, c='k', marker='+', alpha=.5)</span></span><br><span class="line">    plt.title(<span class="string">'DataSet'</span>)</span><br><span class="line">    plt.xlabel(<span class="string">'X'</span>)</span><br><span class="line">    plt.show()</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    datMat = np.mat(loadDataSet(<span class="string">'testSet2.txt'</span>))</span><br><span class="line">    centList, myNewAssments = biKmeans(datMat, <span class="number">3</span>)</span><br><span class="line">    plotDataSet(<span class="string">'testSet2.txt'</span>, <span class="number">3</span>)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Machine_Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ML </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>《机器学习实战》《西瓜书》笔记（七）- SVM</title>
      <link href="/2019/11/30/Machine_Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%887%20-SVM)/"/>
      <url>/2019/11/30/Machine_Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%887%20-SVM)/</url>
      
        <content type="html"><![CDATA[<h1 id="SVM（支持向量机）"><a href="#SVM（支持向量机）" class="headerlink" title="SVM（支持向量机）"></a>SVM（支持向量机）</h1><p>支持向量（support vector)就是离分隔超平面最近的那些点。最大化支持向量到分割面的距离。</p><div align = center><img src = "https://img.vim-cn.com/25/6dd0e73f2ac658c2e82d39ddc79adc759cf28e.png"></div><h2 id="核函数（kneral-function"><a href="#核函数（kneral-function" class="headerlink" title="核函数（kneral function)"></a>核函数（kneral function)</h2><p>核函数就是将数据转化成易于分类器理解的一种形式，目前相对流行的一种核函数：径向基函数</p><h3 id="径向基函数"><a href="#径向基函数" class="headerlink" title="径向基函数"></a>径向基函数</h3><p>把数据从一个特征空间映射到另一个特征空间<br>$k(x,y)=exp(\frac{-||x-y||^2}{2\sigma^2})$<br>其中$\sigma$是确定到达率，是函数值跌倒0的速度参数</p><h1 id="代码示例"><a href="#代码示例" class="headerlink" title="代码示例"></a>代码示例</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br><span class="line">429</span><br><span class="line">430</span><br><span class="line">431</span><br><span class="line">432</span><br><span class="line">433</span><br><span class="line">434</span><br><span class="line">435</span><br><span class="line">436</span><br><span class="line">437</span><br><span class="line">438</span><br><span class="line">439</span><br><span class="line">440</span><br><span class="line">441</span><br><span class="line">442</span><br><span class="line">443</span><br><span class="line">444</span><br><span class="line">445</span><br><span class="line">446</span><br><span class="line">447</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Created on Wed Jul 25 11:04:01 2018</span></span><br><span class="line"><span class="string">k1越大会过拟合</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">@author: wzy</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">类说明：维护所有需要操作的值</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    dataMatIn - 数据矩阵</span></span><br><span class="line"><span class="string">    classLabels - 数据标签</span></span><br><span class="line"><span class="string">    C - 松弛变量</span></span><br><span class="line"><span class="string">    toler - 容错率</span></span><br><span class="line"><span class="string">    kTup - 包含核函数信息的元组，第一个参数存放该核函数类别，第二个参数存放必要的核函数需要用到的参数</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    None</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">optStruct</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, dataMatIn, classLabels, C, toler, kTup)</span>:</span></span><br><span class="line">        <span class="comment"># 数据矩阵</span></span><br><span class="line">        self.X = dataMatIn</span><br><span class="line">        <span class="comment"># 数据标签</span></span><br><span class="line">        self.labelMat = classLabels</span><br><span class="line">        <span class="comment"># 松弛变量</span></span><br><span class="line">        self.C = C</span><br><span class="line">        <span class="comment"># 容错率</span></span><br><span class="line">        self.tol = toler</span><br><span class="line">        <span class="comment"># 矩阵的行数</span></span><br><span class="line">        self.m = np.shape(dataMatIn)[<span class="number">0</span>]</span><br><span class="line">        <span class="comment"># 根据矩阵行数初始化alphas矩阵，一个m行1列的全零列向量</span></span><br><span class="line">        self.alphas = np.mat(np.zeros((self.m, <span class="number">1</span>)))</span><br><span class="line">        <span class="comment"># 初始化b参数为0</span></span><br><span class="line">        self.b = <span class="number">0</span></span><br><span class="line">        <span class="comment"># 根据矩阵行数初始化误差缓存矩阵，第一列为是否有效标志位，第二列为实际的误差E的值</span></span><br><span class="line">        self.eCache = np.mat(np.zeros((self.m, <span class="number">2</span>)))</span><br><span class="line">        <span class="comment"># 初始化核K</span></span><br><span class="line">        self.K = np.mat(np.zeros((self.m, self.m)))</span><br><span class="line">        <span class="comment"># 计算所有数据的核K</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(self.m):</span><br><span class="line">            self.K[:, i] = kernelTrans(self.X, self.X[i, :], kTup)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：通过核函数将数据转换更高维空间</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    X - 数据矩阵</span></span><br><span class="line"><span class="string">    A - 单个数据的向量</span></span><br><span class="line"><span class="string">    kTup - 包含核函数信息的元组</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    K - 计算的核K</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">kernelTrans</span><span class="params">(X, A, kTup)</span>:</span></span><br><span class="line">    <span class="comment"># 读取X的行列数</span></span><br><span class="line">    m, n = np.shape(X)</span><br><span class="line">    <span class="comment"># K初始化为m行1列的零向量</span></span><br><span class="line">    K = np.mat(np.zeros((m, <span class="number">1</span>)))</span><br><span class="line">    <span class="comment"># 线性核函数只进行内积</span></span><br><span class="line">    <span class="keyword">if</span> kTup[<span class="number">0</span>] == <span class="string">'lin'</span>:</span><br><span class="line">        K = X * A.T</span><br><span class="line">    <span class="comment"># 高斯核函数，根据高斯核函数公式计算</span></span><br><span class="line">    <span class="keyword">elif</span> kTup[<span class="number">0</span>] == <span class="string">'rbf'</span>:</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(m):</span><br><span class="line">            deltaRow = X[j, :] - A</span><br><span class="line">            K[j] = deltaRow * deltaRow.T</span><br><span class="line">        K = np.exp(K / (<span class="number">-1</span> * kTup[<span class="number">1</span>] ** <span class="number">2</span>))</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">raise</span> NameError(<span class="string">'核函数无法识别'</span>)</span><br><span class="line">    <span class="keyword">return</span> K</span><br><span class="line">     </span><br><span class="line">        </span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：读取数据</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    fileName - 文件名</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    dataMat - 数据矩阵</span></span><br><span class="line"><span class="string">    labelMat - 数据标签</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadDataSet</span><span class="params">(fileName)</span>:</span></span><br><span class="line">    <span class="comment"># 数据矩阵</span></span><br><span class="line">    dataMat = []</span><br><span class="line">    <span class="comment"># 标签向量</span></span><br><span class="line">    labelMat = []</span><br><span class="line">    <span class="comment"># 打开文件</span></span><br><span class="line">    fr = open(fileName)</span><br><span class="line">    <span class="comment"># 逐行读取</span></span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> fr.readlines():</span><br><span class="line">        <span class="comment"># 去掉每一行首尾的空白符，例如'\n','\r','\t',' '</span></span><br><span class="line">        <span class="comment"># 将每一行内容根据'\t'符进行切片</span></span><br><span class="line">        lineArr = line.strip().split(<span class="string">'\t'</span>)</span><br><span class="line">        <span class="comment"># 添加数据(100个元素排成一行)</span></span><br><span class="line">        dataMat.append([float(lineArr[<span class="number">0</span>]), float(lineArr[<span class="number">1</span>])])</span><br><span class="line">        <span class="comment"># 添加标签(100个元素排成一行)</span></span><br><span class="line">        labelMat.append(float(lineArr[<span class="number">2</span>]))</span><br><span class="line">    <span class="keyword">return</span> dataMat, labelMat</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：计算误差</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    oS - 数据结构</span></span><br><span class="line"><span class="string">    k - 标号为k的数据</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    Ek - 标号为k的数据误差</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calcEk</span><span class="params">(oS, k)</span>:</span></span><br><span class="line">    <span class="comment"># multiply(a,b)就是个乘法，如果a,b是两个数组，那么对应元素相乘</span></span><br><span class="line">    <span class="comment"># .T为转置</span></span><br><span class="line">    fXk = float(np.multiply(oS.alphas, oS.labelMat).T * oS.K[:, k]  + oS.b)</span><br><span class="line">    <span class="comment"># 计算误差项</span></span><br><span class="line">    Ek = fXk - float(oS.labelMat[k])</span><br><span class="line">    <span class="comment"># 返回误差项</span></span><br><span class="line">    <span class="keyword">return</span> Ek</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：随机选择alpha_j</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    i - alpha_i的索引值</span></span><br><span class="line"><span class="string">    m - alpha参数个数</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    j - alpha_j的索引值</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">selectJrand</span><span class="params">(i, m)</span>:</span></span><br><span class="line">    j = i</span><br><span class="line">    <span class="keyword">while</span>(j == i):</span><br><span class="line">        <span class="comment"># uniform()方法将随机生成一个实数，它在[x, y)范围内</span></span><br><span class="line">        j = int(random.uniform(<span class="number">0</span>, m))</span><br><span class="line">    <span class="keyword">return</span> j</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：内循环启发方式2</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    i - 标号为i的数据的索引值</span></span><br><span class="line"><span class="string">    oS - 数据结构</span></span><br><span class="line"><span class="string">    Ei - 标号为i的数据误差</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    j - 标号为j的数据的索引值</span></span><br><span class="line"><span class="string">    maxK - 标号为maxK的数据的索引值</span></span><br><span class="line"><span class="string">    Ej - 标号为j的数据误差</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">selectJ</span><span class="params">(i, oS, Ei)</span>:</span></span><br><span class="line">    <span class="comment"># 初始化</span></span><br><span class="line">    maxK = <span class="number">-1</span></span><br><span class="line">    maxDeltaE = <span class="number">0</span></span><br><span class="line">    Ej = <span class="number">0</span></span><br><span class="line">    <span class="comment"># 根据Ei更新误差缓存</span></span><br><span class="line">    oS.eCache[i] = [<span class="number">1</span>, Ei]</span><br><span class="line">    <span class="comment"># 对一个矩阵.A转换为Array类型</span></span><br><span class="line">    <span class="comment"># 返回误差不为0的数据的索引值</span></span><br><span class="line">    validEcacheList = np.nonzero(oS.eCache[:, <span class="number">0</span>].A)[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># 有不为0的误差</span></span><br><span class="line">    <span class="keyword">if</span>(len(validEcacheList) &gt; <span class="number">1</span>):</span><br><span class="line">        <span class="comment"># 遍历，找到最大的Ek</span></span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> validEcacheList:</span><br><span class="line">            <span class="comment"># 不计算k==i节省时间</span></span><br><span class="line">            <span class="keyword">if</span> k == i:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            <span class="comment"># 计算Ek</span></span><br><span class="line">            Ek = calcEk(oS, k)</span><br><span class="line">            <span class="comment"># 计算|Ei - Ek|</span></span><br><span class="line">            deltaE = abs(Ei - Ek)</span><br><span class="line">            <span class="comment"># 找到maxDeltaE</span></span><br><span class="line">            <span class="keyword">if</span>(deltaE &gt; maxDeltaE):</span><br><span class="line">                maxK = k</span><br><span class="line">                maxDeltaE = deltaE</span><br><span class="line">                Ej = Ek</span><br><span class="line">        <span class="comment"># 返回maxK，Ej</span></span><br><span class="line">        <span class="keyword">return</span> maxK, Ej</span><br><span class="line">    <span class="comment"># 没有不为0的误差</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># 随机选择alpha_j的索引值</span></span><br><span class="line">        j = selectJrand(i, oS.m)</span><br><span class="line">        <span class="comment"># 计算Ej</span></span><br><span class="line">        Ej = calcEk(oS, j)</span><br><span class="line">    <span class="comment"># 返回j，Ej</span></span><br><span class="line">    <span class="keyword">return</span> j, Ej</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：计算Ek,并更新误差缓存</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    oS - 数据结构</span></span><br><span class="line"><span class="string">    k - 标号为k的数据的索引值</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    None</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">updateEk</span><span class="params">(oS, k)</span>:</span></span><br><span class="line">    <span class="comment"># 计算Ek</span></span><br><span class="line">    Ek = calcEk(oS, k)</span><br><span class="line">    <span class="comment"># 更新误差缓存</span></span><br><span class="line">    oS.eCache[k] = [<span class="number">1</span>, Ek]</span><br><span class="line">    </span><br><span class="line">      </span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：修剪alpha_j</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    aj - alpha_j值</span></span><br><span class="line"><span class="string">    H - alpha上限</span></span><br><span class="line"><span class="string">    L - alpha下限</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    aj - alpha_j值</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Modify:</span></span><br><span class="line"><span class="string">    2018-07-24</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">clipAlpha</span><span class="params">(aj, H, L)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> aj &gt; H:</span><br><span class="line">        aj = H</span><br><span class="line">    <span class="keyword">if</span> L &gt; aj:</span><br><span class="line">        aj = L</span><br><span class="line">    <span class="keyword">return</span> aj</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：优化的SMO算法</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    i - 标号为i的数据的索引值</span></span><br><span class="line"><span class="string">    oS - 数据结构</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    1 - 有任意一对alpha值发生变化</span></span><br><span class="line"><span class="string">    0 - 没有任意一对alpha值发生变化或变化太小</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">innerL</span><span class="params">(i, oS)</span>:</span></span><br><span class="line">    <span class="comment"># 步骤1：计算误差Ei</span></span><br><span class="line">    Ei = calcEk(oS, i)</span><br><span class="line">    <span class="comment"># 优化alpha,设定一定的容错率</span></span><br><span class="line">    <span class="keyword">if</span>((oS.labelMat[i] * Ei &lt; -oS.tol) <span class="keyword">and</span> (oS.alphas[i] &lt; oS.C)) <span class="keyword">or</span> ((oS.labelMat[i] * Ei &gt; oS.tol) <span class="keyword">and</span> (oS.alphas[i] &gt; <span class="number">0</span>)):</span><br><span class="line">        <span class="comment"># 使用内循环启发方式2选择alpha_j,并计算Ej</span></span><br><span class="line">        j, Ej = selectJ(i, oS, Ei)</span><br><span class="line">        <span class="comment"># 保存更新前的alpha值，使用深层拷贝</span></span><br><span class="line">        alphaIold = oS.alphas[i].copy()</span><br><span class="line">        alphaJold = oS.alphas[j].copy()</span><br><span class="line">        <span class="comment"># 步骤2：计算上界H和下界L</span></span><br><span class="line">        <span class="keyword">if</span>(oS.labelMat[i] != oS.labelMat[j]):</span><br><span class="line">            L = max(<span class="number">0</span>, oS.alphas[j] - oS.alphas[i])</span><br><span class="line">            H = min(oS.C, oS.C + oS.alphas[j] - oS.alphas[i])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            L = max(<span class="number">0</span>, oS.alphas[j] + oS.alphas[i] - oS.C)</span><br><span class="line">            H = min(oS.C, oS.alphas[j] + oS.alphas[i])</span><br><span class="line">        <span class="keyword">if</span> L == H:</span><br><span class="line">            print(<span class="string">"L == H"</span>)</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        <span class="comment"># 步骤3：计算eta</span></span><br><span class="line">        eta = <span class="number">2.0</span> * oS.K[i, j] - oS.K[i, i] - oS.K[j, j]</span><br><span class="line">        <span class="keyword">if</span> eta &gt;= <span class="number">0</span>:</span><br><span class="line">            print(<span class="string">"eta &gt;= 0"</span>)</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        <span class="comment"># 步骤4：更新alpha_j</span></span><br><span class="line">        oS.alphas[j] -= oS.labelMat[j] * (Ei - Ej) / eta</span><br><span class="line">        <span class="comment"># 步骤5：修剪alpha_j</span></span><br><span class="line">        oS.alphas[j] = clipAlpha(oS.alphas[j], H, L)</span><br><span class="line">        <span class="comment"># 更新Ej至误差缓存</span></span><br><span class="line">        updateEk(oS, j)</span><br><span class="line">        <span class="keyword">if</span>(abs(oS.alphas[j] - alphaJold) &lt; <span class="number">0.00001</span>):</span><br><span class="line">            print(<span class="string">"alpha_j变化太小"</span>)</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        <span class="comment"># 步骤6：更新alpha_i</span></span><br><span class="line">        oS.alphas[i] += oS.labelMat[i] * oS.labelMat[j] * (alphaJold - oS.alphas[j])</span><br><span class="line">        <span class="comment"># 更新Ei至误差缓存</span></span><br><span class="line">        updateEk(oS, i)</span><br><span class="line">        <span class="comment"># 步骤7：更新b_1和b_2:</span></span><br><span class="line">        b1 = oS.b - Ei - oS.labelMat[i] * (oS.alphas[i] - alphaIold) * oS.K[i, i] - oS.labelMat[j] * (oS.alphas[j] - alphaJold) * oS.K[j, i]</span><br><span class="line">        b2 = oS.b - Ej - oS.labelMat[i] * (oS.alphas[i] - alphaIold) * oS.K[i, j] - oS.labelMat[j] * (oS.alphas[j] - alphaJold) * oS.K[j, j]</span><br><span class="line">        <span class="comment"># 步骤8：根据b_1和b_2更新b</span></span><br><span class="line">        <span class="keyword">if</span>(<span class="number">0</span> &lt; oS.alphas[i] &lt; oS.C):</span><br><span class="line">            oS.b = b1</span><br><span class="line">        <span class="keyword">elif</span>(<span class="number">0</span> &lt; oS.alphas[j] &lt; oS.C):</span><br><span class="line">            oS.b = b2</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            oS.b = (b1 + b2) / <span class="number">2.0</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：完整的线性SMO算法</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    dataMatIn - 数据矩阵</span></span><br><span class="line"><span class="string">    classLabels - 数据标签</span></span><br><span class="line"><span class="string">    C - 松弛变量</span></span><br><span class="line"><span class="string">    toler - 容错率</span></span><br><span class="line"><span class="string">    maxIter - 最大迭代次数</span></span><br><span class="line"><span class="string">    kTup - 包含核函数信息的元组</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    oS.b - SMO算法计算的b</span></span><br><span class="line"><span class="string">    oS.alphas - SMO算法计算的alphas</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">smoP</span><span class="params">(dataMatIn, classLabels, C, toler, maxIter, kTup = <span class="params">(<span class="string">'lin'</span>, <span class="number">0</span>)</span>)</span>:</span></span><br><span class="line">    <span class="comment"># 初始化数据结构</span></span><br><span class="line">    oS = optStruct(np.mat(dataMatIn), np.mat(classLabels).transpose(), C, toler, kTup)</span><br><span class="line">    <span class="comment"># 初始化当前迭代次数</span></span><br><span class="line">    iter = <span class="number">0</span></span><br><span class="line">    entrieSet = <span class="literal">True</span></span><br><span class="line">    alphaPairsChanged = <span class="number">0</span></span><br><span class="line">    <span class="comment"># 遍历整个数据集alpha都没有更新或者超过最大迭代次数，则退出循环</span></span><br><span class="line">    <span class="keyword">while</span>(iter &lt; maxIter) <span class="keyword">and</span> ((alphaPairsChanged &gt; <span class="number">0</span>) <span class="keyword">or</span> (entrieSet)):</span><br><span class="line">        alphaPairsChanged = <span class="number">0</span></span><br><span class="line">        <span class="comment"># 遍历整个数据集</span></span><br><span class="line">        <span class="keyword">if</span> entrieSet:</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(oS.m):</span><br><span class="line">                <span class="comment"># 使用优化的SMO算法</span></span><br><span class="line">                alphaPairsChanged += innerL(i, oS)</span><br><span class="line">                print(<span class="string">"全样本遍历:第%d次迭代 样本:%d, alpha优化次数:%d"</span> % (iter, i, alphaPairsChanged))</span><br><span class="line">            iter += <span class="number">1</span></span><br><span class="line">        <span class="comment"># 遍历非边界值</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 遍历不在边界0和C的alpha</span></span><br><span class="line">            nonBoundIs = np.nonzero((oS.alphas.A &gt; <span class="number">0</span>) * (oS.alphas.A &lt; C))[<span class="number">0</span>]</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> nonBoundIs:</span><br><span class="line">                alphaPairsChanged += innerL(i, oS)</span><br><span class="line">                print(<span class="string">"非边界遍历:第%d次迭代 样本:%d, alpha优化次数:%d"</span> % (iter, i, alphaPairsChanged))</span><br><span class="line">            iter += <span class="number">1</span></span><br><span class="line">        <span class="comment"># 遍历一次后改为非边界遍历</span></span><br><span class="line">        <span class="keyword">if</span> entrieSet:</span><br><span class="line">            entrieSet = <span class="literal">False</span></span><br><span class="line">        <span class="comment"># 如果alpha没有更新，计算全样本遍历</span></span><br><span class="line">        <span class="keyword">elif</span>(alphaPairsChanged == <span class="number">0</span>):</span><br><span class="line">            entrieSet = <span class="literal">True</span></span><br><span class="line">        print(<span class="string">"迭代次数:%d"</span> % iter)</span><br><span class="line">    <span class="comment"># 返回SMO算法计算的b和alphas</span></span><br><span class="line">    <span class="keyword">return</span> oS.b, oS.alphas</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：测试函数</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    k1 - 使用高斯核函数的时候表示到达率</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    None</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">testRbf</span><span class="params">(k1 = <span class="number">1.3</span>)</span>:</span></span><br><span class="line">    <span class="comment"># 加载训练集</span></span><br><span class="line">    dataArr, labelArr = loadDataSet(<span class="string">'testSetRBF.txt'</span>)</span><br><span class="line">    <span class="comment"># 根据训练集计算b, alphas</span></span><br><span class="line">    b, alphas = smoP(dataArr, labelArr, <span class="number">200</span>, <span class="number">0.0001</span>, <span class="number">100</span>, (<span class="string">'rbf'</span>, k1))</span><br><span class="line">    datMat = np.mat(dataArr)</span><br><span class="line">    labelMat = np.mat(labelArr).transpose()</span><br><span class="line">    <span class="comment"># 获得支持向量</span></span><br><span class="line">    svInd = np.nonzero(alphas.A &gt; <span class="number">0</span>)[<span class="number">0</span>]</span><br><span class="line">    sVs = datMat[svInd]</span><br><span class="line">    labelSV = labelMat[svInd]</span><br><span class="line">    print(<span class="string">"支持向量个数:%d"</span> % np.shape(sVs)[<span class="number">0</span>])</span><br><span class="line">    m, n = np.shape(datMat)</span><br><span class="line">    errorCount = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">        <span class="comment"># 计算各个点的核</span></span><br><span class="line">        kernelEval = kernelTrans(sVs, datMat[i, :], (<span class="string">'rbf'</span>, k1))</span><br><span class="line">        <span class="comment"># 根据支持向量的点计算超平面，返回预测结果</span></span><br><span class="line">        predict = kernelEval.T * np.multiply(labelSV, alphas[svInd]) + b</span><br><span class="line">        <span class="comment"># 返回数组中各元素的正负号，用1和-1表示，并统计错误个数</span></span><br><span class="line">        <span class="keyword">if</span> np.sign(predict) != np.sign(labelArr[i]):</span><br><span class="line">            errorCount += <span class="number">1</span></span><br><span class="line">    <span class="comment"># 打印错误率</span></span><br><span class="line">    print(<span class="string">'训练集错误率:%.2f%%'</span> % ((float(errorCount) / m) * <span class="number">100</span>))</span><br><span class="line">    <span class="comment"># 加载测试集</span></span><br><span class="line">    dataArr, labelArr = loadDataSet(<span class="string">'testSetRBF2.txt'</span>)</span><br><span class="line">    errorCount = <span class="number">0</span></span><br><span class="line">    datMat = np.mat(dataArr)</span><br><span class="line">    labelMat = np.mat(labelArr).transpose()</span><br><span class="line">    m, n = np.shape(datMat)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">        <span class="comment"># 计算各个点的核</span></span><br><span class="line">        kernelEval = kernelTrans(sVs, datMat[i, :], (<span class="string">'rbf'</span>, k1))</span><br><span class="line">        <span class="comment"># 根据支持向量的点计算超平面，返回预测结果</span></span><br><span class="line">        predict = kernelEval.T * np.multiply(labelSV, alphas[svInd]) + b</span><br><span class="line">        <span class="comment"># 返回数组中各元素的正负号，用1和-1表示，并统计错误个数</span></span><br><span class="line">        <span class="keyword">if</span> np.sign(predict) != np.sign(labelArr[i]):</span><br><span class="line">            errorCount += <span class="number">1</span></span><br><span class="line">    <span class="comment"># 打印错误率</span></span><br><span class="line">    print(<span class="string">'训练集错误率:%.2f%%'</span> % ((float(errorCount) / m) * <span class="number">100</span>))</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：数据可视化</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    dataMat - 数据矩阵</span></span><br><span class="line"><span class="string">    labelMat - 数据标签</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    None</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">showDataSet</span><span class="params">(dataMat, labelMat)</span>:</span></span><br><span class="line">    <span class="comment"># 正样本</span></span><br><span class="line">    data_plus = []</span><br><span class="line">    <span class="comment"># 负样本</span></span><br><span class="line">    data_minus = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(dataMat)):</span><br><span class="line">        <span class="keyword">if</span> labelMat[i] &gt; <span class="number">0</span>:</span><br><span class="line">            data_plus.append(dataMat[i])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            data_minus.append(dataMat[i])</span><br><span class="line">    <span class="comment"># 转换为numpy矩阵</span></span><br><span class="line">    data_plus_np = np.array(data_plus)</span><br><span class="line">    <span class="comment"># 转换为numpy矩阵</span></span><br><span class="line">    data_minus_np = np.array(data_minus)</span><br><span class="line">    <span class="comment"># 正样本散点图（scatter）</span></span><br><span class="line">    <span class="comment"># transpose转置</span></span><br><span class="line">    plt.scatter(np.transpose(data_plus_np)[<span class="number">0</span>], np.transpose(data_plus_np)[<span class="number">1</span>])</span><br><span class="line">    <span class="comment"># 负样本散点图（scatter）</span></span><br><span class="line">    plt.scatter(np.transpose(data_minus_np)[<span class="number">0</span>], np.transpose(data_minus_np)[<span class="number">1</span>])</span><br><span class="line">    <span class="comment"># 显示</span></span><br><span class="line">    plt.show()</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    testRbf()</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Machine_Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ML </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>《机器学习实战》《西瓜书》笔记（五）- 朴素贝叶斯</title>
      <link href="/2019/11/28/Machine_Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%885-%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%EF%BC%89/"/>
      <url>/2019/11/28/Machine_Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%885-%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<h1 id="贝叶斯"><a href="#贝叶斯" class="headerlink" title="贝叶斯"></a>贝叶斯</h1><h2 id="贝叶斯定理"><a href="#贝叶斯定理" class="headerlink" title="贝叶斯定理"></a>贝叶斯定理</h2><p>$p(c|x) = \frac{p(x|c)p(c)}{p(x)}$<br>其中c为类别，x为实例具有特征${x_1,x_2,…x_i}$<br>如果 $p(c_1|x) &gt; p(c_2|x)$，那么就属于类别c1,反之属于c2</p><h2 id="朴素贝叶斯的一般过程"><a href="#朴素贝叶斯的一般过程" class="headerlink" title="朴素贝叶斯的一般过程"></a>朴素贝叶斯的一般过程</h2><ol><li>收集数据，可以使用RSS源</li><li>准备数据，需要使用<strong>数值型或者布尔型</strong></li><li>分析数据，大量特征时，可以绘制直方图</li><li>训练算法，计算不同的独立特征的条件概率</li><li>测试算法，计算错误率</li><li>使用算法，封装贝叶斯分类器</li></ol><h2 id="文本分类"><a href="#文本分类" class="headerlink" title="文本分类"></a>文本分类</h2><h3 id="准备数据，从文本中构建词向量"><a href="#准备数据，从文本中构建词向量" class="headerlink" title="准备数据，从文本中构建词向量"></a>准备数据，从文本中构建词向量</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：创建实验样本</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    None</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    postingList - 实验样本切分的词条</span></span><br><span class="line"><span class="string">    classVec - 类别标签向量</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadDataSet</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="comment"># 切分的词条</span></span><br><span class="line">    postingList = [[<span class="string">'my'</span>, <span class="string">'dog'</span>, <span class="string">'has'</span>, <span class="string">'flea'</span>, <span class="string">'problems'</span>, <span class="string">'help'</span>, <span class="string">'please'</span>],</span><br><span class="line">                   [<span class="string">'maybe'</span>, <span class="string">'not'</span>, <span class="string">'take'</span>, <span class="string">'him'</span>, <span class="string">'to'</span>, <span class="string">'dog'</span>, <span class="string">'park'</span>, <span class="string">'stupid'</span>],</span><br><span class="line">                   [<span class="string">'my'</span>, <span class="string">'dalmation'</span>, <span class="string">'is'</span>, <span class="string">'so'</span>, <span class="string">'cute'</span>, <span class="string">'I'</span>, <span class="string">'love'</span>, <span class="string">'him'</span>],</span><br><span class="line">                   [<span class="string">'stop'</span>, <span class="string">'posting'</span>, <span class="string">'stupid'</span>, <span class="string">'worthless'</span>, <span class="string">'garbage'</span>],</span><br><span class="line">                   [<span class="string">'mr'</span>, <span class="string">'licks'</span>, <span class="string">'ate'</span>, <span class="string">'my'</span>, <span class="string">'steak'</span>, <span class="string">'how'</span>, <span class="string">'to'</span>, <span class="string">'stop'</span>, <span class="string">'him'</span>],</span><br><span class="line">                   [<span class="string">'quit'</span>, <span class="string">'buying'</span>, <span class="string">'worthless'</span>, <span class="string">'dog'</span>, <span class="string">'food'</span>, <span class="string">'stupid'</span>]]</span><br><span class="line">    <span class="comment"># 类别标签向量，1代表侮辱性词汇，0代表不是</span></span><br><span class="line">    classVec = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>]</span><br><span class="line">    <span class="comment"># 返回实验样本切分的词条、类别标签向量</span></span><br><span class="line">    <span class="keyword">return</span> postingList, classVec</span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：将切分的实验样本词条整理成不重复的词条列表，也就是词汇表</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    dataSet - 整理的样本数据集</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    vocabSet - 返回不重复的词条列表，也就是词汇表</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">createVocabList</span><span class="params">(dataSet)</span>:</span></span><br><span class="line">    <span class="comment"># 创建一个空的不重复列表</span></span><br><span class="line">    <span class="comment"># set是一个无序且不重复的元素集合</span></span><br><span class="line">    vocabSet = set([])</span><br><span class="line">    <span class="keyword">for</span> document <span class="keyword">in</span> dataSet:</span><br><span class="line">        <span class="comment"># 取并集</span></span><br><span class="line">        vocabSet = vocabSet | set(document)</span><br><span class="line">    <span class="keyword">return</span> list(vocabSet)</span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：根据vocabList词汇表，将inputSet向量化，向量的每个元素为1或0</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    vocabList - createVocabList返回的列表</span></span><br><span class="line"><span class="string">    inputSet - 切分的词条列表</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    returnVec - 文档向量，词集模型</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">setOfWords2Vec</span><span class="params">(vocabList, inputSet)</span>:</span></span><br><span class="line">    <span class="comment"># 创建一个其中所含元素都为0的向量</span></span><br><span class="line">    returnVec = [<span class="number">0</span>] * len(vocabList)</span><br><span class="line">    <span class="comment"># 遍历每个词条</span></span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> inputSet:</span><br><span class="line">        <span class="keyword">if</span> word <span class="keyword">in</span> vocabList:</span><br><span class="line">            <span class="comment"># 如果词条存在于词汇表中，则置1</span></span><br><span class="line">            <span class="comment"># index返回word出现在vocabList中的索引</span></span><br><span class="line">            <span class="comment"># 若这里改为+=则就是基于词袋的模型，遇到一个单词会增加单词向量中德对应值</span></span><br><span class="line">            returnVec[vocabList.index(word)] = <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            print(<span class="string">"the word: %s is not in my Vocabulary"</span> % word)</span><br><span class="line">    <span class="comment"># 返回文档向量</span></span><br><span class="line">    <span class="keyword">return</span> returnVec</span><br><span class="line"></span><br><span class="line">&gt;&gt; imort bayes</span><br><span class="line">&gt;&gt; listOposts, listClasses = bayes.loadDataSet()</span><br><span class="line">&gt;&gt; myVocabList = bayes.createVocabList(listOpists)</span><br><span class="line">&gt;&gt; bayes.setOfWords2Vec(myVocabList, listOpists)</span><br><span class="line">[<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0.</span>........]</span><br></pre></td></tr></table></figure><h3 id="训练算法，从词向量计算概率"><a href="#训练算法，从词向量计算概率" class="headerlink" title="训练算法，从词向量计算概率"></a>训练算法，从词向量计算概率</h3><p>$p(c|w) = \frac{p(w|c)p(c)}{p(w)}$<br>$p(c) = \frac{类别c的实例数}{总的实例数}$<br>$p(w|c)  = p(w_0,w_1,w_2,w_3,w_4 |c_i)$<br>$p(w|c)  = p(w_0|c_i)p(w_1|c_i)p(w_2|c_i)p(w_3|c_i)…p(w_n|c_i)$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br></pre></td><td class="code"><pre><span class="line">计算每个类别中的文档数目</span><br><span class="line">对每篇训练文档</span><br><span class="line">    对每个类被</span><br><span class="line">        如果词条出现在文档中，增加该词条的计数值</span><br><span class="line">        增加所有词条的计数值</span><br><span class="line">    对每个类别</span><br><span class="line">        对每个词条：</span><br><span class="line">            将该词条的数目除以总的词条数目<span class="number">1</span>得到条件概率</span><br><span class="line">    返回每个类别的条件概率</span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：朴素贝叶斯分类器训练函数</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    trainMatrix - 训练文档矩阵，即setOfWords2Vec返回的returnVec构成的矩阵</span></span><br><span class="line"><span class="string">    trainCategory - 训练类标签向量，即loadDataSet返回的classVec</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    p0Vect - 侮辱类的条件概率数组</span></span><br><span class="line"><span class="string">    p1Vect - 非侮辱类的条件概率数组</span></span><br><span class="line"><span class="string">    pAbusive - 文档属于侮辱类的概率</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">trainNB0</span><span class="params">(trainMatrix, trainCategory)</span>:</span></span><br><span class="line">    <span class="comment"># 计算训练文档数目</span></span><br><span class="line">    numTrainDocs = len(trainMatrix)</span><br><span class="line">    <span class="comment"># 计算每篇文档的词条数目</span></span><br><span class="line">    numWords = len(trainMatrix[<span class="number">0</span>])</span><br><span class="line">    <span class="comment"># 文档属于侮辱类的概率</span></span><br><span class="line">    pAbusive = sum(trainCategory)/float(numTrainDocs)</span><br><span class="line">    <span class="comment"># 创建numpy.zeros数组，词条出现数初始化为0</span></span><br><span class="line">    <span class="comment"># p0Num = np.zeros(numWords)</span></span><br><span class="line">    <span class="comment"># p1Num = np.zeros(numWords)</span></span><br><span class="line">    <span class="comment"># 创建numpy.ones数组，词条出现数初始化为1,拉普拉斯平滑</span></span><br><span class="line">    p0Num = np.ones(numWords)</span><br><span class="line">    p1Num = np.ones(numWords)</span><br><span class="line">    <span class="comment"># 分母初始化为0</span></span><br><span class="line">    <span class="comment"># p0Denom = 0.0</span></span><br><span class="line">    <span class="comment"># p1Denom = 0.0</span></span><br><span class="line">    <span class="comment"># 分母初始化为2，拉普拉斯平滑</span></span><br><span class="line">    p0Denom = <span class="number">2.0</span></span><br><span class="line">    p1Denom = <span class="number">2.0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(numTrainDocs):</span><br><span class="line">        <span class="comment"># 统计属于侮辱类的条件概率所需的数据，即P(w0|1),P(w1|1),P(w2|1)...</span></span><br><span class="line">        <span class="keyword">if</span> trainCategory[i] == <span class="number">1</span>:</span><br><span class="line">            <span class="comment"># 统计所有侮辱类文档中每个单词出现的个数</span></span><br><span class="line">            p1Num += trainMatrix[i]</span><br><span class="line">            <span class="comment"># 统计一共出现的侮辱单词的个数</span></span><br><span class="line">            p1Denom += sum(trainMatrix[i])</span><br><span class="line">        <span class="comment"># 统计属于非侮辱类的条件概率所需的数据，即P(w0|0),P(w1|0),P(w2|0)...</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 统计所有非侮辱类文档中每个单词出现的个数</span></span><br><span class="line">            p0Num += trainMatrix[i]</span><br><span class="line">            <span class="comment"># 统计一共出现的非侮辱单词的个数</span></span><br><span class="line">            p0Denom += sum(trainMatrix[i])</span><br><span class="line">    <span class="comment"># 每个侮辱类单词分别出现的概率</span></span><br><span class="line">    <span class="comment"># p1Vect = p1Num / p1Denom</span></span><br><span class="line">    <span class="comment"># 取对数，防止下溢出</span></span><br><span class="line">    p1Vect = np.log(p1Num / p1Denom)</span><br><span class="line">    <span class="comment"># 每个非侮辱类单词分别出现的概率</span></span><br><span class="line">    <span class="comment"># p0Vect = p0Num / p0Denom</span></span><br><span class="line">    <span class="comment"># 取对数，防止下溢出</span></span><br><span class="line">    p0Vect = np.log(p0Num / p0Denom)</span><br><span class="line">    <span class="comment"># 返回属于侮辱类的条件概率数组、属于非侮辱类的条件概率数组、文档属于侮辱类的概率</span></span><br><span class="line">    <span class="keyword">return</span> p0Vect, p1Vect, pAbusive</span><br><span class="line">```           </span><br><span class="line"><span class="comment">### 测试算法，改进</span></span><br><span class="line">为了避免$p(w|c)  = p(w_0|c_i)p(w_1|c_i)p(w_2|c_i)p(w_3|c_i)...p(w_n|c_i)$中出现某一项为<span class="number">0</span>的情况，这里采用对数矫正：</span><br><span class="line">$ln(a*b) = lna + lnb$</span><br><span class="line">```python</span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：朴素贝叶斯分类器分类函数</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    vec2Classify - 待分类的词条数组</span></span><br><span class="line"><span class="string">    p0Vec - 侮辱类的条件概率数组</span></span><br><span class="line"><span class="string">    p1Vec - 非侮辱类的条件概率数组</span></span><br><span class="line"><span class="string">    pClass1 - 文档属于侮辱类的概率</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    0 - 属于非侮辱类</span></span><br><span class="line"><span class="string">    1 - 属于侮辱类</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Modify:</span></span><br><span class="line"><span class="string">    2018-07-21</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">classifyNB</span><span class="params">(vec2Classify, p0Vec, p1Vec, pClass1)</span>:</span></span><br><span class="line">    <span class="comment"># 对应元素相乘</span></span><br><span class="line">    <span class="comment"># p1 = reduce(lambda x,y:x*y, vec2Classify * p1Vec) * pClass1</span></span><br><span class="line">    <span class="comment"># p0 = reduce(lambda x,y:x*y, vec2Classify * p0Vec) * (1.0 - pClass1)</span></span><br><span class="line">    <span class="comment"># 对应元素相乘，logA*B = logA + logB所以这里是累加</span></span><br><span class="line">    p1 = sum(vec2Classify * p1Vec) + np.log(pClass1)</span><br><span class="line">    p0 = sum(vec2Classify * p0Vec) + np.log(<span class="number">1.0</span> - pClass1)</span><br><span class="line">    <span class="comment"># print('p0:', p0)</span></span><br><span class="line">    <span class="comment"># print('p1:', p1)</span></span><br><span class="line">    <span class="keyword">if</span> p1 &gt; p0:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：测试朴素贝叶斯分类器</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    None</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    None</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Modify:</span></span><br><span class="line"><span class="string">    2018-07-21</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">testingNB</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="comment"># 创建实验样本</span></span><br><span class="line">    listOPosts, listclasses = loadDataSet()</span><br><span class="line">    <span class="comment"># 创建词汇表,将输入文本中的不重复的单词进行提取组成单词向量</span></span><br><span class="line">    myVocabList = createVocabList(listOPosts)</span><br><span class="line">    trainMat = []</span><br><span class="line">    <span class="keyword">for</span> postinDoc <span class="keyword">in</span> listOPosts:</span><br><span class="line">        <span class="comment"># 将实验样本向量化若postinDoc中的单词在myVocabList出现则将returnVec该位置的索引置1</span></span><br><span class="line">        <span class="comment"># 将6组数据list存储在trainMat中</span></span><br><span class="line">        trainMat.append(setOfWords2Vec(myVocabList, postinDoc))</span><br><span class="line">    <span class="comment"># 训练朴素贝叶斯分类器</span></span><br><span class="line">    p0V, p1V, pAb = trainNB0(np.array(trainMat), np.array(listclasses))</span><br><span class="line">    <span class="comment"># 测试样本1</span></span><br><span class="line">    testEntry = [<span class="string">'love'</span>, <span class="string">'my'</span>, <span class="string">'dalmation'</span>]</span><br><span class="line">    <span class="comment"># 测试样本向量化返回这三个单词出现位置的索引</span></span><br><span class="line">    thisDoc = np.array(setOfWords2Vec(myVocabList, testEntry))</span><br><span class="line">    <span class="keyword">if</span> classifyNB(thisDoc, p0V, p1V, pAb):</span><br><span class="line">        <span class="comment"># 执行分类并打印结果</span></span><br><span class="line">        print(testEntry, <span class="string">'属于侮辱类'</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># 执行分类并打印结果</span></span><br><span class="line">        print(testEntry, <span class="string">'属于非侮辱类'</span>)</span><br><span class="line">    <span class="comment"># 测试样本2</span></span><br><span class="line">    testEntry = [<span class="string">'stupid'</span>, <span class="string">'garbage'</span>]</span><br><span class="line">    <span class="comment"># 将实验样本向量化</span></span><br><span class="line">    thisDoc = np.array(setOfWords2Vec(myVocabList, testEntry))</span><br><span class="line">    <span class="keyword">if</span> classifyNB(thisDoc, p0V, p1V, pAb):</span><br><span class="line">        <span class="comment"># 执行分类并打印结果</span></span><br><span class="line">        print(testEntry, <span class="string">'属于侮辱类'</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># 执行分类并打印结果</span></span><br><span class="line">        print(testEntry, <span class="string">'属于非侮辱类'</span>)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Machine_Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ML </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>《机器学习实战》《西瓜书》笔记（六）- logist回归</title>
      <link href="/2019/11/28/Machine_Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%886-%20Logistic%E5%9B%9E%E5%BD%92%EF%BC%89/"/>
      <url>/2019/11/28/Machine_Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%886-%20Logistic%E5%9B%9E%E5%BD%92%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<h1 id="logist回归"><a href="#logist回归" class="headerlink" title="logist回归"></a>logist回归</h1><h2 id="最佳回归系数与Sigmod函数"><a href="#最佳回归系数与Sigmod函数" class="headerlink" title="最佳回归系数与Sigmod函数"></a>最佳回归系数与Sigmod函数</h2><p>$\sigma = 1/(1 + e^{-z})$<br>$z = w_0x_0+ w_1x_1+ w_2x_2+ ….w_nx_n$<br>$z = w^TX$</p><h3 id="梯度上升法"><a href="#梯度上升法" class="headerlink" title="梯度上升法"></a>梯度上升法</h3><p>$w = w + α* grad f(w)$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：梯度上升算法测试函数</span></span><br><span class="line"><span class="string">        求函数f(x) = -x^2+4x的极大值</span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    None</span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    None</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">Gradient_Ascent_test</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="comment"># f(x)的导数</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">f_prime</span><span class="params">(x_old)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">-2</span> * x_old + <span class="number">4</span></span><br><span class="line">    <span class="comment"># 初始值，给一个小于x_new的值</span></span><br><span class="line">    x_old = <span class="number">-1</span></span><br><span class="line">    <span class="comment"># 梯度上升算法初始值，即从(0, 0)开始</span></span><br><span class="line">    x_new = <span class="number">0</span></span><br><span class="line">    <span class="comment"># 步长，也就是学习速率，控制更新的幅度</span></span><br><span class="line">    alpha = <span class="number">0.01</span></span><br><span class="line">    <span class="comment"># 精度，也就是更新阈值</span></span><br><span class="line">    presision = <span class="number">0.00000001</span></span><br><span class="line">    <span class="keyword">while</span> abs(x_new - x_old) &gt; presision:</span><br><span class="line">        x_old = x_new</span><br><span class="line">        <span class="comment"># 利用上面的公式</span></span><br><span class="line">        x_new = x_old + alpha * f_prime(x_old)</span><br><span class="line">    <span class="comment"># 打印最终求解的极值近似值</span></span><br><span class="line">    print(x_new)</span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：sigmoid函数</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    inX - 数据</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    sigmoid函数</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span><span class="params">(inX)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1.0</span> / (<span class="number">1</span> + np.exp(-inX))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：梯度上升法</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    dataMath - 数据集</span></span><br><span class="line"><span class="string">    classLabels - 数据标签</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    weights.getA() - 求得的权重数组（最优参数）</span></span><br><span class="line"><span class="string">    weights_array - 每次更新的回归系数</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gradAscent</span><span class="params">(dataMath, classLabels)</span>:</span></span><br><span class="line">    <span class="comment"># 转换成numpy的mat(矩阵)</span></span><br><span class="line">    dataMatrix = np.mat(dataMath)</span><br><span class="line">    <span class="comment"># 转换成numpy的mat(矩阵)并进行转置</span></span><br><span class="line">    labelMat = np.mat(classLabels).transpose()</span><br><span class="line">    <span class="comment"># 返回dataMatrix的大小，m为行数，n为列数</span></span><br><span class="line">    m, n = np.shape(dataMatrix)</span><br><span class="line">    <span class="comment"># 移动步长，也就是学习效率，控制更新的幅度</span></span><br><span class="line">    alpha = <span class="number">0.01</span></span><br><span class="line">    <span class="comment"># 最大迭代次数</span></span><br><span class="line">    maxCycles = <span class="number">500</span></span><br><span class="line">    weights = np.ones((n, <span class="number">1</span>))</span><br><span class="line">    weights_array = np.array([])</span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> range(maxCycles):</span><br><span class="line">        <span class="comment"># 梯度上升矢量化公式</span></span><br><span class="line">        h = sigmoid(dataMatrix * weights)</span><br><span class="line">        error = labelMat - h</span><br><span class="line">        weights = weights + alpha * dataMatrix.transpose() * error</span><br><span class="line">        <span class="comment"># numpy.append(arr, values, axis=None):就是arr和values会重新组合成一个新的数组，做为返回值。</span></span><br><span class="line">        <span class="comment"># 当axis无定义时，是横向加成，返回总是为一维数组</span></span><br><span class="line">        weights_array = np.append(weights_array, weights)</span><br><span class="line">    weights_array = weights_array.reshape(maxCycles, n)</span><br><span class="line">    <span class="comment"># 将矩阵转换为数组，返回权重数组</span></span><br><span class="line">    <span class="comment"># mat.getA()将自身矩阵变量转化为ndarray类型变量</span></span><br><span class="line">    <span class="keyword">return</span> weights.getA(), weights_array</span><br></pre></td></tr></table></figure><h3 id="绘制决策边界"><a href="#绘制决策边界" class="headerlink" title="绘制决策边界"></a>绘制决策边界</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：绘制数据集</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    weights - 权重参数数组</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    None</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plotBestFit</span><span class="params">(weights)</span>:</span></span><br><span class="line">    <span class="comment"># 加载数据集</span></span><br><span class="line">    dataMat, labelMat = loadDataSet()</span><br><span class="line">    <span class="comment"># 转换成numpy的array数组</span></span><br><span class="line">    dataArr = np.array(dataMat)</span><br><span class="line">    <span class="comment"># 数据个数</span></span><br><span class="line">    <span class="comment"># 例如建立一个4*2的矩阵c，c.shape[1]为第一维的长度2， c.shape[0]为第二维的长度4</span></span><br><span class="line">    n = np.shape(dataMat)[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># 正样本</span></span><br><span class="line">    xcord1 = []</span><br><span class="line">    ycord1 = []</span><br><span class="line">    <span class="comment"># 负样本</span></span><br><span class="line">    xcord2 = []</span><br><span class="line">    ycord2 = []</span><br><span class="line">    <span class="comment"># 根据数据集标签进行分类</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(n):</span><br><span class="line">        <span class="keyword">if</span> int(labelMat[i]) == <span class="number">1</span>:</span><br><span class="line">            <span class="comment"># 1为正样本</span></span><br><span class="line">            xcord1.append(dataArr[i, <span class="number">1</span>])</span><br><span class="line">            ycord1.append(dataArr[i, <span class="number">2</span>])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 0为负样本</span></span><br><span class="line">            xcord2.append(dataArr[i, <span class="number">1</span>])</span><br><span class="line">            ycord2.append(dataArr[i, <span class="number">2</span>])</span><br><span class="line">    <span class="comment"># 新建图框</span></span><br><span class="line">    fig = plt.figure()</span><br><span class="line">    <span class="comment"># 添加subplot</span></span><br><span class="line">    ax = fig.add_subplot(<span class="number">111</span>)</span><br><span class="line">    <span class="comment"># 绘制正样本</span></span><br><span class="line">    ax.scatter(xcord1, ycord1, s=<span class="number">20</span>, c=<span class="string">'red'</span>, marker=<span class="string">'s'</span>, alpha=<span class="number">.5</span>)</span><br><span class="line">    <span class="comment"># 绘制负样本</span></span><br><span class="line">    ax.scatter(xcord2, ycord2, s=<span class="number">20</span>, c=<span class="string">'green'</span>, alpha=<span class="number">.5</span>)</span><br><span class="line">    <span class="comment"># x轴坐标</span></span><br><span class="line">    x = np.arange(<span class="number">-3.0</span>, <span class="number">3.0</span>, <span class="number">0.1</span>)</span><br><span class="line">    <span class="comment"># w0*x0 + w1*x1 * w2*x2 = 0</span></span><br><span class="line">    <span class="comment"># x0 = 1, x1 = x, x2 = y</span></span><br><span class="line">    y = (-weights[<span class="number">0</span>] - weights[<span class="number">1</span>] * x) / weights[<span class="number">2</span>]</span><br><span class="line">    ax.plot(x, y)</span><br><span class="line">    <span class="comment"># 绘制title</span></span><br><span class="line">    plt.title(<span class="string">'BestFit'</span>)</span><br><span class="line">    <span class="comment"># 绘制label</span></span><br><span class="line">    plt.xlabel(<span class="string">'x1'</span>)</span><br><span class="line">    plt.ylabel(<span class="string">'y2'</span>)</span><br><span class="line">    <span class="comment"># 显示</span></span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure><h3 id="随机梯度上升法"><a href="#随机梯度上升法" class="headerlink" title="随机梯度上升法"></a>随机梯度上升法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：改进的随机梯度上升法</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    dataMatrix - 数据数组</span></span><br><span class="line"><span class="string">    classLabels - 数据标签</span></span><br><span class="line"><span class="string">    numIter - 迭代次数</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    weights - 求得的回归系数数组（最优参数）</span></span><br><span class="line"><span class="string">    weights_array - 每次更新的回归系数</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">stocGradAscent1</span><span class="params">(dataMatrix, classLabels, numIter=<span class="number">150</span>)</span>:</span></span><br><span class="line">    <span class="comment"># 返回dataMatrix的大小，m为行数，n为列数</span></span><br><span class="line">    m, n = np.shape(dataMatrix)</span><br><span class="line">    <span class="comment"># 参数初始化</span></span><br><span class="line">    weights = np.ones(n)</span><br><span class="line">    weights_array = np.array([])</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(numIter):</span><br><span class="line">        dataIndex = list(range(m))</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">            <span class="comment"># 每次都降低alpha的大小</span></span><br><span class="line">            alpha = <span class="number">4</span>/(<span class="number">1.0</span>+j+i)+<span class="number">0.01</span></span><br><span class="line">            <span class="comment"># 随机选择样本</span></span><br><span class="line">            randIndex = int(random.uniform(<span class="number">0</span>, len(dataIndex)))</span><br><span class="line">            <span class="comment"># 随机选择一个样本计算h</span></span><br><span class="line">            h = sigmoid(sum(dataMatrix[randIndex] * weights))</span><br><span class="line">            <span class="comment"># 计算误差</span></span><br><span class="line">            error = classLabels[randIndex] - h</span><br><span class="line">            <span class="comment"># 更新回归系数</span></span><br><span class="line">            weights = weights + alpha * error * dataMatrix[randIndex]</span><br><span class="line">            <span class="comment"># 添加返回系数到数组中当axis为0时，数组是加在下面（列数要相同）</span></span><br><span class="line">            weights_array = np.append(weights_array, weights, axis=<span class="number">0</span>)</span><br><span class="line">            <span class="comment"># 删除已使用的样本</span></span><br><span class="line">            <span class="keyword">del</span>(dataIndex[randIndex])</span><br><span class="line">    <span class="comment"># 改变维度</span></span><br><span class="line">    weights_array = weights_array.reshape(numIter*m, n)</span><br><span class="line">    <span class="comment"># 返回</span></span><br><span class="line">    <span class="keyword">return</span> weights, weights_array</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：绘制回归系数与迭代次数的关系</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    weights_array1 - 回归系数数组1</span></span><br><span class="line"><span class="string">    weights_array2 - 回归系数数组2</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    None</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plotWeights</span><span class="params">(weights_array1, weights_array2)</span>:</span></span><br><span class="line">    <span class="comment"># 设置汉字格式为14号简体字</span></span><br><span class="line">    font = FontProperties(fname=<span class="string">r"C:\Windows\Fonts\simsun.ttc"</span>, size=<span class="number">14</span>)</span><br><span class="line">    <span class="comment"># 将fig画布分隔成1行1列，不共享x轴和y轴，fig画布的大小为（20, 10）</span></span><br><span class="line">    <span class="comment"># 当nrows=3，ncols=2时，代表fig画布被分为6个区域，axs[0][0]代表第一行第一个区域</span></span><br><span class="line">    fig, axs = plt.subplots(nrows=<span class="number">3</span>, ncols=<span class="number">2</span>, sharex=<span class="literal">False</span>, sharey=<span class="literal">False</span>, figsize=(<span class="number">20</span>, <span class="number">10</span>))</span><br><span class="line">    <span class="comment"># x1坐标轴的范围</span></span><br><span class="line">    x1 = np.arange(<span class="number">0</span>, len(weights_array1), <span class="number">1</span>)</span><br><span class="line">    <span class="comment"># 绘制w0与迭代次数的关系</span></span><br><span class="line">    axs[<span class="number">0</span>][<span class="number">0</span>].plot(x1, weights_array1[:, <span class="number">0</span>])</span><br><span class="line">    axs0_title_text = axs[<span class="number">0</span>][<span class="number">0</span>].set_title(<span class="string">u'改进的梯度上升算法，回归系数与迭代次数关系'</span>, FontProperties=font)</span><br><span class="line">    axs0_ylabel_text = axs[<span class="number">0</span>][<span class="number">0</span>].set_ylabel(<span class="string">u'w0'</span>, FontProperties=font)</span><br><span class="line">    plt.setp(axs0_title_text, size=<span class="number">20</span>, weight=<span class="string">'bold'</span>, color=<span class="string">'black'</span>)</span><br><span class="line">    plt.setp(axs0_ylabel_text, size=<span class="number">20</span>, weight=<span class="string">'bold'</span>, color=<span class="string">'black'</span>)</span><br><span class="line">    <span class="comment"># 绘制w1与迭代次数的关系</span></span><br><span class="line">    axs[<span class="number">1</span>][<span class="number">0</span>].plot(x1, weights_array1[:, <span class="number">1</span>])</span><br><span class="line">    axs1_ylabel_text = axs[<span class="number">1</span>][<span class="number">0</span>].set_ylabel(<span class="string">u'w1'</span>, FontProperties=font)</span><br><span class="line">    plt.setp(axs1_ylabel_text, size=<span class="number">20</span>, weight=<span class="string">'bold'</span>, color=<span class="string">'black'</span>)</span><br><span class="line">    <span class="comment"># 绘制w2与迭代次数的关系</span></span><br><span class="line">    axs[<span class="number">2</span>][<span class="number">0</span>].plot(x1, weights_array1[:, <span class="number">2</span>])</span><br><span class="line">    axs2_title_text = axs[<span class="number">2</span>][<span class="number">0</span>].set_title(<span class="string">u'迭代次数'</span>, FontProperties=font)</span><br><span class="line">    axs2_ylabel_text = axs[<span class="number">2</span>][<span class="number">0</span>].set_ylabel(<span class="string">u'w2'</span>, FontProperties=font)</span><br><span class="line">    plt.setp(axs2_title_text, size=<span class="number">20</span>, weight=<span class="string">'bold'</span>, color=<span class="string">'black'</span>)</span><br><span class="line">    plt.setp(axs2_ylabel_text, size=<span class="number">20</span>, weight=<span class="string">'bold'</span>, color=<span class="string">'black'</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># x2坐标轴的范围</span></span><br><span class="line">    x2 = np.arange(<span class="number">0</span>, len(weights_array2), <span class="number">1</span>)</span><br><span class="line">    <span class="comment"># 绘制w0与迭代次数的关系</span></span><br><span class="line">    axs[<span class="number">0</span>][<span class="number">1</span>].plot(x2, weights_array2[:, <span class="number">0</span>])</span><br><span class="line">    axs0_title_text = axs[<span class="number">0</span>][<span class="number">1</span>].set_title(<span class="string">u'梯度上升算法，回归系数与迭代次数关系'</span>, FontProperties=font)</span><br><span class="line">    axs0_ylabel_text = axs[<span class="number">0</span>][<span class="number">1</span>].set_ylabel(<span class="string">u'w0'</span>, FontProperties=font)</span><br><span class="line">    plt.setp(axs0_title_text, size=<span class="number">20</span>, weight=<span class="string">'bold'</span>, color=<span class="string">'black'</span>)</span><br><span class="line">    plt.setp(axs0_ylabel_text, size=<span class="number">20</span>, weight=<span class="string">'bold'</span>, color=<span class="string">'black'</span>)</span><br><span class="line">    <span class="comment"># 绘制w1与迭代次数的关系</span></span><br><span class="line">    axs[<span class="number">1</span>][<span class="number">1</span>].plot(x2, weights_array2[:, <span class="number">1</span>])</span><br><span class="line">    axs1_ylabel_text = axs[<span class="number">1</span>][<span class="number">1</span>].set_ylabel(<span class="string">u'w1'</span>, FontProperties=font)</span><br><span class="line">    plt.setp(axs1_ylabel_text, size=<span class="number">20</span>, weight=<span class="string">'bold'</span>, color=<span class="string">'black'</span>)</span><br><span class="line">    <span class="comment"># 绘制w2与迭代次数的关系</span></span><br><span class="line">    axs[<span class="number">2</span>][<span class="number">1</span>].plot(x2, weights_array2[:, <span class="number">2</span>])</span><br><span class="line">    axs2_title_text = axs[<span class="number">2</span>][<span class="number">1</span>].set_title(<span class="string">u'迭代次数'</span>, FontProperties=font)</span><br><span class="line">    axs2_ylabel_text = axs[<span class="number">2</span>][<span class="number">1</span>].set_ylabel(<span class="string">u'w2'</span>, FontProperties=font)</span><br><span class="line">    plt.setp(axs2_title_text, size=<span class="number">20</span>, weight=<span class="string">'bold'</span>, color=<span class="string">'black'</span>)</span><br><span class="line">    plt.setp(axs2_ylabel_text, size=<span class="number">20</span>, weight=<span class="string">'bold'</span>, color=<span class="string">'black'</span>)</span><br><span class="line">    </span><br><span class="line">    plt.show()</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="comment"># 测试简单梯度上升法</span></span><br><span class="line">    <span class="comment"># Gradient_Ascent_test()</span></span><br><span class="line">    <span class="comment"># 加载数据集</span></span><br><span class="line">    dataMat, labelMat = loadDataSet()</span><br><span class="line">    <span class="comment"># 训练权重</span></span><br><span class="line">    weights2, weights_array2 = gradAscent(dataMat, labelMat)</span><br><span class="line">    <span class="comment"># 新方法训练权重</span></span><br><span class="line">    weights1, weights_array1 = stocGradAscent1(np.array(dataMat), labelMat)</span><br><span class="line">    <span class="comment"># 绘制数据集中的y和x的散点图</span></span><br><span class="line">    <span class="comment"># plotBestFit(weights)</span></span><br><span class="line">    <span class="comment"># print(gradAscent(dataMat, labelMat))</span></span><br><span class="line">    plotWeights(weights_array1, weights_array2)</span><br></pre></td></tr></table></figure><h2 id="梯度下降法"><a href="#梯度下降法" class="headerlink" title="梯度下降法"></a>梯度下降法</h2><p>$w = w - α*gradf(w)$</p>]]></content>
      
      
      <categories>
          
          <category> Machine_Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ML </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>《机器学习实战》《西瓜书》笔记（四）- 决策树</title>
      <link href="/2019/11/27/Machine_Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%884-DecisionTree)/"/>
      <url>/2019/11/27/Machine_Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%884-DecisionTree)/</url>
      
        <content type="html"><![CDATA[<h1 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h1><p>决策树本质上是一种流程图，长方形代表<strong>判断模块</strong>，椭圆代表<strong>终止模块</strong>，左右箭头指引<strong>节点的上下分支</strong><br>决策树相比较于KNN，其重要的原因就是其数据形式非常容易理解，而KNN的数据形式所包含的内在含义却不是很容易理解</p><div align = center><img src = " https://img.vim-cn.com/10/8d6b3cb5f550b03b25681ed2bdc0f7cc424005.png"></div><p><strong>优点</strong><br>计算复杂度不高，可以处理不相关特征数据，对中间数据的缺省值不敏感<br><strong>缺点</strong><br>会产生过度匹配问题</p><h2 id="信息论划分数据集"><a href="#信息论划分数据集" class="headerlink" title="信息论划分数据集"></a>信息论划分数据集</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""划分数据集的伪代码"""</span></span><br><span class="line">检测数据集是否属于同一类：</span><br><span class="line">    <span class="keyword">if</span> so  <span class="keyword">return</span> 类标签</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        寻找划分数据集的最好特征</span><br><span class="line">        划分数据集</span><br><span class="line">        创建分支节点</span><br><span class="line">            <span class="keyword">for</span> 每个划分的子类</span><br><span class="line">                调用函数createBranch并增加返回节点到结果上</span><br><span class="line">        <span class="keyword">return</span> 分支节点</span><br></pre></td></tr></table></figure><h2 id="决策树的流程"><a href="#决策树的流程" class="headerlink" title="决策树的流程"></a>决策树的流程</h2><ol><li>收集数据：可以使用任何方法</li><li>准备数据：<strong>树构造算法适用于标称型数据，如果数据是数值型数据，需要先把数据进行离散化</strong></li><li>分析数据：构造树完成，进行检查</li><li>训练算法：构造树的数据结构</li><li>测试算法：使用经验树计算错误率</li><li>使用算法</li></ol><h2 id="信息增益与信息熵"><a href="#信息增益与信息熵" class="headerlink" title="信息增益与信息熵"></a>信息增益与信息熵</h2><p><strong>划分数据集的最大原则是，将无序的数据变得更加有序</strong><br><strong>信息增益</strong>：划分数据集前后信息发生的变化称为信息增益<br>计算每个特征划分数据集获得的信息增益，获得信息增益最高的特征就是最好的选择<br><strong>如何计算信息增益？</strong><br>集合信息的度量方式称为<strong>香农熵</strong><br>熵定义为信息的期望值：<br>符号$x_i$的信息定义为$l(x_i) = -log_2p(x_i)$，p(x_i)是选择该分类的概率<br>则信息熵为：$H = -\sum\nolimits_{i=1}^{n}p(x_i)log_2p(x_i)$,其中n是分类的数目</p><h2 id="计算信息熵的源代码"><a href="#计算信息熵的源代码" class="headerlink" title="计算信息熵的源代码"></a>计算信息熵的源代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">用于计算给定的信息熵</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：计算给定数据集的经验熵（香农熵）</span></span><br><span class="line"><span class="string">        H = -SUM（kp*Log2（kp））</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    dataSet - 数据集</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    shannonEnt - 经验熵（香农熵）</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calcShannonEnt</span><span class="params">(dataSet)</span>:</span></span><br><span class="line">    <span class="comment"># 返回数据集的行数</span></span><br><span class="line">    numEntires = len(dataSet)</span><br><span class="line">    <span class="comment"># 保存每个标签（Label）出现次数的“字典”</span></span><br><span class="line">    labelCounts = &#123;&#125;</span><br><span class="line">    <span class="comment"># 对每组特征向量进行统计</span></span><br><span class="line">    <span class="keyword">for</span> featVec <span class="keyword">in</span> dataSet:     <span class="comment"># 按行进行遍历</span></span><br><span class="line">        <span class="comment"># 提取标签（Label）信息</span></span><br><span class="line">        currentLabel = featVec[<span class="number">-1</span>]    <span class="comment"># 取每一行最后一列特征值</span></span><br><span class="line">        <span class="comment"># 如果标签（Label）没有放入统计次数的字典，添加进去</span></span><br><span class="line">        <span class="keyword">if</span> currentLabel <span class="keyword">not</span> <span class="keyword">in</span> labelCounts.keys():</span><br><span class="line">            <span class="comment"># 创建一个新的键值对，键为currentLabel值为0</span></span><br><span class="line">            labelCounts[currentLabel] = <span class="number">0</span></span><br><span class="line">        <span class="comment"># Label计数</span></span><br><span class="line">        labelCounts[currentLabel] += <span class="number">1</span></span><br><span class="line">    <span class="comment"># 经验熵（香农熵）</span></span><br><span class="line">    shannonEnt = <span class="number">0.0</span></span><br><span class="line">    <span class="comment"># 计算香农熵</span></span><br><span class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> labelCounts:</span><br><span class="line">        <span class="comment"># 选择该标签（Label）的概率</span></span><br><span class="line">        prob = float(labelCounts[key]) / numEntires</span><br><span class="line">        <span class="comment"># 利用公式计算</span></span><br><span class="line">        shannonEnt -= prob*log(prob, <span class="number">2</span>)</span><br><span class="line">    <span class="comment"># 返回经验熵（香农熵）</span></span><br><span class="line">    <span class="keyword">return</span> shannonEnt</span><br></pre></td></tr></table></figure><p><strong>创建数据集</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">createDataSet</span><span class="params">()</span>：</span></span><br><span class="line">    dataSet = [[1, ,1 , 'yes'],[1, 1, 'yes'],[1, 0, 'no'],[0, 1, 'no'],[0, 1, 'no']]</span><br><span class="line">    labels = [<span class="string">'no surfacing'</span>, <span class="string">'flippers'</span>]</span><br><span class="line">    <span class="keyword">return</span> dataSet, labels</span><br><span class="line"></span><br><span class="line">&gt;&gt; reload(trees.py)</span><br><span class="line">&gt;&gt; myDat, labels = trees.createDataSet()</span><br><span class="line">&gt;&gt; trees.calcShannonEnt(mydata)</span><br></pre></td></tr></table></figure><h2 id="划分数据集的算法与代码"><a href="#划分数据集的算法与代码" class="headerlink" title="划分数据集的算法与代码"></a>划分数据集的算法与代码</h2><p>一般可用二分法划分数据集，这里采用<strong>ID3算法</strong>进行划分数据集<br>香农熵可用来度量数据集的无序度，数据无序度越大，香农熵值越大。<br>分类算法除了需要测量信息熵还需要一个<strong>度量数据划分准确度的熵值</strong>，这就像在二维坐标中画直线进行划分平面坐标系、</p><ol><li><strong>按照给定特征划分数据集</strong><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数：按照给定的特征划分数据集</span></span><br><span class="line"><span class="string">输入：</span></span><br><span class="line"><span class="string">    dataSet,数据集</span></span><br><span class="line"><span class="string">    axis, 划分数据集的特征</span></span><br><span class="line"><span class="string">    value, 需要返回的特征值</span></span><br><span class="line"><span class="string">Return:</span></span><br><span class="line"><span class="string">    retDataSet,划分的数据集</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">splitDataSet</span><span class="params">(dataSet, axis, value)</span>:</span></span><br><span class="line">    retDataSet = []</span><br><span class="line">    <span class="keyword">for</span> featVec <span class="keyword">in</span> dataSet:  <span class="comment"># 按行遍历数据集</span></span><br><span class="line">        <span class="keyword">if</span> featVec[axis] == value:   <span class="comment"># 去掉特征为axis的数据集</span></span><br><span class="line">            reducedFeatVec = featVec[:axis]</span><br><span class="line">            reducedFeatVec.extend(featVec[axis+<span class="number">1</span>:])  <span class="comment"># 扩展列表元素</span></span><br><span class="line">            retDataSet.append(reducedFeatVec)  <span class="comment"># 添加嵌套列表</span></span><br><span class="line">    <span class="keyword">return</span> retDataSet</span><br><span class="line"></span><br><span class="line">&gt;&gt; <span class="keyword">import</span> DecisionTree <span class="keyword">as</span> DT</span><br><span class="line">&gt;&gt; mydat, labels = DT.createDataSet()</span><br><span class="line">&gt;&gt; DT.splitDataSet(mydat, <span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line">&gt;&gt; DT.splitDataSet(mydat, <span class="number">0</span>, <span class="number">1</span>)</span><br></pre></td></tr></table></figure></li><li>选择最好的数据集划分方式<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数：选择最好的数据集划分方式</span></span><br><span class="line"><span class="string">Para:</span></span><br><span class="line"><span class="string">    dataSet:数据集</span></span><br><span class="line"><span class="string">return:</span></span><br><span class="line"><span class="string">    bestFeature:最好的特征的索引值</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">chooseBestFeatureToSplit</span><span class="params">(dataSet)</span>:</span></span><br><span class="line"></span><br><span class="line">    numFeatures = len(dataSet[<span class="number">0</span>]) - <span class="number">1</span>  <span class="comment"># 特征的个数-1</span></span><br><span class="line">    baseEntropy = calcShannonEnt(dataSet)  <span class="comment"># 计算数据集的香农熵</span></span><br><span class="line">    bestInfoGain = <span class="number">0.0</span> ; bestFeature = <span class="number">-1</span>  <span class="comment"># 最大信息增益和最优划分特征的索引值</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(numFeatures): <span class="comment"># 遍历特征</span></span><br><span class="line">        featList = [example[i] <span class="keyword">for</span> example <span class="keyword">in</span> dataSet] <span class="comment"># 列表生成式生成特征所有的取值</span></span><br><span class="line">        uniqueVals = set(featList) <span class="comment"># 删去重复值</span></span><br><span class="line">        newEntropy = <span class="number">0.0</span> <span class="comment"># 香农熵</span></span><br><span class="line">        <span class="keyword">for</span> values <span class="keyword">in</span> uniqueVals:  <span class="comment"># 遍历特征值</span></span><br><span class="line">            subDataSet = splitDataSet(dataset, i , value)  <span class="comment"># 划分数据集</span></span><br><span class="line">            prob = len(subDataSet) / float(len(dataSet))  <span class="comment"># 计算概率</span></span><br><span class="line">            newEntropy += prob * calcShannonEnt(subDataSet)  <span class="comment"># 计算经验条件熵</span></span><br><span class="line">        infoGain = baseEntropy - newEntropy  <span class="comment"># 信息增益值</span></span><br><span class="line">        print(<span class="string">"第%d个特征的增益为%.3f"</span> % (i, infoGain)) <span class="comment"># 打印每个特征的信息增益，取正</span></span><br><span class="line">        <span class="keyword">if</span>(infoGain &gt; baseEntropy):    <span class="comment"># 找到对应最大信息增益的特征</span></span><br><span class="line">            baseInfoGain = infoGain</span><br><span class="line">            bestFeature = i</span><br><span class="line">    <span class="keyword">return</span> bestFeature</span><br><span class="line"></span><br><span class="line">&gt;&gt; DecisionTree.chooseBestFeaturToSplit(mydat)</span><br></pre></td></tr></table></figure><h2 id="递归构建决策树"><a href="#递归构建决策树" class="headerlink" title="递归构建决策树"></a>递归构建决策树</h2><div align = center><img src = "https://img.vim-cn.com/81/18e71a83e22a268a8899ee9aff50fe083ddbd4.png"></div></li></ol><p>当特征值多与两个的时候，就可能存在大于两个分支的数据集划分，这时我们就通过递归调用来实现它！<br><strong>递归结束的条件</strong><br>程序遍历完所有划分数据的属性，或者每个分支下的所有实例都具有相同的分类。如果所有实例都具有相同的分类，则得到一个叶子节点或者终止快。任何到达叶子结点所属的分类必然属于叶子节点的类。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：统计classList中出现次数最多的元素（类标签）</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    classList - 类标签列表</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    sortedClassCount[0][0] - 出现次数最多的元素（类标签）</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">"""</span>   </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">majorityCnt</span><span class="params">(classList)</span>:</span></span><br><span class="line">    classCount = &#123;&#125;</span><br><span class="line">    <span class="comment"># 统计classList中每个元素出现的次数</span></span><br><span class="line">    <span class="keyword">for</span> vote <span class="keyword">in</span> classList:</span><br><span class="line">        <span class="keyword">if</span> vote <span class="keyword">not</span> <span class="keyword">in</span> classCount.keys():</span><br><span class="line">            classCount[vote] = <span class="number">0</span></span><br><span class="line">        classCount[vote] += <span class="number">1</span></span><br><span class="line">    <span class="comment"># 根据字典的值降序排序</span></span><br><span class="line">    <span class="comment"># operator.itemgetter(1)获取对象的第1列的值</span></span><br><span class="line">    sortedClassCount = sorted(classCount.items(), key = operator.itemgetter(<span class="number">1</span>), reverse = <span class="literal">True</span>)</span><br><span class="line">    <span class="comment"># 返回classList中出现次数最多的元素</span></span><br><span class="line">    <span class="keyword">return</span> sortedClassCount[<span class="number">0</span>][<span class="number">0</span>]</span><br></pre></td></tr></table></figure><p><strong>创建决策树的代码</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：创建决策树（ID3算法）</span></span><br><span class="line"><span class="string">        递归有两个终止条件：1、所有的类标签完全相同，直接返回类标签</span></span><br><span class="line"><span class="string">                        2、用完所有标签但是得不到唯一类别的分组，即特征不够用，挑选出现数量最多的类别作为返回</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    dataSet - 训练数据集</span></span><br><span class="line"><span class="string">    labels - 分类属性标签</span></span><br><span class="line"><span class="string">    featLabels - 存储选择的最优特征标签</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    myTree - 决策树</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">createTree</span><span class="params">(dataSet, labels, featLabels)</span>:</span></span><br><span class="line">    classList = [example[<span class="number">-1</span>] <span class="keyword">for</span> example <span class="keyword">in</span> dataSet]   <span class="comment"># 取分类标签（是否放贷：yes or no）</span></span><br><span class="line">    <span class="keyword">if</span> classList.count(classList[<span class="number">0</span>]) == len(classList):  <span class="comment"># 如果类别完全相同则停止继续划分</span></span><br><span class="line">        <span class="keyword">return</span> classList[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">if</span> len(dataSet[<span class="number">0</span>]) == <span class="number">1</span>:  <span class="comment"># 遍历完所有特征时返回出现次数最多的类标签</span></span><br><span class="line">        <span class="keyword">return</span> majorityCnt(classList)</span><br><span class="line">    bestFeat = chooseBestFeatureToSplit(dataSet) <span class="comment"># 选择最优特征</span></span><br><span class="line">    bestFeatLabel = labels[bestFeat]  <span class="comment"># 最优特征的标签</span></span><br><span class="line">    featLabels.append(bestFeatLabel)</span><br><span class="line">    myTree = &#123;bestFeatLabel:&#123;&#125;&#125; <span class="comment"># 根据最优特征的标签生成树</span></span><br><span class="line">    <span class="keyword">del</span>(labels[bestFeat])      <span class="comment"># 删除已经使用的特征标签</span></span><br><span class="line">    featValues = [example[bestFeat] <span class="keyword">for</span> example <span class="keyword">in</span> dataSet] <span class="comment"># 得到训练集中所有最优解特征的属性值</span></span><br><span class="line">    uniqueVals = set(featValues) <span class="comment"># 去掉重复的属性值</span></span><br><span class="line">    <span class="keyword">for</span> value <span class="keyword">in</span> uniqueVals: <span class="comment"># 遍历特征，创建决策树</span></span><br><span class="line">        myTree[bestFeatLabel][value] = createTree(splitDataSet(dataSet, bestFeat, value), labels, featLabels)</span><br><span class="line">    <span class="keyword">return</span> myTree</span><br><span class="line"></span><br><span class="line">&gt;&gt; my tree = DecisionTree.createTree(mydata,labels)</span><br><span class="line">&gt;&gt; my tree</span><br></pre></td></tr></table></figure><h2 id="测试算法与分类器"><a href="#测试算法与分类器" class="headerlink" title="测试算法与分类器"></a>测试算法与分类器</h2><h3 id="测试算法构造分类器"><a href="#测试算法构造分类器" class="headerlink" title="测试算法构造分类器"></a>测试算法构造分类器</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数：使用决策树的分类函数</span></span><br><span class="line"><span class="string">para:</span></span><br><span class="line"><span class="string">    inputree,</span></span><br><span class="line"><span class="string">    featLabels,</span></span><br><span class="line"><span class="string">    testVec</span></span><br><span class="line"><span class="string">return:</span></span><br><span class="line"><span class="string">    classlabel,分类器</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">classify</span><span class="params">(inputTree, featLabels, testVec)</span>:</span></span><br><span class="line">    <span class="comment"># 获取决策树结点</span></span><br><span class="line">    firstStr = next(iter(inputTree))</span><br><span class="line">    <span class="comment"># 下一个字典</span></span><br><span class="line">    secondDict = inputTree[firstStr]</span><br><span class="line">    featIndex = featLabels.index(firstStr)</span><br><span class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> secondDict.keys():</span><br><span class="line">        <span class="keyword">if</span> testVec[featIndex] == key:</span><br><span class="line">            <span class="keyword">if</span> type(secondDict[key]).__name__ == <span class="string">'dict'</span>:</span><br><span class="line">                classLabel = classify(secondDict[key], featLabels, testVec)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                classLabel = secondDict[key]</span><br><span class="line">    <span class="keyword">return</span> classLabel</span><br></pre></td></tr></table></figure><h3 id="使用算法"><a href="#使用算法" class="headerlink" title="使用算法"></a>使用算法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：存储决策树</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    inputTree - 已经生成的决策树</span></span><br><span class="line"><span class="string">    filename - 决策树的存储文件名</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    None</span></span><br><span class="line"><span class="string">"""</span>   </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">storeTree</span><span class="params">(inputTree, filename)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> open(filename, <span class="string">'wb'</span>) <span class="keyword">as</span> fw:</span><br><span class="line">        pickle.dump(inputTree, fw)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：读取决策树</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    filename - 决策树的存储文件名</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    pickle.load(fr) - 决策树字典</span></span><br><span class="line"><span class="string">"""</span> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">grabTree</span><span class="params">(filename)</span>:</span></span><br><span class="line">    fr = open(filename, <span class="string">'rb'</span>)</span><br><span class="line">    <span class="keyword">return</span> pickle.load(fr)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Machine_Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ML </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>色彩搭配与设计</title>
      <link href="/2019/11/26/%E8%AE%BE%E8%AE%A1/%E5%85%B3%E4%BA%8E%E9%A2%9C%E8%89%B2/"/>
      <url>/2019/11/26/%E8%AE%BE%E8%AE%A1/%E5%85%B3%E4%BA%8E%E9%A2%9C%E8%89%B2/</url>
      
        <content type="html"><![CDATA[<h1 id="Color"><a href="#Color" class="headerlink" title="Color"></a>Color</h1><h2 id="Material-design中的color"><a href="#Material-design中的color" class="headerlink" title="Material design中的color"></a>Material design中的color</h2><p><div><img src = "https://img.vim-cn.com/65/c21d40de1a5e93d9dbfd5f35e17f18d52b931f.webp"></div><br><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!--Material Colors--&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">color</span> <span class="attr">name</span>=<span class="string">"materialColorRed"</span>&gt;</span>#f44336<span class="tag">&lt;/<span class="name">color</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">color</span> <span class="attr">name</span>=<span class="string">"materialColorPink"</span>&gt;</span>#e91e63<span class="tag">&lt;/<span class="name">color</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">color</span> <span class="attr">name</span>=<span class="string">"materialColorPurple"</span>&gt;</span>#9c27b0<span class="tag">&lt;/<span class="name">color</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">color</span> <span class="attr">name</span>=<span class="string">"materialColorDeepPurple"</span>&gt;</span>#673ab7<span class="tag">&lt;/<span class="name">color</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">color</span> <span class="attr">name</span>=<span class="string">"materialColorIndigo"</span>&gt;</span>#3f51b5<span class="tag">&lt;/<span class="name">color</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">color</span> <span class="attr">name</span>=<span class="string">"materialColorBlue"</span>&gt;</span>#2196f3<span class="tag">&lt;/<span class="name">color</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">color</span> <span class="attr">name</span>=<span class="string">"materialColorLightBlue"</span>&gt;</span>#03a9f4<span class="tag">&lt;/<span class="name">color</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">color</span> <span class="attr">name</span>=<span class="string">"materialColorCyan"</span>&gt;</span>#00bcd4<span class="tag">&lt;/<span class="name">color</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">color</span> <span class="attr">name</span>=<span class="string">"materialColorTeal"</span>&gt;</span>#009688<span class="tag">&lt;/<span class="name">color</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">color</span> <span class="attr">name</span>=<span class="string">"materialColorGreen"</span>&gt;</span>#4caf50<span class="tag">&lt;/<span class="name">color</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">color</span> <span class="attr">name</span>=<span class="string">"materialColorLightGreen"</span>&gt;</span>#8bc34a<span class="tag">&lt;/<span class="name">color</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">color</span> <span class="attr">name</span>=<span class="string">"materialColorLime"</span>&gt;</span>#cddc39<span class="tag">&lt;/<span class="name">color</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">color</span> <span class="attr">name</span>=<span class="string">"materialColorYellow"</span>&gt;</span>#FFeb3b<span class="tag">&lt;/<span class="name">color</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">color</span> <span class="attr">name</span>=<span class="string">"materialColorAmber"</span>&gt;</span>#FFc107<span class="tag">&lt;/<span class="name">color</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">color</span> <span class="attr">name</span>=<span class="string">"materialColorOrange"</span>&gt;</span>#FF9800<span class="tag">&lt;/<span class="name">color</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">color</span> <span class="attr">name</span>=<span class="string">"materialColorDeepOrange"</span>&gt;</span>#FF5722<span class="tag">&lt;/<span class="name">color</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">color</span> <span class="attr">name</span>=<span class="string">"materialColorBrown"</span>&gt;</span>#795548<span class="tag">&lt;/<span class="name">color</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">color</span> <span class="attr">name</span>=<span class="string">"materialColorGrey"</span>&gt;</span>#9e9e9e<span class="tag">&lt;/<span class="name">color</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">color</span> <span class="attr">name</span>=<span class="string">"materialColorBlueGrey"</span>&gt;</span>#607d8b<span class="tag">&lt;/<span class="name">color</span>&gt;</span></span><br><span class="line">   <span class="comment">&lt;!--Text Colors--&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">color</span> <span class="attr">name</span>=<span class="string">"primaryText"</span>&gt;</span>#212121<span class="tag">&lt;/<span class="name">color</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">color</span> <span class="attr">name</span>=<span class="string">"secondaryText"</span>&gt;</span>#757575<span class="tag">&lt;/<span class="name">color</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">color</span> <span class="attr">name</span>=<span class="string">"dividerColor"</span>&gt;</span>#bdbdbd<span class="tag">&lt;/<span class="name">color</span>&gt;</span></span><br></pre></td></tr></table></figure></p><h2 id="色彩的巧妙搭配"><a href="#色彩的巧妙搭配" class="headerlink" title="色彩的巧妙搭配"></a>色彩的巧妙搭配</h2><p><div align = center><img src = "https://img.vim-cn.com/21/b362eb8232618c5eb6692fef2cb5f1cf24aa63.png"></div><br><br></p><p><strong>几个色彩网站推荐</strong></p><p>拼色网站1： <a href="https://colordrop.io/" target="_blank" rel="noopener">https://colordrop.io/</a><br>拼色网站2：<a href="http://www.peise.net/tools/web/#" target="_blank" rel="noopener">http://www.peise.net/tools/web/#</a><br>RGB色值对照表 ：<a href="https://tool.oschina.net/commons?type=3" target="_blank" rel="noopener">https://tool.oschina.net/commons?type=3</a></p><p><strong>一个免费图片网站</strong><br><a href="https://unsplash.com/" target="_blank" rel="noopener">https://unsplash.com/</a></p>]]></content>
      
      
      <categories>
          
          <category> 设计 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> color </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>《机器学习实战》《西瓜书》笔记（二）- 模型评估与选择</title>
      <link href="/2019/11/26/Machine_Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%882%EF%BC%89/"/>
      <url>/2019/11/26/Machine_Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%882%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<h1 id="《机器学习实战》《西瓜书》笔记（二）-模型评估与选择"><a href="#《机器学习实战》《西瓜书》笔记（二）-模型评估与选择" class="headerlink" title="《机器学习实战》《西瓜书》笔记（二）- 模型评估与选择"></a>《机器学习实战》《西瓜书》笔记（二）- 模型评估与选择</h1><h2 id="经验误差与过拟合"><a href="#经验误差与过拟合" class="headerlink" title="经验误差与过拟合"></a>经验误差与过拟合</h2><ul><li><strong>错误率与精度</strong><br>错误率是分类错误的样本数占样本总数的比例，精度是分类正确的样本数占样本总数的比例。</li><li><strong>误差与经验误差</strong><br>学习器的实际预测输出与样本的真实输出之间的差异称为“误差”，学习器在训练集上的误差称为训练误差/经验误差，在新样本上的误差称为“泛化误差”。</li><li><strong>过拟合与欠拟合</strong><br>然而，当学习器把训练样本学得”太 好”了的时候，很可能巳经把训练样本自身的一些特点当作了所有潜在样本都 会具有的一般性质，这样就会导致泛化性能下降，叫做 <strong>过拟合（overfitting)</strong><br>训练样本的一般性质尚未学好叫做 <strong>欠拟合</strong><div align = center><img src= "https://img.vim-cn.com/30/0e0722ac9770db63a1185dd505a770f82ec37a.png"></div></li></ul><h2 id="评估方法"><a href="#评估方法" class="headerlink" title="评估方法"></a>评估方法</h2><p>通常我们使用测试集上样本产生的泛化误差作为评估标准，就是以“测试误差”来代表学习器的“泛化误差”</p><h2 id="划分数据集-D-与测试机-T-的常用方法"><a href="#划分数据集-D-与测试机-T-的常用方法" class="headerlink" title="划分数据集(D)与测试机(T)的常用方法"></a>划分数据集(D)与测试机(T)的常用方法</h2><h3 id="留出法"><a href="#留出法" class="headerlink" title="留出法"></a>留出法</h3><p>“留出法”直接将数据集D划分为两个互斥的集合，其中一个集合作为训练集S，另一个作为训练集T。训练/测试集的划分要尽可能保持数据分布的一致性，例如在分类任务中至少要保持样本的类别比例相似。如果从采样的角度来看待数据集的划分过程，则保留类别比例的采样方式通常称为“分层采样”。<br>单次使用留出法得到的估计结果往往不够稳定可靠，在使用留出法时，一般要采用若干次随机划分，重复进行实验评估后取平均值作为留出法的评估结果。通常将2/3~4/5的样本用于训练，剩余样本用于测试。</p><h3 id="交叉验证法"><a href="#交叉验证法" class="headerlink" title="交叉验证法"></a>交叉验证法</h3><p>先将数据集D划分为k个大小相似的互斥子集，每个子集都尽可能保持数据分布的一致性，即从D中通过分层采样得到，然后，每次用k-1个子集的并集作为训练集，余下的那个子集作为测试集；这样就可获得k组训练/测试集，从而可进行k次训练和测试，最终返回的是这k个测试结果的均值。<br>交叉验证法评估结果的稳定性和保真性在很大程度上取决于k的取值，通常又称为“k折交叉验证”。与留出法相似，将数据集划分为k个子集同样存在多种划分方式，为减少因样本划分不同而引入的差别，k折交叉验证通常要随机使用不同的划分重复p次，最终的评估结果是这p次k折交叉验证结果的均值。<br>假定数据集中包含m个样本，若令k=m，则得到了交叉验证法的一个特例：留一法。</p><div align = center><img src = "https://img.vim-cn.com/a3/a25652e1f7a9e0ef4038c3fbf67f4d31bc04be.png"></div><h3 id="自助法"><a href="#自助法" class="headerlink" title="自助法"></a>自助法</h3><p>为减少训练样本规模不同造成的影响，同时比较高效地进行实验估计。自助法（bootstrapping）以自助采样法为基础。给定包含m个样本的数据集D，我们对它进行采样产生数据集D’：每次随机从D中挑选一个样本，将其拷贝放入D’，然后再将该样本放回初始数据集中，使得该样本在下次采样时仍有可能被采到；这个过程重复执行m次后，我们就得到了包含m个样本的数据集D’。显然，D中有一部分样本在D’中多次出现，而一部分样本不出现。通过自助采样，初始数据集D中约有36.8%的样本未出现在采样数据集D’中。于是将D’用作训练集，D/D’用作测试集。这样的测试结果，亦称“包外估计”。<br>没有留出法，和交叉验证法常用</p><h2 id="调参与最终模型"><a href="#调参与最终模型" class="headerlink" title="调参与最终模型"></a>调参与最终模型</h2><p>大多数学习算法都有些参数(parameter)需要设定，参数配置不同，学得模 型的性能往往有显著差别.因此，在进行模型评估与选择时，除了要对适用学习 算法进行选择，还需对算法参数进行设定，这就是通常所说的”参数调节”或 简称”调参” (parameter tuning).<br>现实中常用的做法?是对每个参数选定一个 范围和变化步长，例如在 [0 ，0.2] 范围内以 0.05 为步长，则实际要评估的候选参 数值有 5 个，最终是从这 5 个候选值中产生选定值.显然，这样选定的参数值往 往不是”最佳”值，但这是在计算开销和性能估计之间进行折中的结果，通过 这个折中，学习过程才变得可行.事实上，即便在进行这样的折中后，调参往往 仍很困难.可以简单估算一下:假定算法有 3 个参数，每个参数仅考虑 5 个候选 值，这样对每一组训练/测试集就有 53 = 125 个模型需考察<br>另外，需注意的是，我们通常把学得模型在实际使用中遇到的数据称为测 试数据，为了加以区分，模型评估与选择中用于评估测试的数据集常称为”验 证集” (validation set). 例如，在研究对比不同算法的泛化性能时，我们用测试 集上的判别效果来估计模型在实际使用时的泛化能力，而把训练数据另外划分 为训练集和验证集，基于验证集上的性能来进行模型选择和调参.</p><h2 id="性能度量"><a href="#性能度量" class="headerlink" title="性能度量"></a>性能度量</h2><p>对学习器的泛化性能进行评估，不仅需要有效可行的实验估计方法，还需 要有衡量模型泛化能力的评价标准，这就是性能度量(performance measure).</p><h3 id="错误率与精度"><a href="#错误率与精度" class="headerlink" title="错误率与精度"></a>错误率与精度</h3><p>错误率是分类错误的样本数占样本总数的比例，精度是分类正确的样本数占样本总数的比例。</p><h3 id="查准率、查全率、F1"><a href="#查准率、查全率、F1" class="headerlink" title="查准率、查全率、F1"></a>查准率、查全率、F1</h3><p>对于二分类问题，可将样例根据其真实类别与学习器预测类别的组合划分为真正例(true positive)、假正例(false positive)、真反倒(true negative) 、 假反例(false negative)四种情形，令 TP、 FP、 TN、 FN 分别表示其对应的 样例数，则显然有 TP+FP+TN+FN=样例总数.分类结果的”泪淆矩 阵” (co时usion matrix),如下表所示</p><div align = center><img src = "https://img.vim-cn.com/42/14fe59f1eb909caaeb22588f2f4594c29c6682.png"></div>准率和查全率是一对矛盾的度量。查准率-查全率曲线，简称“P-R曲线”。在进行比较时，若一个学习器的P-R曲线被另一个学习器的曲线完全“包住”，则可断言后者的性能优于前者。如果两个学习器的P-R曲线交叉，难以一般性断言两者孰优孰劣。比较合理的判据是比较P-R曲线下面积的大小。为综合考虑查准率、查全率的性能度量，“平衡点”即“查准率=查全率”时的取值，更常用的是F1度量。当对查准率和查全率的重视程度有所不同，F1度量的一般形式Fβ.　β>0度量了查全率对查准率的相对重要性。β=1时退化为标准的F1，β>1时查全率有更大影响，β<1,查准率有更大影响。对于有多个二分类混淆矩阵，可以在各混淆矩阵上分别计算查准率和查全率，再计算平均值，这样就得到“宏查准率”、“宏查全率”以及“宏F1”；还可将各混淆矩阵的对应元素进行平均，得到TP、FP、TN、 FN的平均值，再基于这些平均值计算出“微查准率”、“微查全率”和“微F1”。<div align = center><img src = "https://img.vim-cn.com/4e/de127ae4820dca223d54d1e8cf1fb9eab42d37.png"></div><h3 id="ROC-与-RUC"><a href="#ROC-与-RUC" class="headerlink" title="ROC 与 RUC"></a>ROC 与 RUC</h3><p>很多学习器是为测试样本产生一个实值或概率预测，然后将这个预测值与 神经网络参几第 5 章<br>一个分类阔值(threshold)进行比较，若大于|词值则分为正类，否则为反类.例 如，神经网络在一般情形下是对每个测试样本预测出一个 [0.0 ，1.0] 之间的实值， 然后将这个值与 0.5 进行比较，大于 0.5 则判为正例，否则为反例.这个实值或 概率预测结果的好坏，直接决定了学习器的泛化能力.实际上?根据这个实值或 概率预测结果，我们可将测试样本进行排序，”最可能”是正例的排在最前面， “最不可能”是正例的排在最后面.这样，分类过程就相当于在这个排序中以 某个”截断点” (cut point)将样本分为两部分，前一部分判作正例，后一部分则 判作反例.<br>我们根据学习器的预 测结果对样例进行排序，按此顺序逐个把样本作为正例进行预测，每次计算 出两个重要量的值，分别以它们为横、纵坐标作图’就得到了 “ROC 曲线 与 P卫-R 曲线使用查准率、查全率为纵、横轴不同， ROC 曲线的纵轴是”真正 例率” (True Positive Rate，简称 TPR)，横轴是”假正例率” (False Positive Rate，简称 FPR)，基于表 2.1 中的符号，两者分别定义为,<br>$TPR= \frac{TP} {TP+FN}$<br>$FPR= \frac{FP} {TN+FP}$</p><p>进行学习器的比较时， 与 P-R 图相似， 若一个学习器的 ROC 曲线被另一<br>个学习器的曲线完全”包住”， 则可断言后者的性能优于前者;若两个学习器 的 ROC 曲线发生交叉，则难以-般性地断言两者孰优孰劣. 此时如果一定要进 行比较， 则较为合理的判据是比较 ROC 曲线下的面积，即 AUC (Area Under ROC Curve)</p><h3 id="代价敏感错误率与代价曲线"><a href="#代价敏感错误率与代价曲线" class="headerlink" title="代价敏感错误率与代价曲线"></a>代价敏感错误率与代价曲线</h3><div align = center><img src = "https://img.vim-cn.com/a7/92725fd772dbf66d9a108906ca5154fa42081a.png"></div><div align = center><img src = "https://img.vim-cn.com/1b/655c2c88f7541eaef782c9fc1b2611c6174fc8.png"></div><div align = center><img src = "https://img.vim-cn.com/08/4616ba375fc1fdf425257fe78da623dd23ce4d.png"></div><h3 id="比较检验"><a href="#比较检验" class="headerlink" title="比较检验"></a>比较检验</h3><p>有了实验评估方法和性能度量，看起来就能对学习器的性能进行评估比较 了:先使用某种实验评估方法测得学习器的某个性能度量结果，然后对这些结 果进行比较.但怎么来做这个”比较”呢?是直接取得性能度量的值然后”比 大小”吗?实际上，机器学习中性能比较这件事要比大家想象的复杂得多.这 里面涉及几个重要因素:首先，我们希望比较的是泛化性能，然而通过实验评估 方法我们获得的是测试集上的性能，两者的对比结果可能未必相同;第二，测试 集上的性能与测试集本身的选择有很大关系，且不论使用不同大小的测试集会 得到不同的结果，即使用相同大小的测试集?若包含的测试样例不同，测试结果 也会有不同;第二，很多机器学习算法本身有一定的随机性，即便用相同的参数 设置在同一个测试集上多次运行，其结果也会有不同.那么，有没有适当的方法 对学习器的性能进行比较呢? 统计假设检验(hypothesis test)为我们进行学习器t性能比较提供了重要依 据.基于假设检验结果我们可推断出，若在测试集上观察到学习器 A 比 B 好， 则 A 的泛化性能是否在统计意义上优于 B，以及这个结论的把握有多大.下面 我们先介绍两种最基本的假设检验，然后介绍几种常用的机器学习性能比较方 法.为便于讨论，本节默认以错误率为性能度量，用 E 表示.</p><h3 id="偏差与方差"><a href="#偏差与方差" class="headerlink" title="偏差与方差"></a>偏差与方差</h3><p>偏差方差分解试图对学习算法的期望泛化错误率进行拆解.我们知道，算 法在不同训练集上学得的结果很可能不同，即便这些训练集是来自同一个分布. 对测试样本队令 YD 为 m 在数据集中的标记， y 为 2 的真实标记， f(x; D) 为训 练集 D 上学得模型 f 在 m 上的预测输出.<br><strong>期望输出与真实标记的差别称为偏差(bias)</strong></p><div align = center><img src = "https://img.vim-cn.com/11/682d2fceff5b7f82736f9d08f3646f50cc1fe3.png"></div><p><strong>泛化误差为偏差与噪声值与方差之和</strong></p><div align = center><img src = "https://img.vim-cn.com/5e/aa3982956888fcbd37ef36f06d6cde0e0c4b36.png"></div>]]></content>
      
      
      <categories>
          
          <category> Machine_Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ML </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>《机器学习实战》《西瓜书》笔记（三）- KNN</title>
      <link href="/2019/11/26/Machine_Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%883-KNN)/"/>
      <url>/2019/11/26/Machine_Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%883-KNN)/</url>
      
        <content type="html"><![CDATA[<h1 id="《机器学习实战》《西瓜书》笔记（三）-KNN"><a href="#《机器学习实战》《西瓜书》笔记（三）-KNN" class="headerlink" title="《机器学习实战》《西瓜书》笔记（三）- KNN"></a>《机器学习实战》《西瓜书》笔记（三）- KNN</h1><h2 id="KNN原理"><a href="#KNN原理" class="headerlink" title="KNN原理"></a>KNN原理</h2><ol><li>输入带有标签的训练集</li><li>输入没有标签的新数据</li><li>算法将输入数据的特征与训练集的数据的特征进行比较</li><li>求新数据与样本集中数据的距离</li><li>算法提取样本集中最相似数据（最近邻）的分类标签，只选择前K个最相似的数据</li><li>选取k个相似数据频率最多的分类属性作为新数据的分类属性</li></ol><h2 id="KNN伪代码"><a href="#KNN伪代码" class="headerlink" title="KNN伪代码"></a>KNN伪代码</h2><ol><li>计算已知类别数据集中点与当前点的距离</li><li>按照距离从小到大递增排序</li><li>选取与当前点距离最小的k个点</li><li>确定前k个点所在类别出现的频率</li><li>返回前k个点出现频率最高的类别作为当前点的预测分类</li></ol><h2 id="KNN源代码"><a href="#KNN源代码" class="headerlink" title="KNN源代码"></a>KNN源代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">classify0</span><span class="params">(inX, dataSet, labels, k)</span>:</span></span><br><span class="line">    <span class="comment"># numpy函数shape[0]返回dataSet的行数</span></span><br><span class="line">    dataSetSize = dataSet.shape[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># 将inX重复dataSetSize次并排成一列</span></span><br><span class="line">    diffMat = np.tile(inX, (dataSetSize, <span class="number">1</span>)) - dataSet</span><br><span class="line">    <span class="comment"># 二维特征相减后平方（用diffMat的转置乘diffMat）</span></span><br><span class="line">    sqDiffMat = diffMat**<span class="number">2</span></span><br><span class="line">    <span class="comment"># sum()所有元素相加，sum(0)列相加，sum(1)行相加</span></span><br><span class="line">    sqDistances = sqDiffMat.sum(axis=<span class="number">1</span>)</span><br><span class="line">    <span class="comment"># 开方，计算出距离</span></span><br><span class="line">    distances = sqDistances**<span class="number">0.5</span></span><br><span class="line">    <span class="comment"># argsort函数返回的是distances值从小到大的--索引值</span></span><br><span class="line">    sortedDistIndicies = distances.argsort()</span><br><span class="line">    <span class="comment"># 定义一个记录类别次数的字典</span></span><br><span class="line">    classCount = &#123;&#125;</span><br><span class="line">    <span class="comment"># 选择距离最小的k个点</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(k):</span><br><span class="line">        <span class="comment"># 取出前k个元素的类别</span></span><br><span class="line">        voteIlabel = labels[sortedDistIndicies[i]]</span><br><span class="line">        <span class="comment"># 字典的get()方法，返回指定键的值，如果值不在字典中返回0</span></span><br><span class="line">        <span class="comment"># 计算类别次数</span></span><br><span class="line">        classCount[voteIlabel] = classCount.get(voteIlabel, <span class="number">0</span>) + <span class="number">1</span></span><br><span class="line">    <span class="comment"># python3中用items()替换python2中的iteritems()</span></span><br><span class="line">    <span class="comment"># key = operator.itemgetter(1)根据字典的值进行排序</span></span><br><span class="line">    <span class="comment"># key = operator.itemgetter(0)根据字典的键进行排序</span></span><br><span class="line">    <span class="comment"># reverse降序排序字典</span></span><br><span class="line">    sortedClassCount = sorted(classCount.items(),\</span><br><span class="line">                              key = operator.itemgetter(<span class="number">1</span>), reverse = <span class="literal">True</span>)</span><br><span class="line">    <span class="comment"># 返回次数最多的类别，即所要分类的类别</span></span><br><span class="line">    <span class="keyword">return</span> sortedClassCount[<span class="number">0</span>][<span class="number">0</span>]</span><br></pre></td></tr></table></figure><p><strong>越预测数据所在的分类</strong><br>在终端中的交互解释器执行：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt; classify([<span class="number">1.0</span>, <span class="number">1.0</span>], group, lables, <span class="number">5</span>)</span><br></pre></td></tr></table></figure><p>即可测试得到一个结果</p><h2 id="简单的一个示例"><a href="#简单的一个示例" class="headerlink" title="简单的一个示例"></a>简单的一个示例</h2><h3 id="数据的准备"><a href="#数据的准备" class="headerlink" title="数据的准备"></a>数据的准备</h3><p>在KNN的模块中添加一个实现数据样本的函数，代码如下所示：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> operator</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">creatDataSet</span><span class="params">()</span>:</span></span><br><span class="line">    group = np.array([<span class="number">1</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">1.1</span>], [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0.1</span>])</span><br><span class="line">    labels = [<span class="string">'A'</span>, <span class="string">'A'</span>, <span class="string">'B'</span>, <span class="string">'B'</span>]</span><br><span class="line">    <span class="keyword">return</span> group, labels</span><br></pre></td></tr></table></figure><p>在交互解释器中执行:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt; <span class="keyword">import</span> KNN</span><br><span class="line">&gt;&gt; group, lables = KNN.creatDataSet()</span><br><span class="line">&gt;&gt; KNN.classify0([<span class="number">0</span>,<span class="number">0</span>], group, labels, <span class="number">3</span>)</span><br><span class="line">&gt;&gt; B</span><br></pre></td></tr></table></figure><p>可生成一个初步应用于KNN的4维2列的数据集</p><h2 id="如何测试分类器"><a href="#如何测试分类器" class="headerlink" title="如何测试分类器"></a>如何测试分类器</h2><p>使用分类器的错误率，即分类器给出的错误结果除以测试执行的综述来判断分类器的好坏</p><h2 id="示例1-KNN进行约会匹配"><a href="#示例1-KNN进行约会匹配" class="headerlink" title="示例1 KNN进行约会匹配"></a>示例1 KNN进行约会匹配</h2><h3 id="执行流程"><a href="#执行流程" class="headerlink" title="执行流程"></a>执行流程</h3><ol><li>收集数据 ： 导入文本文件</li><li>准备数据: 使用python解析</li><li>分析数据： matplotlib绘图</li><li>训练算法：k-近邻不适用</li><li>测试算法</li><li>使用算法<h3 id="准备数据"><a href="#准备数据" class="headerlink" title="准备数据"></a>准备数据</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：打开解析文件，对数据进行分类，1代表不喜欢，2代表魅力一般，3代表极具魅力</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    filename - 文件名</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    returnMat - 特征矩阵</span></span><br><span class="line"><span class="string">    classLabelVector - 分类label向量</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">file2matrix</span><span class="params">(filename)</span>:</span></span><br><span class="line">    <span class="comment"># 打开文件</span></span><br><span class="line">    fr = open(filename)</span><br><span class="line">    <span class="comment"># 读取文件所有内容</span></span><br><span class="line">    arrayOlines = fr.readlines()</span><br><span class="line">    <span class="comment"># 得到文件行数</span></span><br><span class="line">    numberOfLines = len(arrayOlines)</span><br><span class="line">    <span class="comment"># 返回的NumPy矩阵numberOfLines行，3列</span></span><br><span class="line">    returnMat = np.zeros((numberOfLines, <span class="number">3</span>))</span><br><span class="line">    <span class="comment"># 创建分类标签向量</span></span><br><span class="line">    classLabelVector = []</span><br><span class="line">    <span class="comment"># 行的索引值</span></span><br><span class="line">    index = <span class="number">0</span></span><br><span class="line">    <span class="comment"># 读取每一行</span></span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> arrayOlines:</span><br><span class="line">        <span class="comment"># 去掉每一行首尾的空白符，例如'\n','\r','\t',' '</span></span><br><span class="line">        line = line.strip()</span><br><span class="line">        <span class="comment"># 将每一行内容根据'\t'符进行切片,本例中一共有4列</span></span><br><span class="line">        listFromLine = line.split(<span class="string">'\t'</span>)</span><br><span class="line">        <span class="comment"># 将数据的前3列进行提取保存在returnMat矩阵中，也就是特征矩阵</span></span><br><span class="line">        returnMat[index,:] = listFromLine[<span class="number">0</span>:<span class="number">3</span>]</span><br><span class="line">        <span class="comment"># 根据文本内容进行分类1：不喜欢；2：一般；3：喜欢</span></span><br><span class="line">        <span class="keyword">if</span> listFromLine[<span class="number">-1</span>] == <span class="string">'didntLike'</span>:</span><br><span class="line">            classLabelVector.append(<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">elif</span> listFromLine[<span class="number">-1</span>] == <span class="string">'smallDoses'</span>:</span><br><span class="line">            classLabelVector.append(<span class="number">2</span>)</span><br><span class="line">        <span class="keyword">elif</span> listFromLine[<span class="number">-1</span>] == <span class="string">'largeDoses'</span>:</span><br><span class="line">            classLabelVector.append(<span class="number">3</span>)</span><br><span class="line">        index += <span class="number">1</span></span><br><span class="line">    <span class="comment"># 返回标签列向量以及特征矩阵</span></span><br><span class="line">    <span class="keyword">return</span> returnMat, classLabelVector</span><br></pre></td></tr></table></figure></li></ol><h3 id="分析数据，使用matplotlib进行画图"><a href="#分析数据，使用matplotlib进行画图" class="headerlink" title="分析数据，使用matplotlib进行画图"></a>分析数据，使用matplotlib进行画图</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：可视化数据</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    datingDataMat - 特征矩阵</span></span><br><span class="line"><span class="string">    datingLabels - 分类Label</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    None</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Modify:</span></span><br><span class="line"><span class="string">    2018-07-13</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">showdatas</span><span class="params">(datingDataMat, datingLabels)</span>:</span></span><br><span class="line">    <span class="comment"># 设置汉字格式为14号简体字</span></span><br><span class="line">    font = FontProperties(fname=<span class="string">r"C:\Windows\Fonts\simsun.ttc"</span>, size=<span class="number">14</span>)</span><br><span class="line">    <span class="comment"># 将fig画布分隔成1行1列，不共享x轴和y轴，fig画布的大小为（13，8）</span></span><br><span class="line">    <span class="comment"># 当nrows=2，ncols=2时，代表fig画布被分为4个区域，axs[0][0]代表第一行第一个区域</span></span><br><span class="line">    fig, axs = plt.subplots(nrows=<span class="number">2</span>, ncols=<span class="number">2</span>, sharex=<span class="literal">False</span>, sharey=<span class="literal">False</span>, figsize=(<span class="number">13</span>, <span class="number">8</span>))</span><br><span class="line">    <span class="comment"># 获取datingLabels的行数作为label的个数</span></span><br><span class="line">    <span class="comment"># numberOfLabels = len(datingLabels)</span></span><br><span class="line">    <span class="comment"># label的颜色配置矩阵</span></span><br><span class="line">    LabelsColors = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> datingLabels:</span><br><span class="line">        <span class="comment"># didntLike</span></span><br><span class="line">        <span class="keyword">if</span> i == <span class="number">1</span>:</span><br><span class="line">            LabelsColors.append(<span class="string">'black'</span>)</span><br><span class="line">        <span class="comment"># smallDoses</span></span><br><span class="line">        <span class="keyword">if</span> i == <span class="number">2</span>:</span><br><span class="line">            LabelsColors.append(<span class="string">'orange'</span>)</span><br><span class="line">        <span class="comment"># largeDoses</span></span><br><span class="line">        <span class="keyword">if</span> i == <span class="number">3</span>:</span><br><span class="line">            LabelsColors.append(<span class="string">'red'</span>)</span><br><span class="line">    <span class="comment"># 画出散点图，以datingDataMat矩阵第一列为x，第二列为y，散点大小为15, 透明度为0.5</span></span><br><span class="line">    axs[<span class="number">0</span>][<span class="number">0</span>].scatter(x=datingDataMat[:,<span class="number">0</span>], y=datingDataMat[:,<span class="number">1</span>], color=LabelsColors, s=<span class="number">15</span>, alpha=<span class="number">.5</span>)</span><br><span class="line">    <span class="comment"># 设置标题，x轴label， y轴label</span></span><br><span class="line">    axs0_title_text = axs[<span class="number">0</span>][<span class="number">0</span>].set_title(<span class="string">u'每年获得的飞行常客里程数与玩视频游戏所消耗时间占比'</span>, FontProperties=font)</span><br><span class="line">    axs0_xlabel_text = axs[<span class="number">0</span>][<span class="number">0</span>].set_xlabel(<span class="string">u'每年获得的飞行常客里程数'</span>, FontProperties=font)</span><br><span class="line">    axs0_ylabel_text = axs[<span class="number">0</span>][<span class="number">0</span>].set_ylabel(<span class="string">u'玩视频游戏所消耗时间占比'</span>, FontProperties=font)</span><br><span class="line">    plt.setp(axs0_title_text, size=<span class="number">9</span>, weight=<span class="string">'bold'</span>, color=<span class="string">'red'</span>)</span><br><span class="line">    plt.setp(axs0_xlabel_text, size=<span class="number">7</span>, weight=<span class="string">'bold'</span>, color=<span class="string">'black'</span>)</span><br><span class="line">    plt.setp(axs0_ylabel_text, size=<span class="number">7</span>, weight=<span class="string">'bold'</span>, color=<span class="string">'black'</span>)</span><br><span class="line">    <span class="comment"># 画出散点图，以datingDataMat矩阵第一列为x，第三列为y，散点大小为15, 透明度为0.5</span></span><br><span class="line">    axs[<span class="number">0</span>][<span class="number">1</span>].scatter(x=datingDataMat[:,<span class="number">0</span>], y=datingDataMat[:,<span class="number">2</span>], color=LabelsColors, s=<span class="number">15</span>, alpha=<span class="number">.5</span>)</span><br><span class="line">    <span class="comment"># 设置标题，x轴label， y轴label</span></span><br><span class="line">    axs1_title_text = axs[<span class="number">0</span>][<span class="number">1</span>].set_title(<span class="string">u'每年获得的飞行常客里程数与每周消费的冰淇淋公升数'</span>, FontProperties=font)</span><br><span class="line">    axs1_xlabel_text = axs[<span class="number">0</span>][<span class="number">1</span>].set_xlabel(<span class="string">u'每年获得的飞行常客里程数'</span>, FontProperties=font)</span><br><span class="line">    axs1_ylabel_text = axs[<span class="number">0</span>][<span class="number">1</span>].set_ylabel(<span class="string">u'每周消费的冰淇淋公升数'</span>, FontProperties=font)</span><br><span class="line">    plt.setp(axs1_title_text, size=<span class="number">9</span>, weight=<span class="string">'bold'</span>, color=<span class="string">'red'</span>)</span><br><span class="line">    plt.setp(axs1_xlabel_text, size=<span class="number">7</span>, weight=<span class="string">'bold'</span>, color=<span class="string">'black'</span>)</span><br><span class="line">    plt.setp(axs1_ylabel_text, size=<span class="number">7</span>, weight=<span class="string">'bold'</span>, color=<span class="string">'black'</span>)</span><br><span class="line">    <span class="comment"># 画出散点图，以datingDataMat矩阵第二列为x，第三列为y，散点大小为15, 透明度为0.5</span></span><br><span class="line">    axs[<span class="number">1</span>][<span class="number">0</span>].scatter(x=datingDataMat[:,<span class="number">1</span>], y=datingDataMat[:,<span class="number">2</span>], color=LabelsColors, s=<span class="number">15</span>, alpha=<span class="number">.5</span>)</span><br><span class="line">    <span class="comment"># 设置标题，x轴label， y轴label</span></span><br><span class="line">    axs2_title_text = axs[<span class="number">1</span>][<span class="number">0</span>].set_title(<span class="string">u'玩视频游戏所消耗时间占比与每周消费的冰淇淋公升数'</span>, FontProperties=font)</span><br><span class="line">    axs2_xlabel_text = axs[<span class="number">1</span>][<span class="number">0</span>].set_xlabel(<span class="string">u'玩视频游戏所消耗时间占比'</span>, FontProperties=font)</span><br><span class="line">    axs2_ylabel_text = axs[<span class="number">1</span>][<span class="number">0</span>].set_ylabel(<span class="string">u'每周消费的冰淇淋公升数'</span>, FontProperties=font)</span><br><span class="line">    plt.setp(axs2_title_text, size=<span class="number">9</span>, weight=<span class="string">'bold'</span>, color=<span class="string">'red'</span>)</span><br><span class="line">    plt.setp(axs2_xlabel_text, size=<span class="number">7</span>, weight=<span class="string">'bold'</span>, color=<span class="string">'black'</span>)</span><br><span class="line">    plt.setp(axs2_ylabel_text, size=<span class="number">7</span>, weight=<span class="string">'bold'</span>, color=<span class="string">'black'</span>)</span><br><span class="line">    <span class="comment"># 设置图例</span></span><br><span class="line">    didntLike = mlines.Line2D([], [], color=<span class="string">'black'</span>, marker=<span class="string">'.'</span>, markersize=<span class="number">6</span>, label=<span class="string">'didntLike'</span>)</span><br><span class="line">    smallDoses = mlines.Line2D([], [], color=<span class="string">'orange'</span>, marker=<span class="string">'.'</span>, markersize=<span class="number">6</span>, label=<span class="string">'smallDoses'</span>)</span><br><span class="line">    largeDoses = mlines.Line2D([], [], color=<span class="string">'red'</span>, marker=<span class="string">'.'</span>, markersize=<span class="number">6</span>, label=<span class="string">'largeDoses'</span>)</span><br><span class="line">    <span class="comment"># 添加图例</span></span><br><span class="line">    axs[<span class="number">0</span>][<span class="number">0</span>].legend(handles=[didntLike, smallDoses, largeDoses])</span><br><span class="line">    axs[<span class="number">0</span>][<span class="number">1</span>].legend(handles=[didntLike, smallDoses, largeDoses])</span><br><span class="line">    axs[<span class="number">1</span>][<span class="number">0</span>].legend(handles=[didntLike, smallDoses, largeDoses])</span><br><span class="line">    <span class="comment"># 显示图片</span></span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure><h3 id="准备数据，归一化"><a href="#准备数据，归一化" class="headerlink" title="准备数据，归一化"></a>准备数据，归一化</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：对数据进行归一化</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    dataSet - 特征矩阵</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    normDataSet - 归一化后的特征矩阵</span></span><br><span class="line"><span class="string">    ranges - 数据范围</span></span><br><span class="line"><span class="string">    minVals - 数据最小值</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Modify:</span></span><br><span class="line"><span class="string">    2018-07-13</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">autoNorm</span><span class="params">(dataSet)</span>:</span></span><br><span class="line">    <span class="comment"># 获取数据的最小值</span></span><br><span class="line">    minVals = dataSet.min(<span class="number">0</span>)</span><br><span class="line">    <span class="comment"># 获取数据的最大值</span></span><br><span class="line">    maxVals = dataSet.max(<span class="number">0</span>)</span><br><span class="line">    <span class="comment"># 最大值和最小值的范围</span></span><br><span class="line">    ranges = maxVals - minVals</span><br><span class="line">    <span class="comment"># shape(dataSet)返回dataSet的矩阵行列数</span></span><br><span class="line">    normDataSet = np.zeros(np.shape(dataSet))</span><br><span class="line">    <span class="comment"># numpy函数shape[0]返回dataSet的行数</span></span><br><span class="line">    m = dataSet.shape[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># 原始值减去最小值（x-xmin）</span></span><br><span class="line">    normDataSet = dataSet - np.tile(minVals, (m, <span class="number">1</span>))</span><br><span class="line">    <span class="comment"># 差值处以最大值和最小值的差值（x-xmin）/（xmax-xmin）</span></span><br><span class="line">    normDataSet = normDataSet / np.tile(ranges, (m, <span class="number">1</span>))</span><br><span class="line">    <span class="comment"># 归一化数据结果，数据范围，最小值</span></span><br><span class="line">    <span class="keyword">return</span> normDataSet, ranges, minVals</span><br></pre></td></tr></table></figure><h3 id="测试算法，作为完整程序验证分类器"><a href="#测试算法，作为完整程序验证分类器" class="headerlink" title="测试算法，作为完整程序验证分类器"></a>测试算法，作为完整程序验证分类器</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：分类器测试函数</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    None</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    normDataSet - 归一化后的特征矩阵</span></span><br><span class="line"><span class="string">    ranges - 数据范围</span></span><br><span class="line"><span class="string">    minVals - 数据最小值</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Modify:</span></span><br><span class="line"><span class="string">    2018-07-13</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">datingClassTest</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="comment"># 打开文件名</span></span><br><span class="line">    filename = <span class="string">"datingTestSet.txt"</span></span><br><span class="line">    <span class="comment"># 将返回的特征矩阵和分类向量分别存储到datingDataMat和datingLabels中</span></span><br><span class="line">    datingDataMat, datingLabels = file2matrix(filename)</span><br><span class="line">    <span class="comment"># 取所有数据的10% hoRatio越小，错误率越低</span></span><br><span class="line">    hoRatio = <span class="number">0.10</span></span><br><span class="line">    <span class="comment"># 数据归一化，返回归一化数据结果，数据范围，最小值</span></span><br><span class="line">    normMat, ranges, minVals = autoNorm(datingDataMat)</span><br><span class="line">    <span class="comment"># 获取normMat的行数</span></span><br><span class="line">    m = normMat.shape[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># 10%的测试数据的个数</span></span><br><span class="line">    numTestVecs = int(m * hoRatio)</span><br><span class="line">    <span class="comment"># 分类错误计数</span></span><br><span class="line">    errorCount = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(numTestVecs):</span><br><span class="line">        <span class="comment"># 前numTestVecs个数据作为测试集，后m-numTestVecs个数据作为训练集</span></span><br><span class="line">        <span class="comment"># k选择label数+1（结果比较好）</span></span><br><span class="line">        classifierResult = classify0(normMat[i,:], normMat[numTestVecs:m,:],\</span><br><span class="line">                                     datingLabels[numTestVecs:m], <span class="number">4</span>)</span><br><span class="line">        print(<span class="string">"分类结果:%d\t真实类别:%d"</span> % (classifierResult, datingLabels[i]))</span><br><span class="line">        <span class="keyword">if</span> classifierResult != datingLabels[i]:</span><br><span class="line">            errorCount += <span class="number">1.0</span></span><br><span class="line">    print(<span class="string">"错误率:%f%%"</span> % (errorCount/float(numTestVecs)*<span class="number">100</span>))</span><br></pre></td></tr></table></figure><h3 id="使用算法"><a href="#使用算法" class="headerlink" title="使用算法"></a>使用算法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">函数说明：通过输入一个人的三围特征，进行分类输出</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    None</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    None</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">Modify:</span></span><br><span class="line"><span class="string">    2018-07-14</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">classifyPerson</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="comment"># 输出结果</span></span><br><span class="line">    resultList = [<span class="string">'讨厌'</span>, <span class="string">'有些喜欢'</span>, <span class="string">'非常喜欢'</span>]</span><br><span class="line">    <span class="comment"># 三维特征用户输入</span></span><br><span class="line">    percentTats = float(input(<span class="string">"玩视频游戏所消耗时间百分比："</span>))</span><br><span class="line">    ffMiles = float(input(<span class="string">"每年获得的飞行常客里程数："</span>))</span><br><span class="line">    iceCream = float(input(<span class="string">"每周消费的冰淇淋公升数："</span>))</span><br><span class="line">    <span class="comment"># 打开的文件名</span></span><br><span class="line">    filename = <span class="string">"datingTestSet.txt"</span></span><br><span class="line">    <span class="comment"># 打开并处理数据</span></span><br><span class="line">    datingDataMat, datingLabels = file2matrix(filename)</span><br><span class="line">    <span class="comment"># 训练集归一化</span></span><br><span class="line">    normMat, ranges, minVals = autoNorm(datingDataMat)</span><br><span class="line">    <span class="comment"># 生成NumPy数组，测试集</span></span><br><span class="line">    inArr = np.array([percentTats, ffMiles, iceCream])</span><br><span class="line">    <span class="comment"># 测试集归一化</span></span><br><span class="line">    norminArr = (inArr - minVals) / ranges</span><br><span class="line">    <span class="comment"># 返回分类结果</span></span><br><span class="line">    classifierResult = classify0(norminArr, normMat, datingLabels, <span class="number">4</span>)</span><br><span class="line">    <span class="comment"># 打印结果</span></span><br><span class="line">    print(<span class="string">"你可能%s这个人"</span> % (resultList[classifierResult - <span class="number">1</span>]))</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Machine_Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ML </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>《机器学习实战》《西瓜书》笔记（一）</title>
      <link href="/2019/11/26/Machine_Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(1)/"/>
      <url>/2019/11/26/Machine_Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(1)/</url>
      
        <content type="html"><![CDATA[<h1 id="《机器学习实战》《西瓜书》笔记（一）"><a href="#《机器学习实战》《西瓜书》笔记（一）" class="headerlink" title="《机器学习实战》《西瓜书》笔记（一）"></a>《机器学习实战》《西瓜书》笔记（一）</h1><h2 id="机器学习的相关概念"><a href="#机器学习的相关概念" class="headerlink" title="机器学习的相关概念"></a>机器学习的相关概念</h2><p>我们要做的其实是让机器他有自己学习的能力，也就我们要做的应该<code>machine learning</code>的方向。讲的比较拟人化一点，所谓<code>machine learning</code>的方向，就是你就写段程序，然后让机器人变得了很聪明，他就能够有学习的能力。接下来，你就像教一个婴儿、教一个小孩一样的教他，你并不是写程序让他做到这件事，你是写程序让它具有学习的能力。然后接下来，你就可以用像教小孩的方式告诉它。假设你要叫他学会做语音辨识，你就告诉它这段声音是<code>“Hi”</code>，这段声音就是<code>“How are you”</code>，这段声音是<code>“Good bye”</code>。希望接下来它就学会了，你给它一个新的声音，它就可以帮你产生语音辨识的结果。<br><strong>用数学的语义去理解，机器需要一个函数对输入进行自主判断输出，以完成回归预测、分类、聚类等实际任务</strong></p><ul><li><strong>监督学习</strong><br>从给定的训练数据集中学习出一个函数，当新的数据到来时，可以根据这个函数预测结果。监督学习的训练集要求是包括输入和输出，也可以说是特征和目标。训练集中的目标是由人标注的。常见的监督学习算法包括<strong>回归分析和统计分类</strong>。</li><li><strong>无监督学习</strong><br>与监督学习相比，训练集没有人为标注的结果。常见的无监督学习算法有<strong>生成对抗网络（GAN）、聚类</strong></li><li><strong>半监督学习</strong><br>介于监督学习与无监督学习之间</li><li><strong>增强学习机器</strong><br>为了达成目标，随着环境的变动，而逐步调整其行为，并评估每一个行动之后所到的回馈是正向的或负向的</li></ul><h2 id="开发机器学习应用程序的主要步骤"><a href="#开发机器学习应用程序的主要步骤" class="headerlink" title="开发机器学习应用程序的主要步骤"></a>开发机器学习应用程序的主要步骤</h2><ul><li>收集数据</li><li>准备输入数据（Python语言）</li><li>分析输入数据（数据处理、降维等方法）</li><li>训练算法（无监督学习不需要训练算法）</li><li>测试算法</li><li>执行算法</li></ul><h2 id="机器学习的基本术语"><a href="#机器学习的基本术语" class="headerlink" title="机器学习的基本术语"></a>机器学习的基本术语</h2><p>这组记录的集合称为一个 <strong>“数据集” (data set)</strong><br>其中每条记录是关于一个事件或对象(这里是一个西瓜)的描述，称为一个 <strong>“示例” (instance) 或”样本” (sample)</strong><br>反映事件或对象在某方面的表现或性质的事项，例如”色泽” “根蒂” “敲声”，称为”)副主” (attribute) 或 <strong>“特征”</strong>(feature)属性上的取值，例如”青绿” “乌黑”，称为”)副主值” (attribute va1ue)<br>属性张成的空间称为”属性空间” (attribute space)”样本空间” (samp1e space)或”输入空间”<br>例如我们把”色泽” “根蒂” “敲声”作为三个坐标轴，则它们张成一个用于描述西瓜的三维空间，每个西瓜都可在这个空间中找到自己的坐标位置.由于空间中的每个点对应一个坐标向量，因此我们也把…个示例称为一个 <strong>“特征向量” (feature vector)</strong>.<br><code>eg:</code><br>$D = {x_1,x_2,….x_m} $ 样本包含<code>m</code>个实例<br>$x_i = {x_{i1}…..x_{id}}$ 是<code>d</code>维样本空间的一个向量<br>((色泽:青绿;根蒂二蜷缩; 敲声=浊响)，好瓜)” .这里关于示例结果的信息，例如”好瓜”，称为 <strong>“标记” (labe1)</strong>; 拥有了标记信息的示例，则称为”样例” (examp1e).</p><h2 id="假设空间"><a href="#假设空间" class="headerlink" title="假设空间"></a>假设空间</h2><p>归纳是从特殊到一般的“泛化”过程，演绎是从一般到特殊的“特化”过程。<br>学习的目的是“泛化”，即通过对训练集中瓜的学习已获得对没见过的瓜进行判断的能力。<br>学习过程看作一个在所以假设组成的空间中进行搜索的过程，搜索目标是找到与训练集“匹配”的假设，即能够将训练集中的瓜判断正确的假设。假设的表示一旦确实，假设空间及其规模大小就却确定了。 </p><p>我们用 m 表示这 个假设.这样，若”色泽” “根蒂” “敲声”分别有3、 2、 2 种可能取值，则我 们面临的假设空间规模大小为 4 x 3 x 3 + 1 = 37.</p><h2 id="归纳偏好"><a href="#归纳偏好" class="headerlink" title="归纳偏好"></a>归纳偏好</h2><p>现在有三个与训练集一致的假设，但与他们对应的模型在面临新样本的时候，却会产生不同的输出。根据仅有的训练样本无法判断三个假设中哪个“更好”。对于一个具体的学习算法而言，它必须要产生一个模型，这时，学习算法本身的“偏好”起到关键左右。例如，若算法喜欢“尽可能特殊”的模型，则会有相应的模型产生。机器学习算法在学习过程中对某种类型假设的偏好，称为“归纳偏好”。<br>任何一个有效的机器学习算法必有其归纳偏好，否则产生的模型每次在进行预测时随机抽选训练集上的等效假设，学得模型结果不一，显然没有意义。</p><p>归纳偏好可看作学习算法自身在一个可能很庞大的假设空间中对假设进 行选择的启发式或”价值观”那么，有没有一般性的原则来引导算法确立 “正确的”偏好呢? “奥卡姆剃刀” (Occam’s razor)是一种常用的、自然科学 研究中最基本的原则，即”若有多个假设与观察一致，则选最简单的那个”如 果采用这个原则，并且假设我们认为”更平滑”意味着”更简单” (例如曲线 A 更易于描述，其方程式是 $y = x2+ 6x + 1$ ，而曲线 B 则要复杂得多)，则在 图1.3 中我们会自然地偏好”平滑”的曲线 A.</p><h2 id="生成式模型与判别式模型"><a href="#生成式模型与判别式模型" class="headerlink" title="生成式模型与判别式模型"></a>生成式模型与判别式模型</h2><ul><li><p>产生式模型<br>从统计的角度表示数据的分布情况，能够反映同类数据本身的相似度，不关心判别边界。</p></li><li><p>判别式模型<br>寻找不同类别之间的最优分类面，反映的是异类数据之间的差异。</p></li></ul><p><strong>区别：</strong></p><p>假设有样本输入值（或者观察值）x，类别标签（或者输出值）y</p><p>判别式模型评估对象是最大化条件概率p(y|x)并直接对其建模，</p><p>生成式模型评估对象是最大化联合概率p(x,y)并对其建模。</p><p>其实两者的评估目标都是要得到最终的类别标签Y， 而Y=argmax p(y|x)，不同的是判别式模型直接通过解在满足训练样本分布下的最优化问题得到模型参数，主要用到拉格朗日乘算法、梯度下降法，常见的判别式模型如最大熵模型、CRF、LR、SVM等；</p><p>而生成式模型先经过贝叶斯转换成Y = argmax p(y|x) = argmax p(x|y)*p(y)，然后分别学习p(y)和p(x|y)的概率分布，主要通过极大似然估计的方法学习参数，如NGram、HMM、Naive Bayes。</p><p><strong>优缺点：</strong></p><ul><li>生成模型：</li></ul><p>优点：<br>1）实际上带的信息要比判别模型丰富，研究单类问题比判别模型灵活性强<br>2）模型可以通过增量学习得到<br>3）生成模型能够应付存在隐变量的情况，比如混合高斯模型就是含有隐变量的生成方法。</p><p>缺点：<br>1）学习过程比较复杂。<br>2）实践中多数情况下判别模型效果更好。</p><ul><li>判别模型：</li></ul><p>优点：<br>1）分类边界更灵活，比使用纯概率方法或生产模型得到的更高级.<br>2）准确率往往较生成模型高。<br>3）不需要求解类别条件概率，所以允许我们对输入进行抽象（比如降维、构造等），从而能够简化学习问题。</p><p>缺点：<br>1）不能反映训练数据本身的特性。</p>]]></content>
      
      
      <categories>
          
          <category> Machine_Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ML </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java基础（5）</title>
      <link href="/2019/11/26/java/shyjava(5)/"/>
      <url>/2019/11/26/java/shyjava(5)/</url>
      
        <content type="html"><![CDATA[<h1 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h1><h2 id="方法的定义"><a href="#方法的定义" class="headerlink" title="方法的定义"></a>方法的定义</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">MethodDeclaration:</span><br><span class="line">MethodHeader MethodBody</span><br><span class="line">MethodHeader:</span><br><span class="line"><span class="function">Modifiersopt ResultType <span class="title">Identifier</span><span class="params">(FormalParameterListopt)</span> Throwsopt</span></span><br><span class="line"><span class="function">Modifiers:</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">protected</span> <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">abstract</span> <span class="keyword">final</span></span></span><br><span class="line"><span class="function"><span class="keyword">synchronized</span> <span class="keyword">native</span> <span class="keyword">strictfp</span></span></span><br><span class="line"><span class="function">ResultType:</span></span><br><span class="line"><span class="function">Type</span></span><br><span class="line"><span class="function"><span class="keyword">void</span></span></span><br><span class="line"><span class="function">MethodBody:</span></span><br><span class="line"><span class="function"></span>&#123; statements &#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">max</span><span class="params">(<span class="keyword">int</span> num1, <span class="keyword">int</span> num2)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> result = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">if</span>(num1 &gt; num2)</span><br><span class="line">        result = num1;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        result = num2;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>方法签名(Method Signature)指方法名称、参数类型、参数数量和返回类型。一个类中不能包含签名相同或仅返回类型不同的多个方法。</li><li>方法头中声明的变量称为形参(formal parameter)。当调用方法时，可向形参传递一个值，这个值称为实参(actual parameter / argument)。形参可以使用final进行修饰，表示方法内部不允许修改该参数。</li><li>形参不允许有默认值，最后一个可为变长参数（可用…或数组定义，参见第7章数组）。方法不允许static局部变量。</li><li>方法可以有一个返回值(return value)。如果方法没有返回值，返回值类型为void，但构造函数确实没有返回值。</li></ul><h2 id="方法的调用"><a href="#方法的调用" class="headerlink" title="方法的调用"></a>方法的调用</h2><ul><li>声明方法只给出方法的定义。要执行方法，必须调用(call/invoke)方法。</li><li>如果方法有返回值，通常将方法调用作为一个值来处理（可放在一个表达式里）。<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> large = max(<span class="number">3</span>, <span class="number">4</span>) * <span class="number">2</span>;  </span><br><span class="line">System.out.println(max(<span class="number">3</span>,<span class="number">4</span>));</span><br><span class="line">如果方法没有返回值，方法调用必须是一条语句。</span><br><span class="line">System.out.println(“Welcome to Java!”);</span><br></pre></td></tr></table></figure></li><li>当调用方法时，程序控制权转移至被调用的方法。当执行return语句或到达方法结尾时，程序控制权转移至调用者。</li><li>调用当前类中的静态方法：可直接用“方法名”，也可用”类名.方法名“；实例函数中也可用” 方法名“或”this.方法名“调用。</li><li>调用其它类中的静态方法：必须用”类名.方法名“或”对象.方法名“调用；子类实例函数也可用” super.方法名“调用父类方法。</li><li>所有静态方法提倡用”类名.方法名“调用。如<code>Math.sin(3.0)</code></li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestMax</span> </span>&#123;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line"><span class="keyword">int</span> i = <span class="number">5</span>;</span><br><span class="line"><span class="keyword">int</span> j = <span class="number">2</span>;</span><br><span class="line"><span class="keyword">int</span> k = max(i, j);</span><br><span class="line">System.out.println(<span class="string">"The maximum between "</span> + i + <span class="string">" and "</span> + j + <span class="string">" is "</span> + k);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">max</span><span class="params">(<span class="keyword">int</span> num1, <span class="keyword">int</span> num2)</span> </span>&#123;</span><br><span class="line"><span class="keyword">int</span> result;</span><br><span class="line">result = (num1 &gt; num2) ?num1:num2;</span><br><span class="line"><span class="keyword">return</span> result ;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="调用程序栈"><a href="#调用程序栈" class="headerlink" title="调用程序栈"></a>调用程序栈</h2><p>每当调用一个方法时，系统将参数、局部变量存储在一个内存区域中，这个内存区域称为调用堆栈(call stack)。当方法结束返回到调用者时，系统自动释放相应的调用栈。</p><div align = center><img src = "https://img.vim-cn.com/9c/1276a008ebc0f1d635060c80096666064be1de.png"></div><h2 id="方法的参数传递"><a href="#方法的参数传递" class="headerlink" title="方法的参数传递"></a>方法的参数传递</h2><ul><li><p>如果方法声明中包含形参，调用方法时，必须提供实参。<br>实参的类型必须与形参的类型兼容：如父类形参可用子类实参。<br>实参顺序必须与形参的顺序一致。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">nPrintln</span><span class="params">(String message, <span class="keyword">int</span> n)</span> </span>&#123;  </span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n; i++)</span><br><span class="line">    System.out.println(message);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">nPrintln(“Hello”, <span class="number">3</span>); <span class="comment">//正确</span></span><br><span class="line">nPrintln(<span class="number">3</span>, “Hello”); <span class="comment">//错误</span></span><br></pre></td></tr></table></figure></li><li><p>当调用方法时，基本数据类型的实参值的副本被传递给方法的形参。方法内部对形参的修改不影响实参值。(Call by value)<br>对象类型的参数是引用调用（Call by reference）</p></li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestPassByValue</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line"><span class="keyword">int</span> num1 = <span class="number">1</span>;</span><br><span class="line"><span class="keyword">int</span> num2 = <span class="number">2</span>;</span><br><span class="line">System.out.println(<span class="string">"调用swap方法之前：num1 = "</span> + num1 + <span class="string">"，num2 = "</span> + num2);</span><br><span class="line"></span><br><span class="line">swap(num1, num2);</span><br><span class="line">System.out.println(<span class="string">"调用swap方法之后：num1 = "</span> + num1 + <span class="string">"，num2 = "</span> + num2);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">swap</span><span class="params">(<span class="keyword">int</span> n1, <span class="keyword">int</span> n2)</span> </span>&#123;</span><br><span class="line">System.out.println(<span class="string">"\t在swap方法内："</span>);</span><br><span class="line">System.out.println(<span class="string">"\t\t交换之前：n1 = "</span> + n1 + <span class="string">"，n2 = "</span> + n2);</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> temp = n1;</span><br><span class="line">n1 = n2;</span><br><span class="line">n2 = temp;</span><br><span class="line"></span><br><span class="line">System.out.println(<span class="string">"\t\t交换之后：n1 = "</span> + n1 + <span class="string">"，n2 = "</span> + n2);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="方法的重载"><a href="#方法的重载" class="headerlink" title="方法的重载"></a>方法的重载</h2><ul><li>方法重载(overloading)是指方法名称相同，但方法签名不同的方法，仅返回类型不同的方法不可重载。一个类中可以包含多个重载的方法。</li><li>当调用方法时，Java编译器会根据实参的个数和类型寻找最合适的方法进行调用。</li><li>调用时匹配成功的方法可能多于一个，则会产生编译二义性错误，称为歧义调用(ambiguous invocation）<br><strong>重载示例</strong><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestMethodOverloading</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="comment">/** Return the max between two int values */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">max</span><span class="params">(<span class="keyword">int</span> num1, <span class="keyword">int</span> num2)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestMethodOverloading</span> </span>&#123;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">/** Return the max between two int values */</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">max</span><span class="params">(<span class="keyword">int</span> num1, <span class="keyword">int</span> num2)</span> </span>&#123;</span><br><span class="line">                    <span class="keyword">return</span> (num1 &gt; num2) ？num1:num2; </span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">/** Return the max between two double values */</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">double</span> <span class="title">max</span><span class="params">(<span class="keyword">double</span> num1, <span class="keyword">double</span> num2)</span> </span>&#123;</span><br><span class="line">                    <span class="keyword">return</span> (num1 &gt; num2) ？num1:num2;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment">/** Return the max among three double values */</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">double</span> <span class="title">max</span><span class="params">(<span class="keyword">double</span> num1, <span class="keyword">double</span> num2, <span class="keyword">double</span> num3)</span> </span>&#123;</span><br><span class="line">                    <span class="keyword">return</span> max(max(num1, num2), num3);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestMethodOverloading</span> </span>&#123;</span><br><span class="line"> <span class="comment">/** Main method */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[ ] args)</span> </span>&#123;</span><br><span class="line"><span class="comment">// Invoke the max method with int parameters</span></span><br><span class="line">System.out.println(<span class="string">"The maximum between 3 and 4 is "</span></span><br><span class="line">+ max(<span class="number">3</span>, <span class="number">4</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">// Invoke the max method with the double parameters</span></span><br><span class="line">System.out.println(<span class="string">"The maximum between 3.0 and 5.4 is "</span> </span><br><span class="line">+ max(<span class="number">3.0</span>, <span class="number">5.4</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">// Invoke the max method with three double parameters</span></span><br><span class="line">System.out.println(<span class="string">"The maximum between 3.0, 5.4, and 10.14 is "</span> </span><br><span class="line">+ max(<span class="number">3.0</span>, <span class="number">5.4</span>, <span class="number">10.14</span>));</span><br><span class="line">&#125; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><strong>有歧义的重载</strong><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">AmbiguousOverloading</span> </span>&#123;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[ ] args)</span> </span>&#123;</span><br><span class="line"><span class="comment">//System.out.println(max(1, 2));  //该调用产生歧义</span></span><br><span class="line">        &#125;        <span class="comment">//以下任一函数的参数都相容（都能自动转换），编译无法确定用哪个函数</span></span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">double</span> <span class="title">max</span><span class="params">(<span class="keyword">int</span> num1, <span class="keyword">double</span> num2)</span> </span>&#123;</span><br><span class="line"><span class="keyword">if</span> (num1 &gt; num2)</span><br><span class="line"><span class="keyword">return</span> num1;</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line"><span class="keyword">return</span> num2;</span><br><span class="line">        &#125;</span><br><span class="line">       <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">double</span> <span class="title">max</span><span class="params">(<span class="keyword">double</span> num1, <span class="keyword">int</span> num2)</span> </span>&#123;</span><br><span class="line"><span class="keyword">if</span> (num1 &gt; num2)</span><br><span class="line"><span class="keyword">return</span> num1;</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line"><span class="keyword">return</span> num2;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h2 id="局部变量的作用域"><a href="#局部变量的作用域" class="headerlink" title="局部变量的作用域"></a>局部变量的作用域</h2><p>方法内部声明的变量称为局部变量(local variable)。<br>局部变量的作用域(scope)指程序中可以使用该变量的部分。局部变量的生命期和其作用域相同。<br>局部变量的作用域从它的声明开始，直到包含该变量的程序块结束。局部变量在使用前必须先赋值。<br>在方法中，可以在不同的非嵌套程序块中以相同的名称多次声明局部变量。但不能在嵌套的块中以相同的名称多次声明局部变量：无法访问外部块变量。<br>在for语句的初始动作部分声明的变量，作用域是整个循环。在for语句循环体中声明的变量，作用域从变量声明开始到循环体结束<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestLocalVariable</span> </span>&#123;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">method1</span><span class="params">( )</span> </span>&#123;</span><br><span class="line"><span class="keyword">int</span> x = <span class="number">1</span>; <span class="keyword">int</span> y = <span class="number">1</span>;</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt; <span class="number">10</span>; i++) &#123;</span><br><span class="line">x += i;  </span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt; <span class="number">10</span>; i++) &#123;</span><br><span class="line">y += i;              <span class="comment">//正确：两个循环未嵌套，都可用i</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//错误，变量i在嵌套的语句块中声明</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">method2</span><span class="params">( )</span> </span>&#123;</span><br><span class="line"><span class="comment">//int i = 1;</span></span><br><span class="line"><span class="comment">//int sum = 0;</span></span><br><span class="line"><span class="comment">//for (int i = 1; i &lt; 10; i++) &#123;//java不允许函数的局部变量或参数的作用域被覆盖</span></span><br><span class="line"><span class="comment">//sum += i;          //无法访问外部块局部变量</span></span><br><span class="line"><span class="comment">//&#125;</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br><strong>全局变量的声明与使用</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span>  <span class="class"><span class="keyword">class</span> <span class="title">args</span> </span>&#123;  </span><br><span class="line">     <span class="keyword">public</span> <span class="keyword">static</span> String username; <span class="comment">// 全局变量</span></span><br><span class="line">     <span class="keyword">public</span> <span class="keyword">static</span> String password; <span class="comment">//全局变量</span></span><br><span class="line">&#125;</span><br><span class="line">&gt;&gt; args.username</span><br><span class="line">&gt;&gt; args.password</span><br></pre></td></tr></table></figure></p>]]></content>
      
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Python学习笔记</title>
      <link href="/2019/11/23/python/shypython/"/>
      <url>/2019/11/23/python/shypython/</url>
      
        <content type="html"><![CDATA[<h1 id="Shypython-learn-notes"><a href="#Shypython-learn-notes" class="headerlink" title="Shypython-learn-notes"></a>Shypython-learn-notes</h1><h2 id="1-python-数据类型"><a href="#1-python-数据类型" class="headerlink" title="1. python 数据类型"></a>1. python 数据类型</h2><h3 id="1-1-变量"><a href="#1-1-变量" class="headerlink" title="1.1 变量"></a>1.1 变量</h3><p><strong>1.1.1 算术运算符</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">- 加减乘除+、-、*、/</span><br><span class="line">- 取余、取整、取绝对值 %、//、abs()</span><br><span class="line">- 最小、最大值 min()、max()</span><br><span class="line">- 复数 complex(re,im)</span><br><span class="line">- 取共轭 c.conjugate()</span><br><span class="line">- 返回商和余数 divmod(x,y)</span><br></pre></td></tr></table></figure><p><strong>1.1.2 布尔运算符</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">-  小于、大于 &lt; 、 &gt;</span><br><span class="line">- 等于、不等于 == 、 != </span><br><span class="line">- 与、或、非 <span class="keyword">and</span> 、<span class="keyword">or</span> 、<span class="keyword">not</span></span><br></pre></td></tr></table></figure><p><strong>1.1.3 赋值运算符</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">- a=a+b  <span class="keyword">is</span>  a+=b</span><br><span class="line">- a=a-b  <span class="keyword">is</span>  a-=b</span><br><span class="line">- a=a*/b  <span class="keyword">is</span>  a*/b</span><br><span class="line">- a=a**(//)b  <span class="keyword">is</span>  a**(//)=b</span><br></pre></td></tr></table></figure><p><strong>1.1.4 位运算符</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">- 与或 &amp; 、 |  </span><br><span class="line">- 异或、取反 ^ 、~ </span><br><span class="line">- 左位移、右位移  &lt;&lt;   、 &gt;&gt;</span><br></pre></td></tr></table></figure><p><strong>1.1.5 转义符</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">- 续行符 \</span><br><span class="line">- 反斜杠符号 \\</span><br><span class="line">- 引号 \<span class="string">'</span></span><br><span class="line"><span class="string">- 响铃 \a</span></span><br><span class="line"><span class="string">- 退格 \b</span></span><br><span class="line"><span class="string">- 转义 \e</span></span><br><span class="line"><span class="string">- 空 \000</span></span><br><span class="line"><span class="string">- 换行 \n</span></span><br><span class="line"><span class="string">- 纵向制表符 \v</span></span><br><span class="line"><span class="string">- 横向制表符 \t</span></span><br><span class="line"><span class="string">- 回车 \r</span></span><br><span class="line"><span class="string">- 换页 \f</span></span><br><span class="line"><span class="string">- 八进制 \oyy</span></span><br><span class="line"><span class="string">- 十六进制 \xyy</span></span><br></pre></td></tr></table></figure><h3 id="1-2-字符串-不可变类型"><a href="#1-2-字符串-不可变类型" class="headerlink" title="1.2 字符串(不可变类型)"></a>1.2 字符串(不可变类型)</h3><p><strong>1.2.1 切片操作</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 当索引为正数时，从0开始，当索引为负数时，从-1开始（从右往左）</span></span><br><span class="line">- newstr = s[a:b:c]  从索引a开始到b ,每隔c取一个值，左开右闭</span><br><span class="line">- newstr = s[<span class="number">0</span>:]  </span><br><span class="line">- newstr = s[:]  和上面的式子等价</span><br><span class="line">- newstr = s[::<span class="number">-1</span>] 实现字符串的逆序</span><br></pre></td></tr></table></figure><p><strong>1.2.2 字符串运算及方法</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">str = <span class="string">'I LOVE PYTHON!!'</span></span><br><span class="line">- 标准化字符串 <span class="string">r'str'</span> 或者 repr(str)</span><br><span class="line">- x <span class="keyword">in</span> s 子字符串 </span><br><span class="line">- s1 + s2 字符串连接 </span><br><span class="line">- s*n 字符串副本的拼接 </span><br><span class="line">- s[i] 字符串索引 </span><br><span class="line">- str.index(<span class="string">'s'</span>) 获得字符串s字符的索引位置</span><br><span class="line">- len(s) 字符串长度 </span><br><span class="line">- ord(str) 字符串的编码 </span><br><span class="line">- chr(number) 返回某个编码得到的字符 </span><br><span class="line">- str.spilt(<span class="string">', '</span>) 字符串的分割 ,返回值是一个列表</span><br><span class="line">- chr.join(list)  字符串编码的连接 , <span class="string">" "</span>.join(list)</span><br><span class="line">str = <span class="string">"www.runoob.com"</span></span><br><span class="line">- print(str.upper())  把所有字符中的小写字母转换成大写字母</span><br><span class="line">- print(str.lower())  把所有字符中的大写字母转换成小写字母</span><br><span class="line">- print(str.capitalize()) 把第一个字母转化为大写字母，其余小写</span><br><span class="line">- print(str.title())  把每个单词的第一个字母转化为大写，其余小写</span><br></pre></td></tr></table></figure><p><strong>1.2.3深入研究字符串的方法</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">str.find(x)  返回x的第一个字符出现的索引位置</span><br><span class="line">str.count(x)  返回x出现的次数</span><br><span class="line">str.replace(<span class="string">'top'</span>,<span class="string">'bot'</span>)  返回一个修改的副本</span><br><span class="line">str.spilt()</span><br><span class="line">tabel = str.maketrans(<span class="string">'xyz'</span>,<span class="string">'uvw'</span>) ; str.translate(table)  返回一个映射后的副本</span><br><span class="line">str.strip()  返回字符串的一个副本，并且消除前后空格</span><br></pre></td></tr></table></figure><h3 id="1-3-列表（可变类型）"><a href="#1-3-列表（可变类型）" class="headerlink" title="1.3 列表（可变类型）"></a>1.3 列表（可变类型）</h3><p><strong>1.3.1 list的内置方法</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">lst = [<span class="number">1</span>,<span class="number">3</span>,a,[<span class="number">4</span>,<span class="number">5</span>],<span class="number">6</span>]</span><br><span class="line">- list.append(x)  在尾部增加一个元素</span><br><span class="line">- list.insert(x,i)  在索引i处添加一个元素</span><br><span class="line">- list.index(x)  获得元素x的索引</span><br><span class="line">- list.remove(x)  删除列表的原色</span><br><span class="line">- list.pop(i)  弹出索引为i的元素并在列表中删除它</span><br><span class="line">- list.clear() 清楚列表</span><br><span class="line">- list.count(x) 返回列表x出现的次数</span><br><span class="line">- list.sort() 对列表直接排序， 区别于排序函数 sorted()</span><br><span class="line">- list.reverse() 对列表进行反转</span><br><span class="line">- len(list)</span><br><span class="line">- <span class="keyword">for</span> item <span class="keyword">in</span> list:   对列表的遍历</span><br></pre></td></tr></table></figure><p> <strong>1.3.2 列表和字符串的相互转化</strong><br> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"> <span class="number">1.</span> str &gt;&gt;&gt;list </span><br><span class="line"></span><br><span class="line">str1 = <span class="string">"12345"</span></span><br><span class="line">list1 = list(str1)</span><br><span class="line"><span class="keyword">print</span> list1</span><br><span class="line"> </span><br><span class="line">str2 = <span class="string">"123 sjhid dhi"</span></span><br><span class="line">list2 = str2.split() <span class="comment">#or list2 = str2.split(" ")</span></span><br><span class="line"><span class="keyword">print</span> list2</span><br><span class="line"> </span><br><span class="line">str3 = <span class="string">"www.google.com"</span></span><br><span class="line">list3 = str3.split(<span class="string">"."</span>)</span><br><span class="line"><span class="keyword">print</span> list3</span><br><span class="line"> </span><br><span class="line">输出为：</span><br><span class="line">[<span class="string">'1'</span>, <span class="string">'2'</span>, <span class="string">'3'</span>, <span class="string">'4'</span>, <span class="string">'5'</span>]</span><br><span class="line">[<span class="string">'123'</span>, <span class="string">'sjhid'</span>, <span class="string">'dhi'</span>]</span><br><span class="line">[<span class="string">'www'</span>, <span class="string">'google'</span>, <span class="string">'com'</span>]</span><br><span class="line"></span><br><span class="line"><span class="number">2.</span> list &gt;&gt;&gt;str</span><br><span class="line">str4 = <span class="string">""</span>.join(list3)</span><br><span class="line"><span class="keyword">print</span> str4</span><br><span class="line">str5 = <span class="string">"."</span>.join(list3)</span><br><span class="line"><span class="keyword">print</span> str5</span><br><span class="line">str6 = <span class="string">" "</span>.join(list3)</span><br><span class="line"><span class="keyword">print</span> str6</span><br><span class="line">输出为：</span><br><span class="line">wwwgooglecom</span><br><span class="line">www.google.com</span><br><span class="line">www google com</span><br></pre></td></tr></table></figure></p><h3 id="1-3-元组类型（不可变类型）"><a href="#1-3-元组类型（不可变类型）" class="headerlink" title="1.3 元组类型（不可变类型）"></a>1.3 元组类型（不可变类型）</h3><p><strong>1.3.1 元组的运算及操作</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 元组为不可修改的字符串</span></span><br><span class="line">tuple = (<span class="number">2019</span>,<span class="string">'a'</span>,(b,c),<span class="string">'science'</span>)</span><br></pre></td></tr></table></figure><p><strong>1.3.2 元组与列表的转换</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tuple = tuple(list)</span><br><span class="line">list  = list(touple)</span><br></pre></td></tr></table></figure><h3 id="1-4-集合类型（消除关系重复元素）"><a href="#1-4-集合类型（消除关系重复元素）" class="headerlink" title="1.4 集合类型（消除关系重复元素）"></a>1.4 集合类型（消除关系重复元素）</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">myset = [<span class="string">'nature'</span>,<span class="string">'science'</span>]</span><br><span class="line">set.add(x)</span><br><span class="line">set.remove(X)</span><br><span class="line">set.discard(X)</span><br><span class="line">set.clear()</span><br><span class="line">set.pop()</span><br><span class="line">len(set)</span><br><span class="line"><span class="keyword">in</span> / <span class="keyword">not</span> <span class="keyword">in</span></span><br><span class="line">set.issubset(set2)  判断set是否是set2的子集，返回bool类型</span><br><span class="line">set.isuperset(set2)  </span><br><span class="line">set.union(set2)  计算并集</span><br><span class="line">set.intersection(set2)  计算交集</span><br><span class="line">set.difference(set2)  计算差集</span><br><span class="line">set.symmetric_difference(set2)  计算对称差集</span><br></pre></td></tr></table></figure><h3 id="1-5-字典类型（键值对）"><a href="#1-5-字典类型（键值对）" class="headerlink" title="1.5 字典类型（键值对）"></a>1.5 字典类型（键值对）</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">mydict = &#123;<span class="string">'a'</span>:<span class="number">1</span>,<span class="string">'b'</span>:<span class="number">2</span>,<span class="string">'c'</span>:<span class="number">3</span>&#125;</span><br><span class="line">len(dict)</span><br><span class="line">str(dict)</span><br><span class="line">dict(<span class="string">'a'</span>)  访问字典中键为a的值</span><br><span class="line">dict.clear()</span><br><span class="line">dict.items() 以列表形式返回可遍历的（键，值）元素数组</span><br><span class="line">dict.keys() 以列表形式返回一个字典中的所有键</span><br><span class="line">dict.values() 以字典形式返回一个字典中的所有值</span><br><span class="line">``` </span><br><span class="line"></span><br><span class="line"><span class="comment">## 2. 语句类型</span></span><br><span class="line"><span class="comment">### 2.1 if 语句</span></span><br><span class="line">```python </span><br><span class="line"><span class="keyword">if</span> &lt;条件&gt;：</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"><span class="keyword">elif</span> &lt;条件&gt;：</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure><h3 id="2-2-while语句"><a href="#2-2-while语句" class="headerlink" title="2.2 while语句"></a>2.2 while语句</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> &lt;条件&gt;：</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"><span class="comment"># 死循环</span></span><br><span class="line"><span class="keyword">while</span> <span class="number">1</span>:</span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure><h3 id="2-3-for-语句"><a href="#2-3-for-语句" class="headerlink" title="2.3 for 语句"></a>2.3 for 语句</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> list:</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 在for循环中使用内置函数 range()</span></span><br><span class="line">range(a,b,c)  返回一个数字区间的所有整数</span><br><span class="line"></span><br><span class="line"><span class="comment"># 简单的冒泡排序算法S</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(n)<span class="number">-1</span>):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(len(n)-i<span class="number">-1</span>):</span><br><span class="line">        <span class="keyword">if</span> n[j] &gt; n[i]:</span><br><span class="line">            n[j], n[j+<span class="number">1</span>] = n[j+<span class="number">1</span>], n[j]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在for循环中使用内置函数zip()</span></span><br><span class="line">zip(x,y)  将多序列生成一个新的序列，每个序列的元素以元组形式存储数据</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> t1,t2 <span class="keyword">in</span> zip(x,y):</span><br><span class="line">    print(t1,t2)</span><br></pre></td></tr></table></figure><h3 id="2-4-控制语句"><a href="#2-4-控制语句" class="headerlink" title="2.4 控制语句"></a>2.4 控制语句</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">break</span>  跳出循环</span><br><span class="line"><span class="keyword">continue</span>  终止当前一次循环、继续进行下一次循环</span><br><span class="line"><span class="keyword">pass</span> 什么都不做，保持结构完整性</span><br></pre></td></tr></table></figure><h2 id="3-格式化输入与输出"><a href="#3-格式化输入与输出" class="headerlink" title="3. 格式化输入与输出"></a>3. 格式化输入与输出</h2><h3 id="3-1-格式化输入"><a href="#3-1-格式化输入" class="headerlink" title="3.1 格式化输入"></a>3.1 格式化输入</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a = input(&lt;info&gt;)</span><br><span class="line">a = input(repr(str))</span><br></pre></td></tr></table></figure><h3 id="3-2-格式化输出"><a href="#3-2-格式化输出" class="headerlink" title="3.2 格式化输出"></a>3.2 格式化输出</h3><p><strong>3.2.1 print语句</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">print(a, b)   同行以空格隔开输出</span><br><span class="line">print(a, b,s ep=<span class="string">','</span>)  以逗号隔开进行输出</span><br><span class="line">print(s, ewp=<span class="string">'\n'</span>)   以换行隔开进行输出</span><br><span class="line">print(name, end=<span class="string">'!'</span>)  每个输出都要添加!</span><br><span class="line">print(<span class="string">' i love %s '</span> % s)  <span class="keyword">print</span> 格式化输出</span><br><span class="line"><span class="comment"># 对字符串的每个元素进行换行输出</span></span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> list:</span><br><span class="line">    print(item)</span><br></pre></td></tr></table></figure><p><strong>3.2.2 字符串方法format()</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'&#123;0&#125; : &#123;1&#125; : &#123;2&#125;'</span>.format(hour, minute, second))</span><br><span class="line"><span class="comment"># 按照对齐格式化进行排列</span></span><br><span class="line">print(<span class="string">'&#123;0:3&#125;,&#123;1:5&#125;'</span>.format(<span class="number">12</span>, <span class="number">534</span>)) :后面的内容为只等的格式，表示占位数，如果不够，在前面用空格补齐</span><br></pre></td></tr></table></figure><p><strong>3.2.3 数据输出的格式类型</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># a表示占位，不够，按照原长度打印，多了左侧空格补齐，小数点后面为保留几位小数，f位数据类型</span></span><br><span class="line">print(<span class="string">'i love %a.bf'</span>, num)</span><br><span class="line">- b 以二进制形式输出</span><br><span class="line">- c 输出证书值对应的unicode字符</span><br><span class="line">- d 以十进制形式输出数值</span><br><span class="line">- e 以科学计数法形式输出</span><br><span class="line">- o 以八进制形式输出</span><br><span class="line">- x 以小写形式的十六进制输出</span><br><span class="line">- X 以大写形式的十六进制输出</span><br></pre></td></tr></table></figure><h2 id="4-函数"><a href="#4-函数" class="headerlink" title="4. 函数"></a>4. 函数</h2><h3 id="4-1-函数定义及调用函数"><a href="#4-1-函数定义及调用函数" class="headerlink" title="4.1 函数定义及调用函数"></a>4.1 函数定义及调用函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">- <span class="function"><span class="keyword">def</span> <span class="title">funname</span><span class="params">(para1, para2,*，para3...)</span>:</span></span><br><span class="line">    函数体</span><br><span class="line"><span class="comment"># 在参数列表中使用（*），代表调用函数时，在（*）后面的参数都必须指定参数名称，如下</span></span><br><span class="line">funname(para1, para2，para3=<span class="number">2.</span>..)   调用函数</span><br><span class="line">- <span class="function"><span class="keyword">def</span> <span class="title">fun</span><span class="params">(strname, age=<span class="number">32</span>)</span>：   后面的参数位默认形参，默认形参必须放在后面</span></span><br><span class="line"><span class="function">- 对元组和列表进行解包</span></span><br><span class="line"><span class="function"><span class="title">def</span> <span class="title">fun</span><span class="params">(*person)</span>:</span></span><br><span class="line">fun(<span class="string">'shy'</span>,<span class="string">'21'</span>)</span><br><span class="line">mylist = [<span class="string">'shy'</span>,<span class="string">'21'</span>]</span><br><span class="line">fun(*mylist)</span><br><span class="line">- 对字典进行解包定义参数及调用</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fun</span><span class="params">(**person)</span></span></span><br><span class="line"><span class="function"><span class="title">print</span><span class="params">(<span class="string">'姓名'</span>,person[<span class="string">'name'</span>],<span class="string">'年纪'</span>,person[<span class="string">'age'</span>])</span></span></span><br><span class="line"><span class="function"><span class="title">fun</span><span class="params">(<span class="string">'shy'</span>,<span class="string">'21'</span>)</span></span></span><br><span class="line">mydict = &#123;'name':'shy','age':21&#125;</span><br><span class="line">fun(**mydict)</span><br></pre></td></tr></table></figure><h3 id="4-2-函数类型"><a href="#4-2-函数类型" class="headerlink" title="4.2 函数类型"></a>4.2 函数类型</h3><p><strong>4.2.1 python内置函数</strong></p><p>下图python3.8官方文档给出的内置函数库：</p><div style="align: center"><img src="https://img.vim-cn.com/5f/bd7267b5d93389d33733905d3bb7216a43d7c1.png"/></div><p>官方中文文档的连接：<a href="https://docs.python.org/zh-cn/3/library/functions.html" target="_blank" rel="noopener">https://docs.python.org/zh-cn/3/library/functions.html</a></p><p><strong>4.2.2 匿名函数与可迭代函数</strong></p><ul><li><strong>匿名函数</strong><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 匿名函数</span></span><br><span class="line"><span class="keyword">lambda</span> para1, para2... : 表达式</span><br><span class="line">r = <span class="keyword">lambda</span> x,y:x*y</span><br><span class="line"></span><br><span class="line"><span class="comment"># 匿名函数与reduce函数的组合应用</span></span><br><span class="line">reduce(fun, seq, initial)  <span class="comment">#用序列值依次调用fun</span></span><br><span class="line"><span class="keyword">from</span> funtools <span class="keyword">import</span> reduce</span><br><span class="line">a = reduce(<span class="keyword">lambda</span> x,y:x + y, range(<span class="number">1</span>,<span class="number">101</span>))  <span class="comment">#实现求1~100的和</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 匿名函数与map函数的组合应用</span></span><br><span class="line">map(fun, seq[,seq,])  <span class="comment">#将seq内部的元素作为参数依次调用</span></span><br><span class="line">t = map(<span class="keyword">lambda</span> x:x**<span class="number">2</span>,[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>])  <span class="comment">#返回一个map对象</span></span><br><span class="line">print(list(t))   <span class="comment">#打印值为[1,4,9,16,25]</span></span><br><span class="line">y =map(<span class="keyword">lambda</span> x,y:x+y,[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>])</span><br><span class="line">print(list(t))   <span class="comment"># 打印值为[5,7,9]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 匿名函数与filter函数的组合应用</span></span><br><span class="line">filter(fun <span class="keyword">or</span> none, seq)  <span class="comment">#将序列对象依次放到fun中，如果返回true就留下</span></span><br><span class="line">t = filter(<span class="keyword">lambda</span> x:x%<span class="number">2</span>==<span class="number">0</span>, [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>])</span><br><span class="line">print(list(t))   <span class="comment"># 打印值为[2,4,6]</span></span><br></pre></td></tr></table></figure></li><li><strong>可迭代函数</strong><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 每个生成器对象会有一个__next__()方法</span></span><br><span class="line">t = filter(<span class="keyword">lambda</span> x:x%<span class="number">2</span>==<span class="number">0</span>, [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>])</span><br><span class="line">print(t.__next__())  <span class="comment"># 打印2</span></span><br><span class="line">print(t.__next__())  <span class="comment"># 打印4</span></span><br></pre></td></tr></table></figure></li></ul><p><strong>4.2.3 生成器函数与工厂函数</strong></p><ul><li><strong>生成器函数</strong><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 生成器与迭代器不同，迭代器的内容存在内存里，用next函数遍历，生成器用完立即销毁</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">Reverse</span><span class="params">(data)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> idx <span class="keyword">in</span> range(len(data)<span class="number">-1</span>,<span class="number">-1</span>,<span class="number">-1</span>):</span><br><span class="line">        <span class="keyword">yield</span> data[idx]   <span class="comment"># 生成器函数用yield返回</span></span><br><span class="line"><span class="keyword">for</span> c <span class="keyword">in</span> Reverse(<span class="string">'Python'</span>):</span><br><span class="line">    print(c, end = <span class="string">' '</span>)  <span class="comment"># 打印 n o h t y P</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成器表达式</span></span><br><span class="line">mylist = [x*x <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">3</span>)]  <span class="comment"># 使用生成器表达式返回一个对象</span></span><br></pre></td></tr></table></figure></li><li><strong>工厂函数</strong><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 闭合函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">wrapperfun</span><span class="params">(strname)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">recorder</span><span class="params">(age)</span>：</span></span><br><span class="line"><span class="function">        <span class="title">print</span><span class="params">(strname,age)</span></span></span><br><span class="line"><span class="function">    <span class="title">return</span> <span class="title">recorder</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line">fun = wrapperfun('shy')</span><br><span class="line">fun(<span class="number">37</span>)    <span class="comment"># 打印 shy 37</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 装饰器属性：在原有的函数包一个函数，不改变原代码的基础上，添加新功能</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">checkParams</span><span class="params">(fn)</span>:</span>    <span class="comment"># 装饰器函数</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">wrapper</span><span class="params">(strname)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> isinstance(strname.(str))：</span><br><span class="line">            <span class="keyword">return</span> fn(strname)  <span class="comment"># 判断字符串类型</span></span><br><span class="line">        <span class="keyword">print</span> (<span class="string">'error'</span>)  </span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    <span class="keyword">return</span> wrapper</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">wrapperfun</span><span class="params">(strname)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">recorder</span><span class="params">(age)</span>：</span></span><br><span class="line"><span class="function">        <span class="title">print</span><span class="params">(strname,age)</span></span></span><br><span class="line"><span class="function">    <span class="title">return</span> <span class="title">recorder</span></span></span><br><span class="line">wrapperfun2 = checkParams(wrapperfun)</span><br><span class="line">fun = wrapperfun(<span class="string">'shy'</span>)</span><br><span class="line">fun(<span class="number">37</span>)  <span class="comment"># 打印 shy 37</span></span><br><span class="line">fun = wrapperfun2(<span class="number">37</span>)  <span class="comment"># 输入不合法</span></span><br></pre></td></tr></table></figure></li><li><strong>@修饰符</strong><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">checkParams</span><span class="params">(fn)</span>:</span>    <span class="comment"># 装饰器函数</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">wrapper</span><span class="params">(strname)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> isinstance(strname.(str))：</span><br><span class="line">            <span class="keyword">return</span> fn(strname)  <span class="comment"># 判断字符串类型</span></span><br><span class="line">        <span class="keyword">print</span> (<span class="string">'error'</span>)  </span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    <span class="keyword">return</span> wrapper</span><br><span class="line"></span><br><span class="line"><span class="meta">@checkParams   # 使用装饰器函数对wrapperfun函数进行修饰</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">wrapperfun</span><span class="params">(strname)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">recorder</span><span class="params">(age)</span>：</span></span><br><span class="line"><span class="function">        <span class="title">print</span><span class="params">(strname,age)</span></span></span><br><span class="line"><span class="function">    <span class="title">return</span> <span class="title">recorder</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line">fun = wrapperfun('shy')</span><br><span class="line">fun(<span class="number">37</span>)  <span class="comment"># 打印 shy 37</span></span><br><span class="line">fun = wrapperfun2(<span class="number">37</span>)  <span class="comment"># 输入不合法</span></span><br></pre></td></tr></table></figure></li></ul><p><strong>4.4.4 偏函数与递归函数</strong></p><ul><li><strong>偏函数</strong><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 偏函数是重新定义一个函数，并指定了默认参数值</span></span><br><span class="line"><span class="keyword">from</span> funtools <span class="keyword">import</span> partial</span><br><span class="line">partial(fun, *args, **keywords)</span><br></pre></td></tr></table></figure></li><li><strong>递归函数</strong><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 递归函数是自己调用自己的函数，所有的函数调用都是压栈的过程，所以耗内存，栈空间有限，如果程序栈空间地址写满，程序最后会崩溃</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fun</span><span class="params">(n)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> n*fun(n<span class="number">-1</span>)</span><br></pre></td></tr></table></figure></li></ul><p><strong>4.4.5 eval 和 exec函数</strong></p><ul><li><strong>eval函数</strong><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># exec执行不返回结果，eval执行返回结果</span></span><br><span class="line">dic = &#123;&#125;</span><br><span class="line">dic[<span class="string">'b'</span>] = <span class="number">3</span></span><br><span class="line">exec(<span class="string">'a=4'</span>,dic)</span><br><span class="line">print(dic.keys())   <span class="comment">#打印dict_keys(['a','__builtins__','b'])</span></span><br><span class="line"><span class="comment"># 使用这两个函数第一个参数一定是可执行代码</span></span><br></pre></td></tr></table></figure><h3 id="4-3-变量的作用域"><a href="#4-3-变量的作用域" class="headerlink" title="4.3 变量的作用域"></a>4.3 变量的作用域</h3></li></ul><p><strong>4.3.1 global语句</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># global 可以把局部声明为全局</span></span><br><span class="line">a = <span class="number">6</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">func</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">global</span> a</span><br><span class="line">    a = <span class="number">5</span></span><br><span class="line">print(a)   <span class="comment"># 打印5</span></span><br></pre></td></tr></table></figure><p><strong>4.3.2 nonlocal语句</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># nonlocal可以把全局往下一作用域调用</span></span><br><span class="line">a = <span class="number">6</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">func</span><span class="params">()</span>:</span></span><br><span class="line">    a = <span class="number">7</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">nested</span><span class="params">()</span>:</span></span><br><span class="line">        <span class="keyword">nonlocal</span> a</span><br><span class="line">            a+=<span class="number">1</span></span><br><span class="line">    nested()</span><br><span class="line">    print(<span class="string">'本地:'</span>,a)   <span class="comment">#打印 8</span></span><br><span class="line">func()</span><br><span class="line">print(<span class="string">'全局'</span>,a)  <span class="comment"># 打印6</span></span><br><span class="line">print(a)   <span class="comment"># 打印5</span></span><br></pre></td></tr></table></figure><h2 id="5-面向对象的程序设计"><a href="#5-面向对象的程序设计" class="headerlink" title="5. 面向对象的程序设计"></a>5. 面向对象的程序设计</h2><h3 id="5-1-类的结构"><a href="#5-1-类的结构" class="headerlink" title="5.1 类的结构"></a>5.1 类的结构</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyClass</span>：</span></span><br><span class="line"><span class="class">    <span class="title">def</span> <span class="title">__init__</span><span class="params">(self,属性)</span>:</span>  <span class="comment"># 构造函数</span></span><br><span class="line">        self.属性 = 属性</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getname</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.name</span><br><span class="line">    ......</span><br><span class="line"></span><br><span class="line">myc = MyClass(属性)   <span class="comment"># 初始化实例对象，构造函数的属性</span></span><br><span class="line">a = myc.getname()   </span><br><span class="line"></span><br><span class="line"><span class="comment"># 类还具有一些内置属性</span></span><br><span class="line">__name__   名称</span><br><span class="line">__doc__  类的文档字符串</span><br><span class="line">__nodule__ 类的模块</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br></pre></td></tr></table></figure><h3 id="5-2-类方法"><a href="#5-2-类方法" class="headerlink" title="5.2 类方法"></a>5.2 类方法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@classmthod  # 声明为类方法，可以直接用类名进行调用，当然初始化实例对象进行调用也是正确的</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fun</span><span class="params">(cls)</span>:</span></span><br><span class="line"><span class="meta">@staticmethod  # 等同于普通函数，只是被封装在类中，独立于整个类</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fun</span><span class="params">()</span>  # 同上的调用方式，且参数没有限制要求</span></span><br></pre></td></tr></table></figure><h3 id="5-3-类的私有化属性"><a href="#5-3-类的私有化属性" class="headerlink" title="5.3 类的私有化属性"></a>5.3 类的私有化属性</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 私有化属性方法，在类的属性前面加双下划线，同时会提供一个私有化属性的访问函数，不可以被修改,但可以针对具体实例进行对象修改</span></span><br><span class="line">clas MyClass:</span><br><span class="line">    __Occupation = <span class="string">'scientist'</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(sefl,name,age)</span>；</span></span><br><span class="line"><span class="function">    <span class="title">def</span> <span class="title">getOccupation</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.__Occupation</span><br><span class="line"><span class="comment"># 使用装饰器函数实现类的私有化</span></span><br><span class="line">clas MyClass:</span><br><span class="line">    __Occupation = <span class="string">'scientist'</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(sefl,name,age)</span>；</span></span><br><span class="line"><span class="function">    @<span class="title">property</span>  # 装饰为属性，使类的私有化属性也可以被访问</span></span><br><span class="line"><span class="function">    <span class="title">def</span> <span class="title">getOccupation</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.__Occupation</span><br></pre></td></tr></table></figure><h3 id="5-4-类的继承"><a href="#5-4-类的继承" class="headerlink" title="5.4 类的继承"></a>5.4 类的继承</h3><p><strong>5.4.1 继承结构体</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DerivedClass</span><span class="params">(FatherClass1, FatherClass2)</span>：</span></span><br><span class="line"><span class="class">    <span class="title">pass</span></span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Record</span>:</span></span><br><span class="line">    <span class="string">""" A record class """</span></span><br><span class="line">    __Ocuupation = <span class="string">"scientist"</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, name, age)</span>:</span></span><br><span class="line">        self.name = name</span><br><span class="line">        self.age = age</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">showrecode</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">"Occupation:"</span>,self.getOccupation())</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getOccupation</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.__Occupation</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">GirlRecord</span><span class="params">(Record)</span>:</span></span><br><span class="line">    <span class="string">""" A girlrecord class """</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">showrecode</span><span class="params">(self)</span>:</span></span><br><span class="line">        Record.showrecode(self)</span><br><span class="line">        print(<span class="string">"the girl:"</span>, self.name, <span class="string">"age:"</span>, self.age)</span><br><span class="line"></span><br><span class="line">myc = GirlRecord(<span class="string">"Anaa"</span>, <span class="number">21</span>)</span><br><span class="line">myc.showrecode()</span><br></pre></td></tr></table></figure><p><strong>5.4.2 super()函数</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 保障了调用父类方法时只调用一次</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Record</span>:</span></span><br><span class="line">    <span class="string">""" A record class """</span></span><br><span class="line">    __Ocuupation = <span class="string">"scientist"</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, name, age)</span>:</span></span><br><span class="line">        self.name = name</span><br><span class="line">        self.age = age</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">showrecode</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">"Occupation:"</span>,self.getOccupation())</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getOccupation</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.__Occupation</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">GirlRecord</span><span class="params">(Record)</span>:</span></span><br><span class="line">    <span class="string">""" A girlrecord class """</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">showrecode</span><span class="params">(self)</span>:</span></span><br><span class="line">        super().showrecode(self)</span><br><span class="line">        print(<span class="string">"the girl:"</span>, self.name, <span class="string">"age:"</span>, self.age)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MaleRecord</span><span class="params">(Record)</span>:</span></span><br><span class="line">    <span class="string">""" A girlrecord class """</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">showrecode</span><span class="params">(self)</span>:</span></span><br><span class="line">        super().showrecode(self)</span><br><span class="line">        print(<span class="string">"the girl:"</span>, self.name, <span class="string">"age:"</span>, self.age)</span><br><span class="line">        </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ThisRecord</span><span class="params">(GirlRecord, MaleRecord)</span>:</span></span><br><span class="line">    <span class="string">""" A girlrecord class """</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">showrecode</span><span class="params">(self)</span>:</span></span><br><span class="line">        super().showrecode(self)</span><br><span class="line">        print(<span class="string">"the girl:"</span>, self.name, <span class="string">"age:"</span>, self.age)</span><br><span class="line">myc = ThisRecord(<span class="string">"Anaa"</span>, <span class="number">21</span>)</span><br><span class="line">myc.showrecode()</span><br></pre></td></tr></table></figure><h3 id="5-5-类相关的内置函数"><a href="#5-5-类相关的内置函数" class="headerlink" title="5.5 类相关的内置函数"></a>5.5 类相关的内置函数</h3><ul><li><strong>判断实例（isinstance)</strong><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">isinstance(object, class_name)</span><br></pre></td></tr></table></figure></li><li><strong>判断字类（issubclass)</strong><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">issubclass(class1, class2)</span><br></pre></td></tr></table></figure></li><li><strong>判断类实例中是否包含某一个属性（hasattr)</strong><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hasattr(object, name)</span><br></pre></td></tr></table></figure></li><li><strong>获得类实例中的某一个属性（getattr)</strong><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">getattr(object, name[,default])</span><br></pre></td></tr></table></figure></li><li><strong>设置类实例中的某一个属性值（setattr)</strong><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">setattr(object, name, value)</span><br></pre></td></tr></table></figure><h3 id="5-6-重载运算符"><a href="#5-6-重载运算符" class="headerlink" title="5.6 重载运算符"></a>5.6 重载运算符</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyClass</span>:</span></span><br><span class="line">    <span class="string">""" A record class"""</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, name, age)</span>:</span></span><br><span class="line">        self.name = name</span><br><span class="line">        self.age = age</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__str__</span><span class="params">(self)</span>:</span>  <span class="comment"># 将值转化为字符串进行输出</span></span><br><span class="line">        retrun <span class="string">"name:"</span>+self.name;<span class="string">"age:"</span>+str(self.age)</span><br><span class="line">    </span><br><span class="line">    __repr__ = __str__  <span class="comment"># 转化为解释器读取的形式</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__lt__</span><span class="params">(self, record)</span>:</span>  <span class="comment">#重载比较运算符</span></span><br><span class="line">        <span class="keyword">if</span> self.age &lt; record.age:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__add__</span><span class="params">(self, record)</span>:</span>   <span class="comment">#重载加号运算符</span></span><br><span class="line">        <span class="keyword">return</span> MyClass(self.name, self.age+record.age)</span><br><span class="line"></span><br><span class="line">myc = MyClass(<span class="string">"A"</span>, <span class="number">42</span>)</span><br><span class="line">myc1 = MyClass(<span class="string">"B"</span>, <span class="number">23</span>)</span><br><span class="line"></span><br><span class="line">print(repr(myc))  </span><br><span class="line">print(myc)</span><br><span class="line">print(str(myc))</span><br><span class="line">print(myc&lt;myc1)</span><br><span class="line">print(myc+myc1)</span><br></pre></td></tr></table></figure></li><li><strong>运算符重载</strong><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"> 方法名                  运算符和表达式      说明</span><br><span class="line">__add__(self,rhs)        self + rhs        加法</span><br><span class="line">__sub__(self,rhs)        self - rhs         减法</span><br><span class="line">__mul__(self,rhs)        self * rhs         乘法</span><br><span class="line">__truediv__(self,rhs)    self / rhs          除法</span><br><span class="line">__floordiv__(self,rhs)   self //rhs          地板除</span><br><span class="line">__mod__(self,rhs)        self % rhs       取模(求余)</span><br><span class="line">__pow__(self,rhs)        self **rhs         幂运算</span><br><span class="line">合赋值算术运算符的重载:</span><br><span class="line">方法名                  运算符和表达式      说明</span><br><span class="line">__iadd__(self,rhs)       self += rhs        加法</span><br><span class="line">__isub__(self,rhs)       self -= rhs         减法</span><br><span class="line">__imul__(self,rhs)       self *= rhs         乘法</span><br><span class="line">__itruediv__(self,rhs)   self /= rhs        除法</span><br><span class="line">__ifloordiv__(self,rhs)  self //=rhs        地板除</span><br><span class="line">__imod__(self,rhs)       self %= rhs     取模(求余)</span><br><span class="line">__ipow__(self,rhs)       self **=rhs       幂运算</span><br><span class="line"></span><br><span class="line">比较算术运算符的重载:</span><br><span class="line">方法名                  运算符和表达式      说明</span><br><span class="line">__lt__(self,rhs)       self &lt; rhs        小于</span><br><span class="line">__le__(self,rhs)       self &lt;= rhs       小于等于</span><br><span class="line">__gt__(self,rhs)       self &gt; rhs        大于</span><br><span class="line">__ge__(self,rhs)       self &gt;= rhs       大于等于</span><br><span class="line">__eq__(self,rhs)       self == rhs       等于</span><br><span class="line">__ne__(self,rhs)       self != rhs       不等于</span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">位运算符重载</span><br><span class="line">方法名              运算符和表达式        说明</span><br><span class="line">__and__(self,rhs)       self &amp; rhs           位与</span><br><span class="line">__or__(self,rhs)        self | rhs           位或</span><br><span class="line">__xor__(self,rhs)       self ^ rhs           位异或</span><br><span class="line"> __lshift__(self,rhs)    self &lt;&lt;rhs           左移</span><br><span class="line"> __rshift__(self,rhs)    self &gt;&gt;rhs           右移</span><br><span class="line"></span><br><span class="line">反向位运算符重载</span><br><span class="line"></span><br><span class="line">方法名            运算符和表达式       说明</span><br><span class="line">__and__(self,lhs)       lhs &amp; rhs        位与</span><br><span class="line">__or__(self,lhs)         lhs | rhs       位或</span><br><span class="line">__xor__(self,lhs)       lhs ^ rhs        位异或</span><br><span class="line">__lshift__(self,lhs)    lhs &lt;&lt;rhs        左移</span><br><span class="line">__rshift__(self,lhs)    lhs &gt;&gt;rhs        右移</span><br><span class="line"></span><br><span class="line">复合赋值位相关运算符重载</span><br><span class="line">方法名              运算符和表达式          说明</span><br><span class="line">__iand__(self,rhs)       self &amp; rhs       位与</span><br><span class="line">__ior__(self,rhs)        self | rhs       位或</span><br><span class="line">__ixor__(self,rhs)       self ^ rhs       位异或</span><br><span class="line">__ilshift__(self,rhs)    self &lt;&lt;rhs       左移</span><br><span class="line">__irshift__(self,rhs)    self &gt;&gt;rhs       右移</span><br><span class="line"></span><br><span class="line">一元运算符的重载</span><br><span class="line">方法名              运算符和表达式       说明</span><br><span class="line">__neg__(self)         - self           负号</span><br><span class="line">__pos__(self)         + self           正号</span><br><span class="line">__invert__(self)      ~ self           取反</span><br></pre></td></tr></table></figure><h2 id="6-错误异常与文件读写"><a href="#6-错误异常与文件读写" class="headerlink" title="6 错误异常与文件读写"></a>6 错误异常与文件读写</h2><h3 id="6-1-错误异常捕捉"><a href="#6-1-错误异常捕捉" class="headerlink" title="6.1 错误异常捕捉"></a>6.1 错误异常捕捉</h3></li></ul><p><strong>6.1.1 异常语句结构</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"><span class="keyword">except</span>(ZeroDivisionError, ValueError):</span><br><span class="line">    print(<span class="string">'错误'</span>)</span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line">    print(<span class="string">'其它异常’)</span></span><br><span class="line"><span class="string">except Exception as e:  # 捕捉未知异常</span></span><br><span class="line"><span class="string">    print(e)</span></span><br><span class="line"><span class="string">else:</span></span><br><span class="line"><span class="string">    pass   # 没有异常发生时执行</span></span><br><span class="line"><span class="string">finally:</span></span><br><span class="line"><span class="string">    pass  # 最终处理语句，无论是否有异常，都要执行这个语句</span></span><br></pre></td></tr></table></figure><p><strong>6.1.2 异常类型</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 异常名称         异常解释</span></span><br><span class="line">AttributeError试图访问一个对象没有的树形，比如foo.x，但是foo没有属性x</span><br><span class="line">IOError输入/输出异常；基本上是无法打开文件</span><br><span class="line">ImportError无法引入模块或包；基本上是路径问题或名称错误</span><br><span class="line">IndentationError语法错误（的子类） ；代码没有正确对齐</span><br><span class="line">IndexError下标索引超出序列边界，比如当x只有三个元素，却试图访问x[<span class="number">5</span>]</span><br><span class="line">KeyError试图访问字典里不存在的键</span><br><span class="line">KeyboardInterruptCtrl+C被按下</span><br><span class="line">NameError使用一个还未被赋予对象的变量</span><br><span class="line">SyntaxErrorPython代码非法，代码不能编译(个人认为这是语法错误，写错了）</span><br><span class="line">TypeError传入对象类型与要求的不符合</span><br><span class="line">UnboundLocalError</span><br><span class="line">试图访问一个还未被设置的局部变量，基本上是由于另有一个同名的全局变量，导致你以为正在访问它</span><br><span class="line">ValueError传入一个调用者不期望的值，即使值的类型是正确</span><br><span class="line">BaseException                        　　　　所有异常的基类</span><br><span class="line">SystemExit　　　　　　　　 　　　　解释器请求退出</span><br><span class="line">KeyboardInterrupt　　　　　 　　　　用户中断执行(通常是输入^C)</span><br><span class="line">Exception　　　　　　　　　　　　 常规错误的基类</span><br><span class="line">StopIteration 　　　　　　　　　　　　迭代器没有更多的值</span><br><span class="line">GeneratorExit 　　　　　　　　　　生成器(generator)发生异常来通知退出</span><br><span class="line">StandardError　　　　　　　　 　　所有的内建标准异常的基类</span><br><span class="line">ArithmeticError　　　　　　　　　　 所有数值计算错误的基类</span><br><span class="line">FloatingPointError 　　　　　　　　浮点计算错误</span><br><span class="line">OverflowError 　　　　　　　　　　数值运算超出最大限制</span><br><span class="line">ZeroDivisionError　　　　　　 　　除(或取模)零 (所有数据类型)</span><br><span class="line">AssertionError　　　　　　　　 　　断言语句失败</span><br><span class="line">AttributeError 　　　　　　　　　　对象没有这个属性</span><br><span class="line">EOFError 　　　　　　　　　　　　没有内建输入,到达EOF 标记</span><br><span class="line">EnvironmentError　　　　　　 　　操作系统错误的基类</span><br><span class="line">IOError　　　　　　　　　　　　 输入/输出操作失败</span><br><span class="line">OSError　　　　　　　　　　　　 操作系统错误</span><br><span class="line">WindowsError 　　　　　　　　　　系统调用失败</span><br><span class="line">ImportError　　　　　　　　　　 导入模块/对象失败</span><br><span class="line">LookupError　　　　　　　　　　 无效数据查询的基类</span><br><span class="line">IndexError 　　　　　　　　　　序列中没有此索引(index)</span><br><span class="line">KeyError　　　　　　　　　　　　 映射中没有这个键</span><br><span class="line">MemoryError　　　　　　　　　　 内存溢出错误(对于Python 解释器不是致命的)</span><br><span class="line">NameError 　　　　　　　　　　未声明/初始化对象 (没有属性)</span><br><span class="line">UnboundLocalError 　　　　　　　　访问未初始化的本地变量</span><br><span class="line">ReferenceError　　　　　　　　 弱引用(Weak reference)试图访问已经垃圾回收了的对象</span><br><span class="line">RuntimeError　　　　　　　　　　 一般的运行时错误</span><br><span class="line">NotImplementedError 　　　　　　　　尚未实现的方法</span><br><span class="line">SyntaxError Python　　　　　　　　 语法错误</span><br><span class="line">IndentationError　　　　　　　　　　 缩进错误</span><br><span class="line">TabError Tab　　　　　　　　　　 和空格混用</span><br><span class="line">SystemError 　　　　　　　　　　　　一般的解释器系统错误</span><br><span class="line">TypeError　　　　　　　　　　　　 对类型无效的操作</span><br><span class="line">ValueError 　　　　　　　　　　　　传入无效的参数</span><br><span class="line">UnicodeError Unicode　　　　　　　　 相关的错误</span><br><span class="line">UnicodeDecodeError Unicode　　　　 解码时的错误</span><br><span class="line">UnicodeEncodeError Unicode　　　　 编码时错误</span><br><span class="line">UnicodeTranslateError Unicode 　　　　转换时错误</span><br><span class="line">Warning　　　　　　　　　　　　　　 警告的基类</span><br><span class="line">DeprecationWarning　　　　　　　　 关于被弃用的特征的警告</span><br><span class="line">FutureWarning 　　　　　　　　　　　　关于构造将来语义会有改变的警告</span><br><span class="line">OverflowWarning　　　　　　　　　　　 旧的关于自动提升为长整型(long)的警告</span><br><span class="line">PendingDeprecationWarning　　　　　　 关于特性将会被废弃的警告</span><br><span class="line">RuntimeWarning 　　　　　　　　　　　可疑的运行时行为(runtime behavior)的警告</span><br><span class="line">SyntaxWarning　　　　　　　　　　 可疑的语法的警告</span><br><span class="line">UserWarning 　　　　　　　　　　用户代码生成的警告</span><br></pre></td></tr></table></figure><h3 id="6-2-文件读写与导入"><a href="#6-2-文件读写与导入" class="headerlink" title="6.2 文件读写与导入"></a>6.2 文件读写与导入</h3><p><strong>6.2.1 语句结构</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">f = open(<span class="string">'new/test.txt'</span>,<span class="string">'a+'</span>,encoding=<span class="string">'utf-8'</span>)</span><br><span class="line">f.write(<span class="string">'\n今天天气很好'</span>)</span><br><span class="line">f.close()</span><br><span class="line">f = open(<span class="string">'new/test.txt'</span>,<span class="string">'rb'</span>)</span><br><span class="line">w=f.read().decode(<span class="string">'utf-8'</span>)</span><br><span class="line">print(w)</span><br><span class="line"></span><br><span class="line">f = open(<span class="string">'workfile'</span>, <span class="string">'w'</span>)</span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'workfile'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    read_data = f.read()</span><br><span class="line">f.close()</span><br><span class="line">文件常见的读写模式</span><br><span class="line">w     以写方式打开，</span><br><span class="line">W     文件若存在，首先要清空，然后（重新）创建</span><br><span class="line">a     以追加模式打开 (从 EOF 开始, 必要时创建新文件)</span><br><span class="line">r+     以读写模式打开</span><br><span class="line">w+     以读写模式打开 (参见 w )</span><br><span class="line">a+     以读写模式打开 (参见 a )</span><br><span class="line">rb     以二进制读模式打开</span><br><span class="line">wb     以二进制写模式打开 (参见 w )</span><br><span class="line">ab     以二进制追加模式打开 (参见 a )</span><br><span class="line">rb+    以二进制读写模式打开 (参见 r+ )</span><br><span class="line">wb+    以二进制读写模式打开 (参见 w+ )</span><br><span class="line">ab+    以二进制读写模式打开 (参见 a+ )</span><br></pre></td></tr></table></figure><p><strong>6.2.1 文件读写方法</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">f.read()</span><br><span class="line">f.read(size)</span><br><span class="line">f.readline()  <span class="comment"># 读取一行</span></span><br><span class="line">f.readlines()  <span class="comment"># 读取所有行，每一行存储为列表的每一个元素</span></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> f:</span><br><span class="line">    print(line, end=<span class="string">''</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>f.write(<span class="string">'This is a test\n'</span>)</span><br><span class="line"><span class="number">15</span></span><br><span class="line">f.tell() <span class="comment"># 返回一个整数，给出文件对象在文件中的当前位置，表示为二进制模式下时从文件开始的字节数，以及文本模式下的不透明数字。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 要改变文件对象的位置，请使用 f.seek(offset, whence)。 通过向一个参考点添加 offset 来计算位置；  </span></span><br><span class="line"><span class="comment"># 参考点由 whence 参数指定。  </span></span><br><span class="line"><span class="comment"># whence 的 0 值表示从文件开头起算，1 表示使用当前文件位置，2 表示使用文件末尾作为参考点。   </span></span><br><span class="line"><span class="comment"># whence 如果省略则默认值为 0，即使用文件开头作为参考点。</span></span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>f = open(<span class="string">'workfile'</span>, <span class="string">'rb+'</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>f.write(<span class="string">b'0123456789abcdef'</span>)</span><br><span class="line"><span class="number">16</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>f.seek(<span class="number">5</span>)      <span class="comment"># Go to the 6th byte in the file</span></span><br><span class="line"><span class="number">5</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>f.read(<span class="number">1</span>)</span><br><span class="line"><span class="string">b'5'</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>f.seek(<span class="number">-3</span>, <span class="number">2</span>)  <span class="comment"># Go to the 3rd byte before the end</span></span><br><span class="line"><span class="number">13</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>f.read(<span class="number">1</span>)</span><br><span class="line"><span class="string">b'd'</span></span><br></pre></td></tr></table></figure><h3 id="6-3-常见文件类型的读取方式"><a href="#6-3-常见文件类型的读取方式" class="headerlink" title="6.3 常见文件类型的读取方式"></a>6.3 常见文件类型的读取方式</h3><ul><li><strong>csv文件</strong><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> open(<span class="string">'C:/users/lenovo/desktop/student_score.csv'</span>,<span class="string">'r'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> f.readlines(): <span class="comment">#逐行读取</span></span><br><span class="line">        print(line)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 更加高效的是使用panda读取数据，存为一个矩阵的形式</span></span><br><span class="line"><span class="keyword">import</span> panda <span class="keyword">as</span> pd</span><br><span class="line">data = pd.read_csv(sys.argv[<span class="number">1</span>])</span><br></pre></td></tr></table></figure></li><li><strong>txt文件</strong><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> open(<span class="string">'my_file.txt'</span>) <span class="keyword">as</span> f:</span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> f:      <span class="comment">#逐行读取</span></span><br><span class="line">print(line.strip())  <span class="comment">#使用strip删除空格和空行，否则会有\n在最后</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 更加高效的是使用numpy读取数据,转化一个数组</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">dataset = np.loadtxt(<span class="string">'路径'</span>)</span><br><span class="line">dataset.shape( )  <span class="comment"># 查看数组维度</span></span><br><span class="line">newset = reshape(dataset, (<span class="number">100</span>,<span class="number">3</span>))  <span class="comment"># 转化为100行 3列的数组</span></span><br></pre></td></tr></table></figure></li><li><strong>excle文件</strong><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> xlrd   <span class="comment">#使用库函数</span></span><br><span class="line"></span><br><span class="line">workbook = xlrd.open_workbook(<span class="string">'C:/users/lenovo/desktop/student_score.xlsx'</span>)  <span class="comment">#读取路径</span></span><br><span class="line">sheet = workbook.sheet_by_name(<span class="string">'Sheet1'</span>)     <span class="comment">#读取excel中的第一个sheet</span></span><br><span class="line"></span><br><span class="line">data_name = sheet.col_values(<span class="number">0</span>)    <span class="comment">#按列读取，读取第一列</span></span><br><span class="line"><span class="comment">#data_name1 = sheet.row_values(0)  #按行读取，读取第一行</span></span><br><span class="line">data_st_ID = sheet.col_values(<span class="number">1</span>)</span><br><span class="line">data_st_score = sheet.col_values(<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 更加高效的是使用panda读取数据</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">test_df = pd.read_excel(<span class="string">r'G:\test.xlsx'</span>)</span><br></pre></td></tr></table></figure></li><li><strong>mat文件</strong><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line"><span class="keyword">import</span> os </span><br><span class="line">os.chdir(<span class="string">r'F:/data'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> scipy.io <span class="keyword">as</span> scio</span><br><span class="line">data = scio.loadmat(<span class="string">'97.mat'</span>)</span><br><span class="line">print(data)</span><br><span class="line"></span><br><span class="line">de = data[<span class="string">'X097_DE_time'</span>]</span><br><span class="line"></span><br><span class="line">读取的结果是一个字典</span><br><span class="line"><span class="keyword">or</span> </span><br><span class="line"><span class="keyword">from</span> mat4py <span class="keyword">import</span> loadmat</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">data = np.array(loadmat(<span class="string">'test.mat'</span>)[<span class="string">'dictKey'</span>]).astype(<span class="string">'float'</span>)</span><br></pre></td></tr></table></figure><h3 id="6-3-使用json保存结构化数据"><a href="#6-3-使用json保存结构化数据" class="headerlink" title="6.3 使用json保存结构化数据"></a>6.3 使用json保存结构化数据</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> json</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>json.dumps([<span class="number">1</span>, <span class="string">'simple'</span>, <span class="string">'list'</span>])</span><br><span class="line"><span class="string">'[1, "simple", "list"]'</span></span><br></pre></td></tr></table></figure></li></ul><p><strong>6.3.1 将数据保存为json文件</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">model=&#123;&#125; <span class="comment">#数据</span></span><br><span class="line"><span class="keyword">with</span> open(<span class="string">"./hmm.json"</span>,<span class="string">'w'</span>,encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> json_file:</span><br><span class="line">    json.dump(model,json_file,ensure_ascii=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><p><strong>6.3.2 从json文件读取数据</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">model=&#123;&#125; <span class="comment">#存放读取的数据</span></span><br><span class="line"><span class="keyword">with</span> open(<span class="string">"./hmm.json"</span>,<span class="string">'r'</span>,encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> json_file:</span><br><span class="line">    model=json.load(json_file)</span><br><span class="line"></span><br><span class="line">读取返回的为python字典</span><br><span class="line"><span class="keyword">or</span> </span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"> </span><br><span class="line">str_file = <span class="string">'./960x540/config.json'</span></span><br><span class="line"><span class="keyword">with</span> open(str_file, <span class="string">'r'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    print(<span class="string">"Load str file from &#123;&#125;"</span>.format(str_file))</span><br><span class="line">    r = json.load(f)</span><br><span class="line">print(type(r))</span><br><span class="line">print(r)</span><br><span class="line">print(r[<span class="string">'under_game_score_y'</span>])</span><br></pre></td></tr></table></figure><h2 id="7-python标准库"><a href="#7-python标准库" class="headerlink" title="7. python标准库"></a>7. python标准库</h2><div align=" center"><img src="https://img.vim-cn.com/47/19c6e06be5f16f01de1a5d1ef6733fd9129648.png"></div><p><strong>也可以查看标准库文档</strong><br><a href="https://docs.python.org/zh-cn/3/tutorial/index.html" target="_blank" rel="noopener">https://docs.python.org/zh-cn/3/tutorial/index.html</a><br><a href="https://docs.python.org/zh-cn/3/library/index.html" target="_blank" rel="noopener">https://docs.python.org/zh-cn/3/library/index.html</a></p>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java基础（4）</title>
      <link href="/2019/11/23/java/shyjava(4)/"/>
      <url>/2019/11/23/java/shyjava(4)/</url>
      
        <content type="html"><![CDATA[<h1 id="循环"><a href="#循环" class="headerlink" title="循环"></a>循环</h1><h2 id="while循环"><a href="#while循环" class="headerlink" title="while循环"></a>while循环</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> i = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">while</span> (i &lt; <span class="number">100</span>) &#123;</span><br><span class="line">    System.out.println(“Welcome to Java!”);</span><br><span class="line">    i++;     <span class="comment">//必须有语句改变循环条件</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="do-while循环"><a href="#do-while循环" class="headerlink" title="do while循环"></a>do while循环</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">循环体至少执行一次</span></span><br><span class="line"><span class="string">"</span><span class="string">""</span></span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">statement or block</span><br><span class="line"><span class="keyword">while</span> (loop-continuation-condition);</span><br></pre></td></tr></table></figure><h2 id="for-循环"><a href="#for-循环" class="headerlink" title="for 循环"></a>for 循环</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">100</span>; i++) &#123;</span><br><span class="line">    System.out.println(“Welcome to Java!”);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span>循环头中的每个部分可以是零个或多个以逗句分隔的表达式。</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>, j = <span class="number">0</span>; i + j &lt; <span class="number">10</span>; i++, j++) &#123;</span><br><span class="line">    System.out.println(“Welcome to Java!”);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">如果<span class="keyword">for</span>循环中的loop-continuation-condition被省略，则隐含为真。</span><br><span class="line"><span class="keyword">for</span> (;;) &#123;                   <span class="keyword">while</span>(<span class="keyword">true</span>) &#123;</span><br><span class="line">    <span class="comment">//do something  等价于        //do something</span></span><br><span class="line">&#125;                            &#125;</span><br></pre></td></tr></table></figure><h2 id="break-与-continue"><a href="#break-与-continue" class="headerlink" title="break 与 continue"></a>break 与 continue</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">break</span> <span class="comment">//跳出循环</span></span><br><span class="line"><span class="keyword">continue</span> <span class="comment">//跳出当前循环，继续循环</span></span><br></pre></td></tr></table></figure><h2 id="JDK1-5-增强的for循环"><a href="#JDK1-5-增强的for循环" class="headerlink" title="JDK1.5 增强的for循环"></a>JDK1.5 增强的for循环</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">JDK <span class="number">1.5</span>引入新的<span class="keyword">for</span>循环，可以不用下标就可以依次访问数组元素。语法：</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span>(elementType value : arrayRefVar) &#123;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">例如</span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; myList.length; i++) &#123;</span><br><span class="line"> sum += myList[i];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">double</span> value : myList) &#123;</span><br><span class="line">sum += value;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java基础（3）</title>
      <link href="/2019/11/22/java/shyjava(3)/"/>
      <url>/2019/11/22/java/shyjava(3)/</url>
      
        <content type="html"><![CDATA[<h1 id="Shy-Learnjava（3）基础"><a href="#Shy-Learnjava（3）基础" class="headerlink" title="Shy-Learnjava（3）基础"></a>Shy-Learnjava（3）基础</h1><h2 id="3-数学函数、字符与字符串"><a href="#3-数学函数、字符与字符串" class="headerlink" title="3 数学函数、字符与字符串"></a>3 数学函数、字符与字符串</h2><h3 id="3-1-数学函数"><a href="#3-1-数学函数" class="headerlink" title="3.1 数学函数"></a>3.1 数学函数</h3><p><strong>Math是final类：在java.lang.Math中，所有数学函数都是静态方法</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># Math类中定义了常用的数学常量，如</span><br><span class="line">PI : <span class="number">3.14159265358979323846</span></span><br><span class="line">E : <span class="number">2.7182818284590452354</span></span><br><span class="line"># 方法:注意都是静态函数</span><br><span class="line"># 三角函数</span><br><span class="line">sin, cos, tan, asin, acos, atan,toRadians,toDigrees</span><br><span class="line"># 指数</span><br><span class="line">exp, log, log10，pow, sqrt</span><br><span class="line"># 取整</span><br><span class="line">ceil, floor, round</span><br><span class="line"># 其它</span><br><span class="line">min, max, abs, random（[<span class="number">0.0</span>,<span class="number">1.0</span>))</span><br></pre></td></tr></table></figure></p><p><strong>Math.random方法生成[0.0,1.0)之间的double类型的随机数</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">如：</span><br><span class="line">（<span class="keyword">int</span>）(Math.random( )*<span class="number">10</span>);<span class="comment">//[0,10)</span></span><br><span class="line"><span class="number">50</span>+(<span class="keyword">int</span>)(Math.random( )*<span class="number">50</span>);<span class="comment">//[50,100)</span></span><br><span class="line">一般地</span><br><span class="line">a+(<span class="keyword">int</span>)(Math.random( )*b)              <span class="comment">//返回[a, a+b)</span></span><br><span class="line">a+(<span class="keyword">int</span>)(Math.random( )*（b+<span class="number">1</span>）)       <span class="comment">//返回[a, a+b]</span></span><br></pre></td></tr></table></figure><br><strong>编写生成随机字符的方法</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">Java中每个字符对应一个Unicode编码从<span class="number">0000</span>到FFFF。  </span><br><span class="line">在生成一个随机字符，就是产生一个从<span class="number">0</span>到<span class="number">65535</span>之间的随机数。  </span><br><span class="line">所以, 计算表达式为：</span><br><span class="line"></span><br><span class="line">(<span class="keyword">int</span>)(Math.random( ) * (<span class="number">65535</span> + <span class="number">1</span>)) 。</span><br><span class="line"></span><br><span class="line">英文大、小写字母的Unicode是一串连续的整数，如</span><br><span class="line">‘a’的统一码是:   </span><br><span class="line">(<span class="keyword">int</span>)‘a’=<span class="number">97</span></span><br><span class="line">由于<span class="keyword">char</span>类型可自动地被转换为<span class="keyword">int</span>类型，所以我们可以对应使用如下整数值：</span><br><span class="line">‘a’=<span class="number">97</span>, ‘b’=<span class="number">98</span>， …, ‘z’=<span class="number">122</span></span><br><span class="line"></span><br><span class="line">因此，随机生成从‘a’-‘z’之间的字符就等于生成‘a’-‘z’之间的随机数，可用</span><br><span class="line">‘a’+（<span class="keyword">int</span>）(Math.Random( ) * (‘z’-’a’+<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">将上面讨论一般化，按如下表达式，可以生成任意<span class="number">2</span>个字符ch1和ch2（ch1&lt;ch2）之间的随机字符</span><br><span class="line"></span><br><span class="line">(<span class="keyword">char</span>)(ch1+(<span class="keyword">int</span>)(Math.rabdom()*(ch2-ch1+<span class="number">1</span>)))</span><br></pre></td></tr></table></figure></p><h3 id="3-2-字符数据类型"><a href="#3-2-字符数据类型" class="headerlink" title="3.2 字符数据类型"></a>3.2 字符数据类型</h3><p><strong>Unicode和ASCII码</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Java对字符采用<span class="number">16</span>位Unicode编码，因此<span class="keyword">char</span>类型的大小为二个字节</span><br><span class="line"><span class="number">16</span>位的Unicode用以\u开头的<span class="number">4</span>位<span class="number">16</span>进制数表示，范围从’\u0000’到’\uffff’,不能少写位数</span><br><span class="line">Unicode包括ASCII码，从’\u0000’到’\u007f’对应<span class="number">128</span>个ASCII字符</span><br><span class="line">JAVA中的ASCII字符也可以用Unicode表示，例如</span><br><span class="line"><span class="keyword">char</span> letter = ‘A’；</span><br><span class="line"><span class="keyword">char</span> letter = ‘\u0041’；<span class="comment">//等价，\u后面必须写满4位16进制数</span></span><br><span class="line">++和--运算符也可以用在<span class="keyword">char</span>类型数据上，运算结果为该字符之后或之前的字符，例如下面的语句显示字符b</span><br><span class="line"><span class="keyword">char</span> ch = ‘a’;</span><br><span class="line">System.out.println(++ch);  <span class="comment">//显示b</span></span><br></pre></td></tr></table></figure><br><strong>特殊字符转义</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">和C++一样，采用反斜杠(\)后面加上一个字符或者一些数字位组成转义序列，一个转义序列被当做一个字符</span><br><span class="line">如\n  \t  \b  \r  \f  \\  \<span class="string">'  \"</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">如果想打印带””的信息 He said “Java is fun “</span></span><br><span class="line"><span class="string">System.out.println(“He said \”Java is fun \””);</span></span><br></pre></td></tr></table></figure><br><strong>字符型和数据型的转换</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">char</span>类型数据可以转换成任意一种数值类型，反之亦然。将整数转换成<span class="keyword">char</span>类型数据时，只用到该数据的低<span class="number">16</span>位，其余被忽略。例如</span><br><span class="line"><span class="keyword">char</span> ch = （<span class="keyword">char</span>）<span class="number">0xAB0041</span>；</span><br><span class="line">       System.out.println(ch);<span class="comment">//显示A</span></span><br><span class="line">要将浮点数转成<span class="keyword">char</span>时，先把浮点数转成<span class="keyword">int</span>型，然后将整数转换成<span class="keyword">char</span></span><br><span class="line">       <span class="keyword">char</span> ch = （<span class="keyword">char</span>）<span class="number">65.25</span>；</span><br><span class="line">       System.out.println(ch);<span class="comment">//显示A</span></span><br><span class="line">当一个<span class="keyword">char</span>型转换成数值型时，这个字符的Unicode码就被转换成某种特定数据类型</span><br><span class="line">       <span class="keyword">int</span> i = （<span class="keyword">int</span>）‘A’；</span><br><span class="line">       System.out.println(i);<span class="comment">//显示65</span></span><br><span class="line"></span><br><span class="line">如果转换结果适用于目标变量（不会有精度损失），可以采用隐式转换；否则必须强制类型转换</span><br><span class="line"> <span class="keyword">int</span> i = ‘A’；</span><br><span class="line"> <span class="keyword">byte</span> b = （<span class="keyword">byte</span>）‘\uFFF4’;  <span class="comment">//取低8位二进制数</span></span><br><span class="line">所有数值运算符都可以用在<span class="keyword">char</span>型操作数上，  </span><br><span class="line">如果另一个操作数是数值，那么<span class="keyword">char</span>型操作数就自动转换为数值；  </span><br><span class="line">如果另外一个操作数是字符串，那么<span class="keyword">char</span>型操作数会自动转换成字符串再和另外一个操作数字符串相连</span><br><span class="line">      <span class="keyword">int</span> i = ‘<span class="number">2</span>’+ ‘<span class="number">3</span>’;</span><br><span class="line">      System.out.println（i）；  <span class="comment">// i为50+51=101</span></span><br><span class="line">      <span class="keyword">int</span> j = <span class="number">2</span> + ‘a’；       <span class="comment">//j = 99</span></span><br><span class="line">      System.out.println(j + “ is the Unicode of ”+ (<span class="keyword">char</span>)j);<span class="comment">//99 is the Unicode of  c</span></span><br></pre></td></tr></table></figure><br><strong>字符的比较测试</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">两个字符可以通过关系运算符进行比较，如同比较二个数值：通过字符的Unicode值进行比较</span><br><span class="line">Java为每个基本类型实现了对应的包装类，<span class="keyword">char</span>类型的包装类是Character类。注意包装类对象为引用类型，不是值类型</span><br><span class="line">Character类的作用</span><br><span class="line">将<span class="keyword">char</span>类型的数据封装成对象</span><br><span class="line">包含处理字符的方法和常量</span><br><span class="line">方法</span><br><span class="line">isDigit方法判断一个字符是否是数字</span><br><span class="line">isLetter方法判断一个字符是否是字母</span><br><span class="line">isLetterOrDigit方法判断一个字符是否是字母或数字</span><br><span class="line">isLowerCase方法判断一个字符是否是小写</span><br><span class="line">isUpperCase方法判断一个字符是否是大写</span><br><span class="line">toLowerCase方法将一个字符转换成小写</span><br><span class="line">toUpperCase方法将一个字符转换成大写</span><br></pre></td></tr></table></figure></p><h2 id="3-3-String-类，一个final类"><a href="#3-3-String-类，一个final类" class="headerlink" title="3.3 String 类，一个final类"></a>3.3 String 类，一个final类</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">java.lang.String表示一个固定长度的字符序列，实例化后字符不能改。</span><br><span class="line">构造函数</span><br><span class="line">长度(length)</span><br><span class="line">获取字符(charAt)</span><br><span class="line">连接(concat)</span><br><span class="line">截取(substring)</span><br><span class="line">比较(equals, equalsIgnoreCase, compareTo, startWith),</span><br><span class="line">endWith, regionMatch)</span><br><span class="line">转换(toLowerCase, toUpperCase, trim, replace)</span><br><span class="line">查找(indexOf, lastIndexOf)</span><br><span class="line">字符串和数组间转换(getChars, toCharArray), getChars返回<span class="keyword">void</span>,超出长度就异常</span><br><span class="line">字符串和数字间转换(valueOf)</span><br></pre></td></tr></table></figure><p><strong>String类对象的构造</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">从字面值创建字符串</span><br><span class="line">String newString = <span class="keyword">new</span> String(stringLiteral);</span><br><span class="line">例如：</span><br><span class="line">String message = <span class="keyword">new</span> String(<span class="string">"Welcome to Java"</span>);</span><br><span class="line">由于字符串经常使用，java提供了创建字符串的简写形式。</span><br><span class="line">String newString = stringLiteral;</span><br><span class="line">例如：</span><br><span class="line">String m1 = “Welcome”;  <span class="comment">//m1和m2中的字符都是不可修改的</span></span><br><span class="line">String m2 = “Welcome”;  <span class="comment">//故m1和m2可以优化引用同一常量：m1==m2</span></span><br><span class="line">String m3 = <span class="string">"Wel"</span> +<span class="string">"come"</span>;<span class="comment">//m1==m2==m3  </span></span><br><span class="line">String m4 = <span class="string">"Wel"</span> +<span class="keyword">new</span> String(<span class="string">"come"</span>); <span class="comment">//m1!=m4</span></span><br><span class="line"></span><br><span class="line">字符串对象创建之后，其内容是不可修改的。</span><br><span class="line">String s = “java”;</span><br><span class="line">s = “HTML”;</span><br><span class="line">String t =s;</span><br></pre></td></tr></table></figure></p><p><strong>字符串的比较</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">equals方法用于比较两个字符串是否包含相同的内容（字符序列）:</span><br><span class="line">两个字符串内容相同，返回<span class="keyword">true</span></span><br><span class="line">两个字符串内容不同，返回<span class="keyword">false</span></span><br><span class="line">比较字符串内容不能直接比较二个引用变量，比较二个引用变量只是判断这二个引用变量是否指向同一个对象</span><br><span class="line">equalsIngnoeCase忽略大小写比较内容是否相同</span><br><span class="line">regionMatch比较部分内容是否相同</span><br><span class="line">startsWith判断是否以某个字符串开始</span><br><span class="line">endsWith判断是否以某个字符串结束</span><br><span class="line">compareTo方法用于比较两个字符串的大小，即第一个不同字符的差值。s1.compareTo(s2)的返回值:</span><br><span class="line">当两个字符串相同时，返回０</span><br><span class="line">当s1按字典排序在s2之前，返回小于０的值</span><br><span class="line">当s1按字典排序在s2之后，返回大于０的值</span><br><span class="line">String s0 = <span class="string">"Java"</span>;</span><br><span class="line">String s1 = <span class="string">"Welcome to "</span> + s0;</span><br><span class="line">String s2 = <span class="string">"Welcome to Java"</span>;</span><br><span class="line">String s3 = <span class="string">"welcome to java"</span>;</span><br><span class="line">String s6 = <span class="string">"Welcome to Java"</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// equals用于比较两个字符串的内容是否相同</span></span><br><span class="line">System.out.println(<span class="string">"s1.equals(s2) is "</span> + s1.equals(s2)); <span class="comment">//true</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// equalsIgnoreCase忽略大小写</span></span><br><span class="line">System.out.println(<span class="string">"s2.equals(s3) is "</span> + s2.equals(s3)); <span class="comment">//false</span></span><br><span class="line">System.out.println(<span class="string">"s2.equalsIgnoreCase(s3) is "</span> + s2.equalsIgnoreCase(s3)); <span class="comment">//true</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// regionMatches比较部分字符串: 给定两个串的起始位置和长度</span></span><br><span class="line">System.out.println(<span class="string">"s2.regionMatches(11, s0, 0, 4) is "</span> + s2.regionMatches(<span class="number">11</span>, s0, <span class="number">0</span>, <span class="number">4</span>)); <span class="comment">//true</span></span><br><span class="line">System.out.println(<span class="string">"s3.regionMatches(11, s0, 0, 4) is "</span> + s3.regionMatches(<span class="number">11</span>, s0, <span class="number">0</span>, <span class="number">4</span>));<span class="comment">//false</span></span><br><span class="line">System.out.println(<span class="string">"s3.regionMatches(true, 11, s0, 0, 4) is "</span> + s3.regionMatches(<span class="keyword">true</span>, <span class="number">11</span>, s0, <span class="number">0</span>, <span class="number">4</span>));<span class="comment">//true,忽略大小写</span></span><br><span class="line">String s0 = <span class="string">"Java"</span>;</span><br><span class="line">String s1 = <span class="string">"Welcome to "</span> + s0;</span><br><span class="line">String s2 = <span class="string">"Welcome to Java"</span>;</span><br><span class="line">String s3 = <span class="string">"welcome to java"</span>;</span><br><span class="line">String s6 = <span class="string">"Welcome to Java"</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// startsWith判断是否以某个字符串开始</span></span><br><span class="line"><span class="comment">// endsWith判断是否以某个字符串结束</span></span><br><span class="line">System.out.println(<span class="string">"s2.startsWith(s0) is "</span> + s2.startsWith(s0));<span class="comment">//false</span></span><br><span class="line">System.out.println(<span class="string">"s2.endsWith(s0) is "</span> + s2.endsWith(s0));  <span class="comment">//true</span></span><br><span class="line">        </span><br><span class="line"><span class="comment">// compareTo根据字典排序比较两个字符串</span></span><br><span class="line">String s4 = <span class="string">"abc"</span>;</span><br><span class="line">String s5 = <span class="string">"abe"</span>;</span><br><span class="line">System.out.println(<span class="string">"s4.compareTo(s5) is "</span> + s4.compareTo(s5));<span class="comment">//-2</span></span><br></pre></td></tr></table></figure><br><strong>字符串方法</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">调用length( )方法可以获取字符串的长度。</span><br><span class="line">例如：</span><br><span class="line">message.length( )返回<span class="number">15</span></span><br><span class="line">charAt(index)方法可以获取指定位置的字符。index必须在<span class="number">0</span>到s.length()-<span class="number">1</span>之间。</span><br><span class="line">例如：</span><br><span class="line">message.charAt(<span class="number">0</span>)返回字符’W’</span><br><span class="line">concat方法用于连接两个字符串。例如：</span><br><span class="line">String s3 = s1.concat(s2);</span><br><span class="line">使用加号(+)连接两个字符串。例如：</span><br><span class="line">String s3 = s1 + s2;</span><br><span class="line">s1 + s2 + s3 等价于s1.concat(s2).concat(s3)</span><br><span class="line">连接操作返回一个新的字符串：因为String类型的实例不可修改。</span><br><span class="line">substring用于截取字符串的一部分，返回新字符串。</span><br><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">substring</span><span class="params">(<span class="keyword">int</span> beginIndex, <span class="keyword">int</span> endIndex)</span></span></span><br><span class="line"><span class="function">返回字符串的子串。子串从beginIndex开始，直到endIndex-1</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">substring</span><span class="params">(<span class="keyword">int</span> beginIndex)</span></span></span><br><span class="line"><span class="function">返回字符串的子串。子串从beginIndex开始，直到字符串的结尾。</span></span><br><span class="line"><span class="function">toLowerCase将字符串转换成小写形式，得到新串</span></span><br><span class="line"><span class="function">toUpperCase将字符串转换成大写形式，得到新串</span></span><br><span class="line"><span class="function">trim删除两端的空格，得到新串</span></span><br><span class="line"><span class="function">replace字符替换，得到新串</span></span><br><span class="line"><span class="function">String s0 </span>= <span class="string">"Java"</span>;</span><br><span class="line">String s1 = <span class="string">" Welcome to Java "</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// toLowerCase将字符串转换成小写形式</span></span><br><span class="line">System.out.println(<span class="string">"s1.toLowerCase() is "</span> + s1.toLowerCase());</span><br><span class="line">        </span><br><span class="line"><span class="comment">// toUpperCase将字符串转换成大写形式</span></span><br><span class="line">System.out.println(<span class="string">"s1.toUpperCase() is "</span> + s1.toUpperCase());</span><br><span class="line">        </span><br><span class="line"><span class="comment">// trim删除两端的空格</span></span><br><span class="line">System.out.println(<span class="string">"s1.trim() is "</span> + s1.trim( ));</span><br><span class="line">        </span><br><span class="line"><span class="comment">// replace字符替换</span></span><br><span class="line">System.out.println(“s1.replace(s0, \”HTML\“) is ” + s1.replace(s0, “HTML”)); <span class="comment">//Welcome to HTML</span></span><br><span class="line"><span class="comment">// indexOf返回字符串中字符或字符串匹配的位置，返回-1表示未找到。</span></span><br><span class="line"><span class="string">"Welcome to Java"</span>.indexOf(<span class="string">'W'</span>) returns <span class="number">0</span></span><br><span class="line"><span class="string">"Welcome to Java"</span>.indexOf(<span class="string">'x'</span>) returns -<span class="number">1</span></span><br><span class="line"><span class="string">"Welcome to Java"</span>.indexOf(<span class="string">'o‘,5) returns 9</span></span><br><span class="line"><span class="string">"Welcome to Java".indexOf("come") returns 3</span></span><br><span class="line"><span class="string">"Welcome to Java".indexOf("Java", 5) returns 11</span></span><br><span class="line"><span class="string">"Welcome to Java".indexOf("java", 5) returns -1</span></span><br><span class="line"><span class="string">"Welcome to Java".lastIndexOf('</span>a<span class="string">') returns 14</span></span><br></pre></td></tr></table></figure><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">toCharArray将字符串转换成字符数组</span><br><span class="line">String s = “Java”;</span><br><span class="line"><span class="keyword">char</span>[ ] charArray = s.toCharArray( );<span class="comment">// charArray.length=4</span></span><br><span class="line">将字符数组转换成字符串</span><br><span class="line">使用String的构造函数，可同时初始化</span><br><span class="line"><span class="keyword">new</span> String(<span class="keyword">new</span> <span class="keyword">char</span>[ ] &#123;‘J’,‘a’,‘v’,‘a’&#125; );</span><br><span class="line">使用valueOf方法</span><br><span class="line">String.valueOf(<span class="keyword">new</span> <span class="keyword">char</span>[ ] &#123;‘J’,‘a’,‘v’,‘a’&#125;);</span><br><span class="line">String.valueOf(<span class="number">2.34</span>);</span><br><span class="line">valueOf方法将基本数据类型转换为字符串。例如</span><br><span class="line">String s1 = String.valueOf(<span class="number">1.0</span>);  <span class="comment">//“１.0”</span></span><br><span class="line">String s2 = String.valueOf(<span class="keyword">true</span>); <span class="comment">//“true”</span></span><br><span class="line">字符串转换为基本类型</span><br><span class="line">Double.parseDouble(str)</span><br><span class="line">Integer.parseInt(str)</span><br><span class="line">Boolean.parseBoolean(str)</span><br><span class="line">回文是指顺读和倒读都一样的词语。例如“mom”,  “dad”, ”noon”都是回文。编写程序，判断一个字符串是否是回文。</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CheckPalindrome</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">boolean</span> <span class="title">isPalindrome</span><span class="params">(String s)</span> </span>&#123;</span><br><span class="line"><span class="comment">// The index of the first character in the string</span></span><br><span class="line"><span class="keyword">int</span> low = <span class="number">0</span>;</span><br><span class="line"><span class="comment">// The index of the last character in the string</span></span><br><span class="line"><span class="keyword">int</span> high = s.length( ) - <span class="number">1</span>;</span><br><span class="line"><span class="keyword">while</span> (low &lt; high) &#123;</span><br><span class="line"><span class="keyword">if</span> (s.charAt(low) != s.charAt(high)) <span class="keyword">return</span> <span class="keyword">false</span>; <span class="comment">// Not a palindrome</span></span><br><span class="line">low++;</span><br><span class="line">high--;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> <span class="keyword">true</span>; <span class="comment">// The string is a palindrome</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CheckPalindrome</span> </span>&#123;</span><br><span class="line"><span class="comment">/** Main method */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line"><span class="comment">// Prompt the user to enter a string</span></span><br><span class="line">String s = JOptionPane.showInputDialog(<span class="string">"Enter a string:"</span>);</span><br><span class="line">String output = <span class="string">""</span>;</span><br><span class="line"><span class="keyword">if</span> (isPalindrome(s))</span><br><span class="line">output = s + <span class="string">" is a palindrome"</span>;</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">output = s + <span class="string">" is not a palindrome"</span>;</span><br><span class="line"><span class="comment">// Display the result</span></span><br><span class="line">JOptionPane.showMessageDialog(<span class="keyword">null</span>, output);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br><strong>StringBuilder与StringBuffer</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line">String类一旦初始化完成，字符串就是不可修改的。</span><br><span class="line">StringBuilder与StringBuffer(<span class="keyword">final</span>类）初始化后还可以修改字符串。</span><br><span class="line">StringBuffer修改缓冲区的方法是同步的，更适合多任务环境。</span><br><span class="line">StringBuilder在单任务模式下与StringBuffer工作机制类似。</span><br><span class="line">由于可修改字符串， StringBuilder 与StringBuffer 增加了String类没有的一些函数，例如：append、insert、delete、replace、reverse、setCharAt等。</span><br><span class="line">仅以StringBuilder为例：</span><br><span class="line">StringBuilder  stringMy=<span class="keyword">new</span> StringBuilder( );</span><br><span class="line">StringMy.append(“Welcome to”);</span><br><span class="line">      StringMy.append(“ Java”);</span><br><span class="line">StringBuffer用于处理可变内容的字符串。</span><br><span class="line">append方法在字符串的结尾追加数据</span><br><span class="line">insert方法在指定位置上插入数据</span><br><span class="line">reverse方法翻转字符串</span><br><span class="line">replace方法替换字符</span><br><span class="line">toString方法返回String对象</span><br><span class="line">capacity方法返回缓冲区的容量</span><br><span class="line">length方法返回缓冲区中字符的个数</span><br><span class="line">setLength方法设置缓冲区的长度</span><br><span class="line">charAt方法返回指定位置的字符</span><br><span class="line">setCharAt方法设置指定位置的字符</span><br><span class="line">所有对StringBuffer对象内容进行修改的方法，都返回指向相同StringBuffer对象的引用</span><br><span class="line">StringBuffer bf = <span class="keyword">new</span> StringBuffer();</span><br><span class="line">StringBuffer bf1 = bf.append(<span class="string">"Welcome "</span>); </span><br><span class="line">StringBuffer bf2 = bf.append(<span class="string">"to "</span>);</span><br><span class="line">StringBuffer bf3 = bf.append(<span class="string">"Java"</span>);</span><br><span class="line"><span class="keyword">assert</span>(bf==bf1 &amp;&amp; bf==bf2 &amp;&amp; bf == bf3);</span><br><span class="line">因此以上语句可以直接写成：</span><br><span class="line">bf.append(<span class="string">"Welcome "</span>).append(<span class="string">"to "</span>).append(<span class="string">"Java"</span>);</span><br><span class="line"><span class="comment">// 追加</span></span><br><span class="line">StringBuffer bf = <span class="keyword">new</span> StringBuffer();</span><br><span class="line">bf.append(“Welcome”);</span><br><span class="line">bf.append(‘ ‘);</span><br><span class="line">bf.append(“to ”);</span><br><span class="line">bf.append(“Java”);</span><br><span class="line">System.out.println(bf.toString()); <span class="comment">//Welcome to Java</span></span><br><span class="line"><span class="comment">//插入</span></span><br><span class="line">bf.insert(<span class="number">11</span>,”HTML and ”) <span class="comment">//Welcome to HTML and JAVA</span></span><br><span class="line"><span class="comment">//删除</span></span><br><span class="line">bf.delete(<span class="number">8</span>,<span class="number">11</span>); <span class="comment">//Welcome Java</span></span><br><span class="line">bf.deleteCharAt(<span class="number">8</span>);<span class="comment">//Welcome o Java</span></span><br><span class="line">bf.reverse(); <span class="comment">//avaJ ot emocleW</span></span><br><span class="line">bf.replace（<span class="number">11</span>，<span class="number">15</span>，“HTML”）;<span class="comment">//Welcome to HTML</span></span><br><span class="line">bf.setCharAt(<span class="number">0</span>,’w’);<span class="comment">//welcome to java</span></span><br><span class="line"></span><br><span class="line">toString(): 从缓冲区返回字符串</span><br><span class="line">capacity()：返回缓冲区容量。length &lt;= capacity</span><br><span class="line">    当字符串长度超过缓冲区容量，capacity会自动增加</span><br><span class="line">length()：返回缓冲区中字符数量</span><br><span class="line">setLength(newLength)：设置缓冲区长度</span><br><span class="line">charAt(index)：返回下标为index的字符</span><br><span class="line"></span><br><span class="line"><span class="comment">// 编写程序，检查回文，并忽略不是字母和数字的字符。</span></span><br><span class="line">解决方案</span><br><span class="line">创建一个新的StringBuffer，将字符串的字母和数字添加到StringBuffer中，返回过滤后的String对象。</span><br><span class="line">翻转过滤后的字符串，并与过滤后的字符串进行比较，如果内容相同则是回文。</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">boolean</span> <span class="title">isPalindrome</span><span class="params">(String s)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Create a new string that is the reversal of s</span></span><br><span class="line">String s2 = reverse(s);</span><br><span class="line"><span class="comment">// Compare if the reversal is the same as the original stringreturn s2.equals(s);</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">reverse</span><span class="params">(String s)</span> </span>&#123;</span><br><span class="line">StringBuffer strBuf = <span class="keyword">new</span> StringBuffer(s);</span><br><span class="line">strBuf.reverse();</span><br><span class="line"><span class="keyword">return</span> strBuf.toString();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h2 id="3-4-格式化控制台输入输出"><a href="#3-4-格式化控制台输入输出" class="headerlink" title="3.4 格式化控制台输入输出"></a>3.4 格式化控制台输入输出</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">JDK1<span class="number">.5</span>提供了格式化控制台输出方法</span><br><span class="line">System.out.printf(format, item1, item2, …);</span><br><span class="line">格式化字符串</span><br><span class="line">String.format(format, item1, item2, …);</span><br><span class="line">格式描述符</span><br><span class="line">%b 布尔值</span><br><span class="line">%c 字符</span><br><span class="line">%d 十进制整数</span><br><span class="line">%f 浮点数</span><br><span class="line">%e 科学计数法</span><br><span class="line">%s 字符串</span><br><span class="line">String.format(“格式$：%<span class="number">1</span>$d,%<span class="number">2</span>$s”, <span class="number">99</span>,“abc”); <span class="comment">//结果”格式$：99，abc“</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestPrintf</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        System.out.printf(<span class="string">"boolean : %6b\n"</span>, <span class="keyword">false</span>);</span><br><span class="line">        System.out.printf(<span class="string">"boolean : %6b\n"</span>, <span class="keyword">true</span>);</span><br><span class="line">        System.out.printf(<span class="string">"character : %4c\n"</span>, <span class="string">'a'</span>);</span><br><span class="line">        System.out.printf(<span class="string">"integer : %6d, %6d\n"</span>, <span class="number">100</span>, <span class="number">200</span>);</span><br><span class="line">        System.out.printf(<span class="string">"double : %7.2f\n"</span>, <span class="number">12.345</span>);</span><br><span class="line">        System.out.printf(<span class="string">"String : %7s\n"</span>, <span class="string">"hello"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java基础（2）</title>
      <link href="/2019/11/21/java/shyjava(2)/"/>
      <url>/2019/11/21/java/shyjava(2)/</url>
      
        <content type="html"><![CDATA[<h1 id="Shy-Learnjava（2）基础"><a href="#Shy-Learnjava（2）基础" class="headerlink" title="Shy-Learnjava（2）基础"></a>Shy-Learnjava（2）基础</h1><h2 id="2-选择"><a href="#2-选择" class="headerlink" title="2 选择"></a>2 选择</h2><h3 id="2-1-布尔类型和逻辑运算符"><a href="#2-1-布尔类型和逻辑运算符" class="headerlink" title="2.1 布尔类型和逻辑运算符"></a>2.1 布尔类型和逻辑运算符</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">boolean</span>类型的值有真(<span class="keyword">true</span>)或假(<span class="keyword">false</span>)。</span><br><span class="line">关系运算符: &lt;, &lt;=, &gt;, &gt;=, ==, !=</span><br><span class="line">关系运算符的计算结果是<span class="keyword">boolean</span>类型</span><br><span class="line"><span class="keyword">boolean</span>类型不能与其它数据类型混合运算</span><br><span class="line">布尔运算符: !, &amp;&amp;, ||, ^, &amp;, | </span><br><span class="line">&amp;&amp; , ||为条件逻辑运算符: (x&gt;<span class="number">0</span>) &amp;&amp; (x&lt;<span class="number">9</span>)</span><br><span class="line">&amp;，|为无条件逻辑运算符，同时也是位操作符</span><br><span class="line">^ 异或</span><br></pre></td></tr></table></figure><div align = center><img src = "https://img.vim-cn.com/80/4f17375d3236c4af37f9a0803b9272b11b99c5.png"></div><h3 id="2-2-if语句"><a href="#2-2-if语句" class="headerlink" title="2.2 if语句"></a>2.2 if语句</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (radius &gt;= <span class="number">0</span>) &#123;</span><br><span class="line">  area = radius * radius * PI;</span><br><span class="line">  System.out.println(<span class="string">"The area for the circle of radius "</span> </span><br><span class="line">    + radius + <span class="string">" is "</span> + area);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (radius &gt;= <span class="number">0</span>) &#123;   </span><br><span class="line">  area = radius * radius * <span class="number">3.14159</span>;</span><br><span class="line">  System.out.println(<span class="string">"The area for the circle of radius "</span> </span><br><span class="line">    + radius + <span class="string">" is "</span> + area);</span><br><span class="line">&#125; </span><br><span class="line"><span class="keyword">else</span> &#123;  System.out.println(<span class="string">"Negative input"</span>);   &#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (score &gt; <span class="number">90.0</span>)</span><br><span class="line">    grade = ‘A’;</span><br><span class="line"><span class="keyword">else</span> <span class="keyword">if</span> (score &gt;= <span class="number">80.0</span>)</span><br><span class="line">    grade = ‘B’;</span><br><span class="line"><span class="keyword">else</span> <span class="keyword">if</span> (scroe &gt;= <span class="number">70.0</span>)</span><br><span class="line">    grade = ‘C’;</span><br><span class="line"><span class="keyword">else</span> <span class="keyword">if</span> (score &gt;= <span class="number">60.0</span>)</span><br><span class="line">    grade = ‘D’;</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    grade = ‘F’</span><br><span class="line"></span><br><span class="line"><span class="comment">// 高手的if</span></span><br><span class="line"><span class="keyword">if</span> (number % <span class="number">2</span> == <span class="number">0</span>)</span><br><span class="line">    even = <span class="keyword">true</span>;</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    even = <span class="keyword">false</span>;<span class="comment">//新手</span></span><br><span class="line">等价于</span><br><span class="line">even = (number % <span class="number">2</span> == <span class="number">0</span>);<span class="comment">//高手</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (even == <span class="keyword">true</span>)</span><br><span class="line">    System.out.println(“It is even.”);</span><br><span class="line">等价于</span><br><span class="line"><span class="keyword">if</span> (even)</span><br><span class="line">    System.out.println(“It is even.”);</span><br></pre></td></tr></table></figure><h3 id="2-3-条件语句"><a href="#2-3-条件语句" class="headerlink" title="2.3 条件语句"></a>2.3 条件语句</h3><ul><li><p>swith语句</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">switch</span>(expression) &#123;</span><br><span class="line">    <span class="keyword">case</span> value1 : </span><br><span class="line">        statement(s)</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">case</span> value2 : </span><br><span class="line">        statement(s)</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">    …</span><br><span class="line">    <span class="keyword">default</span> : </span><br><span class="line">        statement(s)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>条件表达式</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">max = (num1 &gt; num2) ? num1 : num2;</span><br></pre></td></tr></table></figure><h3 id="2-4-操作符的优先级和表达式规则"><a href="#2-4-操作符的优先级和表达式规则" class="headerlink" title="2.4 操作符的优先级和表达式规则"></a>2.4 操作符的优先级和表达式规则</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">括号优先级最高，如果括号有嵌套，内部括号优先执行。</span><br><span class="line">如果没有括号，则根据操作符的优先级和结合规则确定执行顺序。</span><br><span class="line">如果相邻的操作符有相同的优先级，则根据结合规则确定执行顺序。</span><br><span class="line">除赋值运算符之外的二元运算符都是左结合的。</span><br><span class="line">赋值运算符和?:运算符是右结合的。</span><br><span class="line">例如：</span><br><span class="line">a+b-c+d  等价于 ((a+b)-c)+d</span><br><span class="line">a=b+=c=<span class="number">5</span> 等价于 a=(b+=(c=<span class="number">5</span>))</span><br><span class="line"></span><br><span class="line">操作符的优先级和结合规则只规定了操作符的执行顺序。操作数从左至右进行运算。</span><br><span class="line">二元操作符左边的操作数比右边的操作数优先运算。例如：</span><br><span class="line"><span class="keyword">int</span> a = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">int</span> x = a + (++a);</span><br><span class="line">x的结果为<span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> a = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">int</span> x = (++a) + a;</span><br><span class="line">x的结果为<span class="number">2</span></span><br></pre></td></tr></table></figure></li><li>表达式规则<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">规则</span><br><span class="line">可能的情况下，从左向右计算所有子表达式</span><br><span class="line">根据运算符的优先级进行运算</span><br><span class="line">优先级相同的运算符，根据结合方向进行运算</span><br><span class="line"><span class="number">3</span> + <span class="number">4</span> * <span class="number">4</span> &gt; <span class="number">5</span> * (<span class="number">4</span> + <span class="number">3</span>) - <span class="number">1</span> 的执行顺序为：</span><br><span class="line"> <span class="number">3</span> + <span class="number">4</span> * <span class="number">4</span> &gt; <span class="number">5</span> * (<span class="number">4</span> + <span class="number">3</span>) - <span class="number">1</span> </span><br><span class="line"> <span class="number">3</span> + <span class="number">4</span> * <span class="number">4</span> &gt; <span class="number">5</span> * <span class="number">7</span> – <span class="number">1</span></span><br><span class="line"> <span class="number">3</span> + <span class="number">16</span> &gt; <span class="number">5</span> * <span class="number">7</span> – <span class="number">1</span></span><br><span class="line"> <span class="number">3</span> + <span class="number">16</span> &gt; <span class="number">35</span> – <span class="number">1</span></span><br><span class="line"> <span class="number">19</span> &gt; <span class="number">35</span> – <span class="number">1</span></span><br><span class="line"> <span class="number">19</span> &gt; <span class="number">34</span></span><br><span class="line"> <span class="keyword">false</span></span><br></pre></td></tr></table></figure></li></ul>]]></content>
      
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java基础（1）</title>
      <link href="/2019/11/20/java/shyjava(1)/"/>
      <url>/2019/11/20/java/shyjava(1)/</url>
      
        <content type="html"><![CDATA[<p><strong>从今天开始复习java</strong></p><h1 id="Shy-Learnjava（1）基础"><a href="#Shy-Learnjava（1）基础" class="headerlink" title="Shy-Learnjava（1）基础"></a>Shy-Learnjava（1）基础</h1><h2 id="0-编程风格"><a href="#0-编程风格" class="headerlink" title="0 编程风格"></a>0 编程风格</h2><ul><li><strong>注释</strong><ol><li>类和方法前使用文档注释</li><li>方法步骤前使用行注释。</li></ol></li><li><strong>命名</strong><ol><li>变量和方法名使用小写，如果有多个单词，第一个单词首字母小写，其它单词首字母大写。</li><li>类名的每个单词的首字母大写。</li><li>常量使用大写，单词间以下划线分隔。</li><li>缩进、空格、块样式（在eclipse中使用ctrl+shift+f）</li></ol></li></ul><h2 id="1-基本程序设计"><a href="#1-基本程序设计" class="headerlink" title="1 基本程序设计"></a>1 基本程序设计</h2><ul><li>编写一个程序<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ComputeArea</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span></span>&#123;</span><br><span class="line">        <span class="keyword">double</span> raidus;</span><br><span class="line">        <span class="keyword">double</span> area;</span><br><span class="line">        area = radius * raidus * <span class="number">3.14</span></span><br><span class="line">        System.out.println(<span class="string">"The area of the circle of raius"</span> + radius + <span class="string">"is"</span> + area);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="1-1-标准输入与输出"><a href="#1-1-标准输入与输出" class="headerlink" title="1.1 标准输入与输出"></a>1.1 标准输入与输出</h3></li><li>标准输入<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">System.out <span class="comment">//标准输出流类OutputStrem的对象</span></span><br><span class="line">System.in <span class="comment">//标准输入流类InputStrem的对象</span></span><br></pre></td></tr></table></figure></li><li>Scanner类<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.Scanner</span><br><span class="line">Scanner input = <span class="keyword">new</span> Scanner(System.in)</span><br><span class="line"><span class="keyword">double</span> d = input.nextDouble();</span><br><span class="line"><span class="comment">// 方法有</span></span><br><span class="line">nextByte()</span><br><span class="line">nextShort()</span><br><span class="line">nextInt()</span><br><span class="line">nextLong()</span><br><span class="line">nextFloat()</span><br><span class="line">nextDouble()</span><br><span class="line">next()  <span class="comment">// 读入一个字符串</span></span><br></pre></td></tr></table></figure><h3 id="1-2-标识符、常量与变量"><a href="#1-2-标识符、常量与变量" class="headerlink" title="1.2 标识符、常量与变量"></a>1.2 标识符、常量与变量</h3></li><li>标识符命名规则<ul><li>标识符是由字母、数字、下划线(_)、美元符号($)组成的字符序列。</li><li>标识符必须以字母、下划线(_)、美元符号($)开头。不能以数字开头。标识符不能是保留字。</li><li>标识符不能为true、false或null等事实上的保留字（参见英文维基网）</li><li>标识符可以为任意长度，但编译通常只接受前128字符</li><li>例如：$2, area, radius, showMessageDialog是合法的标识符；2A, d+4是非法的标识符</li></ul></li><li>java保留字<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">abstract</span>       <span class="keyword">default</span> <span class="keyword">if</span>        <span class="keyword">package</span>       <span class="keyword">this</span>   </span><br><span class="line"><span class="keyword">assert</span>               <span class="keyword">do</span>              goto            <span class="keyword">private</span>         <span class="keyword">throw</span>   </span><br><span class="line"><span class="keyword">boolean</span>        <span class="keyword">double</span>          implements<span class="keyword">protected</span> <span class="keyword">throws</span>        </span><br><span class="line"><span class="function"><span class="keyword">break</span>         <span class="keyword">else</span>        <span class="keyword">import</span>        <span class="keyword">public</span>        <span class="title">transient</span><span class="params">(非序列化)</span></span></span><br><span class="line"><span class="function"><span class="keyword">byte</span>        <span class="keyword">enum</span><span class="keyword">instanceof</span>return        <span class="keyword">true</span></span></span><br><span class="line"><span class="function"><span class="keyword">case</span>        extends<span class="keyword">int</span>        <span class="keyword">short</span>        <span class="keyword">try</span></span></span><br><span class="line"><span class="function"><span class="keyword">catch</span>        <span class="keyword">false</span>        interface       <span class="keyword">static</span>        <span class="keyword">void</span></span></span><br><span class="line"><span class="function"><span class="keyword">char</span>        <span class="keyword">final</span>           <span class="keyword">long</span>            <span class="title">strictfp</span><span class="params">(严格浮点)</span>   <span class="keyword">volatile</span>          </span></span><br><span class="line"><span class="function">class                 <span class="keyword">finally</span><span class="title">native</span><span class="params">(本地方法)</span>     <span class="keyword">super</span>        <span class="keyword">while</span></span></span><br><span class="line"><span class="function"><span class="keyword">const</span>        <span class="keyword">float</span>        new     <span class="keyword">switch</span>        </span></span><br><span class="line"><span class="function"><span class="keyword">continue</span>        <span class="keyword">for</span>                     <span class="keyword">null</span>         <span class="keyword">synchronized</span></span></span><br></pre></td></tr></table></figure></li><li>java常量<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">final</span> datatype CONSTANT_NAME = value;</span><br><span class="line"><span class="comment">//注意常量的声明和初始化必须同时完成</span></span><br><span class="line"><span class="keyword">final</span> <span class="keyword">double</span> PI = <span class="number">3.14159</span>;</span><br><span class="line"><span class="comment">// 避免重复输入</span></span><br><span class="line"><span class="comment">// 便于程序修改</span></span><br><span class="line"><span class="comment">// 便于程序阅读</span></span><br></pre></td></tr></table></figure><h3 id="1-3-赋值语句与基本表达式"><a href="#1-3-赋值语句与基本表达式" class="headerlink" title="1.3 赋值语句与基本表达式"></a>1.3 赋值语句与基本表达式</h3></li><li><p>赋值语句</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 赋值语句右读</span></span><br><span class="line">i = j = k = <span class="number">1</span>;</span><br><span class="line"><span class="comment">//不要认为i, j, k的值不变，volatile类型的变量值可变</span></span><br><span class="line">k = <span class="number">1</span>;</span><br><span class="line">j = k;  </span><br><span class="line">i = j;</span><br><span class="line"></span><br><span class="line"><span class="comment">//语法</span></span><br><span class="line">datatype variable = expression;</span><br><span class="line"><span class="comment">//例如：</span></span><br><span class="line"><span class="keyword">int</span> x = <span class="number">1</span>;   <span class="comment">//某些变量在申明时必须同时初始化：final int m=0;</span></span><br><span class="line"><span class="keyword">int</span> x = <span class="number">1</span>, y = <span class="number">2</span>;</span><br><span class="line"><span class="comment">//局部变量在使用前必须赋值。</span></span><br><span class="line"><span class="keyword">int</span> x, y;     <span class="comment">//若是成员变量，x, y有默认值=0</span></span><br><span class="line">y = x + <span class="number">1</span>; <span class="comment">//局部变量无默认值则错error</span></span><br></pre></td></tr></table></figure><h3 id="1-4-java-数据类型"><a href="#1-4-java-数据类型" class="headerlink" title="1.4 java 数据类型"></a>1.4 java 数据类型</h3><div align=center><img src="https://img.vim-cn.com/bc/a351f0120d3312145a6fe46f6a96aa7a61273e.png"></div></li><li><p>数值数据类型</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">整数</span><br><span class="line"><span class="keyword">byte</span><span class="number">8</span>位带符号整数(-<span class="number">128</span> 到 <span class="number">127</span>)</span><br><span class="line"><span class="keyword">short</span><span class="number">16</span>位带符号整数(-<span class="number">32768</span> 到 <span class="number">32767</span>)</span><br><span class="line"><span class="keyword">int</span><span class="number">32</span>位带符号整数(-<span class="number">2147483648</span> 到 <span class="number">2147483647</span>)</span><br><span class="line"><span class="keyword">long</span><span class="number">64</span>位带符号整数(-<span class="number">9223372036854775808</span> 到<span class="number">9223372036854775807</span>)</span><br><span class="line"></span><br><span class="line">浮点数</span><br><span class="line"><span class="keyword">float</span><span class="number">32</span>位浮点数(负数  -<span class="number">3.4</span>×<span class="number">1038</span>到-<span class="number">1.4</span>×<span class="number">10</span>-<span class="number">45</span> </span><br><span class="line">                  正数  <span class="number">1.4</span>×<span class="number">10</span>-<span class="number">45</span>到<span class="number">3.4</span>×<span class="number">1038</span> )</span><br><span class="line"><span class="keyword">double</span><span class="number">64</span>位浮点数(负数  -<span class="number">1.8</span>×<span class="number">10308</span>到-<span class="number">4.9</span>×<span class="number">10</span>-<span class="number">324</span></span><br><span class="line">                 正数  <span class="number">4.9</span>×<span class="number">10</span>-<span class="number">324</span>到<span class="number">1.8</span>×<span class="number">10308</span>)</span><br><span class="line"></span><br><span class="line">加(+)、减(-)、乘(*)、除(/)、求余(%)：注意+，-的优先级较低</span><br><span class="line"><span class="keyword">int</span> a = <span class="number">34</span> + <span class="number">1</span>;<span class="comment">// 35</span></span><br><span class="line"><span class="keyword">double</span> b = <span class="number">34.0</span> – <span class="number">0.1</span>;<span class="comment">// 33.9</span></span><br><span class="line"><span class="keyword">long</span> c = <span class="number">300</span> * <span class="number">30</span>;            <span class="comment">// 9000</span></span><br><span class="line"><span class="keyword">double</span> d = <span class="number">1.0</span> / <span class="number">2.0</span>;<span class="comment">// 0.5: 此处为浮点除</span></span><br><span class="line"><span class="keyword">int</span> e = <span class="number">1</span> / <span class="number">2</span>;<span class="comment">// 0: 此处为整除</span></span><br><span class="line"><span class="keyword">byte</span> f = <span class="number">20</span> % <span class="number">3</span>;<span class="comment">// 2: 取余数</span></span><br><span class="line">整数相除的结果还是整数，省略小数部分。</span><br><span class="line"><span class="keyword">int</span> i = <span class="number">5</span> / <span class="number">2</span><span class="comment">// 2</span></span><br><span class="line"><span class="keyword">int</span> j = -<span class="number">5</span> / <span class="number">2</span> <span class="comment">// -2</span></span><br><span class="line"></span><br><span class="line">字面值是直接出现在程序中的常量值。</span><br><span class="line"><span class="keyword">int</span> i = <span class="number">34</span>;</span><br><span class="line"><span class="keyword">long</span> k = <span class="number">100000L</span>; </span><br><span class="line">整数字面值</span><br><span class="line">以<span class="number">0</span>开头表示八进制，如<span class="number">035</span>；以<span class="number">0</span>x或<span class="number">0</span>X开头表示十六进制，如<span class="number">0x1D</span>,<span class="number">0X1d</span>；以<span class="number">1</span>-<span class="number">9</span>开头表示十进制，如<span class="number">29</span></span><br><span class="line">后缀字母：以l或L结尾表示<span class="keyword">long</span>类型，如<span class="number">29L</span>；其它表示<span class="keyword">int</span>类型。</span><br><span class="line">浮点数字面值</span><br><span class="line">浮点数是包含小数点的十进制数，后跟可选的指数部分。如</span><br><span class="line"><span class="number">18</span>.  <span class="number">1.8e1</span> .<span class="number">18E2</span></span><br><span class="line">后缀字母：以d或D结尾或者无后缀表示<span class="keyword">double</span>类型；以f或F结尾表示<span class="keyword">float</span>类型</span><br></pre></td></tr></table></figure></li><li><p>操作运算符</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">常用简洁操作符, 结果均为右值。</span><br><span class="line">操作符举例等价于</span><br><span class="line">+=i += <span class="number">8</span>i = i + <span class="number">8</span></span><br><span class="line">-=f -= <span class="number">8.0</span>f = f - <span class="number">8.0</span></span><br><span class="line">*=i *= <span class="number">8</span>i = i * <span class="number">8</span></span><br><span class="line">/=i /= <span class="number">8</span>i = i / <span class="number">8</span></span><br><span class="line">%=i %= <span class="number">8</span>i = i % <span class="number">8</span></span><br><span class="line">递增和递减运算符：++, --。结果均为右值。</span><br><span class="line">前缀表示先加(减)<span class="number">1</span>后使用</span><br><span class="line">后缀表示先使用后加(减) <span class="number">1</span></span><br><span class="line">    <span class="keyword">int</span> i =<span class="number">10</span>;             <span class="comment">//i=++i + ++i; 结果为23</span></span><br><span class="line">    <span class="keyword">int</span> newNum= <span class="number">10</span> * i++; <span class="comment">//newNum = 100, i = 11</span></span><br><span class="line">    <span class="keyword">int</span> newNum= <span class="number">10</span> * ++i; <span class="comment">//newNum = 110, i = 11</span></span><br></pre></td></tr></table></figure></li><li><p>数值类型转换</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">如果二元操作符的两个操作数的数据类型不同，那么根据下面的规则对操作数进行转换：</span><br><span class="line">如果有一个操作数是<span class="keyword">double</span>类型，另一个操作数转换为<span class="keyword">double</span>类型。</span><br><span class="line">否则，如果有一个操作数是<span class="keyword">float</span>类型，另一个操作数转换为<span class="keyword">float</span>类型。</span><br><span class="line">否则，如果有一个操作数是<span class="keyword">long</span>类型，另一个操作数转换为<span class="keyword">long</span>类型。</span><br><span class="line">否则，两个操作数都转换为<span class="keyword">int</span>类型。</span><br><span class="line">数据转换总是向较大范围的数据类型转换，避免精度损失</span><br><span class="line"><span class="keyword">long</span> k = i * <span class="number">3</span> + <span class="number">4</span>; <span class="comment">//i变成int参与右边表达式计算，计算结果转long</span></span><br><span class="line"><span class="keyword">double</span> d = i * <span class="number">3.1</span> + k / <span class="number">2</span>; <span class="comment">//i转double， k/2转double</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">将值赋值给较大取值范围的变量时，自动进行类型转换。</span><br><span class="line"><span class="keyword">byte</span> → <span class="keyword">char</span>→ <span class="keyword">short</span> → <span class="keyword">int</span> → <span class="keyword">long</span> → <span class="keyword">float</span> → <span class="keyword">double</span> </span><br><span class="line">将值赋值给较小取值范围的变量时，必须使用强制类型转换(type casting)。语法：</span><br><span class="line">(datatype)variableName</span><br><span class="line">例如：</span><br><span class="line"><span class="keyword">float</span> f = (<span class="keyword">float</span>)<span class="number">10.1</span>;<span class="comment">// 10.1是double类型</span></span><br><span class="line"><span class="keyword">int</span> i = (<span class="keyword">int</span>)f;<span class="comment">// 10</span></span><br><span class="line"><span class="keyword">int</span> j = (<span class="keyword">int</span>)-f;<span class="comment">// -10</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">``</span><br><span class="line"></span><br><span class="line">- 字符数据类型</span><br><span class="line">```java</span><br><span class="line"><span class="keyword">char</span>表示<span class="number">16</span>位的单个Unicode字符。</span><br><span class="line"><span class="keyword">char</span>类型的字面值</span><br><span class="line">以两个单引号界定的单个Unicode字符。如:<span class="string">'男'</span>,<span class="string">'女'</span></span><br><span class="line">可以用\uxxxx形式表示， xxxx为十六进制。如:<span class="string">'\u7537'</span>, <span class="string">'\u5973'</span></span><br><span class="line">转义字符表示：\n   \t  \b  \r   \f   \\   \<span class="string">'   \"</span></span><br><span class="line"><span class="string">例如：</span></span><br><span class="line"><span class="string">char letter = '</span>A<span class="string">';</span></span><br><span class="line"><span class="string">char numChar = '</span><span class="number">4</span><span class="string">';</span></span><br><span class="line"><span class="string">如果想打印带””的信息 He said “Java is fun “</span></span><br><span class="line"><span class="string">      System.out.println(“He said \”Java is fun \””); </span></span><br><span class="line"><span class="string">String表示一个字符序列，注意字符串是String类实现的，是引用类型</span></span><br><span class="line"><span class="string">字符串的字面值是由双引号界定的零个或多个字符。</span></span><br><span class="line"><span class="string">"Welcom to java!"                 ""</span></span><br><span class="line"><span class="string">连接运算：+, +=</span></span><br><span class="line"><span class="string">加号用于连接两个字符串。如果其中一个不是字符串，则先将该操作数转换成字符串，再执行连接操作。</span></span><br><span class="line"><span class="string">String message = "Welcome " + "to " + "java";  // Welcome to Java</span></span><br><span class="line"><span class="string">String s = “Chapter” + 2;           // Chapter2：不能都是数值</span></span><br><span class="line"><span class="string">String s1 += "Supplement" + '</span>B<span class="string">';           // SupplementB  </span></span><br><span class="line"><span class="string">message += " and Java is fun";  // Welcome to Java and Java is fun</span></span><br><span class="line"><span class="string">int i = 1;</span></span><br><span class="line"><span class="string">int j = 2;</span></span><br><span class="line"><span class="string">System.out.println("i + j = "  + i + j);          // i+j=12</span></span><br><span class="line"><span class="string">System.out.println("i + j = "  + (i + j));          // i+j = 3</span></span><br></pre></td></tr></table></figure></li></ul>]]></content>
      
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux</title>
      <link href="/2019/11/01/Linux/linux/"/>
      <url>/2019/11/01/Linux/linux/</url>
      
        <content type="html"><![CDATA[<h2 id="1-linux-的基础系统命令"><a href="#1-linux-的基础系统命令" class="headerlink" title="1. linux 的基础系统命令"></a>1. linux 的基础系统命令</h2><hr><p>在linux中<strong>系统命令</strong>通常是如下的格式：<br><code>命令名称  【命令参数】 【命令对象】</code>  </p><ol><li>获取登录信息<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># w</span></span><br><span class="line"><span class="comment"># who </span></span><br><span class="line"><span class="comment"># who am i</span></span><br></pre></td></tr></table></figure></li><li>查看自己使用的shell<code>ps</code><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ps</span></span><br></pre></td></tr></table></figure></li><li>查看命令的说明<code>whatis</code><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># what is ps</span></span><br><span class="line"><span class="comment"># what is python</span></span><br></pre></td></tr></table></figure></li><li>查看命令的位置<code>which、whereis</code><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># where is ps</span></span><br><span class="line"><span class="comment"># where is python</span></span><br><span class="line"><span class="comment"># which ps</span></span><br><span class="line"><span class="comment"># which python</span></span><br></pre></td></tr></table></figure></li><li>查看帮助文档<code>man、help、apropos</code><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># man ps</span></span><br><span class="line"><span class="comment"># info ps</span></span><br></pre></td></tr></table></figure></li><li>切换用户<code>su</code><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># su hellokitty</span></span><br></pre></td></tr></table></figure></li><li>以管理员身份执行命令<code>sudo</code><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ls /root(fail)</span></span><br><span class="line"><span class="comment"># sudo ls /root(success)</span></span><br></pre></td></tr></table></figure></li><li>登入和登出相关<code>logout、exit、adduser、userdel、passwd、ssh</code><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># adduser hellokitty</span></span><br><span class="line"><span class="comment"># passwd hellokitty (change password)</span></span><br><span class="line"><span class="comment"># ssh@hellokitty@1.2.3.4</span></span><br><span class="line"><span class="comment"># logout</span></span><br></pre></td></tr></table></figure></li><li>查看系统和主机名<code>unname、hostname</code><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># unname</span></span><br><span class="line"><span class="comment"># hostname</span></span><br></pre></td></tr></table></figure></li><li>重启和关机<code>rebot、init 6、shutdown、init 0</code><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># rebot</span></span><br></pre></td></tr></table></figure></li><li>查看历史命令<code>history</code><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># history</span></span><br></pre></td></tr></table></figure></li></ol><hr><h2 id="2-linux常用的实用命令"><a href="#2-linux常用的实用命令" class="headerlink" title="2. linux常用的实用命令"></a>2. linux常用的实用命令</h2><ol><li>创建和删除目录<code>mkdir</code>、<code>rmdir</code><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># mkdir abc</span></span><br><span class="line"><span class="comment"># mkdir -p abc</span></span><br><span class="line"><span class="comment"># rmdir abc</span></span><br></pre></td></tr></table></figure></li><li>创建和删除文件<code>touch</code>、<code>rm</code><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># touch readme.md</span></span><br><span class="line"><span class="comment"># rm readme.md</span></span><br><span class="line"><span class="comment"># rm -rf xyz  </span></span><br><span class="line">```bash</span><br><span class="line">&gt; `touch`命令用于创建空白文件或者修改文件时间。在Linux系统中有三种文件时间：</span><br><span class="line">- 更改文件内容的时间：`mtime`</span><br><span class="line">- 更改权限的时间: `ctime`</span><br><span class="line">- 最后访问时间: `atime`</span><br><span class="line">&gt; rm有几个重要的参数如下：</span><br><span class="line">- `-i` :交互式删除，每个删除项都要询问</span><br><span class="line">- `-r` :删除目录并且递归删除目录及文件</span><br><span class="line">- `-f` :强制删除，忽略存在的文件，没有任何提示</span><br><span class="line"></span><br><span class="line">3. 切换和查看当前的工作目录`<span class="built_in">cd</span>`、`<span class="built_in">pwd</span>`</span><br><span class="line">4. 查看目录内容`ls`</span><br><span class="line">* `-l` :以长格式查看文件和目录</span><br><span class="line">* `-a` ：显示以点开头的文件和目录</span><br><span class="line">* `-R` ：遇到目录，递归展开</span><br><span class="line">* `-d` : 只列出目录，不列出内容</span><br><span class="line">* `-s  -t` : 按照大小和时间进行排序</span><br><span class="line">5. 查看文件内容`cat`、`head`、`tail`、`more`、`less`</span><br><span class="line">```bash</span><br><span class="line"><span class="comment"># cat readme.md</span></span><br><span class="line"><span class="comment"># head -10 sohu.html</span></span><br></pre></td></tr></table></figure></li><li>拷贝和移动文件<code>cp</code>、<code>mv</code><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cp sohu.html  backup/</span></span><br><span class="line"><span class="comment"># cd backup</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># mv sohu.html sohu_index.html</span></span><br></pre></td></tr></table></figure></li><li>查找文件和查找内容<code>find</code>、<code>grep</code></li></ol><ul><li>grep 在搜索字符串时可以直接使用正则表达式，如果需要使用正则表达式，则可以用<code>grep -E</code></li></ul><ol start="8"><li>链接<code>ln</code></li></ol><ul><li>链接可以分为硬链接和软链接，硬链接可以认为是一个指向文件数据的指针。我们平常删除数据时，并没有删除硬盘上的文件，我们删除的是一个指针。而软链接类似于windows里面的快捷方式。   </li></ul><ol start="9"><li>压缩\解压缩\归档\解归档<code>gzip</code>、<code>gunzip</code>、<code>xz</code>、<code>tar</code><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># gunzip redis-4.0.10.tar.gz</span></span><br><span class="line"><span class="comment"># tar -xvf redis-4.0.10.tar</span></span><br></pre></td></tr></table></figure></li><li>其它工具<code>sort</code>、<code>uniq</code>、<code>diff</code>、<code>tr</code>、<code>cut</code>、<code>paste</code>、<code>file</code>、<code>wc</code></li><li>管道和重定向  </li></ol><ul><li>管道的使用：<code>|</code> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># find ./ | wc -1   % 查找当前目录下的文件个数 </span></span><br><span class="line"><span class="comment"># ls | cat - n    % 列出当前路径下的文件加，给每一项加一个编号</span></span><br><span class="line"><span class="comment"># cat record.log | grep AAA | grep - v BBB | wc - 1 % 查找record.log 中的AAA，但不包含BBB的个数</span></span><br></pre></td></tr></table></figure></li><li>输出重定向和错误重定向：<code>- &gt; / &gt;&gt;  / 2 &gt;</code><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">[root@iZwz97tbgo9lkabnat2lo8Z ~]<span class="comment"># cat readme.txt</span></span><br><span class="line">banana</span><br><span class="line">apple</span><br><span class="line">grape</span><br><span class="line">apple</span><br><span class="line">grape</span><br><span class="line">watermelon</span><br><span class="line">pear</span><br><span class="line">pitaya</span><br><span class="line">[root@iZwz97tbgo9lkabnat2lo8Z ~]<span class="comment"># cat readme.txt | sort | uniq &gt; result.txt</span></span><br><span class="line">[root@iZwz97tbgo9lkabnat2lo8Z ~]<span class="comment"># cat result.txt</span></span><br><span class="line">apple</span><br><span class="line">banana</span><br><span class="line">grape</span><br><span class="line">pear</span><br><span class="line">pitaya</span><br><span class="line">watermelon</span><br></pre></td></tr></table></figure></li><li>输入重定向：<code>- &lt;</code><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[root@iZwz97tbgo9lkabnat2lo8Z ~]<span class="comment"># echo 'hello, world!' &gt; hello.txt</span></span><br><span class="line">[root@iZwz97tbgo9lkabnat2lo8Z ~]<span class="comment"># wall &lt; hello.txt</span></span><br><span class="line">[root@iZwz97tbgo9lkabnat2lo8Z ~]<span class="comment">#</span></span><br><span class="line">Broadcast message from root@iZwz97tbgo9lkabnat2lo8Z (Wed Jun 20 19:43:05 2018):</span><br><span class="line">hello, world!</span><br><span class="line">[root@iZwz97tbgo9lkabnat2lo8Z ~]<span class="comment"># echo 'I will show you some code.' &gt;&gt; hello.txt</span></span><br><span class="line">[root@iZwz97tbgo9lkabnat2lo8Z ~]<span class="comment"># wall &lt; hello.txt</span></span><br><span class="line">[root@iZwz97tbgo9lkabnat2lo8Z ~]<span class="comment">#</span></span><br><span class="line">Broadcast message from root@iZwz97tbgo9lkabnat2lo8Z (Wed Jun 20 19:43:55 2018):</span><br><span class="line">hello, world!</span><br><span class="line">I will show you some code.</span><br></pre></td></tr></table></figure></li></ul><ol start="12"><li>别名</li></ol><ul><li><em>alias</em><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@iZwz97tbgo9lkabnat2lo8Z ~]<span class="comment"># alias ll='ls -l'</span></span><br><span class="line">[root@iZwz97tbgo9lkabnat2lo8Z ~]<span class="comment"># alias frm='rm -rf'</span></span><br><span class="line">[root@iZwz97tbgo9lkabnat2lo8Z ~]<span class="comment"># ll</span></span><br><span class="line">...</span><br><span class="line">drwxr-xr-x  2 root       root   4096 Jun 20 12:52 abc</span><br><span class="line">...bash</span><br><span class="line">[root@iZwz97tbgo9lkabnat2lo8Z ~]<span class="comment"># frm abc</span></span><br></pre></td></tr></table></figure></li><li><em>unlias</em><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@iZwz97tbgo9lkabnat2lo8Z ~]<span class="comment"># unalias frm</span></span><br><span class="line">[root@iZwz97tbgo9lkabnat2lo8Z ~]<span class="comment"># frm sohu.html</span></span><br><span class="line">-bash: frm: <span class="built_in">command</span> not found</span><br></pre></td></tr></table></figure></li></ul><ol start="13"><li>其它程序</li></ol><ul><li>时间和日期 <code>date / cal</code><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">[root@iZwz97tbgo9lkabnat2lo8Z ~]<span class="comment"># date</span></span><br><span class="line">Wed Jun 20 12:53:19 CST 2018</span><br><span class="line">[root@iZwz97tbgo9lkabnat2lo8Z ~]<span class="comment"># cal</span></span><br><span class="line">      June 2018</span><br><span class="line">Su Mo Tu We Th Fr Sa</span><br><span class="line">                1  2</span><br><span class="line"> 3  4  5  6  7  8  9</span><br><span class="line">10 11 12 13 14 15 16</span><br><span class="line">17 18 19 20 21 22 23</span><br><span class="line">24 25 26 27 28 29 30</span><br><span class="line">[root@iZwz97tbgo9lkabnat2lo8Z ~]<span class="comment"># cal 5 2017</span></span><br><span class="line">      May 2017</span><br><span class="line">Su Mo Tu We Th Fr Sa</span><br><span class="line">    1  2  3  4  5  6</span><br><span class="line"> 7  8  9 10 11 12 13</span><br><span class="line">14 15 16 17 18 19 20</span><br><span class="line">21 22 23 24 25 26 27</span><br><span class="line">28 29 30 31</span><br></pre></td></tr></table></figure></li><li>录制操作脚本<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">script</span><br></pre></td></tr></table></figure></li><li>给用户发送消息<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mesg / write / wall / mail</span><br></pre></td></tr></table></figure><h2 id="3-文件系统"><a href="#3-文件系统" class="headerlink" title="3. 文件系统"></a>3. 文件系统</h2><h3 id="文件和路径"><a href="#文件和路径" class="headerlink" title="文件和路径"></a>文件和路径</h3></li></ul><ol><li>命名规则：文件名的最大长度与文件系统类型有关，一般情况下，文件名不应该超过255个字符，虽然绝大多数的字符都可以用于文件名，但是最好使用英文大小写字母、数字、下划线、点这样的符号。文件名中虽然可以使用空格，但应该尽可能避免使用空格，否则在输入文件名时需要用将文件名放在双引号中或者通过\对空格进行转义。</li><li>扩展名：在Linux系统下文件的扩展名是可选的，但是使用扩展名有助于对文件内容的理解。有些应用程序要通过扩展名来识别文件，但是更多的应用程序并不依赖文件的扩展名，就像file命令在识别文件时并不是依据扩展名来判定文件的类型</li><li>隐藏文件：以点开头的文件在Linux系统中是隐藏文件（不可见文件）。<h3 id="目录结构"><a href="#目录结构" class="headerlink" title="目录结构"></a>目录结构</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">1.  */bin* - 基本命令的二进制文件。</span><br><span class="line">2.  */boot* - 引导加载程序的静态文件。</span><br><span class="line">3.  */dev* - 设备文件。</span><br><span class="line">4.  */etc* - 配置文件。</span><br><span class="line">5.  */home* - 普通用户主目录的父目录。</span><br><span class="line">6.  */lib* - 共享库文件。</span><br><span class="line">7.  */lib64* - 共享64位库文件。</span><br><span class="line">8.  */lost+found* - 存放未链接文件。</span><br><span class="line">9.  */media* - 自动识别设备的挂载目录。</span><br><span class="line">10.  */mnt* - 临时挂载文件系统的挂载点。</span><br><span class="line">11.  */opt* - 可选插件软件包安装位置。</span><br><span class="line">12.  */proc* - 内核和进程信息。</span><br><span class="line">13.  */root* - 超级管理员用户主目录。</span><br><span class="line">14.  */run* - 存放系统运行时需要的东西。</span><br><span class="line">15.  */sbin* - 超级用户的二进制文件。</span><br><span class="line">16.  */sys* - 设备的伪文件系统。</span><br><span class="line">17.  */tmp* - 临时文件夹。</span><br><span class="line">18.  */usr* - 用户应用目录。</span><br><span class="line">19.  */var* - 变量数据目录。</span><br></pre></td></tr></table></figure><h3 id="访问权限"><a href="#访问权限" class="headerlink" title="访问权限"></a>访问权限</h3></li><li><em>chmod</em> 改变文件模式比特<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">[root@iZwz97tbgo9lkabnat2lo8Z ~]<span class="comment"># ls -l</span></span><br><span class="line">...</span><br><span class="line">-rw-r--r--  1 root       root 211878 Jun 19 16:06 sohu.html</span><br><span class="line">...</span><br><span class="line">[root@iZwz97tbgo9lkabnat2lo8Z ~]<span class="comment"># chmod g+w,o+w sohu.html</span></span><br><span class="line">[root@iZwz97tbgo9lkabnat2lo8Z ~]<span class="comment"># ls -l</span></span><br><span class="line">...</span><br><span class="line">-rw-rw-rw-  1 root       root 211878 Jun 19 16:06 sohu.html</span><br><span class="line">...</span><br><span class="line">[root@iZwz97tbgo9lkabnat2lo8Z ~]<span class="comment"># chmod 644 sohu.html</span></span><br><span class="line">[root@iZwz97tbgo9lkabnat2lo8Z ~]<span class="comment"># ls -l</span></span><br><span class="line">...</span><br><span class="line">-rw-r--r--  1 root       root 211878 Jun 19 16:06 sohu.html</span><br><span class="line">说明：通过上面的例子可以看出，用chmod改变文件模式比特有两种方式：一种是字符设定法，另一种是数字设定法。  </span><br><span class="line">除了chmod之外，可以通过<span class="built_in">umask</span>来设定哪些权限将在新文件的默认权限中被删除。</span><br><span class="line">...</span><br></pre></td></tr></table></figure></li><li><em>chown</em> - 改变文件所有者。<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@iZwz97tbgo9lkabnat2lo8Z ~]<span class="comment"># ls -l</span></span><br><span class="line">...</span><br><span class="line">-rw-r--r--  1 root root     54 Jun 20 10:06 readme.txt</span><br><span class="line">...</span><br><span class="line">[root@iZwz97tbgo9lkabnat2lo8Z ~]<span class="comment"># chown hellokitty readme.txt</span></span><br><span class="line">[root@iZwz97tbgo9lkabnat2lo8Z ~]<span class="comment"># ls -l</span></span><br><span class="line">...bash</span><br><span class="line">-rw-r--r--  1 hellokitty root     54 Jun 20 10:06 readme.txt</span><br></pre></td></tr></table></figure><h3 id="磁盘管理"><a href="#磁盘管理" class="headerlink" title="磁盘管理"></a>磁盘管理</h3></li><li>列出文件系统的磁盘使用状况: <em>df</em><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@iZwz97tbgo9lkabnat2lo8Z ~]<span class="comment"># df -h</span></span><br><span class="line">Filesystem      Size  Used Avail Use% Mounted on</span><br><span class="line">/dev/vda1        40G  5.0G   33G  14% /</span><br><span class="line">devtmpfs        486M     0  486M   0% /dev</span><br><span class="line">tmpfs           497M     0  497M   0% /dev/shm</span><br><span class="line">tmpfs           497M  356K  496M   1% /run</span><br><span class="line">tmpfs           497M     0  497M   0% /sys/fs/cgroup</span><br><span class="line">tmpfs           100M     0  100M   0% /run/user/0</span><br></pre></td></tr></table></figure></li><li>磁盘分区操作: <em>fdisk</em><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[root@iZwz97tbgo9lkabnat2lo8Z ~]<span class="comment"># fdisk -l</span></span><br><span class="line">Disk /dev/vda: 42.9 GB, 42949672960 bytes, 83886080 sectors</span><br><span class="line">Units = sectors of 1 * 512 = 512 bytes</span><br><span class="line">Sector size (logical/physical): 512 bytes / 512 bytes</span><br><span class="line">I/O size (minimum/optimal): 512 bytes / 512 bytes</span><br><span class="line">Disk label <span class="built_in">type</span>: dos</span><br><span class="line">Disk identifier: 0x000a42f4</span><br><span class="line">   Device Boot      Start         End      Blocks   Id  System</span><br><span class="line">/dev/vda1   *        2048    83884031    41940992   83  Linux</span><br><span class="line">Disk /dev/vdb: 21.5 GB, 21474836480 bytes, 41943040 sectors</span><br><span class="line">Units = sectors of 1 * 512 = 512 bytes</span><br><span class="line">Sector size (logical/physical): 512 bytes / 512 bytes</span><br><span class="line">I/O size (minimum/optimal): 512 bytes / 512 bytes</span><br></pre></td></tr></table></figure></li><li>格式化文件系统 <em>mkfs</em></li><li>文件系统检查 <em>fsck</em></li><li>挂载/卸载： <em>mount / umount</em></li></ol><h2 id="4-编辑器-vim"><a href="#4-编辑器-vim" class="headerlink" title="4 编辑器 vim"></a>4 编辑器 <strong>vim</strong></h2><ol><li><p>启动<code>vim</code>。可以通过<code>vi</code>或<code>vim</code>命令来启动<code>vim</code>，启动时可以指定文件名来打开一个文件，如果没有指定文件名，也可以在保存的时候指定文件名。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@iZwz97tbgo9lkabnat2lo8Z ~]<span class="comment"># vim guess.py</span></span><br></pre></td></tr></table></figure></li><li><p>命令模式、编辑模式和末行模式：启动<code>vim</code>进入的是命令模式（也称为<code>Normal</code>模式），在命令模式下输入英文字母i会进入编辑模式（<code>Insert</code>模式），屏幕下方出现– <code>INSERT</code> –提示；在编辑模式下按下<code>Esc</code>会回到命令模式，此时如果输入英文:会进入末行模式，在末行模式下输入<code>q!</code>可以在不保存当前工作的情况下强行退出<code>vim</code>；在命令模式下输入<code>v</code>会进入可视模式（<code>Visual</code>模式），可以用光标选择一个区域再完成对应的操作。</p></li><li><p>保存和退出<code>vim</code>：在命令模式下输入<code>:</code>进入末行模式，输入<code>wq</code>可以实现保存退出；如果想放弃编辑的内容输入<code>q!</code>强行退出，这一点刚才已经提到过了；在命令模式下也可以直接输入<code>ZZ</code>实现保存退出。如果只想保存文件不退出，那么可以在末行模式下输入<code>w</code>；可以在<code>w</code>后面输入空格再指定要保存的文件名。</p></li><li><p>光标操作：</p></li></ol><ul><li>在命令模式下可以通过<code>h、j、k、l</code>来控制光标向左、下、上、右的方向移动，可以在字母前输入数字来表示移动的距离，例如：<code>10h</code>表示向左移动<code>10</code>个字符。</li><li>在命令模式下可以通过<code>Ctrl+y</code>和<code>Ctrl+e</code>来实现向上、向下滚动一行文本的操作，可以通过<code>Ctrl+f</code>和<code>Ctrl+b</code>来实现向前和向后翻页的操作。</li><li>在命令模式下可以通过输入英文字母<code>G</code>将光标移到文件的末尾，可以通过<code>gg</code>将光标移到文件的开始，也可以通过在<code>G</code>前输入数字来将光标移动到指定的行。</li></ul><ol start="5"><li>文本操作</li></ol><ul><li>删除：在命令模式下可以用<code>dd</code>来删除整行；可以在dd前加数字来指定删除的行数；可以用<code>d$</code>来实现删除从光标处删到行尾的操作，也可以通过<code>d0</code>来实现从光标处删到行首的操作；如果想删除一个单词，可以使用<code>dw</code>；如果要删除全文，可以在输入<code>:%d</code>（其中:用来从命令模式进入末行模式）。</li><li>复制和粘贴：在命令模式下可以用<code>yy</code>来复制整行；可以在<code>yy</code>前加数字来指定复制的行数；可以通过<code>p</code>将复制的内容粘贴到光标所在的地方。</li><li>撤销和恢复：在命令模式下输入<code>u</code>可以撤销之前的操作；通过<code>Ctrl+r</code>可以恢复被撤销的操作。</li><li>对内容进行排序：在命令模式下输入<code>%!sort</code>。</li></ul><ol start="6"><li>查找和替换</li></ol><ul><li>查找操作需要输入/进入末行模式并提供正则表达式来匹配与之对应的内容，例如：<code>/doc.*\.</code>，输入n来向前搜索，也可以输入N来向后搜索。</li><li>替换操作需要输入:进入末行模式并指定搜索的范围、正则表达式以及替换后的内容和匹配选项，例如：<code>:1,$s/doc.*/hello/gice</code>，其中：<ul><li><code>g</code> - <code>global</code>：全局匹配。</li><li><code>i</code> - <code>ignore case</code>：忽略大小写匹配。</li><li><code>c</code> - <code>confirm</code>：替换时需要确认。</li><li><code>e</code> - <code>error</code>：忽略错误。</li></ul></li></ul><ol start="7"><li>参数设定在输入:进入末行模式后可以对vim进行设定。</li></ol><ul><li>设置<code>Tab</code>键的空格数：<code>set ts=4</code></li><li>置显示/不显示行号：<code>set nu / set nonu</code></li><li>设置启用/关闭高亮语法：<code>syntax on / syntax off</code></li><li>设置显示标尺（光标所在的行和列）： <code>set ruler</code></li><li>设置启用/关闭搜索结果高亮：<code>set hls / set nohls</code></li></ul><ul><li>说明：如果希望上面的这些设定在每次启动vim时都能生效，需要将这些设定写到用户主目录下的<code>.vimrc</code>文件中。</li></ul><ol start="8"><li>高级技巧</li></ol><ul><li>比较多个文件<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@iZwz97tbgo9lkabnat2lo8Z ~]<span class="comment"># vim -d foo.txt bar.txt</span></span><br></pre></td></tr></table></figure></li><li>打开多个文件<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@iZwz97tbgo9lkabnat2lo8Z ~]<span class="comment"># vim foo.txt bar.txt hello.txt</span></span><br></pre></td></tr></table></figure></li></ul><ul><li><p>启动<code>vim</code>后只有一个窗口显示的是<code>foo.txt</code>，可以在末行模式中输入ls查看到打开的三个文件，也可以在末行模式中输入<code>b &lt;num&gt;</code>来显示另一个文件，例如可以用<code>:b 2</code>将<code>bar.txt</code>显示出来，可以用<code>:b 3</code>将<code>hello.txt</code>显示出来。</p></li><li><p>拆分和切换窗口：<br>可以在末行模式中输入<code>sp</code>或<code>vs</code>来实现对窗口的水平或垂直拆分，这样我们就可以同时打开多个编辑窗口，通过按两次<code>Ctrl</code>+w就可以实现编辑窗口的切换，在一个窗口中执行退出操作只会关闭对应的窗口，其他的窗口继续保留。</p></li><li><p>映射快捷键：在<code>vim</code>下可以将一些常用操作映射为快捷键来提升工作效率。</p><ul><li><p>例子1：在命令模式下输入<code>F4</code>执行从第一行开始删除10000行代码的操作。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">:map &lt;F4&gt; gg10000dd。</span><br></pre></td></tr></table></figure></li><li><p>例子2：在编辑模式下输入__main直接补全为:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">:inoremap __main <span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br></pre></td></tr></table></figure></li></ul></li></ul><ul><li><p>说明：上面例子<code>2</code>的<code>inoremap</code>中的<code>i</code>表示映射的键在编辑模式使用，<code>nore</code>表示不要递归，这一点非常重要，否则如果键对应的内容中又出现键本身，就会引发递归（相当于进入了死循环）。如果希望映射的快捷键每次启动<code>vim</code>时都能生效，需要将映射写到用户主目录下的<code>.vimrc</code>文件中。</p></li><li><p>录制宏：</p><ul><li><p>在命令模式下输入<code>qa</code>开始录制宏（其中a是寄存器的名字，也可以是其他英文字母或<code>0-9</code>的数字）。</p></li><li><p>执行你的操作（光标操作、编辑操作等），这些操作都会被录制下来。</p></li><li><p>如果录制的操作已经完成了，按<code>q</code>结束录制。</p></li><li><p>通过<code>@a</code>（<code>a</code>是刚才使用的寄存器的名字）播放宏，如果要多次执行宏可以在前面加数字，例如<code>100@a</code>表示将宏播放<code>100</code>次。</p></li><li><p>可以试一试下面的例子来体验录制宏的操作，该例子来源于<code>Harttle Land</code>网站，该网站上提供了很多关于<code>vim</code>的使用技巧，有兴趣的可以去了解一下。 </p></li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>理论计算基础</title>
      <link href="/2019/10/20/%E9%87%8F%E5%AD%90%E8%AE%A1%E7%AE%97/%E7%90%86%E8%AE%BA%E5%82%AC%E5%8C%96%E8%AE%A1%E7%AE%97(%E4%B8%80)/"/>
      <url>/2019/10/20/%E9%87%8F%E5%AD%90%E8%AE%A1%E7%AE%97/%E7%90%86%E8%AE%BA%E5%82%AC%E5%8C%96%E8%AE%A1%E7%AE%97(%E4%B8%80)/</url>
      
        <content type="html"><![CDATA[<h1 id="（一）准备工作"><a href="#（一）准备工作" class="headerlink" title="（一）准备工作"></a>（一）准备工作</h1><h2 id="1-系统与软件部分"><a href="#1-系统与软件部分" class="headerlink" title="1 系统与软件部分"></a>1 系统与软件部分</h2><ul><li><code>Linux与windows</code>系统</li><li>编辑器：<code>windows</code>用<code>notepad++</code>编辑器，<code>linux</code>用<code>vim</code>编辑器</li><li>相关程序：</li></ul><ol><li><code>Materials studio</code> (用来建模)</li><li><code>Vesta</code>(用来进行可视化与文件转换)</li><li><code>VASP与CP2k</code>:用来做第一性原理计算的软件,CP2k是从头算分析动力学模拟，是表面催化计算的大杀器，资料少，学习困难</li><li><a href="http://www,psvasp.at" target="_blank" rel="noopener">p4vasp</a>:vasp计算结果的后处理程序</li><li><a href="http://www.ks.uiuc.edu/Research/vmd/" target="_blank" rel="noopener">VMD</a>:分子动力学的可视化程序，作图的玩着，自由度很高，使用复杂</li></ol><h2 id="2-理论知识部分"><a href="#2-理论知识部分" class="headerlink" title="2 理论知识部分"></a>2 理论知识部分</h2><h3 id="2-1-催化化学与量子化学"><a href="#2-1-催化化学与量子化学" class="headerlink" title="2.1 催化化学与量子化学"></a>2.1 催化化学与量子化学</h3><p>这里推荐两本书，<br><img src="https://ss0.baidu.com/73F1bjeh1BF3odCf/it/u=668807871,692209756&amp;fm=85&amp;s=C940E8110E375A88742D76C50300D0A0" alt="电催化，孙世刚院士著"><img src="https://ss0.baidu.com/73F1bjeh1BF3odCf/it/u=2760061665,532098802&amp;fm=85&amp;s=B22BF604505753CC0292E9CC030050BA" alt="量子化学"></p><h3 id="2-2-密度泛函理论"><a href="#2-2-密度泛函理论" class="headerlink" title="2.2 密度泛函理论"></a>2.2 密度泛函理论</h3><p>这里也推荐本书：<br><img src="https://img.vim-cn.com/1d/caf343d9bf941549911857e38766ae912b5f66.jpg" alt=""></p><h1 id="（二）催化模型构建"><a href="#（二）催化模型构建" class="headerlink" title="（二）催化模型构建"></a>（二）催化模型构建</h1><h2 id="3-晶体结构数据库的使用"><a href="#3-晶体结构数据库的使用" class="headerlink" title="3 晶体结构数据库的使用"></a>3 晶体结构数据库的使用</h2><h3 id="3-1-相关说明"><a href="#3-1-相关说明" class="headerlink" title="3.1 相关说明"></a>3.1 相关说明</h3><p>第一篇单原子催化文章：<em>Nat. Chem., 2011, 3,634-641</em><br>研究晶体结构的文献都会给出结构的详细参数：比如，<em>J. Am. Chem. Soc. 136, 20, 7221-7224</em><br>注意：不要用<code>MS</code>里<code>build–crystals–build crystals</code>对着文献输入参数。费了半天劲还容易搞错，在晶体数据库里可以直接找到cif结构文件。</p><h3 id="3-2-晶体结构与数据库"><a href="#3-2-晶体结构与数据库" class="headerlink" title="3.2 晶体结构与数据库"></a>3.2 晶体结构与数据库</h3><ul><li>问题：找晶体结构到底在找什么？<br>答：<code>CIF</code>文件，后缀名为<code>.cif</code>，内部含有结构信息</li><li>常用的晶体结构数据库：<ul><li><code>ICSD – the Inorganic Crystal Structure Database</code> 无机晶体数据库。<a href="http://www2.fiz-karlsruhe.de/icsd_home.html" target="_blank" rel="noopener">http://www2.fiz-karlsruhe.de/icsd_home.html</a></li><li><code>CCDC – The Cambridge Crystallographic Data Centre</code><a href="https://www.ccdc.cam.ac.uk/" target="_blank" rel="noopener">https://www.ccdc.cam.ac.uk/</a></li><li><code>Materials studio</code>自带晶体数据库</li><li><code>Materials Project</code>（强烈推荐）：<a href="https://materialsproject.org/" target="_blank" rel="noopener">https://materialsproject.org/</a><br>特色，不但有实验结构参数，还有理论计算数据，比如磁矩，形成能，密度，带隙，空间群，点群，晶系，能带结构，弹性张量， 压电张量等数据。截至2018年9月11日，收录83989种无机化合物， 52179个能带结构</li><li>AMCSD – American Mineralogist Crystal Structure Database：<a href="http://rruff.geo.arizona.edu/AMS/amcsd.php" target="_blank" rel="noopener">http://rruff.geo.arizona.edu/AMS/amcsd.php</a></li><li>google search （ex： Al2O3 filetype:cif ）<h3 id="3-3-CCDC实战训练（一）-从文章中找到晶体结构"><a href="#3-3-CCDC实战训练（一）-从文章中找到晶体结构" class="headerlink" title="3.3 CCDC实战训练（一）-从文章中找到晶体结构"></a>3.3 CCDC实战训练（一）-从文章中找到晶体结构</h3></li></ul></li><li>如何从文章找到晶体结构？<br>答： 直接到文章末尾去找<code>CCDC</code>编码，但有时晶体结构也会出现在文章中或者SI里面。</li><li>如何从晶体数据库中获得结构文件？<ul><li>登录数据库查找<code>CCDC</code>编码</li></ul><ul><li>下载<code>CIF</code>文件</li></ul></li></ul><h3 id="3-4-ISDC-实战训练（二）-得到各种AL2O3模型"><a href="#3-4-ISDC-实战训练（二）-得到各种AL2O3模型" class="headerlink" title="3.4 ISDC 实战训练（二）-得到各种AL2O3模型"></a>3.4 ISDC 实战训练（二）-得到各种AL2O3模型</h3><p><code>Materials studio</code> 只有一种<code>Al2O3</code> 模型，是<code>a</code>型的<code>trigonal</code>晶系，也称作<code>corundum</code>刚玉。如果想要得到不同晶型的<code>Al2O3</code>就要去晶体数据库上找。</p><ul><li>总结：科研中碰到一个晶体，应该怎么找对应的结构文件。</li><li>依次尝试下列方法：</li></ul><ol><li>在<code>materials project</code>中直接输入对应元素和原子个数。如果<br>搞不清该化合物的晶型，提前<code>Google</code>该晶体所属晶系，点<br>群和空间群。</li><li>在<code>ICSD chemistry</code>中输入对应元素和原子个数。（<code>ICSD</code>是<br>最全的无机晶体数据库，如果这都找不到结构，应该回头<br>看那里搞错了）</li><li>在文献中找结构，然后去ICSD搜索该文献。</li><li>直接<code>google</code>，例如， <code>black phosphorus CIF</code><br>想偷懒可以在<code>MS</code>里， <code>File-input-structures</code>里找结构， <code>MS</code>里只有非常少数的常见结构。</li></ol><h1 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h1><p>非常感谢研之成理和清华化学系刘锦程博士，微信搜索研之成理就可以<code>get</code>一个非常非常优质的公众号了！！</p>]]></content>
      
      
      <categories>
          
          <category> 量子计算 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 量子计算 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hexo + GithubPages 搭建个人博客与网站！</title>
      <link href="/2019/10/15/%E9%85%8D%E7%BD%AE/Hexo-GithubPages%20%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E7%BD%91%E7%AB%99/"/>
      <url>/2019/10/15/%E9%85%8D%E7%BD%AE/Hexo-GithubPages%20%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E7%BD%91%E7%AB%99/</url>
      
        <content type="html"><![CDATA[<h1 id="Hexo-GithubPages-搭建个人博客与网站！"><a href="#Hexo-GithubPages-搭建个人博客与网站！" class="headerlink" title="Hexo + GithubPages 搭建个人博客与网站！"></a>Hexo + GithubPages 搭建个人博客与网站！</h1><h2 id="博客搭建"><a href="#博客搭建" class="headerlink" title="博客搭建"></a>博客搭建</h2><h3 id="准备环境"><a href="#准备环境" class="headerlink" title="准备环境"></a>准备环境</h3><ol><li><p><a href="https://www.simon96.online/2018/11/10/hexo-env/" target="_blank" rel="noopener">node.js 下载</a>，并安装。</p></li><li><p><a href="https://www.simon96.online/2018/11/10/hexo-env/" target="_blank" rel="noopener">Git 下载</a>，并安装。</p></li><li><p>安装<code>Hexo</code>，在命令行（即<code>Git Bash</code>）运行以下命令:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ npm install -g hexo-cli</span><br></pre></td></tr></table></figure></li><li><p>初始化<code>hexo</code>,在命令行依次运行以下命令:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ hexo init folder</span><br><span class="line">$ <span class="built_in">cd</span> folder</span><br><span class="line">$ npm install hexo server</span><br></pre></td></tr></table></figure><blockquote><p>新建完成后，会在路径下产生下列文件和文件夹：  </p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">├── _config.yml  % 站点配置文件</span><br><span class="line">├── package.json</span><br><span class="line">├── scaffolds</span><br><span class="line">├── source</span><br><span class="line">|   ├── _drafts</span><br><span class="line">|   └── _posts  % 文章发布文件夹</span><br><span class="line"> themes  % 主题配置文件夹，可folk别人的模板</span><br></pre></td></tr></table></figure></li><li><p>启动服务，在命令行输入:  </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure></li><li><p>浏览器访问网址,至此，<code>hexo</code>博客已经搭建到本地了</p></li></ol><h3 id="Github实时搭建"><a href="#Github实时搭建" class="headerlink" title="Github实时搭建"></a><code>Github</code>实时搭建</h3><ol><li>在github官网创建账号</li><li>创建仓库：<code>&lt;账号名称&gt;github.io</code></li><li>将本地博客推送到<code>githubPages</code>。</li></ol><ul><li><p>安装<code>hexo-deplyer-git</code>插件。<code>bash</code>命令行运行。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ npm install hexo-deployer-git --save</span><br></pre></td></tr></table></figure></li><li><p>添加<code>github</code>的<code>SSH-KEY</code>,创建一个<code>SSH-KEY</code>,在命令行输入:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ssh-keygen -t rsa -C <span class="string">"邮箱地址"</span></span><br></pre></td></tr></table></figure></li></ul><blockquote><p><code>C:\Users\Administrator\.ssh\id_rsa.pub</code></p></blockquote><ul><li>修改<code>_config.yml</code>,文件末尾修改为:<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">deploy:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">git</span>   <span class="string">%</span> <span class="string">注意冒号后面有一个空格</span></span><br><span class="line">  <span class="attr">repo:</span> <span class="string">git@github.com:shyshy903/shyshy903.github.io</span></span><br><span class="line">  <span class="attr">branch:</span> <span class="string">master</span></span><br></pre></td></tr></table></figure></li><li>推送到<code>githubPages</code>中。<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ hexo g</span><br><span class="line">$ hexo d</span><br></pre></td></tr></table></figure><blockquote><p>之后在浏览器输入：<a href="http://shyshy903.github.io">http://shyshy903.github.io</a> 就可以访问个人博客了  </p></blockquote></li></ul><h3 id="添加域名，创建个人网站"><a href="#添加域名，创建个人网站" class="headerlink" title="添加域名，创建个人网站"></a>添加域名，创建个人网站</h3><ol><li>到万网或者阿里云买一个域名，进行<code>DNS</code>解析</li><li><code>DNS</code>解析：<br>类型选择为 <code>CNAME</code>;<br>机记录即域名前缀，填写为<code>www</code>;<br>录值填写为<code>&lt;Github账号名称&gt;.github.io</code>;<br>解析线路，<code>TTL</code> 默认即可</li><li>仓库设置  </li><li><ol><li>打开博客仓库设置：<code>https://github.com/&lt;Github账号名称&gt;/&lt;Github账号名称&gt;.github.io/settings</code>  </li></ol></li><li><ol start="2"><li>在<code>Custom domain</code>下，填写自定义域名，点击<code>save</code>； </li></ol></li><li><ol start="3"><li>在站点目录的<code>source</code>文件夹下，创建并打开<code>CNAME.txt</code>，写入你的域名（如<code>www.simon96.online</code>），保存，并重命名为<code>CNAME</code><blockquote><p>完成以上步骤，就可以通过域名<code>www.shyshy903.top</code>来访问个人网站和博客了。</p></blockquote></li></ol></li></ol><h3 id="安装必要的插件"><a href="#安装必要的插件" class="headerlink" title="安装必要的插件"></a>安装必要的插件</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm i -S hexo-generator-search hexo-generator-json-content hexo-renderer-less</span><br></pre></td></tr></table></figure><h3 id="站点配置-hexo根目录下config-yml文件"><a href="#站点配置-hexo根目录下config-yml文件" class="headerlink" title="站点配置-hexo根目录下config.yml文件"></a>站点配置-<code>hexo</code>根目录下<code>config.yml</code>文件</h3><ul><li>多语言支持<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">language:</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">zh-CN</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">en</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">zh-HK</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">zh-TW</span></span><br></pre></td></tr></table></figure></li><li>搜索框的配置<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo-generator-searchdb --save</span><br></pre></td></tr></table></figure>站点文件添加下面的代码块：<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">search:</span></span><br><span class="line">    <span class="attr">path:</span> <span class="string">search.xml</span></span><br><span class="line">    <span class="attr">field:</span> <span class="string">post</span></span><br><span class="line">    <span class="attr">format:</span> <span class="string">html</span></span><br><span class="line">    <span class="attr">limit:</span> <span class="number">10000</span></span><br></pre></td></tr></table></figure><h3 id="主题优化之自定样式-cdn的使用"><a href="#主题优化之自定样式-cdn的使用" class="headerlink" title="主题优化之自定样式 cdn的使用"></a>主题优化之自定样式 <code>cdn</code>的使用</h3><code>cdn + github</code>的博客可以参考别人的文章<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">############################### 基本信息 ###############################</span></span><br><span class="line"><span class="attr">info:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">Material</span> <span class="string">X</span></span><br><span class="line">  <span class="attr">docs:</span> <span class="string">https://xaoxuu.com/wiki/material-x/</span></span><br><span class="line">  <span class="attr">cdn:</span> <span class="comment"># 把对应的那一行注释掉就使用本地的文件</span></span><br><span class="line">    <span class="attr">css:</span></span><br><span class="line">      <span class="comment"># style: https://cdn.jsdelivr.net/gh/xaoxuu/cdn-material-x@19.9.9/css/style.css</span></span><br><span class="line">    <span class="attr">js:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">https://cdn.jsdelivr.net/gh/xaoxuu/cdn-material-x@19.9/js/app.js</span></span><br><span class="line">      <span class="attr">search:</span> <span class="string">https://cdn.jsdelivr.net/gh/xaoxuu/cdn-material-x@19.9/js/search.js</span></span><br><span class="line">      <span class="attr">volantis:</span> <span class="string">https://cdn.jsdelivr.net/gh/xaoxuu/volantis@1.0.5/js/volantis.min.js</span></span><br></pre></td></tr></table></figure><h3 id="主题优化之评论系统-valine的使用"><a href="#主题优化之评论系统-valine的使用" class="headerlink" title="主题优化之评论系统 valine的使用"></a>主题优化之评论系统 <code>valine</code>的使用</h3></li><li>站点配置<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">leancloud:</span></span><br><span class="line">  <span class="attr">app_id:</span> <span class="string">你的appId</span>   <span class="comment"># 从leancloud官网获得：https://www.avoscloud.com/dashboard/</span></span><br><span class="line">  <span class="attr">app_key:</span> <span class="string">你的appKey</span></span><br></pre></td></tr></table></figure></li><li>主题配置<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">valine:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">true</span> <span class="comment"># 如果你想用Valine评论系统，请设置enable为true</span></span><br><span class="line">  <span class="attr">volantis:</span> <span class="literal">true</span> <span class="comment"># 是否启用volantis版本（禁止匿名，增加若干贴吧、QQ表情）</span></span><br><span class="line">  <span class="comment"># 还需要在根目录配置文件中添加下面这三行内容</span></span><br><span class="line">  <span class="comment"># leancloud:</span></span><br><span class="line">  <span class="comment">#   app_id: 你的appId</span></span><br><span class="line">  <span class="comment">#   app_key: 你的appKey</span></span><br><span class="line">  <span class="attr">guest_info:</span> <span class="string">nick,mail,link</span> <span class="comment">#valine comment header info</span></span><br><span class="line">  <span class="attr">placeholder:</span> <span class="string">快来评论吧~</span> <span class="comment"># valine comment input placeholder(like: Please leave your footprints )</span></span><br><span class="line">  <span class="attr">avatar:</span> <span class="string">mp</span> <span class="comment"># gravatar style https://valine.js.org/avatar</span></span><br><span class="line">  <span class="attr">pageSize:</span> <span class="number">20</span> <span class="comment"># comment list page size</span></span><br><span class="line">  <span class="attr">verify:</span> <span class="literal">false</span> <span class="comment"># valine verify code (true/false)</span></span><br><span class="line">  <span class="attr">notify:</span> <span class="literal">false</span> <span class="comment"># valine mail notify (true/false)</span></span><br><span class="line">  <span class="attr">lang:</span> <span class="string">zh-cn</span></span><br><span class="line">  <span class="attr">highlight:</span> <span class="literal">false</span></span><br></pre></td></tr></table></figure><h3 id="主题优化之加入萌萌哒表情"><a href="#主题优化之加入萌萌哒表情" class="headerlink" title="主题优化之加入萌萌哒表情"></a>主题优化之加入萌萌哒表情</h3></li></ul><ol><li><p>这里需要安装一个插件哦:  </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ npm install hexo-helper-live2d --save</span><br></pre></td></tr></table></figure></li><li><p>复制你喜欢的名字，如<code>z16</code>。</p></li><li><p>在<code>hexo</code>文件夹中建立一个文件夹<code>live2d_models</code>。  </p></li><li><p>1 在<code>live2d_models</code>中建立文件夹<code>z16</code>。  </p></li><li><p>2 在文件夹啊<code>z16</code>中创建<code>json</code>文件：<code>z16.model.json</code>。</p></li><li><p>将以下代码添加到主题配置文件中去：  </p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">live2d:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">scriptFrom:</span> <span class="string">local</span></span><br><span class="line">  <span class="attr">pluginRootPath:</span> <span class="string">live2dw/</span></span><br><span class="line">  <span class="attr">pluginJsPath:</span> <span class="string">lib/</span></span><br><span class="line">  <span class="attr">pluginModelPath:</span> <span class="string">assets/</span></span><br><span class="line">  <span class="attr">tagMode:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">log:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">model:</span></span><br><span class="line">    <span class="attr">use:</span> <span class="string">live2d-widget-model-z16</span></span><br><span class="line">  <span class="attr">display:</span></span><br><span class="line">    <span class="attr">position:</span> <span class="string">right</span></span><br><span class="line">    <span class="attr">width:</span> <span class="number">150</span></span><br><span class="line">    <span class="attr">height:</span> <span class="number">300</span></span><br><span class="line">  <span class="attr">mobile:</span></span><br><span class="line">    <span class="attr">show:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure></li><li><p>安装模型:  </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ npm install liv2d_models-widget-z16 --save</span><br></pre></td></tr></table></figure></li><li><p>在命令行中运行命令，既可以在<code>&quot;http://localhost:4000&quot;</code>中预览自己的博客网页  </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo clean &amp;&amp; hexo g &amp;&amp; hexo s</span><br></pre></td></tr></table></figure></li><li><p>如果预览的博客符合自己的要求，就可以进行更新,大公告成啦：  </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo d -g</span><br></pre></td></tr></table></figure></li><li><p>如果需要调整插入模型的透明度，可以在第4步中的代码中插入：  </p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">display:</span></span><br><span class="line">    <span class="attr">position:</span> <span class="string">right</span></span><br><span class="line">    <span class="attr">width:</span> <span class="number">300</span></span><br><span class="line">    <span class="attr">height:</span> <span class="number">600</span></span><br><span class="line">    <span class="attr">opacity:</span> <span class="number">0.4</span></span><br><span class="line">  <span class="attr">mobile:</span></span><br><span class="line">    <span class="attr">show:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">react:</span></span><br><span class="line">    <span class="attr">opacity:</span> <span class="number">0.4</span></span><br><span class="line">    <span class="attr">opacityOnHover:</span> <span class="number">0.7</span></span><br></pre></td></tr></table></figure></li></ol>]]></content>
      
      
      <categories>
          
          <category> hexo </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hexo </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2019/10/15/hello-world/"/>
      <url>/2019/10/15/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
